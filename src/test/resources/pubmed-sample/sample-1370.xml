
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">Int J Mol Sci</journal-id><journal-id journal-id-type="iso-abbrev">Int J Mol Sci</journal-id><journal-id journal-id-type="publisher-id">ijms</journal-id><journal-title-group><journal-title>International Journal of Molecular Sciences</journal-title></journal-title-group><issn pub-type="epub">1422-0067</issn><publisher><publisher-name>Molecular Diversity Preservation International (MDPI)</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">24217226</article-id><article-id pub-id-type="pmc">3856056</article-id><article-id pub-id-type="doi">10.3390/ijms141122132</article-id><article-id pub-id-type="publisher-id">ijms-14-22132</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>AlPOs Synthetic Factor Analysis Based on Maximum Weight and Minimum Redundancy Feature Selection</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Guo</surname><given-names>Yuting</given-names></name><xref ref-type="aff" rid="af1-ijms-14-22132">1</xref><xref ref-type="aff" rid="af2-ijms-14-22132">2</xref><xref ref-type="aff" rid="af3-ijms-14-22132">3</xref></contrib><contrib contrib-type="author"><name><surname>Wang</surname><given-names>Jianzhong</given-names></name><xref ref-type="aff" rid="af1-ijms-14-22132">1</xref><xref ref-type="aff" rid="af3-ijms-14-22132">3</xref><xref rid="c1-ijms-14-22132" ref-type="corresp">*</xref></contrib><contrib contrib-type="author"><name><surname>Gao</surname><given-names>Na</given-names></name><xref ref-type="aff" rid="af4-ijms-14-22132">4</xref></contrib><contrib contrib-type="author"><name><surname>Qi</surname><given-names>Miao</given-names></name><xref ref-type="aff" rid="af3-ijms-14-22132">3</xref></contrib><contrib contrib-type="author"><name><surname>Zhang</surname><given-names>Ming</given-names></name><xref ref-type="aff" rid="af1-ijms-14-22132">1</xref><xref ref-type="aff" rid="af3-ijms-14-22132">3</xref><xref rid="c1-ijms-14-22132" ref-type="corresp">*</xref></contrib><contrib contrib-type="author"><name><surname>Kong</surname><given-names>Jun</given-names></name><xref ref-type="aff" rid="af1-ijms-14-22132">1</xref><xref ref-type="aff" rid="af3-ijms-14-22132">3</xref></contrib><contrib contrib-type="author"><name><surname>Lv</surname><given-names>Yinghua</given-names></name><xref ref-type="aff" rid="af2-ijms-14-22132">2</xref><xref rid="c1-ijms-14-22132" ref-type="corresp">*</xref></contrib></contrib-group><aff id="af1-ijms-14-22132"><label>1</label>College of Computer Science and Information Technology, Northeast Normal University, Changchun 130117, Jilin, China; E-Mails: <email>guoyt484@nenu.edu.cn</email> (Y.G.); <email>kongjun@nenu.edu.cn</email> (J.K.)</aff><aff id="af2-ijms-14-22132"><label>2</label>Faculty of Chemistry, Northeast Normal University, Changchun 130024, Jilin, China</aff><aff id="af3-ijms-14-22132"><label>3</label>Key Laboratory of Intelligent Information Processing of Jilin Universities, Northeast Normal University, Changchun 130117, Jilin, China; E-Mail: <email>qim801@nenu.edu.cn</email></aff><aff id="af4-ijms-14-22132"><label>4</label>State Key Laboratory of Inorganic Synthesis and Preparative Chemistry, Changchun 130012, Jilin, China; E-Mail: <email>gaona0431@163.com</email></aff><author-notes><corresp id="c1-ijms-14-22132"><label>*</label>Authors to whom correspondence should be addressed; E-Mails: <email>wangjz019@nenu.edu.cn</email> (J.W.); <email>zhangm545@nenu.edu.cn</email> (M.Z.); <email>luyh@nenu.edu.cn</email> (Y.L.); Tel./Fax: +86-431-8453-6326 (J.W.).</corresp></author-notes><pub-date pub-type="collection"><month>11</month><year>2013</year></pub-date><pub-date pub-type="epub"><day>08</day><month>11</month><year>2013</year></pub-date><volume>14</volume><issue>11</issue><fpage>22132</fpage><lpage>22148</lpage><history><date date-type="received"><day>25</day><month>9</month><year>2013</year></date><date date-type="rev-recd"><day>23</day><month>10</month><year>2013</year></date><date date-type="accepted"><day>23</day><month>10</month><year>2013</year></date></history><permissions><copyright-statement>&#x000a9; 2013 by the authors; licensee MDPI, Basel, Switzerland</copyright-statement><copyright-year>2013</copyright-year><license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/3.0/"><license-p>This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution license (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/3.0/">http://creativecommons.org/licenses/by/3.0/</ext-link>).</license-p></license></permissions><abstract><p>The relationship between synthetic factors and the resulting structures is critical for rational synthesis of zeolites and related microporous materials. In this paper, we develop a new feature selection method for synthetic factor analysis of (6,12)-ring-containing microporous aluminophosphates (AlPOs). The proposed method is based on a maximum weight and minimum redundancy criterion. With the proposed method, we can select the feature subset in which the features are most relevant to the synthetic structure while the redundancy among these selected features is minimal. Based on the database of AlPO synthesis, we use (6,12)-ring-containing AlPOs as the target class and incorporate 21 synthetic factors including gel composition, solvent and organic template to predict the formation of (6,12)-ring-containing microporous aluminophosphates (AlPOs). From these 21 features, 12 selected features are deemed as the optimized features to distinguish (6,12)-ring-containing AlPOs from other AlPOs without such rings. The prediction model achieves a classification accuracy rate of 91.12% using the optimal feature subset. Comprehensive experiments demonstrate the effectiveness of the proposed algorithm, and deep analysis is given for the synthetic factors selected by the proposed method.</p></abstract><kwd-group><kwd>AlPOs</kwd><kwd>data mining</kwd><kwd>feature selection</kwd><kwd>rational synthesis</kwd></kwd-group></article-meta></front><body><sec><label>1.</label><title>Introduction</title><p>As an important class of crystalline materials, zeolites and related microporous materials have been widely used in the petroleum industry for catalysis, separation and ion-exchange [<xref rid="b1-ijms-14-22132" ref-type="bibr">1</xref>,<xref rid="b2-ijms-14-22132" ref-type="bibr">2</xref>]. Following the discovery of the aluminophosphate molecular sieves AlPO<sub>4</sub>-<italic>n</italic> (<italic>n</italic> denotes the structure type) in 1982, a large variety of open-framework aluminophosphates with different structure types have been synthesized and open-framework aluminophosphate materials has become an important member of the porous crystal material family. Recently, the rational synthesis of microporous inorganic materials has attracted extensive attention [<xref rid="b3-ijms-14-22132" ref-type="bibr">3</xref>&#x02013;<xref rid="b10-ijms-14-22132" ref-type="bibr">10</xref>]. However, since the synthesis of such materials is typically carried out in a gel medium under hydrothermal/solvothermal conditions by using alkali metal ions or organic amines/ammoniums as the templates or structure-directing agents (SDAs) [<xref rid="b11-ijms-14-22132" ref-type="bibr">11</xref>], it is very complicated and influenced by many factors. Therefore, in order to provide guidance to rational synthesis of microporous inorganic materials, the researchers of State Key Laboratory of Inorganic Synthesis and Preparative Chemistry of Jilin University established an international ALPO synthesis database [<xref rid="b12-ijms-14-22132" ref-type="bibr">12</xref>] based on a large number of synthesis experiments and collections from the papers.</p><p>With the rapid development of computer technology and artificial intelligence, data mining plays an increasingly important role in more and more research areas. The goal of data mining is to find the implied knowledge from the given data. The applications of data mining techniques in chemical science have shown their feasibility for numeric calculation, simulation and data analysis. Nowadays, one of the most widely used data mining techniques in chemical science is feature selection. Feature selection is usually used as a preprocessing step in machine learning that can select the most important features for particular tasks by seeking the potential information hidden in the data. Recently, several feature selection methods were successfully applied in chemical data analysis. Pichler [<xref rid="b13-ijms-14-22132" ref-type="bibr">13</xref>] developed an interactive feature selection method based on KNN (K Nearest Neighbor) to classify doublet/singlet patterns from the same Stationary Electrode Polarography (SEP) data. Liu evaluated the performance of the methods as Information Gain, Mutual Information, &#x003c7;<sup>2</sup>-Test (CHI), Odds Ratio (OR) and GSS Coefficient (GSS) for finding the optimal feature subset in drug discovery; the features were firstly ranked according to the scores obtained by different feature selection methods and then the top-ranking features were used for classification task [<xref rid="b14-ijms-14-22132" ref-type="bibr">14</xref>]. Teramoto and Fukunishi proposed a supervised consensus scoring (SCS) method for docking and virtual. In SCS, a series of scoring functions including PLP, <italic>F</italic>-Score, LigScore, DrugScore, LUDI, <italic>X</italic>-Score, AutoDock, PMF, <italic>G</italic>-Score, ChemScore and <italic>D</italic>-Score were integrated to form a complementary scoring function, which could compensate for the deficiencies of each scoring method [<xref rid="b15-ijms-14-22132" ref-type="bibr">15</xref>]. In addition, a Mutual Information Gain algorithm was utilized to generate a feature subset which excluded features having weak correlation with the target variable, and then the selected features were input into a Genetic Programming model to analyze QSAR (Quantitative Structure Activity Relationship) data [<xref rid="b16-ijms-14-22132" ref-type="bibr">16</xref>]. In a further study, 649 bitter and 13,530 randomly selected molecules from the MDL Drug Data Repository (MDDR) were analyzed by Information Gain, and the selected features were then classified by Naive Bayes classifier to identify the bitterness of small molecules [<xref rid="b17-ijms-14-22132" ref-type="bibr">17</xref>]. Feature selection methods also have been applied to AlPOs database analysis. Li <italic>et al</italic>. evaluated the classification performance produced by different combinations of synthetic features (11 features in total) using Support Vector Machines (SVM), and then checked which individual or combined features effected most for distinguishing the two classes of AlPOs. They found that suitable template parameters were of vital importance to the classification performance [<xref rid="b18-ijms-14-22132" ref-type="bibr">18</xref>]. Huo <italic>et al</italic>. [<xref rid="b19-ijms-14-22132" ref-type="bibr">19</xref>], measured the importance of the various synthetic features (26 features in total) of AlPOs by <italic>F</italic>-Score [<xref rid="b20-ijms-14-22132" ref-type="bibr">20</xref>], and sorted the features in descending order according to their importance degree. The features were then added into Decision Tree (DT) model orderly to test their discriminative abilities. They regarded the feature subset that could reach the best classification performance as the optimal subset. Through their experiments, they found that T1_Distance2 (the second longest distance of organic template) was the determinant factor to distinguish AlPO<sub>4</sub>-5 from other types of aluminophosphate molecular sieves. Although the pioneering works in [<xref rid="b18-ijms-14-22132" ref-type="bibr">18</xref>] and [<xref rid="b19-ijms-14-22132" ref-type="bibr">19</xref>] have shown that the feature selection techniques can be applied for AlPOs database analysis effectively, there were also some limitations in them. Firstly, the feature subset evaluated in [<xref rid="b18-ijms-14-22132" ref-type="bibr">18</xref>] was generated using an exhaustive searching strategy, which made it hard to be scaled to high-dimensional AlPOs data. Secondly, the optimal feature subsets in both [<xref rid="b18-ijms-14-22132" ref-type="bibr">18</xref>] and [<xref rid="b19-ijms-14-22132" ref-type="bibr">19</xref>] were evaluated by a specific classifier (DT in [<xref rid="b19-ijms-14-22132" ref-type="bibr">19</xref>] and SVM in [<xref rid="b18-ijms-14-22132" ref-type="bibr">18</xref>]). Thus, the classifiers need to be trained and tested many times in the feature selection procedure, which made them very time-consuming. Finally, the correlation among the selected features was neglected in both [<xref rid="b18-ijms-14-22132" ref-type="bibr">18</xref>] and [<xref rid="b19-ijms-14-22132" ref-type="bibr">19</xref>]. Some researchers [<xref rid="b21-ijms-14-22132" ref-type="bibr">21</xref>] have pointed out that a good feature subset should be the one that contains features highly correlated with the class, while uncorrelated with each other. Therefore, ignoring the correlation among the selected features might cause the problem of &#x0201c;information redundancy&#x0201d;, which hinders optimal results from the selected features.</p><p>In order to overcome the limitations of the previous works, a new feature selection algorithm based on maximum weight and minimum correlation criterion is proposed in this paper. The proposed method not only considers the importance of the feature, but also takes the correlation among the selected features into account. Thus, through the proposed method, we can select the optimal feature subset in which the features are maximally relevant to the synthetic structure while the redundancy among these selected features is minimal. In the experiments, three feature evaluation algorithms (Fisher score, ReliefF score and Gini score) are combined with redundancy measurement method (Pearson correlation coefficient) to test the performance of our method. Compared with other feature selection methods [<xref rid="b18-ijms-14-22132" ref-type="bibr">18</xref>,<xref rid="b19-ijms-14-22132" ref-type="bibr">19</xref>] for AlPOs database analysis, our method possesses the following advantages. (1) The optimal feature subset generated by our method does not depend on any classifier. Thus, the feature selection procedure does not need to train any classifier, which makes our algorithm more efficient; (2) The feature selection procedure of our algorithm is a pair-wise updating optimization process, so it can be easily scaled to high-dimensional AlPOs data; (3) The proposed method takes the correlation among features into consideration. Thus, it can obtain better results than other state of the art feature selection methods.</p></sec><sec><label>2.</label><title>Results and Discussions</title><p>In this section, we first compare the performance of the proposed algorithm with other classical scoring feature selection methods that neglect the correlation among features during the feature selection process. Then, the feature selection results obtained by the proposed algorithm are analyzed and compared with the previous works [<xref rid="b18-ijms-14-22132" ref-type="bibr">18</xref>,<xref rid="b19-ijms-14-22132" ref-type="bibr">19</xref>]. At last, we also compare the proposed algorithm with several state of the art feature selection approaches, such as Constraint score [<xref rid="b22-ijms-14-22132" ref-type="bibr">22</xref>], MRMR [<xref rid="b23-ijms-14-22132" ref-type="bibr">23</xref>,<xref rid="b24-ijms-14-22132" ref-type="bibr">24</xref>] and FCBF [<xref rid="b25-ijms-14-22132" ref-type="bibr">25</xref>].</p><p>In the experiments, the Nearest Neighbor and Naive Bayes classifiers are employed as prediction models for their advantage of simplicity. In order to validate the effectiveness of the algorithm comprehensively, we use 10-fold cross validation in the experiments.</p><sec><label>2.1.</label><title>Performance Measures</title><p>The synthetic records used in the experiments contain 398 (6,12)-ring-containing AlPOs and 852 AlPOs without such rings. For the purpose of distinguishing the (6,12)-ring-containing AlPOs from others, we deem the former as positive samples and the latter as negative samples respectively. It is obvious that the numbers of positive and negative samples are imbalanced in this study. So besides the classification accuracy rate, we also utilize the <italic>F</italic>-measure to evaluate the performances of the proposed algorithm.</p><p>Suppose <italic>n</italic><italic><sub>+</sub></italic> and <italic>n</italic><italic><sub>&#x02212;</sub></italic> are the numbers of positive samples and negative samples. With reference to the confusion matrix [<xref rid="b26-ijms-14-22132" ref-type="bibr">26</xref>] in <xref rid="t1-ijms-14-22132" ref-type="table">Table 1</xref>, the classification accuracy rate (Acc_Rate) and <italic>F</italic>-measure can be denoted as:</p><disp-formula id="fd1-ijms-14-22132"><label>(1)</label><mml:math id="m1"><mml:mrow><mml:mtext>classification&#x02009;accuracy&#x02009;rate</mml:mtext><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mo>+</mml:mo></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mo>-</mml:mo></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula><p>and</p><disp-formula id="fd2-ijms-14-22132"><label>(2)</label><mml:math id="m2"><mml:mrow><mml:mi>F</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mtext>measure</mml:mtext></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>&#x003b2;</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mtext>recall</mml:mtext><mml:mo>&#x000d7;</mml:mo><mml:mtext>precision</mml:mtext></mml:mrow><mml:mrow><mml:mi>&#x003b2;</mml:mi><mml:mo>&#x000d7;</mml:mo><mml:mtext>recall</mml:mtext><mml:mo>+</mml:mo><mml:mtext>precision</mml:mtext></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula><p>where recall = <italic><sup>TP</sup></italic>/<italic><sub>TP</sub></italic><sub>+</sub><italic><sub>FN</sub></italic>, precision = <italic><sup>TP</sup></italic>/<italic><sub>TP</sub></italic><sub>+</sub><italic><sub>FP</sub></italic>, and &#x003b2; is a parameter to adjust the relative importance degree between recall and precision. In this work, we set &#x003b2; as 1. The value of <italic>F</italic>-measure lies between 0 and 1, with value closer to 1 indicating better performance for imbalanced problems.</p></sec><sec><label>2.2.</label><title>Effectiveness of the Proposed Method</title><p>We will firstly verify the effectiveness of the proposed method by comparing it with some classical scoring feature selection methods without considering the correlation among features. In this experiment, Fisher score [<xref rid="b27-ijms-14-22132" ref-type="bibr">27</xref>], ReliefF score [<xref rid="b28-ijms-14-22132" ref-type="bibr">28</xref>] and Gini score [<xref rid="b29-ijms-14-22132" ref-type="bibr">29</xref>] are applied to measure the importance of the feature, while Pearson Correlation Coefficient (PCC) is applied to measure the correlation among features. The classification accuracy rate of different methods under various feature dimensions can be seen in <xref rid="f1-ijms-14-22132" ref-type="fig">Figure 1</xref>. In this figure, FI (Fisher improve) denotes the proposed method that utilizes the Fisher score and Pearson Correlation Coefficient to estimate the importance and correlation of features. RI (ReliefF improve) denotes the proposed method that utilizes the ReliefF score and Pearson Correlation Coefficient to estimate the importance and correlation of features. And GI (Gini improve) denotes the proposed method that utilizes the Gini score and Pearson Correlation Coefficient to estimate the importance and correlation of features. <italic>F</italic>, <italic>R</italic> and <italic>G</italic> denote original Fisher score, ReliefF score and Gini score respectively. The best classification accuracy rates obtained by these methods are listed in <xref rid="t2-ijms-14-22132" ref-type="table">Table 2</xref>.</p><p>From <xref rid="f1-ijms-14-22132" ref-type="fig">Figure 1</xref> and <xref rid="t2-ijms-14-22132" ref-type="table">Table 2</xref>, it can be seen that through taking the correlation among the selected features into consideration, the proposed algorithm can outperform the classical scoring feature selection methods. When the Nearest Neighbor classifier is utilized, the best classification accuracy rates obtained by FI, RI and GI are 91.12%, 90.96% and 90.96% respectively. When the Naive Bayes classifier is employed, the best classification accuracy rates obtained by FI, RI and GI are 87.67%, 86.08% and 86.48%. Moreover, it also should be noted that the dimensions of the optimal feature subset obtained by the proposed algorithm are less than the classical scoring feature selection algorithms in most cases.</p><p>In this paper, the numbers of the positive samples and negative samples are imbalanced, so we take the <italic>F</italic>-measure to evaluate the performance of proposed method. As shown in <xref rid="t3-ijms-14-22132" ref-type="table">Table 3</xref>, the proposed algorithm is superior to the classical scoring feature selection methods for the class imbalance problem especially when the Fisher score is utilized to evaluate the importance of feature.</p><p>From above experimental results, we can find that the performance of Fisher score combined with PCC in the proposed algorithm is superior to ReliefF score and Gini score combined with PCC, since the optimal feature subset generated by FI is in a lower dimension and wins the highest classification accuracy rate as well. So in the next experiment, we will focus on analyzing the features selected by FI.</p></sec><sec><label>2.3.</label><title>Analysis of the Feature Selection Results</title><p>In this part, we make some analysis about the feature selection result obtained by the proposed method (Fisher score combined with PCC) and compare our feature selection result with the previous works [<xref rid="b18-ijms-14-22132" ref-type="bibr">18</xref>,<xref rid="b19-ijms-14-22132" ref-type="bibr">19</xref>].</p><p>Here, let&#x02019;s reconsider the performances of the proposed method (FI-NN) and the original Fisher score (F-NN) in <xref rid="f1-ijms-14-22132" ref-type="fig">Figure 1a</xref>. Firstly, we can find that the classification performances of the proposed method are superior to the original Fisher score under most dimensions. This means that by reducing the redundancy from selected features, the proposed method can select more optimal feature subsets for distinguishing the (6,12)-ring-containing AlPOs. Secondly, it can be observed that when the dimension of the selected features increases from 1 to 12, the classification performance of the FI shows a dramatic upward trend, and reaches its peak point at dimension 12. However when the dimensions of the selected features are larger than 12, the classification performance presents a tiny downward trend. This suggests that the features selected in the previous 12 dimensions may take significant information for separating the (6,12)-ring-containing AlPOs from others. Thirdly, classification accuracy rate sharply increases from about 75.5% to 86.2% when F12 (the second longest distance of organic template) is added to the optimal feature subset at dimension 3. This phenomenon indicates that the second longest distance of organic template is a very crucial factor for the rational synthesis of (6,12)-ring-containing AlPOs.</p><p><xref rid="f2-ijms-14-22132" ref-type="fig">Figure 2</xref> shows the feature selection results obtained by Fisher score and the proposed method (FI). In this figure, in order to distinguish different types of features more clearly, we assign different colors to different categories of features (as shown in <xref rid="f2-ijms-14-22132" ref-type="fig">Figure 2a</xref>). The features marked with green color belong to gel composition, the features marked with blue color and purple color belong to solvent and organic template. <xref rid="f2-ijms-14-22132" ref-type="fig">Figure 2b,c</xref> illustrate feature subsets selected by the original Fisher score and the proposed algorithm (FI). In <xref rid="f2-ijms-14-22132" ref-type="fig">Figure 2b</xref>, the features are sorted in descending order according to their Fisher scores. Since the features with higher Fisher scores are more important, if we want to obtain a feature subset that contains <italic>k</italic> features, we just need to select the first <italic>k</italic> features in the descending sequence mentioned above. <xref rid="f2-ijms-14-22132" ref-type="fig">Figure 2c</xref> demonstrates the features selected by the proposed algorithm (FI) under every dimension (the selected features are sorted in ascending order according to their ID). The features selected by FI under dimension 12 which could lead to the highest classification accuracy rate are F1 (the molar amount of Al<sub>2</sub>O<sub>3</sub>), F3 (the molar amount of solvent), F4 (the molar amount of template in the gel composition), F6 (the melting point), F9 (the dipole moment), F12 (the second longest distance of organic template), F15 (the dipole moment), F16 (the ratio of <italic>C/N</italic>), F17 (the ratio of <italic>N</italic>/(<italic>C</italic> + <italic>N</italic>)), F18 (the ratio of <italic>N</italic>/Van der Waals volume) and F21 (the maximal number of protonated H atoms).</p><p>There is a remarkable phenomenon in <xref rid="f2-ijms-14-22132" ref-type="fig">Figure 2b</xref> that the first 8 features selected by Fisher score are all marked with purple color, which means they all belong to organic template. Although the organic template factors are significant for AlPOs synthesis, these factors are not sufficient to distinguish AlPOs with different structures effectively. From <xref rid="f1-ijms-14-22132" ref-type="fig">Figure 1a</xref>, we can find that when the first two features F16 (ratio of <italic>C/N</italic>) and F12 (second longest distance of organic template) are selected, the classification accuracy rate of the classifier could reach about 71%. However, after the other 6 template features with higher Fisher score (F18 (the ratio of <italic>N</italic>/Van der Waals volume), F17 (the ratio of <italic>N</italic>/(<italic>C</italic> + <italic>N</italic>)), F19 (the Sanderson electronegativity), F14 (the Van der Waals volume), F21 (the maximal number of protonated H atoms), F13 (the shortest distance of organic template)) are added into the selected feature subset gradually, the classification accuracy rate of the classifier is almost unchanged. Failure of the feature selection described above is caused by information redundancy, or the correlation among the selected features. Since the first 8 features in <xref rid="f2-ijms-14-22132" ref-type="fig">Figure 2b</xref> come from the same category (organic template), they are far from orthogonal and cannot improve the performance of the classification task. In other words, although the first 8 template features in <xref rid="f2-ijms-14-22132" ref-type="fig">Figure 2b</xref> have higher Fisher score values, selecting them all into the feature subset does not enable the addition of new information into the selected feature subset. This clarifies the importance of accounting for redundancy during the feature selection process.</p><p>Li <italic>et al</italic>. found the optimal feature subset was consisted of 8 features that obtained the highest classification accuracy rate of 82.44% by SVM classifier [<xref rid="b18-ijms-14-22132" ref-type="bibr">18</xref>]. However, their feature selection process was an exhaustive searching strategy, so the entire process was extraordinarily time consuming. In their study, the correlation among the selected features was not at all mentioned. Thus, the correlations between some of the selected features were very high, for example: the correlation between F7 (boiling point) and F8 (dielectric constant) was 0.8370; the correlation between F7 (boiling point) and F9 (dipole moment) was 0.8306; the correlation between F8 (dielectric constant) and F9 (dipole moment) was 0.9512. Huo <italic>et al</italic>. worked out that a feature subset consisting of 19 features was the best combination for predicting AlPOs, with the highest <italic>AUC</italic> of 90% and the highest classification accuracy rate of 88.18% [<xref rid="b19-ijms-14-22132" ref-type="bibr">19</xref>]. Nevertheless, since the correlation among features was also neglected in their study, there were some highly correlated features in their optimal feature set too. For example, the correlation between F8 (dielectric constant) and F10 (polarity) was 0.9849, while the correlation between F14 (Van der Waals volume) and F20 (number of free rotated single bond) was 0.9073.</p><p>In the proposed method, we take into account the correlation among the selected features in the feature selection process. So, as shown in <xref rid="f1-ijms-14-22132" ref-type="fig">Figure 1a</xref> the classification accuracy rate curve of FI presents a distinctive uptrend before getting to the peak point, and when features belonging to a new category are added to the selected feature set at dimension 2 and 6, the curve appears obviously ascending. In the optimal feature set produced by this study, the molar amount of Al<sub>2</sub>O<sub>3</sub>, solvent and template are gel composition features; melting point and dipole moment are solvent features; the second longest distance of organic template, the dipole moment, the ratio of <italic>C/N</italic>, the ratio of <italic>N/</italic>(<italic>C</italic> + <italic>N</italic>), the ratio of <italic>N</italic>/Van der Waals volume and the maximal number of protonated H atoms are organic template features. Since the selected features by the proposed algorithm are comprehensive, we obtain the highest classification accuracy rate as 91.12% using Nearest Neighbor classifier, which is much simpler than the classifiers employed in [<xref rid="b18-ijms-14-22132" ref-type="bibr">18</xref>] and [<xref rid="b19-ijms-14-22132" ref-type="bibr">19</xref>]. Xu <italic>et al</italic>. pointed out that synthesis of microporous aluminophosphate was carried out in a gel medium under hydrothermal/solvo-thermal conditions by using the templates as structure-directing agents [<xref rid="b11-ijms-14-22132" ref-type="bibr">11</xref>]. Gel composition is the material basis for producing chemical reaction, solvent provides the reaction environment, and template plays a role of structure-directing. Among the optimal features, F12 (second longest distance of organic template) is the most important feature. In the rational synthesis of microporous materials, the geometric factor of the organic template plays a vital role to affect the shape and the pore size of an AlPO structure. For open-framework AlPOs with (6,12)-rings, the organic templates are usually located in the one-dimensional 12-ring channels, thus their longest direction is extended along the channels. Therefore, the second longest distance of the organic templates is determinative to the window size of the channels [<xref rid="b18-ijms-14-22132" ref-type="bibr">18</xref>]. From <xref rid="f2-ijms-14-22132" ref-type="fig">Figure 2</xref>, we can see that the optimal feature subset selected by our method contains 12 features belonging to three categories. However, the original Fisher score only selected features from two categories at dimension 12. Moreover, we can find that the second longest distance of the organic templates (F12) is selected by our method. These observations indicate that the proposed method is more consistent with the prior knowledge of synthetic chemists.</p><p>Compared with the methods in previous works [<xref rid="b18-ijms-14-22132" ref-type="bibr">18</xref>,<xref rid="b19-ijms-14-22132" ref-type="bibr">19</xref>], the proposed method has the following advantages. Firstly, it is independent of any classifier. Thus, as can be seen from the experimental results, the performances of our method are superior to other classical feature selection algorithms under both Nearest Neighbor and Naive Bayes classifiers. Secondly, the proposed method takes the correlations among the selected features into consideration. Therefore, it can remove the redundant information from the selected feature subset. However, we should point out that there also exists an inconvenient point in the proposed method. Since various feature scoring and correlation measurement algorithms can be incorporated into our method, there may be a need to conduct experiments to verify which combination of feature scoring and correlation measuring algorithms can obtain the best feature selection result.</p></sec><sec><label>2.4.</label><title>Comparisons with Other Feature Selection Methods</title><p>In this subsection, we compare the performance of the proposed method with some other state of the art feature selection methods including <italic>T</italic>-test [<xref rid="b30-ijms-14-22132" ref-type="bibr">30</xref>], Constraint score [<xref rid="b22-ijms-14-22132" ref-type="bibr">22</xref>], MRMR [<xref rid="b23-ijms-14-22132" ref-type="bibr">23</xref>,<xref rid="b24-ijms-14-22132" ref-type="bibr">24</xref>] and FCBF [<xref rid="b25-ijms-14-22132" ref-type="bibr">25</xref>]. Among these methods, <italic>T</italic>-test and Constraint score are univariate feature selection methods that select features by the weights or importance degrees of features, while both FCBF and MRMR are multivariable feature selection methods that take the correlation among the selected features into consideration. We compare their performances under various dimensions on the AlPOs dataset (<xref rid="f3-ijms-14-22132" ref-type="fig">Figure 3</xref>). Here, it should be noted that since the number of selected features cannot be predefined in FCBF, we are unable to test its performance under every dimension. Thus, only the average classification accuracy rate of 10-fold cross validation of FCBF is shown in <xref rid="f3-ijms-14-22132" ref-type="fig">Figure 3</xref>. The best classification accuracy rates obtained by these methods are listed in <xref rid="t4-ijms-14-22132" ref-type="table">Table 4</xref>.</p><p>From <xref rid="f3-ijms-14-22132" ref-type="fig">Figure 3</xref> and <xref rid="t4-ijms-14-22132" ref-type="table">Table 4</xref>, we can find that the proposed algorithm outperforms other feature selection methods since it could get higher classification accuracy rate under relatively lower dimension, especially when the Nearest Neighbor is utilized for classification. However, it also can be observed that the proposed algorithm does not win over other algorithms by a very large margin in some cases. Therefore, like the experiments in Section 2.2, the <italic>F</italic>-measure is also employed here to evaluate the performances of different algorithms. From the <italic>F</italic>-measure values obtained by different algorithms in <xref rid="t5-ijms-14-22132" ref-type="table">Table 5</xref>, we can see that the performance of the proposed algorithm is much better than other algorithms. These experimental results are consistent with Section 2.2.</p></sec></sec><sec><label>3.</label><title>Materials and Method</title><sec><label>3.1.</label><title>Data Sets</title><p>The microporous aluminophosphate dataset used in this paper comes from the database of AlPOs synthesis established by the State Key Laboratory of Inorganic Synthesis and Preparative Chemistry of Jilin University (<ext-link ext-link-type="uri" xlink:href="http://zeobank.jlu.edu.cn/">http://zeobank.jlu.edu.cn/</ext-link>). This database contains 1600 synthetic records in all. After removing the records that contain missing values (about 29% of the total), we use the remainder 1250 records in our experiment. In these records, 398 (6,12)-ring-containing AlPOs are deemed as positive samples, while 852 non-(6,12)-ring-containing AlPOs are deemed as negative samples. In this study, 21 synthetic features (or factors) belonging to three categories (Gel composition, Solvent and Organic template) are concerned (shown in <xref rid="t6-ijms-14-22132" ref-type="table">Table 6</xref>). For more details about the definitions and meanings of the synthetic factors in <xref rid="t6-ijms-14-22132" ref-type="table">Table 6</xref>, see [<xref rid="b31-ijms-14-22132" ref-type="bibr">31</xref>].</p></sec><sec><label>3.2.</label><title>The Proposed Algorithm</title><p>Formally, suppose <italic>D</italic> = [<italic>d</italic><sub>1</sub>, <italic>d</italic><sub>2</sub>,..., <italic>d</italic><italic><sub>n</sub></italic> ]&#x003b5; <italic>R</italic><italic><sup>m&#x000d7;n</sup></italic> is the input dataset that contains <italic>n</italic> samples in <italic>m</italic> dimensional space (For the microporous aluminophosphate dataset utilized in this study, the values of <italic>m</italic> and <italic>n</italic> in <italic>D</italic> are 21 and 1250, respectively). We can denote each row vector of <italic>D</italic> by <italic>P</italic><italic><sub>i</sub></italic> (<italic>i</italic> = 1, &#x02026;, <italic>m</italic>), which is corresponding to a feature. The aim of the proposed feature selection algorithm is to select <italic>k</italic> (<italic>k</italic> &#x0003c; <italic>m</italic>) features from the original feature set to form a feature subset <italic>U</italic> in which the importance of the features are maximizing and the correlations among the features are minimizing.</p><p>Let <italic>S</italic> = [<italic>s</italic><sub>1,</sub><italic>s</italic><sub>2,</sub>&#x02026;,<italic>s</italic><italic><sub>m</sub></italic>]<italic><sup>T</sup></italic> &#x003b5; <italic>R</italic><italic><sup>m</sup></italic><sup>&#x000d7;1</sup> be the positive weight of each feature which reflects its importance, where <italic>s</italic><italic><sub>i</sub></italic> is the weight of the <italic>i</italic>th feature (<italic>i</italic> = 1, &#x02026;, <italic>m</italic>). In this study, the weights of features can be obtained by any classical feature evaluation method (such as Fisher score, ReliefF score and Gini score), and the features with larger weights are more important. Let<italic>C</italic> &#x003b5; <italic>R</italic><italic><sup>m</sup></italic><sup>&#x000d7;</sup><italic><sup>m</sup></italic> be the correlation matrix, where <italic>C</italic><italic><sub>ij</sub></italic> &#x02265; 0(<italic>i</italic>&#x02260; <italic>j</italic>) indicates the correlation between the <italic>i</italic>th and <italic>j</italic>th features. Since the self-correlation of the synthetic factor is meaningless, we assign the diagonal elements <italic>C</italic><italic><sub>ii</sub></italic> (<italic>i</italic> = 1, 2, &#x02026;, <italic>m</italic> ) to be 0. <italic>f</italic> = [ <italic>f</italic><sub>1</sub>, <italic>f</italic><sub>2</sub>,..., <italic>f</italic><italic><sub>m</sub></italic>]<italic><sup>T</sup></italic> is an indicator vector, where <italic>f</italic><italic><sub>i</sub></italic> = 1 means that the <italic>i</italic>th feature is selected into the subset <italic>U</italic>, and <italic>f</italic><italic><sub>i</sub></italic> = 0 means the <italic>i</italic>th feature is not selected. The objective function of the proposed feature selection algorithm can be defined as:</p><disp-formula id="fd3-ijms-14-22132"><label>(3)</label><mml:math id="m3"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:munder><mml:mrow><mml:mtext>max</mml:mtext></mml:mrow><mml:mi>f</mml:mi></mml:munder><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mi>S</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:mfrac><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mi>C</mml:mi><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>s</mml:mi><mml:mo>.</mml:mo><mml:mi>t</mml:mi><mml:mo>.</mml:mo><mml:munder><mml:mo>&#x02211;</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mrow><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>&#x02208;</mml:mo><mml:mo stretchy="false">{</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula><p>In <xref rid="fd3-ijms-14-22132" ref-type="disp-formula">Equation (3)</xref>, 
<inline-formula><mml:math id="m4"><mml:mrow><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mi>S</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:mfrac></mml:mrow></mml:math></inline-formula> stands for the average weight of the selected features, 
<inline-formula><mml:math id="m5"><mml:mrow><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mi>C</mml:mi><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:math></inline-formula> stands for the average correlation among the selected features, and the constraints are used for restricting the number of selected features in the <italic>U</italic> to be <italic>k</italic>. Thus, maximizing <xref rid="fd3-ijms-14-22132" ref-type="disp-formula">Equation (3)</xref> can ensure that the selected features in <italic>U</italic> are most important and least redundant. However, <xref rid="fd3-ijms-14-22132" ref-type="disp-formula">Equation (3)</xref> is a quadratic integral programming problem and it is hard to be solved [<xref rid="b32-ijms-14-22132" ref-type="bibr">32</xref>]. Therefore, in our study, we relax the constraint of <italic>f</italic><italic><sub>i</sub></italic> &#x003b5;{0,1} <italic>f</italic><italic><sub>i</sub></italic> to &#x003b5;[0,1], and convert the objective function in <xref rid="fd3-ijms-14-22132" ref-type="disp-formula">Equation (3)</xref> to:</p><disp-formula id="fd4-ijms-14-22132"><label>(4)</label><mml:math id="m6"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:munder><mml:mrow><mml:mtext>max</mml:mtext></mml:mrow><mml:mi>f</mml:mi></mml:munder><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mi>S</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:mfrac><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mi>C</mml:mi><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>s</mml:mi><mml:mo>.</mml:mo><mml:mi>t</mml:mi><mml:mo>.</mml:mo><mml:munder><mml:mo>&#x02211;</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mrow><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>&#x02208;</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></sec><sec><label>3.3.</label><title>Solution</title><p>In this section, a pair-wise updating algorithm similar to that found in [<xref rid="b32-ijms-14-22132" ref-type="bibr">32</xref>] is introduced to solve the maximization problem in <xref rid="fd4-ijms-14-22132" ref-type="disp-formula">Equation (4)</xref>.</p><p>The Lagrangian function of <xref rid="fd4-ijms-14-22132" ref-type="disp-formula">Equation (4)</xref> can be derived as:</p><disp-formula id="fd5-ijms-14-22132"><label>(5)</label><mml:math id="m7"><mml:mrow><mml:mi>L</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">&#x003bb;</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">&#x003bc;</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">&#x003b2;</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mi>S</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:mfrac><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mi>C</mml:mi><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>-</mml:mo><mml:mi mathvariant="normal">&#x003bb;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:munder><mml:mo>&#x02211;</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mrow><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:munder><mml:mo>&#x02211;</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">&#x003bc;</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:munder><mml:mo>&#x02211;</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">&#x003b2;</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula><p>Where &#x003bb;, &#x003bc;<italic><sub>i</sub></italic> and &#x003b2;<italic><sub>i</sub></italic> are Lagrangian multipliers. Based on the Karush-Kuhn-Tucker (KKT) conditions [<xref rid="b33-ijms-14-22132" ref-type="bibr">33</xref>], the solution that maximizes the <xref rid="fd4-ijms-14-22132" ref-type="disp-formula">Equation (4)</xref> must satisfy the first-order necessary conditions as:</p><disp-formula id="fd6-ijms-14-22132"><label>(6)</label><mml:math id="m8"><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mtable columnalign="left"><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mi>S</mml:mi><mml:mi>k</mml:mi></mml:mfrac><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>C</mml:mi><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:mi mathvariant="normal">&#x003bb;</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">&#x003bc;</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">&#x003b2;</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:munder><mml:mo>&#x02211;</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">&#x003bc;</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:munder><mml:mo>&#x02211;</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">&#x003b2;</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula><p>where 
<inline-formula><mml:math id="m9"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mi>S</mml:mi><mml:mi>k</mml:mi></mml:mfrac><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>C</mml:mi><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is the <italic>i</italic>th element of vector 
<inline-formula><mml:math id="m10"><mml:mrow><mml:mfrac><mml:mi>S</mml:mi><mml:mi>k</mml:mi></mml:mfrac><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>C</mml:mi><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:math></inline-formula>. Because <italic>f</italic><italic><sub>i</sub></italic>, &#x003bc;<italic><sub>i</sub></italic> and &#x003b2;<italic><sub>i</sub></italic> are all non-negative, 
<inline-formula><mml:math id="m11"><mml:mrow><mml:mstyle displaystyle="true"><mml:munder><mml:mo>&#x02211;</mml:mo><mml:mi>i</mml:mi></mml:munder></mml:mstyle><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">&#x003bc;</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> means that if <italic>f</italic><italic><sub>i</sub></italic> &#x0003e; 0, then &#x003bc;<italic><sub>i</sub></italic><italic>=</italic> 0. Similarly, 
<inline-formula><mml:math id="m12"><mml:mrow><mml:mstyle displaystyle="true"><mml:munder><mml:mo>&#x02211;</mml:mo><mml:mi>i</mml:mi></mml:munder></mml:mstyle><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">&#x003b2;</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> means that if <italic>f</italic><italic><sub>i</sub></italic> &#x0003c; 1, then &#x003b2; = 0. Thus, according to the relationship between 
<inline-formula><mml:math id="m13"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mi>S</mml:mi><mml:mi>k</mml:mi></mml:mfrac><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>C</mml:mi><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and &#x003bb;, the KKT conditions can be rewritten as:</p><disp-formula id="fd7-ijms-14-22132"><label>(7)</label><mml:math id="m14"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mi>S</mml:mi><mml:mi>k</mml:mi></mml:mfrac><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>C</mml:mi><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mtable columnalign="left"><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mo>&#x02264;</mml:mo><mml:mi mathvariant="normal">&#x003bb;</mml:mi></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo><mml:mi mathvariant="normal">&#x003bb;</mml:mi></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>&#x02208;</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mo>&#x02265;</mml:mo><mml:mi mathvariant="normal">&#x003bb;</mml:mi></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula><p>Here, since 
<inline-formula><mml:math id="m15"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mi>S</mml:mi><mml:mi>k</mml:mi></mml:mfrac><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>C</mml:mi><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> could reflect the relationship between the feature&#x02019;s weight and its average correlation with other features in <italic>U</italic>, we call it the reward of <italic>i</italic>th feature, and denote it by <italic>r</italic><italic><sub>i</sub></italic>(<italic>f</italic>). According to the value of 
<inline-formula><mml:math id="m16"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mi>S</mml:mi><mml:mi>k</mml:mi></mml:mfrac><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>C</mml:mi><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, we can partition the feature set into three subsets, <italic>U</italic><italic><sub>1</sub></italic>= {<italic>P</italic><italic><sub>i</sub></italic> | <italic>f</italic><italic><sub>i</sub></italic>=0}, <italic>U</italic><italic><sub>2</sub></italic>= {<italic>P</italic><italic><sub>i</sub></italic> | <italic>f</italic><italic><sub>i</sub></italic>&#x003b5;(0,1)} and <italic>U</italic><italic><sub>3</sub></italic>= {<italic>P</italic><italic><sub>i</sub></italic> | <italic>f</italic><italic><sub>i</sub></italic>=1}. From the constraints of <italic>f</italic> in <xref rid="fd4-ijms-14-22132" ref-type="disp-formula">Equation (4)</xref>, it can be found that if a feature is in subset <italic>U</italic><italic><sub>1</sub></italic> or <italic>U</italic><italic><sub>2</sub></italic>, the value of its corresponding element in <italic>f</italic> can be increased. On the contrary, if a feature is in subset <italic>U</italic><italic><sub>2</sub></italic> or <italic>U</italic><italic><sub>3</sub></italic>, the value of its corresponding element in <italic>f</italic> can be decreased.</p><p>The pair-wise updating strategy to solve <xref rid="fd4-ijms-14-22132" ref-type="disp-formula">Equation (4)</xref> is defined as:</p><disp-formula id="fd8-ijms-14-22132"><label>(8)</label><mml:math id="m17"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>l</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mtable columnalign="left"><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>l</mml:mi></mml:msub></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mi>l</mml:mi><mml:mo>&#x02260;</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi><mml:mo>&#x02260;</mml:mo><mml:mi>j</mml:mi><mml:mo>;</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>l</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi mathvariant="normal">&#x003b1;</mml:mi></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mi>i</mml:mi><mml:mo>;</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>l</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:mi mathvariant="normal">&#x003b1;</mml:mi></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mi>j</mml:mi><mml:mo>;</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula><p>That is, only the values of two elements in <italic>f</italic> (<italic>f</italic><italic><sub>i</sub></italic> and <italic>f</italic><italic><sub>j</sub></italic>, <italic>i</italic> &#x02260; <italic>j</italic> ) are updated in each iteration of our algorithm. After updating <italic>f</italic><italic><sub>i</sub></italic> and <italic>f</italic><italic><sub>j</sub></italic>, the change of <xref rid="fd4-ijms-14-22132" ref-type="disp-formula">Equation (4)</xref> is:</p><disp-formula id="fd9-ijms-14-22132"><label>(9)</label><mml:math id="m18"><mml:mtable columnalign="left" columnspacing="2pt"><mml:mtr><mml:mtd><mml:mi mathvariant="normal">&#x00394;</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>w</mml:mi><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mi>S</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:mfrac><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>w</mml:mi><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mi>C</mml:mi><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mi>S</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:mfrac><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mi>C</mml:mi><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>w</mml:mi><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mi>S</mml:mi><mml:mo>-</mml:mo><mml:msup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mi>S</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mi>C</mml:mi><mml:mi>f</mml:mi><mml:mo>-</mml:mo><mml:msup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>w</mml:mi><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mi>C</mml:mi><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mi mathvariant="normal">&#x003b1;</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">&#x003b1;</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mi>C</mml:mi><mml:mi>f</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mi>C</mml:mi><mml:mi>f</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi mathvariant="normal">&#x003b1;</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">&#x003b1;</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mi mathvariant="normal">&#x003b1;</mml:mi><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mi>C</mml:mi><mml:mi>f</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mi>C</mml:mi><mml:mi>f</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi mathvariant="normal">&#x003b1;</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula><p>where <italic>e</italic><italic><sub>i</sub></italic> is a row vector with only the <italic>i</italic>th element equal to 1, and 0 otherwise. So, <xref rid="fd9-ijms-14-22132" ref-type="disp-formula">Equation (9)</xref> can be further converted as:</p><disp-formula id="fd10-ijms-14-22132"><label>(10)</label><mml:math id="m19"><mml:mtable columnalign="left" columnspacing="2pt"><mml:mtr><mml:mtd><mml:mi mathvariant="normal">&#x00394;</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">&#x003b1;</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mi mathvariant="normal">&#x003b1;</mml:mi><mml:mo>-</mml:mo><mml:mn>2</mml:mn><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mi>C</mml:mi><mml:mi>f</mml:mi><mml:mi mathvariant="normal">&#x003b1;</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mi mathvariant="normal">&#x003b1;</mml:mi><mml:mo>-</mml:mo><mml:mn>2</mml:mn><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mi>C</mml:mi><mml:mi>f</mml:mi><mml:mi mathvariant="normal">&#x003b1;</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">&#x003b1;</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mi>k</mml:mi></mml:mfrac><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mi>C</mml:mi><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi mathvariant="normal">&#x003b1;</mml:mi><mml:mo>-</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mi>k</mml:mi></mml:mfrac><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mi>C</mml:mi><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi mathvariant="normal">&#x003b1;</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">&#x003b1;</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mi>S</mml:mi><mml:mi>k</mml:mi></mml:mfrac><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>C</mml:mi><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mi mathvariant="normal">&#x003b1;</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mi>S</mml:mi><mml:mi>k</mml:mi></mml:mfrac><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>C</mml:mi><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mi mathvariant="normal">&#x003b1;</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">&#x003b1;</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi mathvariant="normal">&#x003b1;</mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula><p>With the aim of maximizing &#x00394;, according to <xref rid="fd10-ijms-14-22132" ref-type="disp-formula">Equation (10)</xref> and the constraints of <italic>f</italic>, &#x003b1; can be computed as:</p><disp-formula id="fd11-ijms-14-22132"><label>(11)</label><mml:math id="m20"><mml:mrow><mml:mi mathvariant="normal">&#x003b1;</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mtable columnalign="left"><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mtext>min</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mtext>if&#x02009;</mml:mtext><mml:mn>2</mml:mn><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02265;</mml:mo><mml:mn>0</mml:mn><mml:mi>&#x02009;</mml:mi><mml:mtext>and&#x02009;</mml:mtext><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x0003e;</mml:mo><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mtext>min</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mfrac><mml:mrow><mml:mi>k</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mtext>if&#x02009;</mml:mtext><mml:mn>2</mml:mn><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>&#x0003c;</mml:mo><mml:mn>0</mml:mn><mml:mi>&#x02009;</mml:mi><mml:mtext>and&#x02009;</mml:mtext><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x0003e;</mml:mo><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mtext>min</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mtext>if&#x02009;</mml:mtext><mml:mn>2</mml:mn><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>&#x0003e;</mml:mo><mml:mn>0</mml:mn><mml:mi>&#x02009;</mml:mi><mml:mtext>and&#x02009;</mml:mtext><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula><p>Note that in the updating algorithm above, only the situation that <italic>r</italic><italic><sub>i</sub></italic>(<italic>f</italic>) &#x02265; <italic>r</italic><italic><sub>j</sub></italic>(<italic>f</italic>) is considered. If <italic>r</italic><italic><sub>i</sub></italic>(f) &#x0003c; <italic>r</italic><italic><sub>j</sub></italic>(<italic>f</italic>), exchange <italic>i</italic> and <italic>j</italic> to implement the algorithm.</p><p>By iteratively updating the values of pair-wise elements in <italic>f</italic> and computing &#x003b1; using <xref rid="fd8-ijms-14-22132" ref-type="disp-formula">Equations (8)</xref> and <xref rid="fd11-ijms-14-22132" ref-type="disp-formula">(11)</xref>, the objective function in <xref rid="fd4-ijms-14-22132" ref-type="disp-formula">Equation (4)</xref> can be increased and reach its maximum [<xref rid="b32-ijms-14-22132" ref-type="bibr">32</xref>]. The implementation details of the proposed feature selection method are summarized in <xref rid="t7-ijms-14-22132" ref-type="table">Algorithm 1</xref>.</p><p>As can be seen in <xref rid="t7-ijms-14-22132" ref-type="table">Algorithm 1</xref>, a heuristic strategy is adopted in each iteration of the pair-wise updating algorithm to increase the objective function maximally. In this strategy, a pair of elements in <italic>f</italic> whose values should be updated is selected according to the rewards of their corresponding features. In other words, the element whose value should be increased in each iteration is selected as the one whose corresponding feature has the largest reword in subset <italic>U</italic><italic><sub>1</sub></italic> or <italic>U</italic><italic><sub>2</sub></italic>, and the element whose value should be decreased in each iteration is selected as the one whose corresponding feature has the smallest reword in subset <italic>U</italic><italic><sub>2</sub></italic> or <italic>U</italic><italic><sub>3</sub></italic>. From <xref rid="fd10-ijms-14-22132" ref-type="disp-formula">Equation (10)</xref>, we can find that the increase of the objective function in <xref rid="fd4-ijms-14-22132" ref-type="disp-formula">Equation (4)</xref> can be maximized by this method. The solution of proposed algorithm is obtained when the value of <xref rid="fd4-ijms-14-22132" ref-type="disp-formula">Equation (4)</xref> cannot be further increased.</p></sec></sec><sec sec-type="conclusions"><label>4.</label><title>Conclusions</title><p>In this study, a novel feature selection method based on maximum weight and minimum redundancy criterion is proposed. Comprehensive experiments and deep analysis based on the microporous aluminophosphates (AlPOs) database demonstrate the effectiveness of the proposed algorithm. This work also demonstrates the feasibility of feature selection techniques in chemical data analysis. By taking advantage of the proposed algorithm, we investigate the relationship between synthetic factors and rational synthesis of microporus materials. The classification result with a classification accuracy rate of 91.12% shows that a number of synthetic factors including the molar amount of Al<sub>2</sub>O<sub>3</sub>, the molar amount of solvent, the molar amount of template in the gel composition, the melting point, the dipole moment, the second longest distance of organic template, the dipole moment, the ratio of <italic>C/N</italic>, the ratio of <bold>N</bold><italic>/</italic>(<italic>C</italic> + <italic>N</italic>), the ratio of <italic>N</italic>/Van der Waals volume and the maximal number of protonated H atoms play vital roles for rational synthesis of (6,12)-ring-containing AlPOs. Among these optimal synthetic factors, the second longest distance of organic template, which is the geometric size of the organic template, plays the most important role in the prediction. This work provides <italic>a priori</italic> knowledge and a useful guidance for rational synthesis experiments of such materials.</p><p>In future studies, we will gradually add more synthetic features (or factors) into the database to investigate their influences for the synthesis of AlPOs.</p></sec></body><back><ack><title>Acknowledgments</title><p>This work was supported by the Fund of Jilin Provincial Science &#x00026; Technology Department (No.201115003), the Fundamental Research Funds for the Central Universities (No.11QNJJ005), the Science Foundation for Post-Doctor of Jilin Province (No.2011274), the Young Scientific Research Fund of Jilin Province Science, the Technology Development Project (No.201201070, 201201063), and the Fund of Key Laboratory of Symbolic Engineering MOE (No.93K172012K13).</p></ack><notes><title>Conflicts of Interest</title><p>The authors declare no conflict of interest.</p></notes><ref-list><title>References</title><ref id="b1-ijms-14-22132"><label>1</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hyunjoo</surname><given-names>L.</given-names></name><name><surname>Zones</surname><given-names>S.I.</given-names></name><name><surname>Davis</surname><given-names>M.E.</given-names></name></person-group><article-title>A combustion-free methodology for synthesizing zeolites and zeolite-like materials</article-title><source>Nature</source><year>2003</year><volume>425</volume><fpage>385</fpage><lpage>388</lpage><pub-id pub-id-type="pmid">14508485</pub-id></element-citation></ref><ref id="b2-ijms-14-22132"><label>2</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yu</surname><given-names>J.H.</given-names></name><name><surname>Xu</surname><given-names>R.R.</given-names></name></person-group><article-title>Insight into the construction of open-framework aluminophosphates</article-title><source>Chem. Soc. Rev</source><year>2006</year><volume>25</volume><fpage>593</fpage><lpage>604</lpage><pub-id pub-id-type="pmid">16791331</pub-id></element-citation></ref><ref id="b3-ijms-14-22132"><label>3</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>Y.</given-names></name><name><surname>Yu</surname><given-names>J.H.</given-names></name><name><surname>Liu</surname><given-names>D.H.</given-names></name><name><surname>Yan</surname><given-names>W.F.</given-names></name><name><surname>Xu</surname><given-names>R.R.</given-names></name><name><surname>Xu</surname><given-names>Y.</given-names></name></person-group><article-title>Design of zeolite frameworks with defined pore geometry through constrained assembly of atoms</article-title><source>Chem. Mater</source><year>2003</year><volume>15</volume><fpage>2780</fpage><lpage>2785</lpage></element-citation></ref><ref id="b4-ijms-14-22132"><label>4</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>Y.</given-names></name><name><surname>Yu</surname><given-names>J.H.</given-names></name><name><surname>Wang</surname><given-names>Z.P.</given-names></name><name><surname>Zhang</surname><given-names>J.N.</given-names></name><name><surname>Guo</surname><given-names>M.</given-names></name><name><surname>Xu</surname><given-names>R.R.</given-names></name></person-group><article-title>Design of chiral zeolite frameworks with specified channels through constrained assembly of atoms</article-title><source>Chem. Mater</source><year>2005</year><volume>17</volume><fpage>4399</fpage><lpage>4405</lpage></element-citation></ref><ref id="b5-ijms-14-22132"><label>5</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>Y.</given-names></name><name><surname>Yu</surname><given-names>J.H.</given-names></name><name><surname>Xu</surname><given-names>R.R.</given-names></name><name><surname>Baerlocher</surname><given-names>C.</given-names></name><name><surname>McCusker</surname><given-names>L.B.</given-names></name></person-group><article-title>Combining structure modeling and electron microscopy to determine complex zeolite framework structures</article-title><source>Angew Chem</source><year>2008</year><volume>120</volume><fpage>4473</fpage><lpage>4477</lpage></element-citation></ref><ref id="b6-ijms-14-22132"><label>6</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>Y.</given-names></name><name><surname>Yu</surname><given-names>J.H.</given-names></name><name><surname>Jiang</surname><given-names>J.X.</given-names></name><name><surname>Wang</surname><given-names>Z.P.</given-names></name><name><surname>Zhang</surname><given-names>J.N.</given-names></name><name><surname>Xu</surname><given-names>R.R.</given-names></name></person-group><article-title>Prediction of open-framework aluminophosphate structures using the automated assembly of secondary building units method with Lowenstein&#x02019;s constraints</article-title><source>Chem. Mater</source><year>2005</year><volume>17</volume><fpage>6086</fpage><lpage>6093</lpage></element-citation></ref><ref id="b7-ijms-14-22132"><label>7</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ren</surname><given-names>X.Y.</given-names></name><name><surname>Li</surname><given-names>Y.</given-names></name><name><surname>Pan</surname><given-names>Q.H.</given-names></name><name><surname>Yu</surname><given-names>J.H.</given-names></name><name><surname>Xu</surname><given-names>R.R.</given-names></name><name><surname>Xu</surname><given-names>Y.</given-names></name></person-group><article-title>A crystalline germanate with mesoporous 30-ring channels</article-title><source>J. Am. Chem. Soc</source><year>2009</year><volume>131</volume><fpage>14128</fpage><lpage>14129</lpage><pub-id pub-id-type="pmid">19807168</pub-id></element-citation></ref><ref id="b8-ijms-14-22132"><label>8</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>J.Y.</given-names></name><name><surname>Li</surname><given-names>L.</given-names></name><name><surname>Liang</surname><given-names>J.</given-names></name><name><surname>Chen</surname><given-names>P.</given-names></name><name><surname>Yu</surname><given-names>J.H.</given-names></name><name><surname>Xu</surname><given-names>Y.</given-names></name><name><surname>Xu</surname><given-names>R.R.</given-names></name></person-group><article-title>Template-designed syntheses of open-framework zinc phosphites with extra-large 24-ring channels</article-title><source>Cryst. Growth Des</source><year>2008</year><volume>8</volume><fpage>2318</fpage><lpage>2323</lpage></element-citation></ref><ref id="b9-ijms-14-22132"><label>9</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>J.Y.</given-names></name><name><surname>Yu</surname><given-names>J.H.</given-names></name><name><surname>Yan</surname><given-names>W.F.</given-names></name><name><surname>Xu</surname><given-names>Y.H.</given-names></name><name><surname>Xu</surname><given-names>W.G.</given-names></name><name><surname>Qiu</surname><given-names>S.L.</given-names></name><name><surname>Xu</surname><given-names>R.R.</given-names></name></person-group><article-title>Structures and templating effect in the formation of 2D layered aluminophosphates with Al<sub>3</sub>P<sub>4</sub>O16<sup>3&#x02212;</sup> stoichiometry</article-title><source>Chem. Mater</source><year>1999</year><volume>11</volume><fpage>2600</fpage><lpage>2606</lpage></element-citation></ref><ref id="b10-ijms-14-22132"><label>10</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yu</surname><given-names>J.H.</given-names></name><name><surname>Li</surname><given-names>J.Y.</given-names></name><name><surname>Wang</surname><given-names>K.X.</given-names></name><name><surname>Xu</surname><given-names>R.R.</given-names></name><name><surname>Sugiyama</surname><given-names>K.</given-names></name><name><surname>Terasaki</surname><given-names>O.</given-names></name></person-group><article-title>Rational synthesis of microporous aluminophosphates with an inorganic open framework analogous to Al<sub>4</sub>P<sub>5</sub>O<sub>20</sub>HC<sub>6</sub>H<sub>18</sub>N<sub>2</sub></article-title><source>Chem. Mater</source><year>2000</year><volume>12</volume><fpage>3783</fpage><lpage>3787</lpage></element-citation></ref><ref id="b11-ijms-14-22132"><label>11</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Xu</surname><given-names>R.R.</given-names></name><name><surname>Pang</surname><given-names>W.Q.</given-names></name><name><surname>Yu</surname><given-names>J.H.</given-names></name><name><surname>Huo</surname><given-names>Q.S.</given-names></name><name><surname>Chen</surname><given-names>J.S.</given-names></name></person-group><source>Chemistry of Zeolites and Related Porous Materials: Synthesis and Structure</source><publisher-name>John Wiley and Sons</publisher-name><publisher-loc>Singapore</publisher-loc><year>2007</year></element-citation></ref><ref id="b12-ijms-14-22132"><label>12</label><element-citation publication-type="webpage"><person-group person-group-type="author"><name><surname>Li</surname><given-names>J.Y.</given-names></name><name><surname>Yu</surname><given-names>J.H.</given-names></name><name><surname>Xu</surname><given-names>R.R.</given-names></name></person-group><source>Database of AlPO Syntheses</source><comment>Available online: <ext-link ext-link-type="uri" xlink:href="http://zeobank.jlu.edu.cn">http://zeobank.jlu.edu.cn</ext-link></comment><date-in-citation>(accessed on 26 October 2011)</date-in-citation></element-citation></ref><ref id="b13-ijms-14-22132"><label>13</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pichler</surname><given-names>M.A.</given-names></name><name><surname>Perone</surname><given-names>S.P.</given-names></name></person-group><article-title>Computerized pattern recognition applications to chemical analysis: Development of interactive feature selection methods for the K-nearest neighbor technique</article-title><source>Anal. Chem</source><year>1974</year><volume>46</volume><fpage>1790</fpage><lpage>1798</lpage></element-citation></ref><ref id="b14-ijms-14-22132"><label>14</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>Y.</given-names></name></person-group><article-title>A comparative study on feature selection methods for drug discovery</article-title><source>J. Chem. Inf. Comput. Sci</source><year>2004</year><volume>44</volume><fpage>1823</fpage><lpage>1828</lpage><pub-id pub-id-type="pmid">15446842</pub-id></element-citation></ref><ref id="b15-ijms-14-22132"><label>15</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Teramoto</surname><given-names>R.</given-names></name><name><surname>Fukunishi</surname><given-names>H.</given-names></name></person-group><article-title>Supervised consensus scoring for docking and virtual screening</article-title><source>J. Chem. Inf. Model</source><year>2007</year><volume>47</volume><fpage>526</fpage><lpage>534</lpage><pub-id pub-id-type="pmid">17295466</pub-id></element-citation></ref><ref id="b16-ijms-14-22132"><label>16</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Venkatraman</surname><given-names>V.</given-names></name><name><surname>Dalby</surname><given-names>A.R.</given-names></name><name><surname>Yang</surname><given-names>Z.R.</given-names></name></person-group><article-title>Evaluation of mutual information and genetic programming for feature selection in QSAR</article-title><source>J. Chem. Inf. Comput. Sci</source><year>2004</year><volume>44</volume><fpage>1686</fpage><lpage>1692</lpage><pub-id pub-id-type="pmid">15446827</pub-id></element-citation></ref><ref id="b17-ijms-14-22132"><label>17</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rodgers</surname><given-names>S.</given-names></name><name><surname>Glen</surname><given-names>R.C.</given-names></name><name><surname>Bender</surname><given-names>A.</given-names></name></person-group><article-title>Characterizing bitterness: Identification of key structural features and development of a classification model</article-title><source>J. Chem. Inf. Model</source><year>2006</year><volume>46</volume><fpage>569</fpage><lpage>576</lpage><pub-id pub-id-type="pmid">16562985</pub-id></element-citation></ref><ref id="b18-ijms-14-22132"><label>18</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>J.Y.</given-names></name><name><surname>Qi</surname><given-names>M.</given-names></name><name><surname>Kong</surname><given-names>J.</given-names></name><name><surname>Wang</surname><given-names>J.Z.</given-names></name><name><surname>Yan</surname><given-names>Y.</given-names></name><name><surname>Huo</surname><given-names>W.F.</given-names></name><name><surname>Yu</surname><given-names>J.H.</given-names></name><name><surname>Xu</surname><given-names>R.R.</given-names></name><name><surname>Xu</surname><given-names>Y.</given-names></name></person-group><article-title>Computational prediction of the formation of microporous aluminophosphates with desired structural features</article-title><source>Microporous Mesoporous Mater</source><year>2010</year><volume>129</volume><fpage>251</fpage><lpage>255</lpage></element-citation></ref><ref id="b19-ijms-14-22132"><label>19</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huo</surname><given-names>W.F.</given-names></name><name><surname>Gao</surname><given-names>N.</given-names></name><name><surname>Yan</surname><given-names>Y.</given-names></name><name><surname>Li</surname><given-names>J.Y.</given-names></name><name><surname>Yu</surname><given-names>J.H.</given-names></name><name><surname>Xu</surname><given-names>R.R.</given-names></name></person-group><article-title>Decision trees combined with feature selection for the rationalsynthesis of aluminophosphate AlPO<sub>4&#x02013;5</sub></article-title><source>Acta Phys. Chim. Sin</source><year>2011</year><volume>27</volume><fpage>2111</fpage><lpage>2117</lpage></element-citation></ref><ref id="b20-ijms-14-22132"><label>20</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>Y.W.</given-names></name><name><surname>Lin</surname><given-names>C.-J.</given-names></name></person-group><article-title>Combining SVMs with various feature selection strategies</article-title><source>Feature Extraction</source><year>2006</year><volume>207</volume><fpage>315</fpage><lpage>324</lpage></element-citation></ref><ref id="b21-ijms-14-22132"><label>21</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Hall</surname><given-names>M.A.</given-names></name></person-group><article-title>Correlation-Based Feature Selection for Discrete and Numeric Class Machine Learning</article-title><source>Machine Learning: Proceedings of the International Conference</source><publisher-name>Morgan Kaufmann</publisher-name><publisher-loc>San Francisco, CA, USA</publisher-loc><year>2000</year><fpage>359</fpage><lpage>366</lpage></element-citation></ref><ref id="b22-ijms-14-22132"><label>22</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>D.Q.</given-names></name><name><surname>Chen</surname><given-names>S.C.</given-names></name><name><surname>Zhou</surname><given-names>Z.-H.</given-names></name></person-group><article-title>Constraint score: A new filter method for feature selection with pairwise constraints</article-title><source>Pattern Recogn</source><year>2008</year><volume>41</volume><fpage>1440</fpage><lpage>1451</lpage></element-citation></ref><ref id="b23-ijms-14-22132"><label>23</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ding</surname><given-names>C.</given-names></name><name><surname>Peng</surname><given-names>H.C.</given-names></name></person-group><article-title>Minimum redundancy feature selection from microarray gene expression data</article-title><source>J. Bioinf. Comput. Biol</source><year>2005</year><volume>3</volume><fpage>185</fpage><lpage>205</lpage></element-citation></ref><ref id="b24-ijms-14-22132"><label>24</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Peng</surname><given-names>H.C.</given-names></name><name><surname>Long</surname><given-names>F.H.</given-names></name><name><surname>Ding</surname><given-names>C.</given-names></name></person-group><article-title>Feature selection based on mutual information: Criteria of max-dependency, max-relevance, and min-redundancy</article-title><source>IEEE Trans. Pattern Anal. Mach. Intell</source><year>2005</year><volume>27</volume><fpage>1226</fpage><lpage>1238</lpage><pub-id pub-id-type="pmid">16119262</pub-id></element-citation></ref><ref id="b25-ijms-14-22132"><label>25</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Yu</surname><given-names>L.</given-names></name><name><surname>Liu</surname><given-names>H.</given-names></name></person-group><article-title>Feature Selection for High-Dimensional Data: A Fast Correlation-Based Filter Solution</article-title><conf-name>Proceedings of the Twentieth International Conference on Machine Learning (ICML-2003)</conf-name><conf-loc>Washington, DC, USA</conf-loc><conf-date>21&#x02013;24 August 2003</conf-date></element-citation></ref><ref id="b26-ijms-14-22132"><label>26</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Soda</surname><given-names>P.</given-names></name></person-group><article-title>A multi-objective optimization approach for class imbalance learning</article-title><source>Pattern Recogn</source><year>2011</year><volume>44</volume><fpage>801</fpage><lpage>1810</lpage></element-citation></ref><ref id="b27-ijms-14-22132"><label>27</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Bishop</surname><given-names>C.M.</given-names></name></person-group><source>Neural Networks for Pattern Recognition</source><publisher-name>Oxford University Press</publisher-name><publisher-loc>Oxford, UK</publisher-loc><year>1995</year></element-citation></ref><ref id="b28-ijms-14-22132"><label>28</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Kononenko</surname><given-names>I.</given-names></name></person-group><article-title>Estimating Features: Analysis and Extension of RELIEF</article-title><conf-name>Proceedings of the 6th European Conference on Machine Learning</conf-name><conf-loc>Catania, Italy</conf-loc><conf-date>6&#x02013;8 April 1994</conf-date><fpage>171</fpage><lpage>182</lpage></element-citation></ref><ref id="b29-ijms-14-22132"><label>29</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Breiman</surname><given-names>L.</given-names></name><name><surname>Friedman</surname><given-names>J.H.</given-names></name><name><surname>Olshen</surname><given-names>R.A.</given-names></name></person-group><source>Classification and Regression Trees</source><publisher-name>Wadsworth International Group</publisher-name><publisher-loc>Belmont, CA, USA</publisher-loc><year>1984</year></element-citation></ref><ref id="b30-ijms-14-22132"><label>30</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Saeys</surname><given-names>Y.</given-names></name><name><surname>Inza</surname><given-names>I.</given-names></name><name><surname>Larranaga</surname><given-names>P.</given-names></name></person-group><article-title>A review of feature selection techniques in bioinformatics</article-title><source>Bioinformatics</source><year>2007</year><volume>23</volume><fpage>2507</fpage><lpage>2517</lpage><pub-id pub-id-type="pmid">17720704</pub-id></element-citation></ref><ref id="b31-ijms-14-22132"><label>31</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yan</surname><given-names>Y.</given-names></name><name><surname>Li</surname><given-names>J.Y.</given-names></name><name><surname>Qi</surname><given-names>M.</given-names></name><name><surname>Zhang</surname><given-names>X.</given-names></name><name><surname>Yu</surname><given-names>J.H.</given-names></name><name><surname>Xu</surname><given-names>R.R.</given-names></name></person-group><article-title>Database of open-framework aluminophosphate syntheses: Introduction and application (I)</article-title><source>Sci. China Ser. B</source><year>2009</year><volume>52</volume><fpage>1734</fpage><lpage>1738</lpage></element-citation></ref><ref id="b32-ijms-14-22132"><label>32</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>H.R.</given-names></name><name><surname>Yang</surname><given-names>X.W.</given-names></name><name><surname>Latecki</surname><given-names>L.J.</given-names></name><name><surname>Yan</surname><given-names>S.C.</given-names></name></person-group><article-title>Dense neighborhoods on affinity graph</article-title><source>Int. J. Comput. Vis</source><year>2012</year><volume>98</volume><fpage>65</fpage><lpage>82</lpage></element-citation></ref><ref id="b33-ijms-14-22132"><label>33</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Kuhn</surname><given-names>W.</given-names></name><name><surname>Tucker</surname><given-names>A.</given-names></name></person-group><article-title>Nonlinear Programming</article-title><conf-name>Proceedings of the Second Berkeley Symposium</conf-name><conf-loc>Berkeley, CA, USA</conf-loc><conf-date>31 July&#x02013;12 August 1950</conf-date><fpage>481</fpage><lpage>492</lpage></element-citation></ref></ref-list></back><floats-group><fig id="f1-ijms-14-22132" position="float"><label>Figure 1</label><caption><p>Comparison of the original and proposed feature selection methods. (<bold>a</bold>) Using Nearest Neighbor as classifier; (<bold>b</bold>) Using Naive Bayes as classifier.</p></caption><graphic xlink:href="ijms-14-22132f1"/></fig><fig id="f2-ijms-14-22132" position="float"><label>Figure 2</label><caption><p>The features selected by Fisher and Fisher combined with PCC. (<bold>a</bold>) Different category synthesis factors are represented as different color; (<bold>b</bold>) features selected by Fisher score; (<bold>c</bold>) features selected by Fisher score combined with PCC in our algorithm.</p></caption><graphic xlink:href="ijms-14-22132f2"/></fig><fig id="f3-ijms-14-22132" position="float"><label>Figure 3</label><caption><p>Performance comparison of the proposed algorithm and some popular feature selection methods. (<bold>a</bold>) Using nearest neighbor as classifier; (<bold>b</bold>) Using Naive Bayes as classifier.</p></caption><graphic xlink:href="ijms-14-22132f3"/></fig><table-wrap id="t1-ijms-14-22132" position="float"><label>Table 1</label><caption><p>Confusion matrix.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="bottom" rowspan="1" colspan="1">Hypothesis</th><th align="center" valign="bottom" rowspan="1" colspan="1">Actual positive</th><th align="center" valign="bottom" rowspan="1" colspan="1">Actual negative</th></tr></thead><tbody><tr><td align="center" valign="top" rowspan="1" colspan="1">Hypothesise positive</td><td align="center" valign="top" rowspan="1" colspan="1">True positive (<italic>TP</italic>)</td><td align="center" valign="top" rowspan="1" colspan="1">False positive (<italic>FP</italic>)</td></tr><tr><td align="center" valign="top" rowspan="1" colspan="1">Hypothesise negative</td><td align="center" valign="top" rowspan="1" colspan="1">False negative (<italic>FN</italic>)</td><td align="center" valign="top" rowspan="1" colspan="1">True negative (<italic>TN</italic>)</td></tr></tbody></table></table-wrap><table-wrap id="t2-ijms-14-22132" position="float"><label>Table 2</label><caption><p>Highest classification accuracy rates reached by the original and the proposed feature selection methods.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="bottom" rowspan="1" colspan="1"/><th colspan="2" align="center" valign="bottom" rowspan="1">Nearest Neighbor</th><th colspan="2" align="center" valign="bottom" rowspan="1">Naive Bayes</th></tr><tr><th align="center" valign="bottom" rowspan="1" colspan="1"/><th colspan="2" align="left" valign="bottom" rowspan="1">
<hr/></th><th colspan="2" align="left" valign="bottom" rowspan="1">
<hr/></th></tr><tr><th align="center" valign="bottom" rowspan="1" colspan="1">Method</th><th align="center" valign="bottom" rowspan="1" colspan="1">Highest Acc_Rate</th><th align="center" valign="bottom" rowspan="1" colspan="1">Dimension</th><th align="center" valign="bottom" rowspan="1" colspan="1">Highest Acc_Rate</th><th align="center" valign="bottom" rowspan="1" colspan="1">Dimension</th></tr></thead><tbody><tr><td align="center" valign="top" rowspan="1" colspan="1">F</td><td align="center" valign="top" rowspan="1" colspan="1">0.9080</td><td align="center" valign="top" rowspan="1" colspan="1">20</td><td align="center" valign="top" rowspan="1" colspan="1">0.8736</td><td align="center" valign="top" rowspan="1" colspan="1">3</td></tr><tr><td align="center" valign="top" rowspan="1" colspan="1">FI</td><td align="center" valign="top" rowspan="1" colspan="1">0.9112</td><td align="center" valign="top" rowspan="1" colspan="1">12</td><td align="center" valign="top" rowspan="1" colspan="1">0.8767</td><td align="center" valign="top" rowspan="1" colspan="1">5</td></tr><tr><td align="center" valign="top" rowspan="1" colspan="1">R</td><td align="center" valign="top" rowspan="1" colspan="1">0.9088</td><td align="center" valign="top" rowspan="1" colspan="1">17</td><td align="center" valign="top" rowspan="1" colspan="1">0.8608</td><td align="center" valign="top" rowspan="1" colspan="1">21</td></tr><tr><td align="center" valign="top" rowspan="1" colspan="1">RI</td><td align="center" valign="top" rowspan="1" colspan="1">0.9096</td><td align="center" valign="top" rowspan="1" colspan="1">17</td><td align="center" valign="top" rowspan="1" colspan="1">0.8608</td><td align="center" valign="top" rowspan="1" colspan="1">3</td></tr><tr><td align="center" valign="top" rowspan="1" colspan="1">G</td><td align="center" valign="top" rowspan="1" colspan="1">0.9080</td><td align="center" valign="top" rowspan="1" colspan="1">21</td><td align="center" valign="top" rowspan="1" colspan="1">0.8624</td><td align="center" valign="top" rowspan="1" colspan="1">19</td></tr><tr><td align="center" valign="top" rowspan="1" colspan="1">GI</td><td align="center" valign="top" rowspan="1" colspan="1">0.9096</td><td align="center" valign="top" rowspan="1" colspan="1">13</td><td align="center" valign="top" rowspan="1" colspan="1">0.8648</td><td align="center" valign="top" rowspan="1" colspan="1">13</td></tr></tbody></table></table-wrap><table-wrap id="t3-ijms-14-22132" position="float"><label>Table 3</label><caption><p>Highest <italic>F</italic>-measure reached by the original and the improved feature selection methods.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="bottom" rowspan="1" colspan="1">Method</th><th align="center" valign="bottom" rowspan="1" colspan="1">Highest <italic>F</italic>-measure (Nearest Neighbor)</th><th align="center" valign="bottom" rowspan="1" colspan="1">Highest <italic>F</italic>-measure (Naive Bayes)</th></tr></thead><tbody><tr><td align="center" valign="top" rowspan="1" colspan="1">F</td><td align="center" valign="top" rowspan="1" colspan="1">0.8144</td><td align="center" valign="top" rowspan="1" colspan="1">0.7817</td></tr><tr><td align="center" valign="top" rowspan="1" colspan="1">FI</td><td align="center" valign="top" rowspan="1" colspan="1">0.8586</td><td align="center" valign="top" rowspan="1" colspan="1">0.8071</td></tr><tr><td align="center" valign="top" rowspan="1" colspan="1">R</td><td align="center" valign="top" rowspan="1" colspan="1">0.8585</td><td align="center" valign="top" rowspan="1" colspan="1">0.7851</td></tr><tr><td align="center" valign="top" rowspan="1" colspan="1">RI</td><td align="center" valign="top" rowspan="1" colspan="1">0.8599</td><td align="center" valign="top" rowspan="1" colspan="1">0.7851</td></tr><tr><td align="center" valign="top" rowspan="1" colspan="1">G</td><td align="center" valign="top" rowspan="1" colspan="1">0.8518</td><td align="center" valign="top" rowspan="1" colspan="1">0.7640</td></tr><tr><td align="center" valign="top" rowspan="1" colspan="1">GI</td><td align="center" valign="top" rowspan="1" colspan="1">0.8579</td><td align="center" valign="top" rowspan="1" colspan="1">0.8003</td></tr></tbody></table></table-wrap><table-wrap id="t4-ijms-14-22132" position="float"><label>Table 4</label><caption><p>Highest classification accuracy rates reached by different feature selection methods.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="bottom" rowspan="1" colspan="1"/><th colspan="2" align="center" valign="bottom" rowspan="1">Nearest Neighbor</th><th colspan="2" align="center" valign="bottom" rowspan="1">Naive Bayes</th></tr><tr><th align="center" valign="bottom" rowspan="1" colspan="1"/><th colspan="2" align="left" valign="bottom" rowspan="1">
<hr/></th><th colspan="2" align="left" valign="bottom" rowspan="1">
<hr/></th></tr><tr><th align="center" valign="bottom" rowspan="1" colspan="1">Method</th><th align="center" valign="bottom" rowspan="1" colspan="1">Highest <italic>Acc_Rate</italic></th><th align="center" valign="bottom" rowspan="1" colspan="1">Dimension</th><th align="center" valign="bottom" rowspan="1" colspan="1">Highest <italic>Acc_Rate</italic></th><th align="center" valign="bottom" rowspan="1" colspan="1">Dimension</th></tr></thead><tbody><tr><td align="center" valign="top" rowspan="1" colspan="1">Constraint Score</td><td align="center" valign="top" rowspan="1" colspan="1">0.908</td><td align="center" valign="top" rowspan="1" colspan="1">21</td><td align="center" valign="top" rowspan="1" colspan="1">0.8639</td><td align="center" valign="top" rowspan="1" colspan="1">19</td></tr><tr><td align="center" valign="top" rowspan="1" colspan="1">Ttest</td><td align="center" valign="top" rowspan="1" colspan="1">0.9096</td><td align="center" valign="top" rowspan="1" colspan="1">19</td><td align="center" valign="top" rowspan="1" colspan="1">0.8728</td><td align="center" valign="top" rowspan="1" colspan="1">2</td></tr><tr><td align="center" valign="top" rowspan="1" colspan="1">FCBF</td><td align="center" valign="top" rowspan="1" colspan="1">0.8072</td><td align="center" valign="top" rowspan="1" colspan="1">/</td><td align="center" valign="top" rowspan="1" colspan="1">0.8584</td><td align="center" valign="top" rowspan="1" colspan="1">/</td></tr><tr><td align="center" valign="top" rowspan="1" colspan="1">MRMR</td><td align="center" valign="top" rowspan="1" colspan="1">0.908</td><td align="center" valign="top" rowspan="1" colspan="1">21</td><td align="center" valign="top" rowspan="1" colspan="1">0.868</td><td align="center" valign="top" rowspan="1" colspan="1">1</td></tr><tr><td align="center" valign="top" rowspan="1" colspan="1">Our algorithm (FI)</td><td align="center" valign="top" rowspan="1" colspan="1">0.9112</td><td align="center" valign="top" rowspan="1" colspan="1">12</td><td align="center" valign="top" rowspan="1" colspan="1">0.8767</td><td align="center" valign="top" rowspan="1" colspan="1">5</td></tr></tbody></table></table-wrap><table-wrap id="t5-ijms-14-22132" position="float"><label>Table 5</label><caption><p>Optimal <italic>F</italic>-measure values reached by different feature selection methods.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="bottom" rowspan="1" colspan="1">Method</th><th align="center" valign="bottom" rowspan="1" colspan="1"><italic>F</italic>-measure (Nearest Neighbor)</th><th align="center" valign="bottom" rowspan="1" colspan="1"><italic>F</italic>-measure (Naive Bayes)</th></tr></thead><tbody><tr><td align="center" valign="top" rowspan="1" colspan="1">Constraint Score</td><td align="center" valign="top" rowspan="1" colspan="1">0.8388</td><td align="center" valign="top" rowspan="1" colspan="1">0.7588</td></tr><tr><td align="center" valign="top" rowspan="1" colspan="1">Ttest</td><td align="center" valign="top" rowspan="1" colspan="1">0.8046</td><td align="center" valign="top" rowspan="1" colspan="1">0.7825</td></tr><tr><td align="center" valign="top" rowspan="1" colspan="1">FCBF</td><td align="center" valign="top" rowspan="1" colspan="1">0.5416</td><td align="center" valign="top" rowspan="1" colspan="1">0.7730</td></tr><tr><td align="center" valign="top" rowspan="1" colspan="1">MRMR</td><td align="center" valign="top" rowspan="1" colspan="1">0.7723</td><td align="center" valign="top" rowspan="1" colspan="1">0.7721</td></tr><tr><td align="center" valign="top" rowspan="1" colspan="1">Our algorithm (FI)</td><td align="center" valign="top" rowspan="1" colspan="1">0.8586</td><td align="center" valign="top" rowspan="1" colspan="1">0.8071</td></tr></tbody></table></table-wrap><table-wrap id="t6-ijms-14-22132" position="float"><label>Table 6</label><caption><p>Description of the input synthetic factors.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="bottom" rowspan="1" colspan="1">Category</th><th align="center" valign="bottom" rowspan="1" colspan="1">ID</th><th align="left" valign="bottom" rowspan="1" colspan="1">Description</th></tr></thead><tbody><tr><td align="center" valign="top" rowspan="4" colspan="1">Gel composition</td><td align="center" valign="top" rowspan="1" colspan="1">F1</td><td align="left" valign="top" rowspan="1" colspan="1">The molar amount of Al<sub>2</sub>O<sub>3</sub> in the gel composition</td></tr><tr><td align="center" valign="top" rowspan="1" colspan="1">F2</td><td align="left" valign="top" rowspan="1" colspan="1">The molar amount of P<sub>2</sub>O<sub>5</sub> in the gel composition</td></tr><tr><td align="center" valign="top" rowspan="1" colspan="1">F3</td><td align="left" valign="top" rowspan="1" colspan="1">The molar amount of solvent in the gel composition</td></tr><tr><td align="center" valign="top" rowspan="1" colspan="1">F4</td><td align="left" valign="top" rowspan="1" colspan="1">The molar amount of template in the gel composition</td></tr><tr><td colspan="3" align="left" valign="top" rowspan="1">
<hr/></td></tr><tr><td align="center" valign="top" rowspan="6" colspan="1">Solvent</td><td align="center" valign="top" rowspan="1" colspan="1">F5</td><td align="left" valign="top" rowspan="1" colspan="1">The density</td></tr><tr><td align="center" valign="top" rowspan="1" colspan="1">F6</td><td align="left" valign="top" rowspan="1" colspan="1">The melting point</td></tr><tr><td align="center" valign="top" rowspan="1" colspan="1">F7</td><td align="left" valign="top" rowspan="1" colspan="1">The boiling point</td></tr><tr><td align="center" valign="top" rowspan="1" colspan="1">F8</td><td align="left" valign="top" rowspan="1" colspan="1">The dielectric constant</td></tr><tr><td align="center" valign="top" rowspan="1" colspan="1">F9</td><td align="left" valign="top" rowspan="1" colspan="1">The dipole moment</td></tr><tr><td align="center" valign="top" rowspan="1" colspan="1">F10</td><td align="left" valign="top" rowspan="1" colspan="1">The polarity</td></tr><tr><td colspan="3" align="left" valign="top" rowspan="1">
<hr/></td></tr><tr><td align="center" valign="top" rowspan="11" colspan="1">Organic template</td><td align="center" valign="top" rowspan="1" colspan="1">F11</td><td align="left" valign="top" rowspan="1" colspan="1">The longest distance of organic template</td></tr><tr><td align="center" valign="top" rowspan="1" colspan="1">F12</td><td align="left" valign="top" rowspan="1" colspan="1">The second longest distance of organic template</td></tr><tr><td align="center" valign="top" rowspan="1" colspan="1">F13</td><td align="left" valign="top" rowspan="1" colspan="1">The shortest distance of organic template</td></tr><tr><td align="center" valign="top" rowspan="1" colspan="1">F14</td><td align="left" valign="top" rowspan="1" colspan="1">The Van der Waals volume</td></tr><tr><td align="center" valign="top" rowspan="1" colspan="1">F15</td><td align="left" valign="top" rowspan="1" colspan="1">The dipole moment</td></tr><tr><td align="center" valign="top" rowspan="1" colspan="1">F16</td><td align="left" valign="top" rowspan="1" colspan="1">The ratio of <italic>C/N</italic></td></tr><tr><td align="center" valign="top" rowspan="1" colspan="1">F17</td><td align="left" valign="top" rowspan="1" colspan="1">The ratio of <italic>N/</italic>(<italic>C</italic> + <italic>N</italic>)</td></tr><tr><td align="center" valign="top" rowspan="1" colspan="1">F18</td><td align="left" valign="top" rowspan="1" colspan="1">The ratio of <italic>N</italic>/Van der Waals volume</td></tr><tr><td align="center" valign="top" rowspan="1" colspan="1">F19</td><td align="left" valign="top" rowspan="1" colspan="1">The Sanderson electronegativity</td></tr><tr><td align="center" valign="top" rowspan="1" colspan="1">F20</td><td align="left" valign="top" rowspan="1" colspan="1">The number of free rotated single bond</td></tr><tr><td align="center" valign="top" rowspan="1" colspan="1">F21</td><td align="left" valign="top" rowspan="1" colspan="1">The maximal number of protonated H atoms</td></tr></tbody></table></table-wrap><table-wrap id="t7-ijms-14-22132" position="float"><label>Algorithm 1</label><caption><p>The feature selection process of the proposed method.</p></caption><table frame="box" rules="none"><tbody><tr><td align="left" valign="top" rowspan="1" colspan="1">Input: The original data sample <italic>D</italic>.<break/>Output: The indicator vector <italic>f</italic>.<break/>1. Compute scores of features <italic>S</italic> and correlation matrix <italic>C</italic>.<break/>2. Initialize <italic>f</italic>;<break/>3. Do<break/>4. Select <italic>P</italic><italic><sub>i</sub></italic> &#x003b5; <italic>U</italic><sub>1</sub> &#x0222a; <italic>U</italic><sub>2</sub> which has the largest reward <italic>r</italic><italic><sub>i</sub></italic>(<italic>f</italic>);<break/>5. Select <italic>P</italic><italic><sub>j</sub></italic> &#x003b5; <italic>U</italic><sub>2</sub> &#x0222a;<italic>U</italic><sub>3</sub> which has the smallest reward <italic>r</italic><italic><sub>j</sub></italic>(<italic>f</italic>);<break/>6. if <italic>r</italic><italic><sub>i</sub></italic>(<italic>f</italic>) &#x0003e; <italic>r</italic><italic><sub>j</sub></italic>(<italic>f</italic>)<break/>Compute &#x003b1; using <xref rid="fd11-ijms-14-22132" ref-type="disp-formula">Equation (11)</xref>, and then update <italic>f</italic><italic><sub>i</sub></italic> and <italic>f</italic><italic><sub>j</sub></italic> according to <xref rid="fd8-ijms-14-22132" ref-type="disp-formula">Equation (8)</xref>;<break/>7. else if <italic>r</italic><italic><sub>i</sub></italic>(<italic>f</italic>) = <italic>r</italic><italic><sub>j</sub></italic>(<italic>f</italic>)<break/>8. if 2<italic>C</italic><italic><sub>ij</sub></italic> &#x02212; <italic>C</italic><italic><sub>ii</sub></italic> &#x02212; <italic>C</italic><italic><sub>jj</sub></italic> &#x0003e; 0<break/>Compute &#x003b1; using <xref rid="fd11-ijms-14-22132" ref-type="disp-formula">Equation (11)</xref>, and then update <italic>f</italic><italic><sub>i</sub></italic> and <italic>f</italic><italic><sub>j</sub></italic> according to <xref rid="fd8-ijms-14-22132" ref-type="disp-formula">Equation (8)</xref>;<break/>9. else if 2<italic>C</italic><italic><sub>ij</sub></italic> &#x02212; <italic>C</italic><italic><sub>ii</sub></italic> &#x02212; <italic>C</italic><italic><sub>jj</sub></italic> = 0<break/>Check whether there exist a <italic>P</italic><sub>0</sub> &#x003b5; <italic>U</italic><sub>1</sub> &#x0222a; <italic>U</italic><sub>2</sub> and a <italic>P</italic><italic><sub>x</sub></italic> &#x003b5; <italic>U</italic><sub>2</sub> &#x0222a; <italic>U</italic><sub>3</sub> such that 2<italic>C</italic><italic><sub>ox</sub></italic> &#x02212; <italic>C</italic><italic><sub>oo</sub></italic> &#x02212; <italic>C</italic><italic><sub>xx</sub></italic> &#x0003e; 0 and <italic>r</italic><italic><sub>o</sub></italic>(<italic>f</italic>) = <italic>r</italic><italic><sub>x</sub></italic>(<italic>f</italic>). If the pair (<italic>P</italic><italic><sub>o</sub></italic>, <italic>P</italic><italic><sub>x</sub></italic>) can be found, Compute &#x003b1; using <xref rid="fd11-ijms-14-22132" ref-type="disp-formula">Equation (11)</xref>, and then update <italic>f</italic><italic><sub>o</sub></italic> and <italic>f</italic><italic><sub>x</sub></italic> according to <xref rid="fd8-ijms-14-22132" ref-type="disp-formula">Equation (8)</xref>; Otherwise, <italic>f</italic> is a solution of <xref rid="fd4-ijms-14-22132" ref-type="disp-formula">Equation (4)</xref>;<break/>10. end if<break/>11. end if<break/>12. until <italic>f</italic> is a solution of <xref rid="fd4-ijms-14-22132" ref-type="disp-formula">Equation (4)</xref>.</td></tr></tbody></table></table-wrap></floats-group></article>