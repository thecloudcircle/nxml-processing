
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">Front Comput Neurosci</journal-id><journal-id journal-id-type="iso-abbrev">Front Comput Neurosci</journal-id><journal-id journal-id-type="publisher-id">Front. Comput. Neurosci.</journal-id><journal-title-group><journal-title>Frontiers in Computational Neuroscience</journal-title></journal-title-group><issn pub-type="epub">1662-5188</issn><publisher><publisher-name>Frontiers Media S.A.</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">32132915</article-id><article-id pub-id-type="pmc">7041413</article-id><article-id pub-id-type="doi">10.3389/fncom.2020.00012</article-id><article-categories><subj-group subj-group-type="heading"><subject>Neuroscience</subject><subj-group><subject>Original Research</subject></subj-group></subj-group></article-categories><title-group><article-title>Adaptive Tuning Curve Widths Improve Sample Efficient Learning</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Meier</surname><given-names>Florian</given-names></name><xref ref-type="corresp" rid="c001"><sup>*</sup></xref><uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/782931/overview"/></contrib><contrib contrib-type="author"><name><surname>Dang-Nhu</surname><given-names>Rapha&#x000eb;l</given-names></name><uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/781197/overview"/></contrib><contrib contrib-type="author"><name><surname>Steger</surname><given-names>Angelika</given-names></name></contrib></contrib-group><aff><institution>Department of Computer Science, ETH Z&#x000fc;rich</institution>, <addr-line>Zurich</addr-line>, <country>Switzerland</country></aff><author-notes><fn fn-type="edited-by"><p>Edited by: Rava Azeredo da Silveira, &#x000c9;cole Normale Sup&#x000e9;rieure, France</p></fn><fn fn-type="edited-by"><p>Reviewed by: Artur Luczak, University of Lethbridge, Canada; Cheng Qiu, University of Pennsylvania, United States; Jiang Mao, University of Pennsylvania, United States, in collaboration with reviewer CQ</p></fn><corresp id="c001">*Correspondence: Florian Meier <email>meierflo@inf.ethz.ch</email></corresp></author-notes><pub-date pub-type="epub"><day>18</day><month>2</month><year>2020</year></pub-date><pub-date pub-type="collection"><year>2020</year></pub-date><volume>14</volume><elocation-id>12</elocation-id><history><date date-type="received"><day>20</day><month>8</month><year>2019</year></date><date date-type="accepted"><day>29</day><month>1</month><year>2019</year></date></history><permissions><copyright-statement>Copyright &#x000a9; 2020 Meier, Dang-Nhu and Steger.</copyright-statement><copyright-year>2020</copyright-year><copyright-holder>Meier, Dang-Nhu and Steger</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</license-p></license></permissions><abstract><p>Natural brains perform miraculously well in learning new tasks from a small number of samples, whereas sample efficient learning is still a major open problem in the field of machine learning. Here, we raise the question, how the neural coding scheme affects sample efficiency, and make first progress on this question by proposing and analyzing a learning algorithm that uses a simple reinforce-type plasticity mechanism and does not require any gradients to learn low dimensional mappings. It harnesses three bio-plausible mechanisms, namely, population codes with bell shaped tuning curves, continous attractor mechanisms and probabilistic synapses, to achieve sample efficient learning. We show both theoretically and by simulations that population codes with broadly tuned neurons lead to high sample efficiency, whereas codes with sharply tuned neurons account for high final precision. Moreover, a dynamic adaptation of the tuning width during learning gives rise to both, high sample efficiency and high final precision. We prove a sample efficiency guarantee for our algorithm that lies within a logarithmic factor from the information theoretical optimum. Our simulations show that for low dimensional mappings, our learning algorithm achieves comparable sample efficiency to multi-layer perceptrons trained by gradient descent, although it does not use any gradients. Furthermore, it achieves competitive sample efficiency in low dimensional reinforcement learning tasks. From a machine learning perspective, these findings may inspire novel approaches to improve sample efficiency. From a neuroscience perspective, these findings suggest sample efficiency as a yet unstudied functional role of adaptive tuning curve width.</p></abstract><kwd-group><kwd>sample efficiency</kwd><kwd>neural tuning curves</kwd><kwd>population codes</kwd><kwd>gradient-free learning</kwd><kwd>reinforcement learning</kwd></kwd-group><funding-group><award-group><funding-source id="cn001">Schweizerischer Nationalfonds zur F&#x000f6;rderung der Wissenschaftlichen Forschung<named-content content-type="fundref-id">10.13039/501100001711</named-content></funding-source></award-group></funding-group><counts><fig-count count="5"/><table-count count="2"/><equation-count count="3"/><ref-count count="103"/><page-count count="13"/><word-count count="10984"/></counts></article-meta></front><body><sec sec-type="intro" id="s1"><title>1. Introduction</title><p>Humans operate in a rich and complex world and are extremely fast in learning new tasks and adapting to new environments. The level of generalization and speed of adaptation achieved by human brains remain unmatched by machine learning approaches, despite tremendous progress in the last years. How do real brains accomplish this outstanding skill of generalization and sample efficient learning, and what are the neural mechanisms that contribute to this ability of fast learning? Here, we investigate how neural coding supports sample efficient learning, by analyzing a learning algorithm that exploits three bio-plausible principles for sample efficient learning, namely, population codes of tuned neurons, continuous attractor mechanisms and probabilistic synapses.</p><p>From early on, neuroscience researchers characterized the first order response of single neurons by neural tuning curves (Adrian and Zotterman, <xref rid="B1" ref-type="bibr">1926</xref>). The <italic>neural tuning curve</italic> is defined to be the neurons mean firing rate as a function of some stimuli parameter. It typically peaks for a preferred parameter value and decays gradually as this parameter moves away from the preferred value, such as in orientation columns in the visual cortex (Hubel and Wiesel, <xref rid="B38" ref-type="bibr">1959</xref>, <xref rid="B39" ref-type="bibr">1962</xref>), spatially tuned cells in auditory cortex (Knudsen and Konishi, <xref rid="B47" ref-type="bibr">1978</xref>), direction selective cells in motor cortex (Georgopoulos et al., <xref rid="B31" ref-type="bibr">1988</xref>) and hippocampal place and head direction cells (O'Keefe, <xref rid="B62" ref-type="bibr">1976</xref>; Ranck, <xref rid="B67" ref-type="bibr">1985</xref>). In populations of tuned neurons, narrow (broad) tuning curves imply that a small (large) fraction of neurons is active for a given stimuli parameter. Here, we assume that such neural populations are geometrically ordered according to the neuron's preferred parameter value. Then, the neural activity resembles a localized bump activation like experimentally observed in the compass system of the drosophila fly (Seelig and Jayaraman, <xref rid="B81" ref-type="bibr">2015</xref>; Kim et al., <xref rid="B44" ref-type="bibr">2017</xref>) and theoretically studied in continuous attractor models (Wilson and Cowan, <xref rid="B100" ref-type="bibr">1973</xref>; Amari, <xref rid="B3" ref-type="bibr">1977</xref>; Ben-Yishai et al., <xref rid="B9" ref-type="bibr">1995</xref>; Skaggs et al., <xref rid="B85" ref-type="bibr">1995</xref>; Seeholzer et al., <xref rid="B80" ref-type="bibr">2017</xref>). In this coding scheme, which we call <italic>bump coding scheme</italic>, the center of a bump activation corresponds to the parameter value encoded by the bump activation (see <xref ref-type="fig" rid="F1">Figure 1A</xref>), and the width of the bump is determined by the number of active neurons in the bump. Further, we assume that neural populations are equipped with a <italic>continuous attractor mechanism</italic> that ensures that only one bump is active at a time. Continuous attractor mechanisms are an established model of cortical working memory (Seeholzer et al., <xref rid="B80" ref-type="bibr">2017</xref>), and emerge from the wiring motive of local excitation and long range inhibition (Kim et al., <xref rid="B44" ref-type="bibr">2017</xref>). As another bio-plausible ingredient, we use <italic>probabilistic synapses</italic>. We assume a simple synaptic model consisting of a plastic synaptic probability <italic>p</italic> and a synaptic weight <italic>w</italic>, which we fix to 1 in order to concentrate on our main ideas. The synaptic probability corresponds to the pre-synaptic neuro-transmitter release probability and the weight <italic>w</italic> to the post-synaptic quantal amplitude (Llera-Montero et al., <xref rid="B55" ref-type="bibr">2019</xref>). The neuro-transmitter release probability of synapses in the brain is highly variable and typically between 0.1 and 0.9 (Branco and Staras, <xref rid="B17" ref-type="bibr">2009</xref>).</p><fig id="F1" position="float"><label>Figure 1</label><caption><p>Bump coding scheme and model setup. <bold>(A)</bold> A neural population encoding a 2-dimensional parameter. The dots represent neurons. The blue neurons indicate a bump activation with center neuron <italic>j</italic> encoding the value (0.3, 0.6). The brown shaded area visualizes the parameter values for which neuron <italic>i</italic> is active. <bold>(B)</bold> Network setup. Two populations <italic>A</italic> and <italic>B</italic> of neurons both encoding a one-dimensional parameter are connected by probabilistic synapses <italic>P</italic>. The green input bump <italic>I</italic><sub>1</sub> with center <italic>x</italic> and width <italic>k</italic><sub><italic>A</italic></sub> activated the green output bump <italic>J</italic><sub>1</sub> with center <italic>y</italic> and width <italic>k</italic><sub><italic>B</italic></sub>. The shaded area between the two bumps visualizes the <italic>k</italic><sub><italic>A</italic></sub>&#x000b7;<italic>k</italic><sub><italic>B</italic></sub> synapses that are updated according to the error feedback <italic>L</italic>(<italic>x, y</italic>). <bold>(C)</bold> The neural populations <italic>A</italic> and <italic>B</italic> are aligned on the <italic>x</italic>- and <italic>y</italic>-axis, respectively, such that the synapses connecting population <italic>A</italic> to <italic>B</italic> are visualized by the (<italic>x, y</italic>)-space. The red area around the function <italic>f</italic>(<italic>x</italic>) indicates for each input <italic>x</italic> the <italic>y</italic> values that receive error feedback <italic>L</italic> smaller than some error threshold <inline-formula><mml:math id="M1"><mml:mover accent="true"><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula>. If an input output pair (<italic>x, y</italic>) is inside the red area (e.g., for the blue sample activation), then the theoretical bump algorithm increments the synaptic counters of the synapses between the bumps. Otherwise (e.g., for the green sample activation) it decrements the synaptic counters for the synapses between the bumps.</p></caption><graphic xlink:href="fncom-14-00012-g0001"/></fig><p>We explain now with a sample application, how these three bio-inspired principles are integrated into a reinforce-type (Williams, <xref rid="B99" ref-type="bibr">1992</xref>), gradient-free learning mechanism. Assume that a robot arm with two joints should learn to reach given target positions <italic>x</italic> = (<italic>x</italic><sub>1</sub>, <italic>x</italic><sub>2</sub>) by applying the correct angles &#x00177; = (&#x003b1;, &#x003b2;) to the joints, such that they reach the given target position <italic>x</italic>. Consider two populations of neurons <italic>A</italic> and <italic>B</italic> connected by probabilistic synapses. Population <italic>A</italic> and <italic>B</italic> use the bump coding scheme to encode the target position <italic>x</italic> and the angles <italic>y</italic> that are applied to the two joints, respectively, see <xref ref-type="fig" rid="F1">Figure 1B</xref>. The goal is to adapt the synaptic probabilities such that every target position <italic>x</italic> is mapped to the correct angles &#x00177;. A bump activation encoding <italic>x</italic> in population <italic>A</italic> is propagated via probabilistic synapses to population <italic>B</italic>, where an abstract continuous attractor mechanism ensures that a single bump remains active in <italic>B</italic>. Its center <italic>y</italic> encodes the applied angles (&#x003b1;, &#x003b2;). Note that <italic>y</italic> usually varies from trial to trial since the synapses between population <italic>A</italic> and <italic>B</italic> are probabilistic. According to the final arm position, the network receives a scalar error feedback <italic>L</italic>(<italic>x, y</italic>), that depends on the input <italic>x</italic> and the output <italic>y</italic> generated by the network. Then, the synaptic probabilities between the bumps in population <italic>A</italic> and <italic>B</italic> are updated depending to this error feedback. The larger the bump width <italic>k</italic> is, the more synapses are between the two bumps, whose probabilities are all updated according to the same error feedback. In this way, the network exploits the continuity of the task for sample efficient learning.</p><p>Related to this work, populations of tuned neurons have been used to learn sensory-motor transformations (Bullock et al., <xref rid="B23" ref-type="bibr">1993</xref>; Salinas and Abbott, <xref rid="B70" ref-type="bibr">1995</xref>; Baraduc et al., <xref rid="B6" ref-type="bibr">2001</xref>; Baraduc and Guigon, <xref rid="B5" ref-type="bibr">2002</xref>; Sanger, <xref rid="B75" ref-type="bibr">2003</xref>), extending and building on the investigation of radial basis networks conducted in the 1980s and 1990s (Klopfenstein and Sverdlove, <xref rid="B45" ref-type="bibr">1983</xref>; Broomhead and Lowe, <xref rid="B19" ref-type="bibr">1988</xref>; Sanger, <xref rid="B72" ref-type="bibr">1991</xref>, <xref rid="B73" ref-type="bibr">1997</xref>, <xref rid="B74" ref-type="bibr">1998</xref>; Pouget et al., <xref rid="B65" ref-type="bibr">1998</xref>). These studies use Hebbian plasticity mechanisms, that require simultaneous activation of inputs and target outputs, whereas we propose reinforce-type learning algorithms, that learn the correct outputs through exploration of the output space. Furthermore, the investigation of the relation between sample efficiency and tuning curve width is novel.</p><p>The main contributions of this paper are summarized as follows. We introduce a reinforce-type learning algorithm that exploits the bump coding scheme, abstract continuous attractor mechanisms and probabilistic synapses for sample efficient learning of general low dimensional mappings. We show theoretically and by simulations that if the bump width is static during learning, then large bump width improves sample efficiency but harms the final precision, whereas small width impairs sample efficiency but improves final precision. Benefits of both are accomplished, if the bump width is dynamically decreased during the learning progress. Moreover, we show that the obtained sample efficiency is asymptotically optimal up to a log<italic>n</italic> factor in the limit of large population size <italic>n</italic>. For low dimensional mappings, the bump coding scheme achieves similar performance as a multi-layer perceptron trained by the backpropagation algorithm (Rumelhart et al., <xref rid="B69" ref-type="bibr">1985</xref>), and it outperforms a multi-layer perceptron trained by the reinforce algorithm (Williams, <xref rid="B99" ref-type="bibr">1992</xref>). It also achieves competitive performance on low dimensional reinforcement learning environments. Finally, we relate our findings to experimental observations of decreasing tuning curve width during learning and conclude that our findings propose sample efficiency as a functional role of the tuning curve width.</p></sec><sec sec-type="results" id="s2"><title>2. Results</title><p>Assume that a network consisting of populations <italic>A</italic> and <italic>B</italic> should learn a mapping <inline-formula><mml:math id="M2"><mml:mi>f</mml:mi><mml:mo>:</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup><mml:mo>&#x02192;</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:math></inline-formula>, e.g., mapping target position <inline-formula><mml:math id="M3"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> to joint angles (&#x003b1;, &#x003b2;) as illustrated in the robotic arm task of the introduction. We consider general mappings <italic>f</italic>, that are only restricted to be Lipschitz continuous<xref ref-type="fn" rid="fn0001"><sup>1</sup></xref>. This general framework, can be applied to many tasks including reinforcement learning as demonstrated in section 2.2. Populations <italic>A</italic> and <italic>B</italic>, are connected by probabilistic synapses and encode input <italic>x</italic> and output <italic>y</italic>, respectively, using a bump coding scheme, see <xref ref-type="fig" rid="F1">Figure 1</xref> and section 3.1 for a formal description. The goal is to learn the plastic synaptic probabilities, whereas synaptic weights are assumed to be fixed. The implicit goal of our learning algorithm is that a neuron <italic>x</italic> in population <italic>A</italic> keeps all synapses to the neurons <italic>y</italic> in <italic>B</italic> for which |<italic>y</italic> &#x02212; <italic>f</italic>(<italic>x</italic>)| is small and decreases the synaptic probabilities of all other synapses, see <xref ref-type="fig" rid="F1">Figure 1C</xref>. This will ensure that a bump <italic>x</italic> in population <italic>A</italic> activates a bump with center <italic>y</italic> close to <italic>f</italic>(<italic>x</italic>) in population <italic>B</italic>.</p><p>We begin by stating our theoretical results in section 2.1 before presenting the results obtained by simulations in section 2.2. For the theoretical results, we use a simplified version of the algorithm used in the simulations, because it allows a rigorous mathematical analysis and it illustrates the conceptual ideas of the algorithm. Both algorithm use the same basic principles and behave qualitatively the same.</p><sec><title>2.1. Theoretical Results</title><p>We consider the following learning mechanism with fixed bump width <italic>k</italic> involving synaptic counters that are initialized with 0. We refer to a neuron with preferred parameter value <italic>x</italic> as neuron <italic>x</italic> and to a bump with center <italic>x</italic> as bump <italic>x</italic>. For every sample, a random input bump <italic>x</italic> is activated. The probabilistic synapses propagate the activity in <italic>A</italic> to population <italic>B</italic>, where an abstract continuous attractor mechanism activates the bump <italic>y</italic> in <italic>B</italic> that received highest synaptic input. The algorithm receives a scalar error feedback <italic>L</italic>(<italic>x, y</italic>) that depends on input <italic>x</italic> and the output <italic>y</italic>, e.g., the euclidean distance between output <italic>y</italic> and target output <italic>f</italic>(<italic>x</italic>). Then, the counters of the synapses between the two active bumps are decremented by 1 if the error feedback <italic>L</italic>(<italic>x, y</italic>) is larger than some error threshold <inline-formula><mml:math id="M4"><mml:mover accent="true"><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula> and incremented otherwise, see <xref ref-type="fig" rid="F1">Figure 1C</xref>. After observing proportional <inline-formula><mml:math id="M5"><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:mfrac></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup><mml:mo class="qopname">log</mml:mo><mml:mi>n</mml:mi></mml:math></inline-formula> many samples, we prune all synapses with non-positive counters, that is, we set their synaptic probabilities to 0. For a formal description of the algorithm, we refer to section 3.</p><p>We define the <italic>error</italic> of a learned network to be the expected error feedback &#x1d53c;[<italic>L</italic>(<italic>x, y</italic>)] if the input is randomly chosen. If the mapping <italic>f</italic> is Lipschitz continous and the network obtains the euclidean distance <italic>L</italic>(<italic>x, y</italic>) = &#x02225;<italic>y</italic> &#x02212; <italic>f</italic>(<italic>x</italic>)&#x02225;<sub>2</sub> as error feedback, the following theorems hold.</p><p>Theorem 1 (Static bump width <italic>k</italic>). <italic>The learning algorithm with static bump width <italic>k</italic> and euclidean error feedback learns a mapping</italic>
<inline-formula><mml:math id="M6"><mml:mi>f</mml:mi><mml:mo>:</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup><mml:mo>&#x02192;</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:math></inline-formula>
<italic>with error smaller than</italic>
<inline-formula><mml:math id="M7"><mml:mfrac><mml:mrow><mml:mn>3</mml:mn><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mfrac></mml:math></inline-formula>
<italic>after proportional to</italic>
<inline-formula><mml:math id="M8"><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:mfrac></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup><mml:mtext>&#x000a0;log&#x000a0;</mml:mtext><mml:mi>n</mml:mi></mml:math></inline-formula>
<italic>many random samples, where <italic>n</italic> is the population size</italic>.</p><p>The approach with static bump width <italic>k</italic> ensures that each neuron <italic>x</italic> maintains the synapses to a small continuous interval of output neurons around value <italic>f</italic>(<italic>x</italic>) and prunes away the other synapses. Thus, we can reapply the same learning mechanism, this time with smaller bump width <italic>k</italic> and smaller error threshold <inline-formula><mml:math id="M9"><mml:mover accent="true"><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula> (for a formal description see section 3). Repeating this procedure will cause an input bump <italic>x</italic> to be mapped to a random bump <italic>y</italic> from a shrinking and shrinking interval around <italic>f</italic>(<italic>x</italic>). This yields the following theorem.</p><p>Theorem 2 (Dynamic bump width <italic>k</italic>). <italic>The learning algorithm with dynamic bump width and euclidean error feedback learns the mapping</italic>
<inline-formula><mml:math id="M10"><mml:mi>f</mml:mi><mml:mo>:</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup><mml:mo>&#x02192;</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:math></inline-formula>
<italic>with error smaller than &#x003b5; after proportional to</italic>
<inline-formula><mml:math id="M11"><mml:msup><mml:mrow><mml:mi>&#x003b5;</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup><mml:mtext>&#x000a0;log&#x000a0;</mml:mtext><mml:mi>n</mml:mi></mml:math></inline-formula>
<italic>many random samples, where n is the population size</italic>.</p><p>We conclude that in order to reach error <inline-formula><mml:math id="M12"><mml:mi>&#x003b5;</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>3</mml:mn><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mfrac></mml:math></inline-formula> the dynamic bump algorithm requires proportional to <inline-formula><mml:math id="M13"><mml:msup><mml:mrow><mml:mi>&#x003b5;</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:math></inline-formula> times less samples than the static bump algorithm with bump width <italic>k</italic>. We remark that above results generalize to circular input and output spaces, that encode for example head direction or orientation angles, see the <xref ref-type="supplementary-material" rid="SM1">Supplementary Material</xref> for more details. Our proofs show that it is not necessary that above algorithms obtain the precise Euclidean distance as error feedback, but rather one bit of feedback suffices, if it indicates whether the Euclidean distance is larger than the error threshold <inline-formula><mml:math id="M14"><mml:mover accent="true"><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula> or not. For such an algorithm, a lower bound on the sample efficiency can be obtained by an entropy argument.</p><p>Theorem 3 (Lower Bound). <italic>For any algorithm that obtains only a single bit of feedback per sample, there are Lipschitz continuous mappings</italic>
<inline-formula><mml:math id="M15"><mml:mi>f</mml:mi><mml:mo>:</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup><mml:mo>&#x02192;</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:math></inline-formula>, <italic>such that the algorithm requires at least proportional to</italic>
<inline-formula><mml:math id="M16"><mml:msup><mml:mrow><mml:mi>&#x003b5;</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:math></inline-formula>
<italic>many samples to learn f with error smaller than &#x003b5;</italic>.</p><p>Then, Theorem 2 and 3 imply that the learning mechanism with dynamic <italic>k</italic> accomplishes a sample efficiency that is asymptotically optimal up to a log<italic>n</italic> factor. For the proofs of these theorems, we refer to the <xref ref-type="supplementary-material" rid="SM1">Supplementary Material</xref>.</p></sec><sec><title>2.2. Empirical Results</title><p>For the simulations, we use a slightly more sophisticated learning algorithm that follows the same underlying principles, but differs from the algorithm that we analyze theoretically in five aspects. Firstly, it is designed to handle more general error feedback functions. For example, in the robotic arm task of the introduction, the error feedback is not given by the euclidean distance between the output angles, but by the distance between the reached position and the target position. In turn, the magnitude of the error feedback can change for different inputs, and a single error threshold <inline-formula><mml:math id="M17"><mml:mover accent="true"><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula> will not allow fast learning for all inputs. To resolve this issue, we assume that every input neuron <italic>i</italic> keeps track of a running mean <inline-formula><mml:math id="M18"><mml:mover accent="true"><mml:mrow><mml:msup><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula> of the error feedbacks that were obtained when <italic>i</italic> was active. For the update of the outgoing synapses of neuron <italic>i</italic>, <inline-formula><mml:math id="M19"><mml:mover accent="true"><mml:mrow><mml:msup><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula> is compared to the error feedback <italic>L</italic>. Secondly, if <inline-formula><mml:math id="M20"><mml:mi>L</mml:mi><mml:mo>&#x02265;</mml:mo><mml:mover accent="true"><mml:mrow><mml:msup><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula> for a neuron <italic>i</italic> of the bump in population <italic>A</italic>, the synapses projecting from neuron <italic>i</italic> on the bump in population <italic>B</italic> are pruned away immediately. Thirdly, for the dynamic case, the bump width <italic>k</italic> is adapted continuously instead of repeatingly applying the static algorithm. Since the learning progress might vary for different input regimes, we allow <italic>k</italic> to depend on the input, and we set <italic>k</italic> for input <italic>x</italic> proportional to the number of outgoing synapses of neuron <italic>x</italic>. Note that this number is a reasonable measure of how well input <italic>x</italic> is already learned as the precision of the output depends on the magnitude of the interval of synapses connecting <italic>x</italic> to neurons around <italic>f</italic>(<italic>x</italic>). Fourthly, long-time inactive synapses are pruned away, i.e., they are pruned if the post-synaptic neuron has not been active for a couple of times when the pre-synaptic neuron was active. Finally, synapses of neuron <italic>i</italic> are consolidated (that is its probability is set to 1) if its number of synapses drops below a certain threshold value. We call this algorithm the <italic>dynamic bump algorithm</italic>. We refer to section 3 for a formal description of the algorithm and to <xref ref-type="fig" rid="F2">Figure 2</xref> for an illustration of the evolution of the synaptic probabilities.</p><fig id="F2" position="float"><label>Figure 2</label><caption><p>Evolution of synaptic probabilities when learning a one dimensional mapping <italic>f</italic>(<italic>x</italic>) = <italic>x</italic><sup>2</sup> &#x02212; 3<italic>x</italic> + 1 with the dynamic bump algorithm. Each small color plot displays the synaptic probabilities, where input neuron is on the <italic>x</italic>-axis and output neuron on the <italic>y</italic>-axis. Blue areas visualize pruned synapses, yellow areas visualize consolidated synapses. Input and output population consist of 100 neurons each and the output bump is 3 times as large as the input bump.</p></caption><graphic xlink:href="fncom-14-00012-g0002"/></fig><p>The <italic>static bump algorithm</italic> works analogously to the dynamic bump algorithm, except that <italic>k</italic> is held constant during the whole algorithm. <xref ref-type="fig" rid="F3">Figure 3</xref> empirically confirms the trade-off between sample efficiency and final performance for static bump width <italic>k</italic>. Larger <italic>k</italic> leads to faster learning compared to smaller <italic>k</italic>, however reaches worse final error. The advantages of both large and small <italic>k</italic> can be exploited by adapting the bump width dynamically during the learning process, see <xref ref-type="fig" rid="F3">Figure 3</xref>.</p><fig id="F3" position="float"><label>Figure 3</label><caption><p>Sample efficiency vs. final error trade-off for static bump width <italic>k</italic>. Recall that the error is defined to be the expected error feedback if the input is randomly chosen. Plot <bold>(A)</bold> shows the evolution of the error of the static bump algorithm for different <italic>k</italic>, when learning the one-dimensional identity mapping <italic>f</italic>(<italic>x</italic>) = <italic>x</italic> with euclidean error feedback. The dynamic bump algorithm, is labeled as &#x0201c;dynamic <italic>k</italic>.&#x0201d; Plot <bold>(B)</bold> shows the minimal error against the number of training samples required to reach this error for different <italic>k</italic> (given as number next to the blue data points); to avoid taking into account the slow progress before final convergence, the number of samples required to achieve 1.5 times the final error is plotted. Analogously, we plot the number of samples required by the dynamic bump algorithm to achieve 1.5 times the shown error values. For both plots, populations <italic>A</italic> and <italic>B</italic> consist of 1,000 neurons each, and the mean of 10 trials is plotted.</p></caption><graphic xlink:href="fncom-14-00012-g0003"/></fig><p>In order to put the sample efficiency of the bump coding scheme into context with other coding schemes, we compare it to the performance of a multi-layer perceptron (MLP), which encodes information with real valued units. <xref ref-type="fig" rid="F4">Figure 4</xref> compares performance of the dynamic bump algorithm, with a MLP trained by the backpropagation algorithm (Rumelhart et al., <xref rid="B69" ref-type="bibr">1985</xref>) and a reinforce algorithm as described in Williams (<xref rid="B99" ref-type="bibr">1992</xref>). Note that the backpropagation algorithm requires full access to the first order derivative of the error with respect to the parameters and thus is a first-order optimization technique, whereas the reinforce and dynamic bump algorithm only require a scalar error feedback and thus are zeroth-order optimization techniques. Nevertheless the dynamic bump algorithm achieves similar performance as the MLP trained by backpropagation and outperforms the MLP trained by the reinforce algorithm, <xref ref-type="fig" rid="F4">Figure 4</xref>. For the backpropagation and reinforce algorithm, we used a hyper-parameter search to determine the best parameters. We note that this search yielded an untypically high learning rate and small batch size for the backpropagation algorithm. The learning rate is in the upper end of the recommended interval [10<sup>&#x02212;6</sup>, 1] and much higher than the suggested default value of 0.01 (Bengio, <xref rid="B8" ref-type="bibr">2012</xref>). This is necessary to achieve good performance after 1,000 samples, see <xref ref-type="fig" rid="F4">Figure 4</xref>.</p><fig id="F4" position="float"><label>Figure 4</label><caption><p>Comparison of the sample efficiency to a multi-layer perceptron. The learning progress of the dynamic bump algorithm, of a MLP trained with the backpropagation algorithm and of a MLP trained with the reinforce algorithm is shown for the sinus, second-order polynomial, throw ball and robotic arm tasks in <bold>(A&#x02013;D)</bold>, respectively. The tasks are described in detail in section 3.5. We plot the learning curve that achieves best performance after 1,000 samples obtained by our hyper-parameter search. The hyper-parameters for each learning algorithm are given in the <xref ref-type="supplementary-material" rid="SM1">Supplementary Material</xref>. For each algorithm, we plot average and standard deviation of 10 runs.</p></caption><graphic xlink:href="fncom-14-00012-g0004"/></fig><p>In <xref ref-type="fig" rid="F5">Figure 5</xref>, we illustrate the performance of the bump coding scheme on reinforcement learning (RL) tasks. In RL environments an agent should learn to interact with an environment with the goal of maximizing some reward. At any time step, the agent observes the current state of the environment and outputs an action, which in turn affects the state of the environment. The agent obtains rewards for reaching certain states. It is unclear which actions lead to the reward, due to the well known credit-assignment problem. A classical RL method to mitigate this problem is the temporal difference learning method (Sutton et al., <xref rid="B89" ref-type="bibr">1998</xref>), that relies on learning a <italic>policy function</italic> that maps states to actions and a <italic>value function</italic> that maps states to an estimate of the future expected reward. Then, the difference of the estimated expected future reward before and after each action can be computed. Combined with the obtained reward of that time step, one can estimate the reward that arose from that specific action, which allows to update the policy.</p><fig id="F5" position="float"><label>Figure 5</label><caption><p>Reinforcement learning experiments. The plots show the learning progress of different learning algorithms on the Mountain Car <bold>(A)</bold> and Inverted Pendulum <bold>(B)</bold> task. The tasks are described in more detail in section 3.5. The RL bump algorithm is compared with the <italic>deep deterministic policy gradient</italic> algorithm (ddpg) and the <italic>proximal policy optimization</italic> algorithm (ppo2), cf. text for implementation details. For every algorithm, the average reward per episode and its standard deviation for 10 different random seeds are smoothed for better readability. The algorithm hyper-parameters are optimized to maximize the mean reward on the last 30 episodes for the Mountain Car, and the last 300 episodes for the Inverted Pendulum, and are given in the <xref ref-type="supplementary-material" rid="SM1">Supplementary Material</xref>.</p></caption><graphic xlink:href="fncom-14-00012-g0005"/></fig><p>Our <italic>RL bump algorithm</italic> uses the temporal difference learning method. More precisely, it learns the policy with a static bump algorithm, while the value function is stored in tabular representation as done in the literature (Sutton et al., <xref rid="B89" ref-type="bibr">1998</xref>). At any time step, the temporal difference learning method provides an estimate of the reward arising from the action at this time step. This estimate is used as error feedback for the bump algorithm. Since this estimate might be off, we update the synaptic probabilities more gradually, instead of pruning away synapses immediately as in above algorithms. The magnitude of the updates are chosen proportional to the reward estimates. We refer to section 3.4 for a detailed description.</p><p>We evaluate the RL bump algorithm on two RL tasks, the Mountain Car environment and the Inverted Pendulum, see section 3.5 for a description of the tasks. The resulting learning curves are displayed in <xref ref-type="fig" rid="F5">Figure 5</xref>. We compare our algorithm with two different deep reinforcement learning algorithms: <italic>deep deterministic policy gradient</italic> (ddpg) (Lillicrap et al., <xref rid="B54" ref-type="bibr">2015</xref>) and <italic>proximal policy optimization</italic> (ppo2) (Schulman et al., <xref rid="B78" ref-type="bibr">2017</xref>). Both are state-of-the-art reinforcement learning algorithms that use neural networks as a representation of the policy. For both algorithms, we use the implementation and the standard parameters provided by the OpenAI Baselines (Dhariwal et al., <xref rid="B26" ref-type="bibr">2017</xref>). Since these parameters do not aim at efficiently solving the exploration problem of the Mountain Car environment, we added an implementation of ddpg specifically tailored to achieve sample efficiency in the Mountain-Car environment: the parameters and implementation are taken from de Broissia and Sigaud (<xref rid="B25" ref-type="bibr">2016</xref>) and the resulting curve is labeled as <italic>sample-efficient ddpg</italic>.</p><p>We observe that our algorithm performs comparable or better than the baselines on both environments, see <xref ref-type="fig" rid="F5">Figure 5</xref>. In the Mountain Car experiment, we observe that the OpenAI baselines implementation are unable to make substantial progress on the observed time scale. The sample efficient ddpg implementation from de Broissia and Sigaud (<xref rid="B25" ref-type="bibr">2016</xref>) is able to reach higher rewards, but it is very quickly outperformed by our algorithm in terms of final performance. In the Pendulum experiment, we observe a first phase during which the learning curve of our algorithm is very similar to ddpg, whereas ppo2 does not make any progress. In a second phase, the ppo2 learning curve catches up our algorithm, while ddpg is outperformed. We close this section with a word of caution. <xref ref-type="fig" rid="F5">Figure 5</xref> seems to indicate that our algorithm outperforms deep policy gradient methods for reinforcement learning tasks. However, note that both, Mountain Car and Inverted Pendulum, have a low dimensional input space (2 dimensions for Mountain Car, 4 for Inverted Pendulum). Currently, our algorithm does not scale up to a higher number of dimensions in terms of computational cost, whereas deep policy gradient algorithms have been engineered to deal with high-dimensional spaces.</p></sec></sec><sec sec-type="methods" id="s3"><title>3. Methods</title><p>In sections 3.1&#x02013;3.4, we describe the bump coding scheme and our algorithms formally. Section 3.5, contains a description of all the tasks used for evaluation of the algorithms.</p><sec><title>3.1. Bump Coding Scheme</title><p>We assume that a population of binary neurons is arranged in a grid. Intuitively, a <italic>d</italic>-dimensional parameter <italic>x</italic> is encoded by a bump of active neurons that lay within the <italic>d</italic>-dimensional cube with side length <italic>k</italic> and center <italic>x</italic>, see <xref ref-type="fig" rid="F1">Figure 1</xref>. We note that our results qualitatively do not depend on the precise shape of the bump, that is, whether it is the <italic>d</italic>-dimensional cube or ball, however our cube shaped bumps facilitate efficient simulations. Formally, a population of <italic>n</italic><sup><italic>d</italic></sup> neurons encodes values in the <italic>d</italic>-dimensional interval [0, 1]<sup><italic>d</italic></sup>. Define <italic>A</italic><sub><italic>i</italic></sub> = [<italic>n</italic>], where [<italic>n</italic>] denotes the set of integers {1, &#x02026;, <italic>n</italic>}, and define the set of neurons to be <italic>A</italic> = <italic>A</italic><sub>1</sub> &#x000d7; &#x02026; &#x000d7; <italic>A</italic><sub><italic>d</italic></sub>. Then, a neuron <italic>i</italic> &#x02208; <italic>A</italic> represents the value (<italic>i</italic><sub>1</sub>/<italic>n</italic>, &#x02026;<italic>i</italic><sub><italic>d</italic></sub>/<italic>n</italic>) in [0, 1]<sup><italic>d</italic></sup>. Moreover, for <italic>a</italic> &#x02208; [<italic>n</italic>] define <italic>Int</italic><sub><italic>k</italic></sub>(<italic>a</italic>) to be the set of integers in the interval [<italic>a</italic> &#x02212; <italic>k</italic>/2, <italic>a</italic> + <italic>k</italic>/2]; to be precise, we actually define <italic>Int</italic><sub><italic>k</italic></sub>(<italic>a</italic>) as the set of integers in the interval [max{0, <italic>a</italic> &#x02212; <italic>k</italic>/2}, min{<italic>n, a</italic> + <italic>k</italic>/2}] in order to take care of cases close to the boundary of the interval. We define the <italic>bump of width</italic>
<italic>k</italic> with center neuron <italic>i</italic> &#x02208; <italic>A</italic> to be <italic>Int</italic><sub><italic>k</italic></sub>(<italic>i</italic>): = <italic>Int</italic><sub><italic>k</italic></sub>(<italic>i</italic><sub>1</sub>) &#x000d7; &#x02026; &#x000d7; <italic>Int</italic><sub><italic>k</italic></sub>(<italic>i</italic><sub><italic>d</italic></sub>). In the bump coding scheme of width <italic>k</italic> the value <italic>a</italic> is encoded by the <italic>Int</italic><sub><italic>k</italic></sub>(<italic>a</italic>)-activation, where an <italic>I</italic>-activation is defined to be the state, where the neurons in <italic>I</italic> are active and the ones not in <italic>I</italic> are inactive.</p></sec><sec><title>3.2. Network Architecture, Activation Distribution, and Feedback Error Measure</title><p>In order to learn a mapping <inline-formula><mml:math id="M21"><mml:mi>f</mml:mi><mml:mo>:</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup><mml:mo>&#x02192;</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:math></inline-formula>, we consider a network consisting of populations <italic>A</italic> and <italic>B</italic> equipped with probabilistic synapses and an abstract continuous attractor mechanism in population <italic>B</italic>. Intuitively, given a bump activation <italic>I</italic> in population <italic>A</italic>, the attractor mechanism activates the bump <italic>J</italic> in population <italic>B</italic> that received most synaptic input from the bump activation in <italic>A</italic>. This way, the probabilistic synapses enable exploration of the output space. More formally, the network consists of population <italic>A</italic> and <italic>B</italic> consisting of <inline-formula><mml:math id="M22"><mml:msup><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:math></inline-formula> and <inline-formula><mml:math id="M23"><mml:msup><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:math></inline-formula> neurons, respectively. These encode values according to the bump coding scheme defined above. They are fully connected by probabilistic synapses with weights <italic>w</italic><sub><italic>ij</italic></sub> fixed to value 1 and plastic synaptic probabilities <italic>p</italic><sub><italic>ij</italic></sub>. Given an input <italic>x</italic>, the bump <italic>I</italic> = <italic>Int</italic><sub><italic>k</italic><sub><italic>a</italic></sub></sub>(<italic>x</italic>) with width <italic>k</italic><sub><italic>A</italic></sub> and center <italic>x</italic>, the matrix of synaptic probabilites <italic>P</italic> and the bump width <italic>k</italic><sub><italic>B</italic></sub> in population <italic>B</italic>, we define the following <italic>activation distribution</italic>
<italic>Act</italic>(<italic>I, k</italic><sub><italic>B</italic></sub>, <italic>P</italic>) that returns (<italic>J, y</italic>), where <italic>J</italic> is the sampled bump in population <italic>B</italic> with center <italic>y</italic>. Assuming that the bump <italic>I</italic> is active in population <italic>A</italic>, we explain now how a bump activation <italic>J</italic> in population <italic>B</italic> is sampled. Denote by <inline-formula><mml:math id="M24"><mml:mrow><mml:mi mathvariant="script">J</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:mrow><mml:mi>I</mml:mi><mml:mi>n</mml:mi><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mi>b</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mi>B</mml:mi></mml:mrow><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:math></inline-formula> the set of all possible bump activations in <italic>B</italic> with width <italic>k</italic><sub><italic>B</italic></sub> and by <italic>X</italic><sub><italic>ij</italic></sub> Bernoulli random variables that are 1 with probability <italic>p</italic><sub><italic>ij</italic></sub> and 0 otherwise, i.e., they indicate whether synapse (<italic>i, j</italic>) is active or not. Then, <inline-formula><mml:math id="M25"><mml:mi>s</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>I</mml:mi><mml:mo>,</mml:mo><mml:mi>J</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munder class="msub"><mml:mrow><mml:mo>&#x02211;</mml:mo></mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>&#x02208;</mml:mo><mml:mi>I</mml:mi><mml:mo>&#x000d7;</mml:mo><mml:mi>J</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the total synaptic input that neurons in <italic>J</italic> receive (recall that we assumed that all synaptic weights are constant and equal to 1), and the <italic>abstract continuous attractor mechanism</italic> activates the output bump <inline-formula><mml:math id="M26"><mml:mi>J</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mrow><mml:mi mathvariant="script">J</mml:mi></mml:mrow></mml:math></inline-formula> with maximal <italic>s</italic>(<italic>I, J</italic>), where ties are broken uniformly at random. Formally, we write (<italic>J, y</italic>) ~ <italic>Act</italic>(<italic>I, k, P</italic>), where <inline-formula><mml:math id="M27"><mml:mi>J</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mstyle class="text"><mml:mtext class="textrm" mathvariant="normal">arg&#x000a0;max</mml:mtext></mml:mstyle></mml:mrow><mml:mrow><mml:mi>J</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mrow><mml:mi mathvariant="script">J</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>I</mml:mi><mml:mo>,</mml:mo><mml:mi>J</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> and <italic>y</italic> is the center of bump <italic>J</italic>. In a machine-learning context this can be efficiently implemented by adding a convolutional layer with suitable weights on top of layer <italic>B</italic>. We remark that for the theoretical analysis, we change the activation distribution slightly to be able to deal with the dependencies between distributions <italic>s</italic>(<italic>I, J</italic>) and <italic>s</italic>(<italic>I, J</italic>&#x02032;), see <xref ref-type="supplementary-material" rid="SM1">Supplementary Material</xref>.</p><p>Given a bump <italic>I</italic> in population <italic>A</italic> with center <italic>x</italic> and a sampled activation (<italic>J, y</italic>) ~ <italic>Act</italic>(<italic>I, k</italic><sub><italic>b</italic></sub>, <italic>P</italic>) the network receives some <italic>error feedback</italic>
<italic>L</italic>(<italic>x, y</italic>), where <italic>L</italic> is a function that depends on the output <italic>y</italic> and the target output <italic>f</italic>(<italic>x</italic>), e.g., the euclidean error feedback returns the euclidean distance between output value <italic>y</italic> and the target value <italic>f</italic>(<italic>x</italic>). Note that the learning task is more difficult if the precise definition of the function <italic>L</italic> is unknown to the algorithm. The <italic>error</italic> of a network with learned synaptic probabilities <inline-formula><mml:math id="M28"><mml:mover accent="true"><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula> is defined to be the expected error feedback &#x1d53c;[<italic>L</italic>(<italic>x, y</italic>)], where <italic>x</italic> is chosen uniformly at random in <italic>A</italic> and <italic>y</italic> is sampled according to <inline-formula><mml:math id="M29"><mml:mi>A</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>I</mml:mi><mml:mi>n</mml:mi><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>.</p></sec><sec><title>3.3. The Static and Dynamic Bump Algorithm</title><p>We first explain the algorithms used for the theoretical analysis and then the ones used for the simulations. The goal of these algorithms is to prune away all synapses for every input neuron <italic>x</italic>, except the ones connecting <italic>x</italic> to some small continuous area around <italic>x</italic>'s target neuron <italic>f</italic>(<italic>x</italic>). The basic mechanism to do so is to prune away synapses between the input and output bump whenever the error feedback is larger than some error threshold, as then the target neuron <italic>f</italic>(<italic>x</italic>) is not contained in the output bump.</p><sec><title>3.3.1. Algorithms for Theoretical Analysis</title><p>For the following algorithms, every synapse (<italic>i, j</italic>) has a synaptic counter <italic>c</italic><sub><italic>ij</italic></sub> that indicates whether a synapse should be pruned away. Further, the input and output bump widths are set such that the fraction <italic>k</italic><sub><italic>B</italic></sub>/<italic>k</italic><sub><italic>A</italic></sub> is equal to the Lipschitz constant <italic>C</italic> of the mapping <italic>f</italic> that is to be learned.</p><p>The <italic>static bump algorithm (theory)</italic> fixes the input width <italic>k</italic><sub><italic>A</italic></sub>, the output bump width <italic>k</italic><sub><italic>B</italic></sub> and the error threshold <inline-formula><mml:math id="M30"><mml:mover accent="true"><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula> proportional to the desired final error &#x02113; and observes <inline-formula><mml:math id="M31"><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:mi>c</mml:mi><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:mfrac></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup><mml:mo class="qopname">log</mml:mo><mml:mi>n</mml:mi></mml:math></inline-formula> many samples with random input <italic>x</italic>, where <inline-formula><mml:math id="M32"><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mi>C</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msqrt><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msqrt><mml:mo>+</mml:mo><mml:msqrt><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msqrt></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:math></inline-formula>. For every sample activation (<italic>J, y</italic>) ~ <italic>Act</italic>(<italic>Int</italic><sub><italic>k</italic><sub><italic>A</italic></sub></sub>(<italic>x</italic>), <italic>P, k</italic><sub><italic>B</italic></sub>), the counters <italic>c</italic><sub><italic>ij</italic></sub> are incremented by 1 for all synapses between the two bumps <italic>I</italic> = <italic>Int</italic><sub><italic>k</italic><sub><italic>A</italic></sub></sub>(<italic>x</italic>) and <italic>J</italic>, if <inline-formula><mml:math id="M33"><mml:mi>L</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>&#x02264;</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula> and otherwise decremented by 1. Finally, all synapses with non-positive counters are pruned away. Intuitively, the choice of sample size <italic>M</italic> ensures with high probability<xref ref-type="fn" rid="fn0002"><sup>2</sup></xref> that any input neuron <italic>x</italic> remains to be connected to output neurons <italic>y</italic> with <inline-formula><mml:math id="M34"><mml:mo stretchy="false">&#x02225;</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>-</mml:mo><mml:mi>y</mml:mi><mml:msub><mml:mrow><mml:mo stretchy="false">&#x02225;</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>&#x02264;</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula>.</p><p>The <italic>dynamic bump algorithm (theory)</italic> proceeds in phases and repeatedly applies the static version, see Algorithm 1. The bump widths <italic>k</italic> and error threshold <inline-formula><mml:math id="M35"><mml:mover accent="true"><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula> are initially chosen large and divided by 2 in every phase. Intuitively, this causes any input neuron <italic>x</italic> to be connected to a shrinking and shrinking area around target output neuron <italic>f</italic>(<italic>x</italic>).</p></sec><sec><title>3.3.2. Algorithms for Simulations</title><p>The following algorithms can deal with error feedback functions that differ in magnitude for different input regimes and adapt the bump width in a more continuous manner. We give a short overview of the mechanisms used in the algorithms. Firstly, every neuron keeps track of its own error threshold <inline-formula><mml:math id="M36"><mml:mover accent="true"><mml:mrow><mml:msup><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula>. <inline-formula><mml:math id="M37"><mml:mover accent="true"><mml:mrow><mml:msup><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula> is the running average with decay factor &#x003b1; of the error feedbacks obtained when neuron <italic>i</italic> was active. Further, a mechanism to prune long-time inactive synapses is implemented with synaptic counters <italic>d</italic><sub><italic>ij</italic></sub>.</p><p>The <italic>dynamic bump algorithm</italic> sets for every sample the input bump width <italic>k</italic><sub><italic>A</italic></sub> and output bump width <italic>k</italic><sub><italic>B</italic></sub> both equal to a constant fraction of the number of synapses of neuron <italic>x</italic>. The <italic>static bump algorithm</italic> sets the bump widths to some fixed constant but otherwise proceeds analogously as follows. Any sample activation consists of input and output bumps <italic>I</italic> and <italic>J</italic> with centers <italic>x</italic> and <italic>y</italic>, respectively, and error feedback <italic>L</italic>(<italic>x, y</italic>). For each sample, the neurons <italic>i</italic> &#x02208; <italic>I</italic> update their error threshold according to <inline-formula><mml:math id="M38"><mml:mover accent="true"><mml:mrow><mml:msup><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>&#x003b1;</mml:mi><mml:mi>L</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>&#x003b1;</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mover accent="true"><mml:mrow><mml:msup><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula>. Synapses (<italic>i, j</italic>) between bumps <italic>I</italic> and <italic>J</italic> are pruned away if <inline-formula><mml:math id="M39"><mml:mi>L</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>&#x02265;</mml:mo><mml:mover accent="true"><mml:mrow><mml:msup><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula>. Further, synapses (<italic>i, j</italic>) with <italic>i</italic> &#x02208; <italic>I</italic> and <italic>j</italic> &#x02209; <italic>J</italic> increase their synaptic counter <italic>d</italic><sub><italic>ij</italic></sub> by 1 and the ones with <italic>i</italic> &#x02208; <italic>I</italic> and <italic>j</italic> &#x02208; <italic>J</italic> reset <italic>d</italic><sub><italic>ij</italic></sub> = 0. Then, long-time inactive synapses (i.e., <italic>d</italic><sub><italic>ij</italic></sub> &#x02265; &#x003b8;<sub><italic>prune</italic></sub>) are pruned away. Finally, synapses (<italic>i, j</italic>) are consolidated, that is, <italic>p</italic><sub><italic>ij</italic></sub> is set to 1, if the number of synapses of input neuron <italic>i</italic> drops below a threshold value. The procedure stops as soon the mean of the <inline-formula><mml:math id="M40"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> drops below the desired precision &#x02113;.</p><p>The hyper-parameters of the algorithm need to be tuned to yield good performance. We optimized them using a coarse grid search for each task. We discuss the influence of the hyper-parameters on performance and give the hyper-parameters used for <xref ref-type="fig" rid="F4">Figure 4</xref>.</p><table-wrap id="d35e3032" position="float"><label>Algorithm 1</label><caption><p>Dynamic bump algorithm for theoretical analysis. It learns a Lipschitz mapping <inline-formula><mml:math id="M41"><mml:mi>f</mml:mi><mml:mo>:</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup><mml:mo>&#x02192;</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:math></inline-formula>. Hyper/parameters: Lipschitz constant or upper bound on Lipschitz constant <italic>C</italic>, desired precision &#x02113;, <inline-formula><mml:math id="M42"><mml:mn>0</mml:mn><mml:mo>&#x0003c;</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02264;</mml:mo><mml:mn>2</mml:mn><mml:mo>/</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>3</mml:mn><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msqrt><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msqrt><mml:mo>+</mml:mo><mml:msqrt><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msqrt></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="M43"><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>&#x000b7;</mml:mo><mml:mi>V</mml:mi><mml:mi>o</mml:mi><mml:mi>l</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mo>/</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msqrt><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msqrt><mml:mo>/</mml:mo><mml:mn>2</mml:mn><mml:mo>+</mml:mo><mml:msqrt><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msqrt><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, where <italic>Vol</italic>(<italic>S</italic><sub><italic>d</italic></sub>(<italic>r</italic>)) denotes the euclidean volume of the <italic>d</italic>-dimensional ball with radius <italic>r</italic>.</p></caption><graphic xlink:href="fncom-14-00012-i0001"/></table-wrap><table-wrap id="d35e3286" position="float"><label>Algorithm 2</label><caption><p>Dynamic bump algorith used for the simulations. It learns a Lipschitz mapping <inline-formula><mml:math id="M53"><mml:mi>f</mml:mi><mml:mo>:</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup><mml:mo>&#x02192;</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:math></inline-formula>. Hyper/parameters: Lipschitz constant or upper bound on Lipschitz constant <italic>C</italic>, desired precision &#x02113;, running average factor &#x003b1;, <italic>c</italic><sub><italic>A</italic></sub>, <italic>c</italic><sub><italic>B</italic></sub>, &#x003b8;<sub><italic>prune</italic></sub>, &#x003b8;<sub><italic>syn</italic></sub>, <inline-formula><mml:math id="M54"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>.</p></caption><graphic xlink:href="fncom-14-00012-i0002"/></table-wrap></sec></sec><sec><title>3.4. Reinforcement Learning Bump Algorithm</title><p>In this section, we describe our <italic>RL bump algorithm</italic>, which combines the classical temporal difference learning method (Sutton et al., <xref rid="B89" ref-type="bibr">1998</xref>) with the bump coding scheme. The building blocks of temporal difference learning are learning a <italic>policy</italic> that maps states to actions and learning a <italic>value function</italic>
<italic>v</italic> that estimates the expected future reward <italic>v</italic>(<italic>S</italic><sub><italic>t</italic></sub>) for states <italic>S</italic><sub><italic>t</italic></sub>. Here, it is assumed that the agent observes the whole state <italic>S</italic><sub><italic>t</italic></sub> of the environment. To learn these mappings, one computes the <italic>return</italic>
<italic>G</italic><sub><italic>t</italic></sub>, that intuitively is the difference between the estimated future reward <italic>v</italic>(<italic>S</italic><sub><italic>t</italic></sub>) and the real future reward. The <italic>k</italic>-step temporal difference method estimates the real future reward using the bootstrap estimate <italic>v</italic>(<italic>S</italic><sub><italic>t</italic>+<italic>k</italic></sub>) and computes <italic>G</italic><sub><italic>t</italic></sub> as</p><disp-formula id="E1"><mml:math id="M59"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02190;</mml:mo><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mo>&#x02026;</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>v</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>-</mml:mo><mml:mi>v</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula><p>where <italic>R</italic><sub><italic>u</italic></sub> denotes the reward received at time <italic>u</italic>. Then, the return <italic>G</italic><sub><italic>t</italic></sub> is used to update the value function, which is stored in a tabular representation (Sutton et al., <xref rid="B89" ref-type="bibr">1998</xref>).</p><disp-formula id="E2"><mml:math id="M60"><mml:mtable columnalign="left"><mml:mtr><mml:mtd columnalign="left"><mml:mi>v</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>&#x02190;</mml:mo><mml:mi>v</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>&#x003b1;</mml:mi><mml:msub><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula><p>where &#x003b1; is a hyper parameter regulating the magnitude of the update. Further, the return <italic>G</italic><sub><italic>t</italic></sub> is used to update the policy, that in our case is learned with a bump coding algorithm with static bump width that updates the synaptic probabilities gradually. If at time step <italic>t</italic>, the activated bumps were <italic>I</italic> and <italic>J</italic>, we update the probabilities <italic>p</italic><sub><italic>ij</italic></sub> for all (<italic>i, j</italic>) &#x02208; <italic>I</italic> &#x000d7; <italic>J</italic> according to</p><disp-formula id="E3"><mml:math id="M61"><mml:mtable columnalign="left"><mml:mtr><mml:mtd columnalign="left"><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02190;</mml:mo><mml:mrow><mml:mo stretchy="true">{</mml:mo><mml:mtable style="text-align:axis;" equalrows="false" columnlines="none" equalcolumns="false" class="array"><mml:mtr><mml:mtd columnalign="left"><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:mn>9</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mtext>&#x000a0;min</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>&#x003b2;</mml:mi><mml:msub><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mtext>&#x000a0;</mml:mtext><mml:msub><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02265;</mml:mo><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mtext>&#x000a0;max</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>&#x003b2;</mml:mi><mml:msub><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mtext>&#x000a0;</mml:mtext><mml:msub><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>&#x0003c;</mml:mo><mml:mn>0</mml:mn></mml:mtd></mml:mtr></mml:mtable><mml:mtext>&#x000a0;</mml:mtext><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula><p>where &#x003b2; is a hyper parameter regulating the magnitude of the update. Intuitively, this update increases <italic>p</italic><sub><italic>ij</italic></sub> proportional to <italic>G</italic><sub><italic>t</italic></sub> and proportional to the distance of <italic>p</italic><sub><italic>ij</italic></sub> to 0.9 if <italic>G</italic><sub><italic>t</italic></sub> &#x02265; 0, and decreases <italic>p</italic><sub><italic>ij</italic></sub> proportional to <italic>G</italic><sub><italic>t</italic></sub> and proportional to the distance of <italic>p</italic><sub><italic>ij</italic></sub> to 0.1 if <italic>G</italic><sub><italic>t</italic></sub> &#x02264; 0. Note that due to the clipping of &#x003b2;<italic>G</italic><sub><italic>t</italic></sub> to [&#x02212;1, 1], the invariant is maintained that all probabilities belong to the interval [0.1, 0.9]. The structure of these updates is very similar to policy gradient methods (Sutton et al., <xref rid="B89" ref-type="bibr">1998</xref>), using the reinforce algorithm. However, the reinforce algorithm does not directly apply to our model as it is internally non differentiable, see Williams (<xref rid="B99" ref-type="bibr">1992</xref>).</p></sec><sec><title>3.5. Description of Tasks</title><sec><title>3.5.1. Low Dimensional Mappings With Immediate Feedback</title><p>As 1-dimensional mappings <italic>f</italic>, we consider the identity function <italic>f</italic>(<italic>x</italic>) = <italic>x</italic>, a sinus function <italic>f</italic>(<italic>x</italic>) = sin(<italic>x</italic>) and a second order polynomial <italic>f</italic>(<italic>x</italic>) = <italic>x</italic><sup>2</sup> &#x02212; 3<italic>x</italic> + 1. For all functions, we consider the absolute distance <italic>L</italic>(<italic>x, y</italic>) = |<italic>f</italic>(<italic>x</italic>) &#x02212; <italic>y</italic>| as error feedback, where <italic>x</italic> and <italic>y</italic> are input and output of the network.</p><p>In the <italic>throw ball task</italic>, the network has to learn to throw a ball to a certain distance. The target distance is given as a 1-dimensional input to the network. The networks gives a 2-dimensional output, that consists of the vertical throwing angle and the initial speed of the ball. The error feedback is the absolute difference between the distance where the ball touches the ground and the target distance. Note that the optimal output is underdetermined, as for any angle in (0, &#x003c0;/2) there exists a speed such that any target distance can be hit.</p><p>In the <italic>robotic arm task</italic>, the network learns how to control a simple robotic arm with two degrees of freedom. The arm is composed of two rigid moving parts and is connected to a fixed anchorage point. As we restrict to movements in the plane, the agent only has to control angles, one at each joint. The target position is given as input in Cartesian coordinates and the network outputs two angles that are applied to the two joints. The feedback is given by the euclidean distance between the actual position of the arm and the target position.</p></sec><sec><title>3.5.2. Reinforcement Learning Tasks</title><p>The RL environments used for assessing the RL bump algorithm are from the OpenAI Gym (Brockman et al., <xref rid="B18" ref-type="bibr">2016</xref>) toolkit: the continuous version of the classical Mountain Car control problem (MountainCarCountinuous-v0), and the Inverted Pendulum environment from the MuJoCo suite (InvertedPendulum-v2). In the <italic>mountain car task</italic> the goal is to reach the top of a hill, that can only be reached by obtaining momentum when driving down the neighboring hill. The network receives as input the position and speed of the car and outputs the acceleration that is applied to the car. There is a large positive reward if the car reaches the top of the hill and a small negative reward for the fuel use in every time step. In the <italic>inverted pendulum task</italic> the goal is to balance an inverted pendulum on a cart. The network receives 4-dimensional input describing position and velocity of the cart and pendulum, and it outputs the acceleration applied to the cart. As long as the pendulum does not fall to the ground, there is a positive reward in every time step.</p></sec></sec></sec><sec sec-type="discussion" id="s4"><title>4. Discussion</title><p>In this section, we first relate our work to related work from the field of machine learning that studies sample efficient learning, then we discuss the bio-plausibility of our proposed coding scheme and learning algorithms, and finally we discuss the insights gained about the bio-plausible mechanisms used in this study.</p><sec><title>4.1. Sample Efficient Learning in Machine Learning</title><p>How to improve sample efficiency of learning algorithms is a major topic in the field of machine learning in general and the field of reinforcement learning in particular (Botvinick et al., <xref rid="B16" ref-type="bibr">2019</xref>). Data samples are often limited, and training of artificial networks is computationally costly. A common approach to improve sample efficiency is to handcraft artificial networks to the task at hand. The most famous example are convolutional neural networks (LeCun and Bengio, <xref rid="B51" ref-type="bibr">1995</xref>; Krizhevsky et al., <xref rid="B49" ref-type="bibr">2012</xref>), where the translational invariance property of images is hand-wired into the convolutional network architecture. Another successful approach is to store all observed samples or the neural states that encode these samples. Then, inputs are classified according to the most similar samples in storage. This idea is present in non-parametric approaches such as the nearest neighbor methods (Bishop, <xref rid="B12" ref-type="bibr">2006</xref>), as well as in deep neural networks augmented with external memory systems (Graves et al., <xref rid="B33" ref-type="bibr">2014</xref>) and attention mechanisms (Bahdanau et al., <xref rid="B4" ref-type="bibr">2014</xref>; Vaswani et al., <xref rid="B94" ref-type="bibr">2017</xref>). In reinforcement learning this idea is known as episodic reinforcement learning (Lengyel and Dayan, <xref rid="B53" ref-type="bibr">2008</xref>; Blundell et al., <xref rid="B14" ref-type="bibr">2016</xref>; Gershman and Daw, <xref rid="B32" ref-type="bibr">2017</xref>; Pritzel et al., <xref rid="B66" ref-type="bibr">2017</xref>). Further, an approach to improve sample efficiency is meta learning (Schaul and Schmidhuber, <xref rid="B76" ref-type="bibr">2010</xref>), which is also often referred to as &#x0201c;learning to learn.&#x0201d; In the meta learning setting, an outer learning system adjusts parameters or learning mechanisms of an inner learning system in order to improve the performance and efficiency of the later (Schmidhuber et al., <xref rid="B77" ref-type="bibr">1996</xref>; Baxter, <xref rid="B7" ref-type="bibr">1998</xref>; Thrun and Pratt, <xref rid="B91" ref-type="bibr">1998</xref>; Hochreiter et al., <xref rid="B37" ref-type="bibr">2001</xref>; Schweighofer and Doya, <xref rid="B79" ref-type="bibr">2003</xref>). The outer learning system usually performs updates in a slow timescale, whereas the inner learning system can adapt fast to new environments, e.g., evolutionary algorithms can optimize learning architectures or loss functions to improve their sample efficiency (Stanley and Miikkulainen, <xref rid="B87" ref-type="bibr">2002</xref>; Jaderberg et al., <xref rid="B40" ref-type="bibr">2018</xref>).</p><p>Our approach is orthogonal to all these approaches. In essence, our work shows that the coding scheme of a network affects its sample efficiency and that adapting the coding scheme during learning can improve its sample efficiency.</p></sec><sec><title>4.2. Bio-plausibility of Our Coding Scheme and Learning Mechanisms</title><p>The proposed coding scheme and learning algorithms are of abstract nature and we do not intend to argue that they might be implemented in biological systems precisely in this form. However, we do claim that neural implementations of the basic concepts used by our model are plausible and the brain might use similar mechanisms for computation.</p><p>Our primary assumption that information is encoded and processed by populations of tuned neurons is supported by the abundance of such neurons across brain areas (Hubel and Wiesel, <xref rid="B39" ref-type="bibr">1962</xref>; O'Keefe, <xref rid="B62" ref-type="bibr">1976</xref>; Knudsen and Konishi, <xref rid="B47" ref-type="bibr">1978</xref>; Ranck, <xref rid="B67" ref-type="bibr">1985</xref>; Georgopoulos et al., <xref rid="B31" ref-type="bibr">1988</xref>). The bump coding scheme described in section 3 requires that geometrically close-by neurons have close-by preferred stimuli parameters. Such geometrically ordered networks are indeed present in real neural network, such as the drosophila fly compass system (Seelig and Jayaraman, <xref rid="B81" ref-type="bibr">2015</xref>; Kim et al., <xref rid="B44" ref-type="bibr">2017</xref>). The underlying network-wiring that gives rise to bump-like activation patterns is generally believed to follow the circuit-motive of local excitation and long-range inhibition, as suggested by experimental evidence (Kim et al., <xref rid="B44" ref-type="bibr">2017</xref>) and theoretical findings (Wilson and Cowan, <xref rid="B100" ref-type="bibr">1973</xref>; Amari, <xref rid="B3" ref-type="bibr">1977</xref>; Ben-Yishai et al., <xref rid="B9" ref-type="bibr">1995</xref>). Note however, that the geometrical ordering of the neurons is not necessary for the results presented in this work. Indeed, the geometrical arrangement can be arbitrary if network-wiring supports activity patterns consisting of neurons with similar preferred stimuli parameters. Such network wiring consists of excitatory connections between neurons that are active for similar stimuli and inhibition that limits the total activity. It can be found across brain areas and animal species (Weliky et al., <xref rid="B98" ref-type="bibr">1995</xref>; Mysore et al., <xref rid="B60" ref-type="bibr">2010</xref>; Ko et al., <xref rid="B48" ref-type="bibr">2011</xref>), and is often assumed by theoretical studies (Ben-Yishai et al., <xref rid="B9" ref-type="bibr">1995</xref>; Skaggs et al., <xref rid="B85" ref-type="bibr">1995</xref>; Knierim and Zhang, <xref rid="B46" ref-type="bibr">2012</xref>). It is conceivable that such experimentally observed wiring motives implement a version of the abstract continuous attractor mechanism used in this paper.</p><p>The dynamic bump algorithm requires a dynamic adaptation of the bump width during the learning process. Experimental and theoretical studies give evidence that the tuning curve width is controlled by inhibition (Suga et al., <xref rid="B88" ref-type="bibr">1997</xref>; Knierim and Zhang, <xref rid="B46" ref-type="bibr">2012</xref>; Lee et al., <xref rid="B52" ref-type="bibr">2012</xref>). Thus, controlling the strength of inhibition in the system yields a straight forward explanation of how the bump width could be adjusted during the learning progress.</p><p>Moreover, the assumption of constant weights and binary neurons are mere abstractions for mathematical simplicity. Due to the on-off nature of binary neurons, we approximated the bell shaped tuning curves by rectangular tuning curves. It seems plausible that the results would translate qualitatively to networks of rate neurons with bell shaped tuning curves. Stable bump like activity patterns also can be produced by spiking networks (Seeholzer et al., <xref rid="B80" ref-type="bibr">2017</xref>). We leave extensions of our algorithms that are more bio-plausible for future investigations. Moreover, we note that all results from this work also hold if the populations are sparsely instead of fully connected. As long as the bump width is broad enough, sufficiently large population codes give rise to stable learning mechanisms for sparsely connected populations (Gauy et al., <xref rid="B29" ref-type="bibr">2017</xref>).</p><p>Furthermore, our plasticity rules are plausible in the sense that they solely depend on pre- and post-synaptic activity, a global reward feedback and memory traces of these quantities. All the neuronal and synaptic counters used in our algorithms require only local storage of activity and reward feedback traces.</p></sec><sec><title>4.3. Functional Role of Tuning Curve Width</title><p>A large body of literature in theoretical and experimental neuroscience investigated tuning curve shape under the aspect of optimal coding (Seung and Sompolinsky, <xref rid="B84" ref-type="bibr">1993</xref>; Brunel and Nadal, <xref rid="B22" ref-type="bibr">1998</xref>; Panzeri et al., <xref rid="B63" ref-type="bibr">1999</xref>; Eurich et al., <xref rid="B27" ref-type="bibr">2000</xref>; Bethge et al., <xref rid="B10" ref-type="bibr">2002</xref>, <xref rid="B11" ref-type="bibr">2003</xref>; Todorov, <xref rid="B92" ref-type="bibr">2002</xref>; Sanger, <xref rid="B75" ref-type="bibr">2003</xref>; Harper and McAlpine, <xref rid="B34" ref-type="bibr">2004</xref>; Johnson and Ray, <xref rid="B41" ref-type="bibr">2004</xref>; Seri&#x000e8;s et al., <xref rid="B82" ref-type="bibr">2004</xref>; L&#x000e1;nsk&#x01ef3; and Greenwood, <xref rid="B50" ref-type="bibr">2005</xref>; Brown and B&#x000e4;cker, <xref rid="B20" ref-type="bibr">2006</xref>; Montemurro and Panzeri, <xref rid="B58" ref-type="bibr">2006</xref>; Toyoizumi et al., <xref rid="B93" ref-type="bibr">2006</xref>; McDonnell and Stocks, <xref rid="B56" ref-type="bibr">2008</xref>; Geisler et al., <xref rid="B30" ref-type="bibr">2009</xref>; Nikitin et al., <xref rid="B61" ref-type="bibr">2009</xref>; Yarrow and Seri&#x000e8;s, <xref rid="B102" ref-type="bibr">2015</xref>). Also the width of tuning curves was analyzed from an information theoretical viewpoint. Hinton et al. (<xref rid="B36" ref-type="bibr">1986</xref>) and Zhang and Sejnowski (<xref rid="B103" ref-type="bibr">1999</xref>) established a dependence between optimal tuning width and the dimensionality of the encoded parameter, Pouget et al. (<xref rid="B64" ref-type="bibr">1999</xref>) and Butts and Goldman (<xref rid="B24" ref-type="bibr">2006</xref>) showed that optimality of tuning width heavily depends on the level of noise and covariance of the noise in the system, and Yaeli and Meir (<xref rid="B101" ref-type="bibr">2010</xref>) found that optimal tuning width depends on the prior uncertainty and on the length of the decoding time window. Such studies can explain the sharpening of tuning curves that is observed in a variety of experimental set-ups (Spitzer et al., <xref rid="B86" ref-type="bibr">1988</xref>; Wagner, <xref rid="B95" ref-type="bibr">1990</xref>; Ringach et al., <xref rid="B68" ref-type="bibr">1997</xref>; Menz and Freeman, <xref rid="B57" ref-type="bibr">2003</xref>; Wang et al., <xref rid="B97" ref-type="bibr">2005</xref>; Samonds et al., <xref rid="B71" ref-type="bibr">2009</xref>).</p><p>In this work, we introduce sample efficiency as a novel notion of optimality. If the neural code is optimized for sample efficient learning, then the model analyzed in this paper predicts that the tuning curves sharpen during the process of learning. In fact, this phenomena is known to occur in the inferior temporal cortex, where tuning curves of shape selective neurons sharpen during acquaintance to new objects (Booth and Rolls, <xref rid="B15" ref-type="bibr">1998</xref>; Freedman et al., <xref rid="B28" ref-type="bibr">2005</xref>), as well as in many sensory areas during development (Brugge et al., <xref rid="B21" ref-type="bibr">1981</xref>; Tavazoie and Reid, <xref rid="B90" ref-type="bibr">2000</xref>; Mrsic-Flogel et al., <xref rid="B59" ref-type="bibr">2003</xref>). The precise relation between tuning curve width and sample efficiency likely depends on the applied plasticity mechanisms. Nonetheless, for any plasticity mechanism that requires pre- and post-synaptic activity, the tuning curve width yields an upper bound on the number of synaptic weight updates, because it limits the number of active neurons per sample. Therefore, the basic principle that larger tuning curve width leads to more synaptic updates per sample and thus faster learning, may apply to many plasticity mechanisms.</p></sec><sec><title>4.4. Functional Role of Probabilistic Synapses</title><p>The functional role of probabilistic synapses is highly debated (Llera-Montero et al., <xref rid="B55" ref-type="bibr">2019</xref>). The proposed functional roles include regularization and improved generalization in deep neural networks (Wan et al., <xref rid="B96" ref-type="bibr">2013</xref>; Blundell et al., <xref rid="B13" ref-type="bibr">2015</xref>) and energy saving constraints (Harris et al., <xref rid="B35" ref-type="bibr">2012</xref>). Further, probabilistic synapses can give rise to a good exploration exploitation trade-off in reinforcement learning (Seung, <xref rid="B83" ref-type="bibr">2003</xref>; Blundell et al., <xref rid="B13" ref-type="bibr">2015</xref>; Kappel et al., <xref rid="B43" ref-type="bibr">2018</xref>), and synaptic sampling can be seen as sampling from some posterior distribution (Aitchison and Latham, <xref rid="B2" ref-type="bibr">2015</xref>; Kappel et al., <xref rid="B42" ref-type="bibr">2015</xref>, <xref rid="B43" ref-type="bibr">2018</xref>). Our model is in line with the last two proposals. In our model, probabilistic synapses combined with an continuous attractor mechanism encode the uncertainty of the learned input-output mapping and implement the variability and exploration that is required for reward-based learning.</p></sec><sec><title>4.5. Conclusion</title><p>In this work, we asked how sample efficient learning is affected by the neural coding scheme. We showed that population codes with tuned neurons support sample efficient learning for low dimensional tasks with immediate reward feedback and low dimensional reinforcement learning tasks. For these tasks, our gradient-free learning algorithm is competitive to multi-layer perceptrons trained by backpropagation. These findings might inspire an integration of tuning curve coding schemes into machine learning approaches, especially, if data-samples are limited and no access to gradient information is given. For our learning mechanisms, we found that tuning curve width severely influences the sample efficiency. We showed that for static tuning widths, there is a trade-off between sample efficiency and final precision. Broad tuning curves give rise to sample efficient learning, whereas narrow tuning curves account for high final precision. Moreover, we showed that dynamic adaptation of the tuning width results in both high sample efficiency and high final accuracy. These results propose sample efficient learning as a functional role of the tuning curve width.</p></sec></sec><sec sec-type="data-availability" id="s5"><title>Data Availability Statement</title><p>The code used for the simulations of the learning algorithms is provided under the following link (<ext-link ext-link-type="uri" xlink:href="https://github.com/rdang-nhu/Sample_Efficient_Tuning_Curves">https://</ext-link><ext-link ext-link-type="uri" xlink:href="https://github.com/rdang-nhu/Sample_Efficient_Tuning_Curves">github.com/rdang-nhu/Sample_Efficient_Tuning_Curves</ext-link>).</p></sec><sec id="s6"><title>Author Contributions</title><p>FM and AS development of model set-up and research question, design, development and analysis of learning algorithms, and writing of the manuscript. RD-N implementation and simulation of the learning algorithms, development of the RL-bump algorithm, and proofreading of the manuscript.</p><sec><title>Conflict of Interest</title><p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p></sec></sec></body><back><ack><p>We thank Ulysse Schaller for preliminary work on the model set-up and research question during his master thesis.</p></ack><fn-group><fn id="fn0001"><p><sup>1</sup>A function <italic>f</italic> is Lipschitz continuous with Lipschitz constant <italic>C</italic>, if |<italic>f</italic>(<italic>x</italic>) &#x02212; <italic>f</italic>(<italic>y</italic>)| &#x02264; <italic>C</italic>|<italic>x</italic> &#x02212; <italic>y</italic>| for all <italic>x, y</italic>. Intuitively, this is the case if the slope of <italic>f</italic> is everywhere smaller than <italic>C</italic>.</p></fn><fn id="fn0002"><p><sup>2</sup><italic>With high probability</italic> means with probability tending to 1 as <italic>n</italic> tends to &#x0221e;.</p></fn></fn-group><fn-group><fn fn-type="financial-disclosure"><p><bold>Funding.</bold> Research supported by grant no. CRSII5173721 of the Swiss National Science Foundation.</p></fn></fn-group><sec sec-type="supplementary-material" id="s7"><title>Supplementary Material</title><p>The Supplementary Material for this article can be found online at: <ext-link ext-link-type="uri" xlink:href="https://www.frontiersin.org/articles/10.3389/fncom.2020.00012/full#supplementary-material">https://www.frontiersin.org/articles/10.3389/fncom.2020.00012/full#supplementary-material</ext-link></p><supplementary-material content-type="local-data" id="SM1"><media xlink:href="Data_Sheet_1.PDF"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material></sec><ref-list><title>References</title><ref id="B1"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Adrian</surname><given-names>E. D.</given-names></name><name><surname>Zotterman</surname><given-names>Y.</given-names></name></person-group> (<year>1926</year>). <article-title>The impulses produced by sensory nerve endings: part 3. Impulses set up by touch and pressure</article-title>. <source>J. Physiol.</source>
<volume>61</volume>, <fpage>465</fpage>&#x02013;<lpage>483</lpage>. <pub-id pub-id-type="doi">10.1113/jphysiol.1926.sp002308</pub-id><pub-id pub-id-type="pmid">16993807</pub-id></mixed-citation></ref><ref id="B2"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aitchison</surname><given-names>L.</given-names></name><name><surname>Latham</surname><given-names>P. E.</given-names></name></person-group> (<year>2015</year>). <article-title>Synaptic sampling: a connection between psp variability and uncertainty explains neurophysiological observations</article-title>. <source>arXiv [Preprint]</source>. arXiv: 1505.04544.</mixed-citation></ref><ref id="B3"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Amari</surname><given-names>S.</given-names></name></person-group> (<year>1977</year>). <article-title>Dynamics of pattern formation in lateral-inhibition type neural fields</article-title>. <source>Biol. Cybern.</source>
<volume>27</volume>, <fpage>77</fpage>&#x02013;<lpage>87</lpage>. <pub-id pub-id-type="doi">10.1007/bf00337259</pub-id><pub-id pub-id-type="pmid">911931</pub-id></mixed-citation></ref><ref id="B4"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bahdanau</surname><given-names>D.</given-names></name><name><surname>Cho</surname><given-names>K.</given-names></name><name><surname>Bengio</surname><given-names>Y.</given-names></name></person-group> (<year>2014</year>). <article-title>Neural machine translation by jointly learning to align and translate</article-title>. <source>arXiv [Preprint]</source>. arXiv: 1409.0473.</mixed-citation></ref><ref id="B5"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baraduc</surname><given-names>P.</given-names></name><name><surname>Guigon</surname><given-names>E.</given-names></name></person-group> (<year>2002</year>). <article-title>Population computation of vectorial transformations</article-title>. <source>Neural Comput.</source>
<volume>14</volume>, <fpage>845</fpage>&#x02013;<lpage>871</lpage>. <pub-id pub-id-type="doi">10.1162/089976602317318983</pub-id><pub-id pub-id-type="pmid">11936964</pub-id></mixed-citation></ref><ref id="B6"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baraduc</surname><given-names>P.</given-names></name><name><surname>Guigon</surname><given-names>E.</given-names></name><name><surname>Burnod</surname><given-names>Y.</given-names></name></person-group> (<year>2001</year>). <article-title>Recoding arm position to learn visuomotor transformations</article-title>. <source>Cereb. Cortex</source>
<volume>11</volume>, <fpage>906</fpage>&#x02013;<lpage>917</lpage>. <pub-id pub-id-type="doi">10.1093/cercor/11.10.906</pub-id><pub-id pub-id-type="pmid">11549613</pub-id></mixed-citation></ref><ref id="B7"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Baxter</surname><given-names>J.</given-names></name></person-group> (<year>1998</year>). <article-title>Theoretical models of learning to learn,</article-title> in <source>Learning to Learn</source>, eds <person-group person-group-type="editor"><name><surname>Thrun</surname><given-names>S.</given-names></name><name><surname>Pratt</surname><given-names>L.</given-names></name></person-group> (<publisher-loc>Boston, MA</publisher-loc>: <publisher-name>Springer</publisher-name>), <fpage>71</fpage>&#x02013;<lpage>94</lpage>.</mixed-citation></ref><ref id="B8"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Bengio</surname><given-names>Y.</given-names></name></person-group> (<year>2012</year>). <article-title>Practical recommendations for gradient-based training of deep architectures,</article-title> in <source>Neural Networks: Tricks of the Trade</source>, eds <person-group person-group-type="editor"><name><surname>Montavon</surname><given-names>G.</given-names></name><name><surname>Orr</surname><given-names>G. B.</given-names></name><name><surname>M&#x000fc;ller</surname><given-names>K.-B.</given-names></name></person-group> (<publisher-loc>Berlin; Heidelberg</publisher-loc>: <publisher-name>Springer</publisher-name>), <fpage>437</fpage>&#x02013;<lpage>478</lpage>.</mixed-citation></ref><ref id="B9"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ben-Yishai</surname><given-names>R.</given-names></name><name><surname>Bar-Or</surname><given-names>R. L.</given-names></name><name><surname>Sompolinsky</surname><given-names>H.</given-names></name></person-group> (<year>1995</year>). <article-title>Theory of orientation tuning in visual cortex</article-title>. <source>Proc. Natl. Acad. Sci. U.S.A.</source>
<volume>92</volume>, <fpage>3844</fpage>&#x02013;<lpage>3848</lpage>. <pub-id pub-id-type="doi">10.1073/pnas.92.9.3844</pub-id><pub-id pub-id-type="pmid">7731993</pub-id></mixed-citation></ref><ref id="B10"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bethge</surname><given-names>M.</given-names></name><name><surname>Rotermund</surname><given-names>D.</given-names></name><name><surname>Pawelzik</surname><given-names>K.</given-names></name></person-group> (<year>2002</year>). <article-title>Optimal short-term population coding: when fisher information fails</article-title>. <source>Neural Comput.</source>
<volume>14</volume>, <fpage>2317</fpage>&#x02013;<lpage>2351</lpage>. <pub-id pub-id-type="doi">10.1162/08997660260293247</pub-id><pub-id pub-id-type="pmid">12396565</pub-id></mixed-citation></ref><ref id="B11"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bethge</surname><given-names>M.</given-names></name><name><surname>Rotermund</surname><given-names>D.</given-names></name><name><surname>Pawelzik</surname><given-names>K.</given-names></name></person-group> (<year>2003</year>). <article-title>Optimal neural rate coding leads to bimodal firing rate distributions</article-title>. <source>Network</source>
<volume>14</volume>, <fpage>303</fpage>&#x02013;<lpage>319</lpage>. <pub-id pub-id-type="doi">10.1088/0954-898X_14_2_307</pub-id><pub-id pub-id-type="pmid">12790186</pub-id></mixed-citation></ref><ref id="B12"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Bishop</surname><given-names>C.</given-names></name></person-group> (<year>2006</year>). <source>Pattern Recognition and Machine Learning</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Springer</publisher-name>.</mixed-citation></ref><ref id="B13"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Blundell</surname><given-names>C.</given-names></name><name><surname>Cornebise</surname><given-names>J.</given-names></name><name><surname>Kavukcuoglu</surname><given-names>K.</given-names></name><name><surname>Wierstra</surname><given-names>D.</given-names></name></person-group> (<year>2015</year>). <article-title>Weight uncertainty in neural networks</article-title>. <source>arXiv [Preprint]</source>. arXiv: 1505.05424.</mixed-citation></ref><ref id="B14"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Blundell</surname><given-names>C.</given-names></name><name><surname>Uria</surname><given-names>B.</given-names></name><name><surname>Pritzel</surname><given-names>A.</given-names></name><name><surname>Li</surname><given-names>Y.</given-names></name><name><surname>Ruderman</surname><given-names>A.</given-names></name><name><surname>Leibo</surname><given-names>J. Z.</given-names></name><etal/></person-group> (<year>2016</year>). <article-title>Model-free episodic control</article-title>. <source>arXiv [Preprint]</source>. arXiv: 1606.04460.</mixed-citation></ref><ref id="B15"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Booth</surname><given-names>M. C.</given-names></name><name><surname>Rolls</surname><given-names>E. T.</given-names></name></person-group> (<year>1998</year>). <article-title>View-invariant representations of familiar objects by neurons in the inferior temporal visual cortex</article-title>. <source>Cereb. Cortex (New York, NY: 1991)</source>
<volume>8</volume>, <fpage>510</fpage>&#x02013;<lpage>523</lpage>. <pub-id pub-id-type="doi">10.1093/cercor/8.6.510</pub-id><pub-id pub-id-type="pmid">9758214</pub-id></mixed-citation></ref><ref id="B16"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Botvinick</surname><given-names>M.</given-names></name><name><surname>Ritter</surname><given-names>S.</given-names></name><name><surname>Wang</surname><given-names>J. X.</given-names></name><name><surname>Kurth-Nelson</surname><given-names>Z.</given-names></name><name><surname>Blundell</surname><given-names>C.</given-names></name><name><surname>Hassabis</surname><given-names>D.</given-names></name></person-group> (<year>2019</year>). <article-title>Reinforcement learning, fast and slow</article-title>. <source>Trends Cogn. Sci</source>. <volume>23</volume>, <fpage>408</fpage>&#x02013;<lpage>422</lpage>. <pub-id pub-id-type="doi">10.1016/j.tics.2019.02.006</pub-id><pub-id pub-id-type="pmid">31003893</pub-id></mixed-citation></ref><ref id="B17"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Branco</surname><given-names>T.</given-names></name><name><surname>Staras</surname><given-names>K.</given-names></name></person-group> (<year>2009</year>). <article-title>The probability of neurotransmitter release: variability and feedback control at single synapses</article-title>. <source>Nat. Rev. Neurosci.</source>
<volume>10</volume>:<fpage>373</fpage>. <pub-id pub-id-type="doi">10.1038/nrn2634</pub-id><pub-id pub-id-type="pmid">19377502</pub-id></mixed-citation></ref><ref id="B18"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brockman</surname><given-names>G.</given-names></name><name><surname>Cheung</surname><given-names>V.</given-names></name><name><surname>Pettersson</surname><given-names>L.</given-names></name><name><surname>Schneider</surname><given-names>J.</given-names></name><name><surname>Schulman</surname><given-names>J.</given-names></name><name><surname>Tang</surname><given-names>J.</given-names></name><etal/></person-group> (<year>2016</year>). OpenAI gym. arXiv:1606.01540.</mixed-citation></ref><ref id="B19"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Broomhead</surname><given-names>D. S.</given-names></name><name><surname>Lowe</surname><given-names>D.</given-names></name></person-group> (<year>1988</year>). <source>Radial Basis Functions, Multi-variable Functional Interpolation and Adaptive Networks</source>. Technical report, Royal Signals and Radar Establishment Malvern.</mixed-citation></ref><ref id="B20"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brown</surname><given-names>W. M.</given-names></name><name><surname>B&#x000e4;cker</surname><given-names>A.</given-names></name></person-group> (<year>2006</year>). <article-title>Optimal neuronal tuning for finite stimulus spaces</article-title>. <source>Neural Comput.</source>
<volume>18</volume>, <fpage>1511</fpage>&#x02013;<lpage>1526</lpage>. <pub-id pub-id-type="doi">10.1162/neco.2006.18.7.1511</pub-id><pub-id pub-id-type="pmid">16764512</pub-id></mixed-citation></ref><ref id="B21"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brugge</surname><given-names>J. F.</given-names></name><name><surname>Kitzes</surname><given-names>L. M.</given-names></name><name><surname>Javel</surname><given-names>E.</given-names></name></person-group> (<year>1981</year>). <article-title>Postnatal development of frequency and intensity sensitivity of neurons in the anteroventral cochlear nucleus of kittens</article-title>. <source>Hear. Res.</source>
<volume>5</volume>, <fpage>217</fpage>&#x02013;<lpage>229</lpage>. <pub-id pub-id-type="doi">10.1016/0378-5955(81)90047-2</pub-id><pub-id pub-id-type="pmid">7309639</pub-id></mixed-citation></ref><ref id="B22"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brunel</surname><given-names>N.</given-names></name><name><surname>Nadal</surname><given-names>J.-P.</given-names></name></person-group> (<year>1998</year>). <article-title>Mutual information, fisher information, and population coding</article-title>. <source>Neural Comput.</source>
<volume>10</volume>, <fpage>1731</fpage>&#x02013;<lpage>1757</lpage>. <pub-id pub-id-type="doi">10.1162/089976698300017115</pub-id><pub-id pub-id-type="pmid">9744895</pub-id></mixed-citation></ref><ref id="B23"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bullock</surname><given-names>D.</given-names></name><name><surname>Grossberg</surname><given-names>S.</given-names></name><name><surname>Guenther</surname><given-names>F. H.</given-names></name></person-group> (<year>1993</year>). <article-title>A self-organizing neural model of motor equivalent reaching and tool use by a multijoint arm</article-title>. <source>J. Cogn. Neurosci.</source>
<volume>5</volume>, <fpage>408</fpage>&#x02013;<lpage>435</lpage>. <pub-id pub-id-type="doi">10.1162/jocn.1993.5.4.408</pub-id><pub-id pub-id-type="pmid">23964916</pub-id></mixed-citation></ref><ref id="B24"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Butts</surname><given-names>D. A.</given-names></name><name><surname>Goldman</surname><given-names>M. S.</given-names></name></person-group> (<year>2006</year>). <article-title>Tuning curves, neuronal variability, and sensory coding</article-title>. <source>PLoS Biol.</source>
<volume>4</volume>:<fpage>e92</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pbio.0040092</pub-id><pub-id pub-id-type="pmid">16529529</pub-id></mixed-citation></ref><ref id="B25"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de Broissia</surname><given-names>A. D. F.</given-names></name><name><surname>Sigaud</surname><given-names>O.</given-names></name></person-group> (<year>2016</year>). <article-title>Actor-critic versus direct policy search: a comparison based on sample complexity</article-title>. <source>arXiv [Preprint]</source>. arXiv: 1606.09152.</mixed-citation></ref><ref id="B26"><mixed-citation publication-type="webpage"><person-group person-group-type="author"><name><surname>Dhariwal</surname><given-names>P.</given-names></name><name><surname>Hesse</surname><given-names>C.</given-names></name><name><surname>Klimov</surname><given-names>O.</given-names></name><name><surname>Nichol</surname><given-names>A.</given-names></name><name><surname>Plappert</surname><given-names>M.</given-names></name><name><surname>Radford</surname><given-names>A.</given-names></name><etal/></person-group> (<year>2017</year>). <source>Openai Baselines</source>. Available online at: <ext-link ext-link-type="uri" xlink:href="https://github.com/openai/baselines">https://github.com/openai/baselines</ext-link></mixed-citation></ref><ref id="B27"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Eurich</surname><given-names>C. W.</given-names></name><name><surname>Wilke</surname><given-names>S. D.</given-names></name><name><surname>Schwegler</surname><given-names>H.</given-names></name></person-group> (<year>2000</year>). <article-title>Neural representation of multi-dimensional stimuli,</article-title> in <source>Advances in Neural Information Processing Systems</source> (<publisher-loc>Cambridge, MA; London</publisher-loc>: <publisher-name>MIT Press</publisher-name>), <fpage>115</fpage>&#x02013;<lpage>121</lpage>.</mixed-citation></ref><ref id="B28"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Freedman</surname><given-names>D. J.</given-names></name><name><surname>Riesenhuber</surname><given-names>M.</given-names></name><name><surname>Poggio</surname><given-names>T.</given-names></name><name><surname>Miller</surname><given-names>E. K.</given-names></name></person-group> (<year>2005</year>). <article-title>Experience-dependent sharpening of visual shape selectivity in inferior temporal cortex</article-title>. <source>Cereb. Cortex</source>
<volume>16</volume>, <fpage>1631</fpage>&#x02013;<lpage>1644</lpage>. <pub-id pub-id-type="doi">10.1093/cercor/bhj100</pub-id><pub-id pub-id-type="pmid">16400159</pub-id></mixed-citation></ref><ref id="B29"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gauy</surname><given-names>M. M.</given-names></name><name><surname>Meier</surname><given-names>F.</given-names></name><name><surname>Steger</surname><given-names>A.</given-names></name></person-group> (<year>2017</year>). <article-title>Multiassociative memory: recurrent synapses increase storage capacity</article-title>. <source>Neural Comput.</source>
<volume>29</volume>, <fpage>1375</fpage>&#x02013;<lpage>1405</lpage>. <pub-id pub-id-type="doi">10.1162/NECO_a_00954</pub-id><pub-id pub-id-type="pmid">28333588</pub-id></mixed-citation></ref><ref id="B30"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Geisler</surname><given-names>W. S.</given-names></name><name><surname>Najemnik</surname><given-names>J.</given-names></name><name><surname>Ing</surname><given-names>A. D.</given-names></name></person-group> (<year>2009</year>). <article-title>Optimal stimulus encoders for natural tasks</article-title>. <source>J. Vis.</source>
<volume>9</volume>:<fpage>17</fpage>. <pub-id pub-id-type="doi">10.1167/9.13.17</pub-id><pub-id pub-id-type="pmid">20055550</pub-id></mixed-citation></ref><ref id="B31"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Georgopoulos</surname><given-names>A. P.</given-names></name><name><surname>Kettner</surname><given-names>R. E.</given-names></name><name><surname>Schwartz</surname><given-names>A. B.</given-names></name></person-group> (<year>1988</year>). <article-title>Primate motor cortex and free arm movements to visual targets in three-dimensional space. II. Coding of the direction of movement by a neuronal population</article-title>. <source>J. Neurosci.</source>
<volume>8</volume>, <fpage>2928</fpage>&#x02013;<lpage>2937</lpage>. <pub-id pub-id-type="doi">10.1523/JNEUROSCI.08-08-02928.1988</pub-id><pub-id pub-id-type="pmid">3411362</pub-id></mixed-citation></ref><ref id="B32"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gershman</surname><given-names>S. J.</given-names></name><name><surname>Daw</surname><given-names>N. D.</given-names></name></person-group> (<year>2017</year>). <article-title>Reinforcement learning and episodic memory in humans and animals: an integrative framework</article-title>. <source>Annu. Rev. Psychol.</source>
<volume>68</volume>, <fpage>101</fpage>&#x02013;<lpage>128</lpage>. <pub-id pub-id-type="doi">10.1146/annurev-psych-122414-033625</pub-id><pub-id pub-id-type="pmid">27618944</pub-id></mixed-citation></ref><ref id="B33"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Graves</surname><given-names>A.</given-names></name><name><surname>Wayne</surname><given-names>G.</given-names></name><name><surname>Danihelka</surname><given-names>I.</given-names></name></person-group> (<year>2014</year>). <article-title>Neural turing machines</article-title>. <source>arXiv [Preprint]</source>. arXiv: 1410.5401.</mixed-citation></ref><ref id="B34"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harper</surname><given-names>N. S.</given-names></name><name><surname>McAlpine</surname><given-names>D.</given-names></name></person-group> (<year>2004</year>). <article-title>Optimal neural population coding of an auditory spatial cue</article-title>. <source>Nature</source>
<volume>430</volume>:<fpage>682</fpage>. <pub-id pub-id-type="doi">10.1038/nature02768</pub-id><pub-id pub-id-type="pmid">15295602</pub-id></mixed-citation></ref><ref id="B35"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harris</surname><given-names>J. J.</given-names></name><name><surname>Jolivet</surname><given-names>R.</given-names></name><name><surname>Attwell</surname><given-names>D.</given-names></name></person-group> (<year>2012</year>). <article-title>Synaptic energy use and supply</article-title>. <source>Neuron</source>
<volume>75</volume>, <fpage>762</fpage>&#x02013;<lpage>777</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuron.2012.08.019</pub-id><pub-id pub-id-type="pmid">22958818</pub-id></mixed-citation></ref><ref id="B36"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Hinton</surname><given-names>G. E.</given-names></name></person-group> (<year>1986</year>). <article-title>Learning distributed representations of concepts,</article-title> in <source>Proceedings of the Eighth Annual Conference of the Cognitive Science Society</source> (<publisher-loc>Amherst, MA</publisher-loc>: <publisher-name>Lawrence Erlbaum Associates</publisher-name>), <fpage>1</fpage>&#x02013;<lpage>12</lpage>.</mixed-citation></ref><ref id="B37"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Hochreiter</surname><given-names>S.</given-names></name><name><surname>Younger</surname><given-names>A. S.</given-names></name><name><surname>Conwell</surname><given-names>P. R.</given-names></name></person-group> (<year>2001</year>). <article-title>Learning to learn using gradient descent,</article-title> in <source>International Conference on Artificial Neural Networks</source> (<publisher-loc>Berlin; Heidelberg</publisher-loc>: <publisher-name>Springer</publisher-name>), <fpage>87</fpage>&#x02013;<lpage>94</lpage>.</mixed-citation></ref><ref id="B38"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hubel</surname><given-names>D. H.</given-names></name><name><surname>Wiesel</surname><given-names>T. N.</given-names></name></person-group> (<year>1959</year>). <article-title>Receptive fields of single neurones in the cat's striate cortex</article-title>. <source>J. Physiol.</source>
<volume>148</volume>, <fpage>574</fpage>&#x02013;<lpage>591</lpage>. <pub-id pub-id-type="doi">10.1113/jphysiol.1959.sp006308</pub-id><pub-id pub-id-type="pmid">14403679</pub-id></mixed-citation></ref><ref id="B39"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hubel</surname><given-names>D. H.</given-names></name><name><surname>Wiesel</surname><given-names>T. N.</given-names></name></person-group> (<year>1962</year>). <article-title>Receptive fields, binocular interaction and functional architecture in the cat's visual cortex</article-title>. <source>J. Physiol.</source>
<volume>160</volume>, <fpage>106</fpage>&#x02013;<lpage>154</lpage>. <pub-id pub-id-type="doi">10.1113/jphysiol.1962.sp006837</pub-id><pub-id pub-id-type="pmid">14449617</pub-id></mixed-citation></ref><ref id="B40"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jaderberg</surname><given-names>M.</given-names></name><name><surname>Czarnecki</surname><given-names>W. M.</given-names></name><name><surname>Dunning</surname><given-names>I.</given-names></name><name><surname>Marris</surname><given-names>L.</given-names></name><name><surname>Lever</surname><given-names>G.</given-names></name><name><surname>Castaneda</surname><given-names>A. G.</given-names></name><etal/></person-group> (<year>2018</year>). <article-title>Human-level performance in first-person multiplayer games with population-based deep reinforcement learning</article-title>. <source>arXiv [Preprint]</source>. arXiv: 1807.01281.</mixed-citation></ref><ref id="B41"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Johnson</surname><given-names>D. H.</given-names></name><name><surname>Ray</surname><given-names>W.</given-names></name></person-group> (<year>2004</year>). <article-title>Optimal stimulus coding by neural populations using rate codes</article-title>. <source>J. Comput. Neurosci.</source>
<volume>16</volume>, <fpage>129</fpage>&#x02013;<lpage>138</lpage>. <pub-id pub-id-type="doi">10.1023/B:JCNS.0000014106.09948.83</pub-id><pub-id pub-id-type="pmid">14758062</pub-id></mixed-citation></ref><ref id="B42"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kappel</surname><given-names>D.</given-names></name><name><surname>Habenschuss</surname><given-names>S.</given-names></name><name><surname>Legenstein</surname><given-names>R.</given-names></name><name><surname>Maass</surname><given-names>W.</given-names></name></person-group> (<year>2015</year>). <article-title>Network plasticity as bayesian inference</article-title>. <source>PLoS Comput. Biol.</source>
<volume>11</volume>:<fpage>e1004485</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pcbi.1004485</pub-id><pub-id pub-id-type="pmid">26545099</pub-id></mixed-citation></ref><ref id="B43"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kappel</surname><given-names>D.</given-names></name><name><surname>Legenstein</surname><given-names>R.</given-names></name><name><surname>Habenschuss</surname><given-names>S.</given-names></name><name><surname>Hsieh</surname><given-names>M.</given-names></name><name><surname>Maass</surname><given-names>W.</given-names></name></person-group> (<year>2018</year>). <article-title>A dynamic connectome supports the emergence of stable computational function of neural circuits through reward-based learning</article-title>. <source>eNeuro</source>
<volume>5</volume>:ENEURO.0301-17.2018. <pub-id pub-id-type="doi">10.1523/ENEURO.0301-17.2018</pub-id><pub-id pub-id-type="pmid">29696150</pub-id></mixed-citation></ref><ref id="B44"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kim</surname><given-names>S. S.</given-names></name><name><surname>Rouault</surname><given-names>H.</given-names></name><name><surname>Druckmann</surname><given-names>S.</given-names></name><name><surname>Jayaraman</surname><given-names>V.</given-names></name></person-group> (<year>2017</year>). <article-title>Ring attractor dynamics in the drosophila central brain</article-title>. <source>Science</source>
<volume>356</volume>, <fpage>849</fpage>&#x02013;<lpage>853</lpage>. <pub-id pub-id-type="doi">10.1126/science.aal4835</pub-id><pub-id pub-id-type="pmid">28473639</pub-id></mixed-citation></ref><ref id="B45"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Klopfenstein</surname><given-names>R. W.</given-names></name><name><surname>Sverdlove</surname><given-names>R.</given-names></name></person-group> (<year>1983</year>). <article-title>Approximation by uniformly spaced gaussian functions,</article-title> in <source>Approximation Theory IV</source>, eds <person-group person-group-type="editor"><name><surname>Chui</surname><given-names>C.K.</given-names></name><name><surname>Schumaker</surname><given-names>L. L.</given-names></name><name><surname>Ward</surname><given-names>J. D.</given-names></name></person-group> (<publisher-loc>New York, NY</publisher-loc>: <publisher-name>Academic Press</publisher-name>), <fpage>575</fpage>&#x02013;<lpage>580</lpage>.</mixed-citation></ref><ref id="B46"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Knierim</surname><given-names>J. J.</given-names></name><name><surname>Zhang</surname><given-names>K.</given-names></name></person-group> (<year>2012</year>). <article-title>Attractor dynamics of spatially correlated neural activity in the limbic system</article-title>. <source>Annu. Rev. Neurosci.</source>
<volume>35</volume>, <fpage>267</fpage>&#x02013;<lpage>285</lpage>. <pub-id pub-id-type="doi">10.1146/annurev-neuro-062111-150351</pub-id><pub-id pub-id-type="pmid">22462545</pub-id></mixed-citation></ref><ref id="B47"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Knudsen</surname><given-names>E. I.</given-names></name><name><surname>Konishi</surname><given-names>M.</given-names></name></person-group> (<year>1978</year>). <article-title>Center-surround organization of auditory receptive fields in the owl</article-title>. <source>Science</source>
<volume>202</volume>, <fpage>778</fpage>&#x02013;<lpage>780</lpage>. <pub-id pub-id-type="doi">10.1126/science.715444</pub-id><pub-id pub-id-type="pmid">715444</pub-id></mixed-citation></ref><ref id="B48"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ko</surname><given-names>H.</given-names></name><name><surname>Hofer</surname><given-names>S. B.</given-names></name><name><surname>Pichler</surname><given-names>B.</given-names></name><name><surname>Buchanan</surname><given-names>K. A.</given-names></name><name><surname>Sj&#x000f6;str&#x000f6;m</surname><given-names>P. J.</given-names></name><name><surname>Mrsic-Flogel</surname><given-names>T. D.</given-names></name></person-group> (<year>2011</year>). <article-title>Functional specificity of local synaptic connections in neocortical networks</article-title>. <source>Nature</source>
<volume>473</volume>:<fpage>87</fpage>. <pub-id pub-id-type="doi">10.1038/nature09880</pub-id><pub-id pub-id-type="pmid">21478872</pub-id></mixed-citation></ref><ref id="B49"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Krizhevsky</surname><given-names>A.</given-names></name><name><surname>Sutskever</surname><given-names>I.</given-names></name><name><surname>Hinton</surname><given-names>G. E.</given-names></name></person-group> (<year>2012</year>). <article-title>Imagenet classification with deep convolutional neural networks,</article-title> in <source>Advances in Neural Information Processing Systems 25</source>, eds <person-group person-group-type="editor"><name><surname>Pereira</surname><given-names>F.</given-names></name><name><surname>Burges</surname><given-names>C. J. C.</given-names></name><name><surname>Bottou</surname><given-names>L.</given-names></name><name><surname>Weinberger</surname><given-names>K. Q.</given-names></name></person-group> (<publisher-loc>Red Hook, NY</publisher-loc>: <publisher-name>Curran Associates, Inc</publisher-name>), <fpage>1097</fpage>&#x02013;<lpage>1105</lpage>.</mixed-citation></ref><ref id="B50"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>L&#x000e1;nsk&#x01ef3;</surname><given-names>P.</given-names></name><name><surname>Greenwood</surname><given-names>P. E.</given-names></name></person-group> (<year>2005</year>). <article-title>Optimal signal estimation in neuronal models</article-title>. <source>Neural Comput.</source>
<volume>17</volume>, <fpage>2240</fpage>&#x02013;<lpage>2257</lpage>. <pub-id pub-id-type="doi">10.1162/0899766054615653</pub-id><pub-id pub-id-type="pmid">16105224</pub-id></mixed-citation></ref><ref id="B51"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Lecun</surname><given-names>Y.</given-names></name><name><surname>Bengio</surname><given-names>Y.</given-names></name></person-group> (<year>1995</year>). <article-title>Convolutional networks for images, speech, and time-series</article-title> in <source>The handbook of BRAIN theory and Neural Networks</source> ed <person-group person-group-type="editor"><name><surname>Arbib</surname><given-names>M. A.</given-names></name></person-group> (<publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>MIT Press</publisher-name>), <fpage>10</fpage>.</mixed-citation></ref><ref id="B52"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>S.-H.</given-names></name><name><surname>Kwan</surname><given-names>A. C.</given-names></name><name><surname>Zhang</surname><given-names>S.</given-names></name><name><surname>Phoumthipphavong</surname><given-names>V.</given-names></name><name><surname>Flannery</surname><given-names>J. G.</given-names></name><name><surname>Masmanidis</surname><given-names>S. C.</given-names></name><etal/></person-group>. (<year>2012</year>). <article-title>Activation of specific interneurons improves v1 feature selectivity and visual perception</article-title>. <source>Nature</source>
<volume>488</volume>:<fpage>379</fpage>. <pub-id pub-id-type="doi">10.1038/nature11312</pub-id><pub-id pub-id-type="pmid">22878719</pub-id></mixed-citation></ref><ref id="B53"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lengyel</surname><given-names>M.</given-names></name><name><surname>Dayan</surname><given-names>P.</given-names></name></person-group> (<year>2008</year>). <article-title>Hippocampal contributions to control: the third way,</article-title> in <source>Advances in Neural Information Processing Systems</source>, <fpage>889</fpage>&#x02013;<lpage>896</lpage>.</mixed-citation></ref><ref id="B54"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lillicrap</surname><given-names>T. P.</given-names></name><name><surname>Hunt</surname><given-names>J. J.</given-names></name><name><surname>Pritzel</surname><given-names>A.</given-names></name><name><surname>Heess</surname><given-names>N.</given-names></name><name><surname>Erez</surname><given-names>T.</given-names></name><name><surname>Tassa</surname><given-names>Y.</given-names></name><etal/></person-group> (<year>2015</year>). <article-title>Continuous control with deep reinforcement learning</article-title>. <source>arXiv [Preprint]</source>. arXiv: 1509.02971.</mixed-citation></ref><ref id="B55"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Llera-Montero</surname><given-names>M.</given-names></name><name><surname>Sacramento</surname><given-names>J.</given-names></name><name><surname>Costa</surname><given-names>R. P.</given-names></name></person-group> (<year>2019</year>). <article-title>Computational roles of plastic probabilistic synapses</article-title>. <source>Curr. Opin. Neurobiol.</source>
<volume>54</volume>, <fpage>90</fpage>&#x02013;<lpage>97</lpage>. <pub-id pub-id-type="doi">10.1016/j.conb.2018.09.002</pub-id><pub-id pub-id-type="pmid">30308457</pub-id></mixed-citation></ref><ref id="B56"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McDonnell</surname><given-names>M. D.</given-names></name><name><surname>Stocks</surname><given-names>N. G.</given-names></name></person-group> (<year>2008</year>). <article-title>Maximally informative stimuli and tuning curves for sigmoidal rate-coding neurons and populations</article-title>. <source>Physi. Rev. Lett.</source>
<volume>101</volume>:<fpage>058103</fpage>. <pub-id pub-id-type="doi">10.1103/PhysRevLett.101.058103</pub-id><pub-id pub-id-type="pmid">18764432</pub-id></mixed-citation></ref><ref id="B57"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Menz</surname><given-names>M. D.</given-names></name><name><surname>Freeman</surname><given-names>R. D.</given-names></name></person-group> (<year>2003</year>). <article-title>Stereoscopic depth processing in the visual cortex: a coarse-to-fine mechanism</article-title>. <source>Nat. Neurosci.</source>
<volume>6</volume>:<fpage>59</fpage>. <pub-id pub-id-type="doi">10.1038/nn986</pub-id><pub-id pub-id-type="pmid">12469131</pub-id></mixed-citation></ref><ref id="B58"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Montemurro</surname><given-names>M. A.</given-names></name><name><surname>Panzeri</surname><given-names>S.</given-names></name></person-group> (<year>2006</year>). <article-title>Optimal tuning widths in population coding of periodic variables</article-title>. <source>Neural Comput.</source>
<volume>18</volume>, <fpage>1555</fpage>&#x02013;<lpage>1576</lpage>. <pub-id pub-id-type="doi">10.1162/neco.2006.18.7.1555</pub-id><pub-id pub-id-type="pmid">16764514</pub-id></mixed-citation></ref><ref id="B59"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mrsic-Flogel</surname><given-names>T. D.</given-names></name><name><surname>Schnupp</surname><given-names>J. W.</given-names></name><name><surname>King</surname><given-names>A. J.</given-names></name></person-group> (<year>2003</year>). <article-title>Acoustic factors govern developmental sharpening of spatial tuning in the auditory cortex</article-title>. <source>Nat. Neurosci.</source>
<volume>6</volume>:<fpage>981</fpage>. <pub-id pub-id-type="doi">10.1038/nn1108</pub-id><pub-id pub-id-type="pmid">12910241</pub-id></mixed-citation></ref><ref id="B60"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mysore</surname><given-names>S. P.</given-names></name><name><surname>Asadollahi</surname><given-names>A.</given-names></name><name><surname>Knudsen</surname><given-names>E. I.</given-names></name></person-group> (<year>2010</year>). <article-title>Global inhibition and stimulus competition in the owl optic tectum</article-title>. <source>J. Neurosci.</source>
<volume>30</volume>, <fpage>1727</fpage>&#x02013;<lpage>1738</lpage>. <pub-id pub-id-type="doi">10.1523/JNEUROSCI.3740-09.2010</pub-id><pub-id pub-id-type="pmid">20130182</pub-id></mixed-citation></ref><ref id="B61"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nikitin</surname><given-names>A. P.</given-names></name><name><surname>Stocks</surname><given-names>N. G.</given-names></name><name><surname>Morse</surname><given-names>R. P.</given-names></name><name><surname>McDonnell</surname><given-names>M. D.</given-names></name></person-group> (<year>2009</year>). <article-title>Neural population coding is optimized by discrete tuning curves</article-title>. <source>Phys. Rev. Lett.</source>
<volume>103</volume>:<fpage>138101</fpage>. <pub-id pub-id-type="doi">10.1103/PhysRevLett.103.138101</pub-id><pub-id pub-id-type="pmid">19905542</pub-id></mixed-citation></ref><ref id="B62"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O'Keefe</surname><given-names>J.</given-names></name></person-group> (<year>1976</year>). <article-title>Place units in the hippocampus of the freely moving rat</article-title>. <source>Exp. Neurol.</source>
<volume>51</volume>, <fpage>78</fpage>&#x02013;<lpage>109</lpage>. <pub-id pub-id-type="doi">10.1016/0014-4886(76)90055-8</pub-id><pub-id pub-id-type="pmid">1261644</pub-id></mixed-citation></ref><ref id="B63"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Panzeri</surname><given-names>S.</given-names></name><name><surname>Treves</surname><given-names>A.</given-names></name><name><surname>Schultz</surname><given-names>S.</given-names></name><name><surname>Rolls</surname><given-names>E. T.</given-names></name></person-group> (<year>1999</year>). <article-title>On decoding the responses of a population of neurons from short time windows</article-title>. <source>Neural Comput.</source>
<volume>11</volume>, <fpage>1553</fpage>&#x02013;<lpage>1577</lpage>. <pub-id pub-id-type="doi">10.1162/089976699300016142</pub-id><pub-id pub-id-type="pmid">10490938</pub-id></mixed-citation></ref><ref id="B64"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pouget</surname><given-names>A.</given-names></name><name><surname>Deneve</surname><given-names>S.</given-names></name><name><surname>Ducom</surname><given-names>J.-C.</given-names></name><name><surname>Latham</surname><given-names>P. E.</given-names></name></person-group> (<year>1999</year>). <article-title>Narrow versus wide tuning curves: what's best for a population code?</article-title>
<source>Neural Comput.</source>
<volume>11</volume>, <fpage>85</fpage>&#x02013;<lpage>90</lpage>. <pub-id pub-id-type="doi">10.1162/089976699300016818</pub-id><pub-id pub-id-type="pmid">9950723</pub-id></mixed-citation></ref><ref id="B65"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pouget</surname><given-names>A.</given-names></name><name><surname>Zhang</surname><given-names>K.</given-names></name><name><surname>Deneve</surname><given-names>S.</given-names></name><name><surname>Latham</surname><given-names>P. E.</given-names></name></person-group> (<year>1998</year>). <article-title>Statistically efficient estimation using population coding</article-title>. <source>Neural Comput.</source>
<volume>10</volume>, <fpage>373</fpage>&#x02013;<lpage>401</lpage>. <pub-id pub-id-type="doi">10.1162/089976698300017809</pub-id><pub-id pub-id-type="pmid">9472487</pub-id></mixed-citation></ref><ref id="B66"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Pritzel</surname><given-names>A.</given-names></name><name><surname>Uria</surname><given-names>B.</given-names></name><name><surname>Srinivasan</surname><given-names>S.</given-names></name><name><surname>Puigdom&#x000e8;nech</surname><given-names>A.</given-names></name><name><surname>Vinyals</surname><given-names>O.</given-names></name><name><surname>Hassabis</surname><given-names>D.</given-names></name><etal/></person-group> (<year>2017</year>). <article-title>Neural episodic control,</article-title> in <source>Proceedings of the 34th International Conference on Machine Learning, Vol. 70</source> (<publisher-loc>Sydney</publisher-loc>: <publisher-name>JMLR. Org</publisher-name>), <fpage>2827</fpage>&#x02013;<lpage>2836</lpage>.</mixed-citation></ref><ref id="B67"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Ranck</surname><given-names>J. B. J.</given-names></name></person-group> (<year>1985</year>). <article-title>Head direction cells in the deep cell layer of dorsolateral pre-subiculum in freely moving rats,</article-title> in <source>Electrical Activity of the Archicortex</source>, eds <person-group person-group-type="editor"><name><surname>Buzs&#x000e1;ki</surname><given-names>G.</given-names></name><name><surname>Vanderwolf</surname><given-names>C. H.</given-names></name></person-group> (<publisher-loc>Budapest</publisher-loc>, <publisher-name>Akademiai Kiado</publisher-name>).</mixed-citation></ref><ref id="B68"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ringach</surname><given-names>D. L.</given-names></name><name><surname>Hawken</surname><given-names>M. J.</given-names></name><name><surname>Shapley</surname><given-names>R.</given-names></name></person-group> (<year>1997</year>). <article-title>Dynamics of orientation tuning in macaque primary visual cortex</article-title>. <source>Nature</source>
<volume>387</volume>:<fpage>281</fpage>. <pub-id pub-id-type="doi">10.1038/387281a0</pub-id><pub-id pub-id-type="pmid">9153392</pub-id></mixed-citation></ref><ref id="B69"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rumelhart</surname><given-names>D. E.</given-names></name><name><surname>Hinton</surname><given-names>G. E.</given-names></name><name><surname>Williams</surname><given-names>R. J.</given-names></name></person-group> (<year>1985</year>). <source>Learning Internal Representations by Error Propagation</source>. Technical report, California Univ San Diego La Jolla Inst for Cognitive Science.</mixed-citation></ref><ref id="B70"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Salinas</surname><given-names>E.</given-names></name><name><surname>Abbott</surname><given-names>L. F.</given-names></name></person-group> (<year>1995</year>). <article-title>Transfer of coded information from sensory to motor networks</article-title>. <source>J. Neurosci.</source>
<volume>15</volume>, <fpage>6461</fpage>&#x02013;<lpage>6474</lpage>. <pub-id pub-id-type="doi">10.1523/JNEUROSCI.15-10-06461.1995</pub-id><pub-id pub-id-type="pmid">7472409</pub-id></mixed-citation></ref><ref id="B71"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Samonds</surname><given-names>J. M.</given-names></name><name><surname>Potetz</surname><given-names>B. R.</given-names></name><name><surname>Lee</surname><given-names>T. S.</given-names></name></person-group> (<year>2009</year>). <article-title>Cooperative and competitive interactions facilitate stereo computations in macaque primary visual cortex</article-title>. <source>J. Neurosci.</source>
<volume>29</volume>, <fpage>15780</fpage>&#x02013;<lpage>15795</lpage>. <pub-id pub-id-type="doi">10.1523/JNEUROSCI.2305-09.2009</pub-id><pub-id pub-id-type="pmid">20016094</pub-id></mixed-citation></ref><ref id="B72"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sanger</surname><given-names>T. D.</given-names></name></person-group> (<year>1991</year>). <article-title>Optimal hidden units for two-layer nonlinear feedforward neural networks</article-title>. <source>Int. J. Patt. Recogn. Artif. Intell.</source>
<volume>5</volume>, <fpage>545</fpage>&#x02013;<lpage>561</lpage>. <pub-id pub-id-type="doi">10.1142/S0218001491000314</pub-id></mixed-citation></ref><ref id="B73"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sanger</surname><given-names>T. D.</given-names></name></person-group> (<year>1997</year>). <article-title>A probability interpretation of neural population coding for movement</article-title>, <source>Adv. Psychol.</source>
<volume>119</volume>, <fpage>75</fpage>&#x02013;<lpage>116</lpage>. <pub-id pub-id-type="doi">10.1016/S0166-4115(97)80005-2</pub-id></mixed-citation></ref><ref id="B74"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sanger</surname><given-names>T. D.</given-names></name></person-group> (<year>1998</year>). <article-title>Probability density methods for smooth function approximation and learning in populations of tuned spiking neurons</article-title>. <source>Neural Comput.</source>
<volume>10</volume>, <fpage>1567</fpage>&#x02013;<lpage>1586</lpage>. <pub-id pub-id-type="doi">10.1162/089976698300017313</pub-id><pub-id pub-id-type="pmid">9698358</pub-id></mixed-citation></ref><ref id="B75"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sanger</surname><given-names>T. D.</given-names></name></person-group> (<year>2003</year>). <article-title>Neural population codes</article-title>. <source>Curr. Opin. Neurobiol.</source>
<volume>13</volume>, <fpage>238</fpage>&#x02013;<lpage>249</lpage>. <pub-id pub-id-type="doi">10.1016/s0959-4388(03)00034-5</pub-id><pub-id pub-id-type="pmid">12744980</pub-id></mixed-citation></ref><ref id="B76"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schaul</surname><given-names>T.</given-names></name><name><surname>Schmidhuber</surname><given-names>J.</given-names></name></person-group> (<year>2010</year>). <article-title>Metalearning</article-title>. <source>Scholarpedia</source>
<volume>5</volume>:<fpage>4650</fpage>
<pub-id pub-id-type="doi">10.4249/scholarpedia.4650</pub-id></mixed-citation></ref><ref id="B77"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schmidhuber</surname><given-names>J.</given-names></name><name><surname>Zhao</surname><given-names>J.</given-names></name><name><surname>Wiering</surname><given-names>M.</given-names></name></person-group> (<year>1996</year>). <article-title>Simple principles of metalearning</article-title>. <source>Technical Report IDSIA</source>
<volume>69</volume>, <fpage>1</fpage>&#x02013;<lpage>23</lpage>.</mixed-citation></ref><ref id="B78"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schulman</surname><given-names>J.</given-names></name><name><surname>Wolski</surname><given-names>F.</given-names></name><name><surname>Dhariwal</surname><given-names>P.</given-names></name><name><surname>Radford</surname><given-names>A.</given-names></name><name><surname>Klimov</surname><given-names>O.</given-names></name></person-group> (<year>2017</year>). <article-title>Proximal policy optimization algorithms</article-title>. <source>arXiv [Preprint]</source>. arXiv: 1707.06347.</mixed-citation></ref><ref id="B79"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schweighofer</surname><given-names>N.</given-names></name><name><surname>Doya</surname><given-names>K.</given-names></name></person-group> (<year>2003</year>). <article-title>Meta-learning in reinforcement learning</article-title>. <source>Neural Netw.</source>
<volume>16</volume>, <fpage>5</fpage>&#x02013;<lpage>9</lpage>. <pub-id pub-id-type="doi">10.1016/s0893-6080(02)00228-9</pub-id><pub-id pub-id-type="pmid">12576101</pub-id></mixed-citation></ref><ref id="B80"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seeholzer</surname><given-names>A.</given-names></name><name><surname>Deger</surname><given-names>M.</given-names></name><name><surname>Gerstner</surname><given-names>W.</given-names></name></person-group> (<year>2017</year>). <article-title>Efficient low-dimensional approximation of continuous attractor networks</article-title>. <source>arXiv [Preprint]</source>. arXiv: 1711.08032.</mixed-citation></ref><ref id="B81"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seelig</surname><given-names>J. D.</given-names></name><name><surname>Jayaraman</surname><given-names>V.</given-names></name></person-group> (<year>2015</year>). <article-title>Neural dynamics for landmark orientation and angular path integration</article-title>. <source>Nature</source>
<volume>521</volume>:<fpage>186</fpage>. <pub-id pub-id-type="doi">10.1038/nature14446</pub-id><pub-id pub-id-type="pmid">25971509</pub-id></mixed-citation></ref><ref id="B82"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seri&#x000e8;s</surname><given-names>P.</given-names></name><name><surname>Latham</surname><given-names>P. E.</given-names></name><name><surname>Pouget</surname><given-names>A.</given-names></name></person-group> (<year>2004</year>). <article-title>Tuning curve sharpening for orientation selectivity: coding efficiency and the impact of correlations</article-title>. <source>Nat. Neurosci.</source>
<volume>7</volume>:<fpage>1129</fpage>. <pub-id pub-id-type="doi">10.1038/nn1321</pub-id><pub-id pub-id-type="pmid">15452579</pub-id></mixed-citation></ref><ref id="B83"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seung</surname><given-names>H. S.</given-names></name></person-group> (<year>2003</year>). <article-title>Learning in spiking neural networks by reinforcement of stochastic synaptic transmission</article-title>. <source>Neuron</source>
<volume>40</volume>, <fpage>1063</fpage>&#x02013;<lpage>1073</lpage>. <pub-id pub-id-type="doi">10.1016/s0896-6273(03)00761-x</pub-id><pub-id pub-id-type="pmid">14687542</pub-id></mixed-citation></ref><ref id="B84"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seung</surname><given-names>H. S.</given-names></name><name><surname>Sompolinsky</surname><given-names>H.</given-names></name></person-group> (<year>1993</year>). <article-title>Simple models for reading neuronal population codes</article-title>. <source>Proc. Natl. Acad. Sci. U.S.A.</source>
<volume>90</volume>, <fpage>10749</fpage>&#x02013;<lpage>10753</lpage>. <pub-id pub-id-type="doi">10.1073/pnas.90.22.10749</pub-id><pub-id pub-id-type="pmid">8248166</pub-id></mixed-citation></ref><ref id="B85"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Skaggs</surname><given-names>W. E.</given-names></name><name><surname>Knierim</surname><given-names>J. J.</given-names></name><name><surname>Kudrimoti</surname><given-names>H. S.</given-names></name><name><surname>McNaughton</surname><given-names>B. L.</given-names></name></person-group> (<year>1995</year>). <article-title>A model of the neural basis of the rat's sense of direction,</article-title> in <source>Advances in Neural Information Processing Systems</source> (<publisher-loc>Red Hook, NY</publisher-loc>: <publisher-name>Curran Associates, Inc</publisher-name>), <fpage>173</fpage>&#x02013;<lpage>180</lpage>.</mixed-citation></ref><ref id="B86"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Spitzer</surname><given-names>H.</given-names></name><name><surname>Desimone</surname><given-names>R.</given-names></name><name><surname>Moran</surname><given-names>J.</given-names></name></person-group> (<year>1988</year>). <article-title>Increased attention enhances both behavioral and neuronal performance</article-title>. <source>Science</source>
<volume>240</volume>, <fpage>338</fpage>&#x02013;<lpage>340</lpage>. <pub-id pub-id-type="doi">10.1126/science.3353728</pub-id><pub-id pub-id-type="pmid">3353728</pub-id></mixed-citation></ref><ref id="B87"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stanley</surname><given-names>K. O.</given-names></name><name><surname>Miikkulainen</surname><given-names>R.</given-names></name></person-group> (<year>2002</year>). <article-title>Evolving neural networks through augmenting topologies</article-title>. <source>Evol. Comput.</source>
<volume>10</volume>, <fpage>99</fpage>&#x02013;<lpage>127</lpage>. <pub-id pub-id-type="doi">10.1162/106365602320169811</pub-id><pub-id pub-id-type="pmid">12180173</pub-id></mixed-citation></ref><ref id="B88"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Suga</surname><given-names>N.</given-names></name><name><surname>Zhang</surname><given-names>Y.</given-names></name><name><surname>Yan</surname><given-names>J.</given-names></name></person-group> (<year>1997</year>). <article-title>Sharpening of frequency tuning by inhibition in the thalamic auditory nucleus of the mustached bat</article-title>. <source>J. Neurophysiol.</source>
<volume>77</volume>, <fpage>2098</fpage>&#x02013;<lpage>2114</lpage>. <pub-id pub-id-type="doi">10.1152/jn.1997.77.4.2098</pub-id><pub-id pub-id-type="pmid">9114258</pub-id></mixed-citation></ref><ref id="B89"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Sutton</surname><given-names>R. S.</given-names></name><name><surname>Barto</surname><given-names>A. G.</given-names></name></person-group> (<year>1998</year>). <article-title>Introduction to Reinforcement Learning</article-title>. <publisher-loc>Cambridge</publisher-loc>: <publisher-name>MIT Press</publisher-name>.</mixed-citation></ref><ref id="B90"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tavazoie</surname><given-names>S. F.</given-names></name><name><surname>Reid</surname><given-names>R. C.</given-names></name></person-group> (<year>2000</year>). <article-title>Diverse receptive fields in the lateral geniculate nucleus during thalamocortical development</article-title>. <source>Nat. Neurosci.</source>
<volume>3</volume>:<fpage>608</fpage>. <pub-id pub-id-type="doi">10.1038/75786</pub-id><pub-id pub-id-type="pmid">10816318</pub-id></mixed-citation></ref><ref id="B91"><mixed-citation publication-type="book"><person-group person-group-type="editor"><name><surname>Thrun</surname><given-names>S.</given-names></name><name><surname>Pratt</surname><given-names>L.</given-names></name></person-group> (eds.). (<year>1998</year>). <article-title>Learning to learn: introduction and overview,</article-title> in <source>Learning to Learn</source> (<publisher-loc>Boston, MA</publisher-loc>: <publisher-name>Springer</publisher-name>).</mixed-citation></ref><ref id="B92"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Todorov</surname><given-names>E.</given-names></name></person-group> (<year>2002</year>). <article-title>Cosine tuning minimizes motor errors</article-title>. <source>Neural Comput.</source>
<volume>14</volume>, <fpage>1233</fpage>&#x02013;<lpage>1260</lpage>. <pub-id pub-id-type="doi">10.1162/089976602753712918</pub-id><pub-id pub-id-type="pmid">12020444</pub-id></mixed-citation></ref><ref id="B93"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Toyoizumi</surname><given-names>T.</given-names></name><name><surname>Aihara</surname><given-names>K.</given-names></name><name><surname>Amari</surname><given-names>S.</given-names></name></person-group> (<year>2006</year>). <article-title>Fisher information for spike-based population decoding</article-title>. <source>Phys. Rev. Lett.</source>
<volume>97</volume>:<fpage>098102</fpage>. <pub-id pub-id-type="doi">10.1103/PhysRevLett.97.098102</pub-id><pub-id pub-id-type="pmid">17026405</pub-id></mixed-citation></ref><ref id="B94"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Vaswani</surname><given-names>A.</given-names></name><name><surname>Shazeer</surname><given-names>N.</given-names></name><name><surname>Parmar</surname><given-names>N.</given-names></name><name><surname>Uszkoreit</surname><given-names>J.</given-names></name><name><surname>Jones</surname><given-names>L.</given-names></name><name><surname>Gomez</surname><given-names>A. N.</given-names></name><etal/></person-group> (<year>2017</year>). <article-title>Attention is all you need,</article-title> in <source>Advances in Neural Information Processing Systems 30</source>, eds <person-group person-group-type="editor"><name><surname>Guyon</surname><given-names>I.</given-names></name><name><surname>Luxburg</surname><given-names>U. V.</given-names></name><name><surname>Bengio</surname><given-names>S.</given-names></name><name><surname>Wallach</surname><given-names>H.</given-names></name><name><surname>Fergus</surname><given-names>R.</given-names></name><name><surname>Vishwanathan</surname><given-names>S.</given-names></name><name><surname>Garnett</surname><given-names>R.</given-names></name></person-group> (<publisher-loc>Red Hook, NY</publisher-loc>: <publisher-name>Curran Associates, Inc</publisher-name>), <fpage>5998</fpage>&#x02013;<lpage>6008</lpage>.</mixed-citation></ref><ref id="B95"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wagner</surname><given-names>H.</given-names></name></person-group> (<year>1990</year>). <article-title>Receptive fields of neurons in the owl's auditory brainstem change dynamically</article-title>. <source>Eur. J. Neurosci.</source>
<volume>2</volume>, <fpage>949</fpage>&#x02013;<lpage>959</lpage>. <pub-id pub-id-type="doi">10.1111/j.1460-9568.1990.tb00007.x</pub-id><pub-id pub-id-type="pmid">12106082</pub-id></mixed-citation></ref><ref id="B96"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wan</surname><given-names>L.</given-names></name><name><surname>Zeiler</surname><given-names>M.</given-names></name><name><surname>Zhang</surname><given-names>S.</given-names></name><name><surname>Le Cun</surname><given-names>Y.</given-names></name><name><surname>Fergus</surname><given-names>R.</given-names></name></person-group> (<year>2013</year>). <article-title>Regularization of neural networks using dropconnect,</article-title> in <source>International Conference on Machine Learning</source> (JMLR.org), <fpage>1058</fpage>&#x02013;<lpage>1066</lpage>.</mixed-citation></ref><ref id="B97"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>X.</given-names></name><name><surname>Lu</surname><given-names>T.</given-names></name><name><surname>Snider</surname><given-names>R. K.</given-names></name><name><surname>Liang</surname><given-names>L.</given-names></name></person-group> (<year>2005</year>). <article-title>Sustained firing in auditory cortex evoked by preferred stimuli</article-title>. <source>Nature</source>
<volume>435</volume>:<fpage>341</fpage>. <pub-id pub-id-type="doi">10.1038/nature03565</pub-id><pub-id pub-id-type="pmid">15902257</pub-id></mixed-citation></ref><ref id="B98"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Weliky</surname><given-names>M.</given-names></name><name><surname>Kandler</surname><given-names>K.</given-names></name><name><surname>Fitzpatrick</surname><given-names>D.</given-names></name><name><surname>Katz</surname><given-names>L. C.</given-names></name></person-group> (<year>1995</year>). <article-title>Patterns of excitation and inhibition evoked by horizontal connections in visual cortex share a common relationship to orientation columns</article-title>. <source>Neuron</source>
<volume>15</volume>, <fpage>541</fpage>&#x02013;<lpage>552</lpage>. <pub-id pub-id-type="doi">10.1016/0896-6273(95)90143-4</pub-id><pub-id pub-id-type="pmid">7546734</pub-id></mixed-citation></ref><ref id="B99"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Williams</surname><given-names>R. J.</given-names></name></person-group> (<year>1992</year>). <article-title>Simple statistical gradient-following algorithms for connectionist reinforcement learning</article-title>. <source>Mach. Learn.</source>
<volume>8</volume>, <fpage>229</fpage>&#x02013;<lpage>256</lpage>. <pub-id pub-id-type="doi">10.1007/BF00992696</pub-id></mixed-citation></ref><ref id="B100"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilson</surname><given-names>H. R.</given-names></name><name><surname>Cowan</surname><given-names>J. D.</given-names></name></person-group> (<year>1973</year>). <article-title>A mathematical theory of the functional dynamics of cortical and thalamic nervous tissue</article-title>. <source>Kybernetik</source>
<volume>13</volume>, <fpage>55</fpage>&#x02013;<lpage>80</lpage>. <pub-id pub-id-type="doi">10.1007/bf00288786</pub-id><pub-id pub-id-type="pmid">4767470</pub-id></mixed-citation></ref><ref id="B101"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yaeli</surname><given-names>S.</given-names></name><name><surname>Meir</surname><given-names>R.</given-names></name></person-group> (<year>2010</year>). <article-title>Error-based analysis of optimal tuning functions explains phenomena observed in sensory neurons</article-title>. <source>Front. Comput. Neurosci.</source>
<volume>4</volume>:<fpage>130</fpage>. <pub-id pub-id-type="doi">10.3389/fncom.2010.00130</pub-id><pub-id pub-id-type="pmid">21079749</pub-id></mixed-citation></ref><ref id="B102"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yarrow</surname><given-names>S.</given-names></name><name><surname>Seri&#x000e8;s</surname><given-names>P.</given-names></name></person-group> (<year>2015</year>). <article-title>The influence of population size, noise strength and behavioral task on best-encoded stimulus for neurons with unimodal or monotonic tuning curves</article-title>. <source>Front. Comput. Neurosci.</source>
<volume>9</volume>:<fpage>18</fpage>. <pub-id pub-id-type="doi">10.3389/fncom.2015.00018</pub-id><pub-id pub-id-type="pmid">25774131</pub-id></mixed-citation></ref><ref id="B103"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>K.</given-names></name><name><surname>Sejnowski</surname><given-names>T. J.</given-names></name></person-group> (<year>1999</year>). <article-title>Neuronal tuning: to sharpen or broaden?</article-title>
<source>Neural Comput.</source>
<volume>11</volume>, <fpage>75</fpage>&#x02013;<lpage>84</lpage>. <pub-id pub-id-type="doi">10.1162/089976699300016809</pub-id><pub-id pub-id-type="pmid">9950722</pub-id></mixed-citation></ref></ref-list></back></article>