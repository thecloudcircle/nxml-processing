
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">Sci Rep</journal-id><journal-id journal-id-type="iso-abbrev">Sci Rep</journal-id><journal-title-group><journal-title>Scientific Reports</journal-title></journal-title-group><issn pub-type="epub">2045-2322</issn><publisher><publisher-name>Nature Publishing Group UK</publisher-name><publisher-loc>London</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">32404971</article-id><article-id pub-id-type="pmc">7220942</article-id><article-id pub-id-type="publisher-id">64655</article-id><article-id pub-id-type="doi">10.1038/s41598-020-64655-4</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>CNN-Peaks: ChIP-Seq peak detection pipeline using convolutional neural networks that imitate human visual inspection</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Oh</surname><given-names>Dongpin</given-names></name><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author"><name><surname>Strattan</surname><given-names>J. Seth</given-names></name><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author"><name><surname>Hur</surname><given-names>Junho K.</given-names></name><xref ref-type="aff" rid="Aff3">3</xref></contrib><contrib contrib-type="author"><name><surname>Bento</surname><given-names>Jos&#x000e9;</given-names></name><xref ref-type="aff" rid="Aff4">4</xref></contrib><contrib contrib-type="author"><name><surname>Urban</surname><given-names>Alexander Eckehart</given-names></name><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Song</surname><given-names>Giltae</given-names></name><address><email>gsong@pusan.ac.kr</email></address><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author"><name><surname>Cherry</surname><given-names>J. Michael</given-names></name><xref ref-type="aff" rid="Aff2">2</xref></contrib><aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0001 0719 8572</institution-id><institution-id institution-id-type="GRID">grid.262229.f</institution-id><institution>School of Computer Science and Engineering, Pusan National University, </institution></institution-wrap>Busan, 46241 South Korea </aff><aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ISNI">0000000419368956</institution-id><institution-id institution-id-type="GRID">grid.168010.e</institution-id><institution>Department of Genetics, </institution><institution>Stanford University, </institution></institution-wrap>Stanford, 94305 USA </aff><aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0001 2171 7818</institution-id><institution-id institution-id-type="GRID">grid.289247.2</institution-id><institution>School of Medicine, Kyung Hee University, </institution></institution-wrap>Seoul, 02447 South Korea </aff><aff id="Aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0004 0444 7053</institution-id><institution-id institution-id-type="GRID">grid.208226.c</institution-id><institution>Department of Computer Science, </institution><institution>Boston College, Chestnut Hill, </institution></institution-wrap>Philadelphia, MA 02467 USA </aff></contrib-group><pub-date pub-type="epub"><day>13</day><month>5</month><year>2020</year></pub-date><pub-date pub-type="pmc-release"><day>13</day><month>5</month><year>2020</year></pub-date><pub-date pub-type="collection"><year>2020</year></pub-date><volume>10</volume><elocation-id>7933</elocation-id><history><date date-type="received"><day>27</day><month>12</month><year>2019</year></date><date date-type="accepted"><day>20</day><month>4</month><year>2020</year></date></history><permissions><copyright-statement>&#x000a9; The Author(s) 2020</copyright-statement><license license-type="OpenAccess"><license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The images or other third party material in this article are included in the article&#x02019;s Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the article&#x02019;s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this license, visit <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p></license></permissions><abstract id="Abs1"><p id="Par1">ChIP-seq is one of the core experimental resources available to understand genome-wide epigenetic interactions and identify the functional elements associated with diseases. The analysis of ChIP-seq data is important but poses a difficult computational challenge, due to the presence of irregular noise and bias on various levels. Although many peak-calling methods have been developed, the current computational tools still require, in some cases, human manual inspection using data visualization. However, the huge volumes of ChIP-seq data make it almost impossible for human researchers to manually uncover all the peaks. Recently developed convolutional neural networks (CNN), which are capable of achieving human-like classification accuracy, can be applied to this challenging problem. In this study, we design a novel supervised learning approach for identifying ChIP-seq peaks using CNNs, and integrate it into a software pipeline called CNN-Peaks. We use data labeled by human researchers who annotate the presence or absence of peaks in some genomic segments, as training data for our model. The trained model is then applied to predict peaks in previously unseen genomic segments from multiple ChIP-seq datasets including benchmark datasets commonly used for validation of peak calling methods. We observe a performance superior to that of previous methods.</p></abstract><kwd-group kwd-group-type="npg-subject"><title>Subject terms</title><kwd>Computational biology and bioinformatics</kwd><kwd>Genetics</kwd><kwd>Molecular biology</kwd></kwd-group><custom-meta-group><custom-meta><meta-name>issue-copyright-statement</meta-name><meta-value>&#x000a9; The Author(s) 2020</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="Sec1" sec-type="introduction"><title>Introduction</title><p id="Par2">In the postgenomic era, understanding epigenetic regulation is one of the most important challenges in the biological and medical sciences. To elucidate pathological mechanisms, and pinpoint target genes for developing therapeutics, it is important to assess abnormalities in the genome-wide interactions of proteins and genomic elements that cause gene misregulation. In this regard, chromatin immunoprecipitation followed by sequencing (ChIP-seq) is a technique widely used to identify genomic binding sites for epigenetic regulators, including histones, transcription factors, and DNA/RNA binding proteins<sup><xref ref-type="bibr" rid="CR1">1</xref>,<xref ref-type="bibr" rid="CR2">2</xref></sup>. ChIP-seq enables the discovery of the interactions between protein complexes and DNA regulatory elements, and their gene regulatory networks<sup><xref ref-type="bibr" rid="CR3">3</xref></sup>. ChIP-seq data analysis has shown how histone modifications and nucleic acid interacting proteins modulate the critical factors of gene regulation, and cell lineage determination and maintenance<sup><xref ref-type="bibr" rid="CR4">4</xref>,<xref ref-type="bibr" rid="CR5">5</xref></sup>.</p><p id="Par3">One of the major computational challenges in analyzing ChIP-seq data is to identify peaks in genomic areas where aligned reads are enriched when sequencing reads are mapped to a given reference genome. This task is a challenge for several reasons. Sequencing errors and local bias caused by structural variations complicate solving the peak-calling problem. The diverse patterns of data, which are caused by biological variability, a variety of domains, experiment environment, and sequencing coverage, make the problem even harder. Sensitive and reliable computational methods to determine peaks from noisy backgrounds are especially important for medical studies, where patient samples can be limited, resulting in sub-optimal data quantity and quality.</p><p id="Par4">Several software tools for calling the peaks in ChIP-seq data have been developed based on various probabilistic and unsupervised learning methods, such as MACS2, HOMER, SICER, and SPP<sup><xref ref-type="bibr" rid="CR4">4</xref>,<xref ref-type="bibr" rid="CR6">6</xref>,<xref ref-type="bibr" rid="CR7">7</xref></sup>. Some of these tools show the high sensitivity of calling the peaks, but suffer from high false-positive error rates. Other tools may need additional information as input data (e.g. mappability scores that the fraction of a region that overlaps at least one uniquely mappable read in the genome<sup><xref ref-type="bibr" rid="CR8">8</xref></sup>).</p><p id="Par5">In<sup><xref ref-type="bibr" rid="CR9">9</xref></sup> a neural network model was proposed to denoise ChIP-seq data and increase the performance of calling the peaks. An ensemble approach was also proposed<sup><xref ref-type="bibr" rid="CR10">10</xref></sup> to improve the accuracy of calling ChIP-seq peaks. The latter exploits the output from multiple existing peak-calling software tools to eliminate outliers among the multiple peak calling decisions. These approaches have increased the sensitivity of calling true peaks, but they still suffer from high false-positive rates<sup><xref ref-type="bibr" rid="CR8">8</xref></sup>. In particular, human cancer cell lines are too complicated for one to understand human malignancy using ChIP-seq, since the data patterns vary substantially depending on patients&#x02019; primary cancer tissues<sup><xref ref-type="bibr" rid="CR11">11</xref>&#x02013;<xref ref-type="bibr" rid="CR13">13</xref></sup>. False-positive rates of calling ChIP-seq peaks in human cancer cell lines are worse than in other datasets<sup><xref ref-type="bibr" rid="CR12">12</xref></sup>.</p><p id="Par6">To resolve these issues, human experts are used to label true peaks using visualization tools such as UCSC genome browser, and the Integrative Genomics Viewer (IGV)<sup><xref ref-type="bibr" rid="CR14">14</xref>,<xref ref-type="bibr" rid="CR15">15</xref></sup>. False-positive peaks can also be corrected by professional researchers<sup><xref ref-type="bibr" rid="CR16">16</xref></sup>. However, it would be extremely inefficient for human scientists to find all of the peaks in the whole genome for large volumes of ChIP-seq data. Hocking <italic>et al</italic>.<sup><xref ref-type="bibr" rid="CR8">8</xref></sup>, have proposed a supervised learning approach based on grid search to optimize a parameter (e.g. a cut-off value) that users need to set up when running peak-calling tools such as MACS2. They use data of which part of the peaks have been labeled by human experts, learn parameter values, and apply the optimized parameters for the rest of the dataset. Unfortunatly, this requires completing labeling task for each individual ChIP-seq dataset and each peak-calling tool.</p><p id="Par7">Recently, supervised machine learning methods based on deep neural networks, such as convolutional neural networks (CNN), have been successfully applied to epigenetics, regulatory genomics, and system biology<sup><xref ref-type="bibr" rid="CR17">17</xref>,<xref ref-type="bibr" rid="CR18">18</xref></sup>. In this article, we develop a novel peak calling software pipeline based on CNN, named CNN-Peaks, that feeds on data partially labeled by human researchers. We identify local peak-calling threshold values, which might differ from one genomic segment to another, and use them to reduce false-positive peak calls, and thus resolve local bias caused by structural variations in, e.g., the human cancer cell lines. Note that some of the peaks in genomic regions that have frequent copy number variations are expected to show higher mapping depth than the others. As training data for CNN-Peaks, we use data labeled by human experts as well as read count information from the preprocessing steps of raw read mapping. Our software tool learns a model for determining proper peak-detection cut-off values in specific genomic regions by taking read mapping patterns in their neighbor regions into account. Our inspiration to use CNNs is the fact that they have been successfully used to solve problems in image processing and natural language translation using data patterns that, like in our case, have features with local dependencies<sup><xref ref-type="bibr" rid="CR19">19</xref>,<xref ref-type="bibr" rid="CR20">20</xref></sup>). We also use integrated annotation information (RefSeq) available in NCBI (<ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/">https://www.ncbi.nlm.nih.gov/</ext-link>) as training input data for building our predictive CNN. The RefSeq data include genomic locations of genes, transcripts and protein encodings that can assist to determine the existence of peaks for human visual inspection.</p><p id="Par8">Our CNN-Peaks software package is composed of three main modules: one for preprocessing original input data (labeled data, genome annotation, and read count information) and feed them into our CNN architecture; another for learning a model using the training data; and a final one for predicting peaks for unknown data. We evaluate the performance of CNN-Peaks using some labeled data reserved as test data. We also test CNN-Peaks on ChIP-seq benchmark datasets that are commonly used for evaluation, and compare its performance against other major peak calling tools. We also use our CNN-Peaks tool to analyze various real datasets for histone modification, such as H3K27ac, and for transcription factor binding, such as GATAD2, in various human cell lines.</p><p id="Par9">Users can install the CNN-Peaks pipeline using a docker image and run the package using their own data with our trained model for predicting narrow histone modifications and transcription factor binding sites in humans. Experienced users can also build a new predictive model trained on their own labeled data using CNN-Peaks. Our software package includes a desktop application to help experts create labeled data easily by labeling peaks in genomic regions randomly selected from a given ChIP-seq read mapping data (Supplementary text S3). Our pipeline can be also applied to other types of high-throughput sequencing data, such as DNase-seq and ATAC-seq. Our package is available through the Github repository <ext-link ext-link-type="uri" xlink:href="http://github.com/odb9402/CNNPeaks">http://github.com/odb9402/CNNPeaks</ext-link>.</p></sec><sec id="Sec2" sec-type="materials|methods"><title>Materials and Methods</title><sec id="Sec3"><title>Data description</title><p id="Par10">We obtained multiple ChIP-seq read mapping datasets in BAM format from the ENCODE data portal<sup><xref ref-type="bibr" rid="CR21">21</xref></sup> for creating labeled data, and validating CNN-Peaks. This data includes several ChIP-seq datasets for examining histone modification, such as histones H3K36me3, H3K4me3, H3K27me3, H2AFZ, and H3K9ac, and transcription factor binding, such as transcription factors GATAD2, POLR2A, SMARCE1, and MAX in cancer cell domains K562, A549, HepG2, HEK293, and GM12878. We also downloaded ChIP-seq data from leukemia cell line K562 and labeled its background binding of genomic regions to then train our CNN model. From the ChIP-seq read mapping data in BAM format, some genomic segments were randomly selected, and the locations of peaks were labeled using our visualization tool with the BAM alignment<sup><xref ref-type="bibr" rid="CR8">8</xref></sup> data as Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref> illustrates.<fig id="Fig1"><label>Figure 1</label><caption><p>Visualization of labeling peaks using ChIP-seq read mapping data. For some genomic regions, human researchers can determine which regions are peaks, or not, and label them using an interface tool included in our CNN-Peaks package.</p></caption><graphic xlink:href="41598_2020_64655_Fig1_HTML" id="d29e417"/></fig></p><p id="Par11">In addition to the labeled data and read mapping BAM files, we used a curated non-redundant collection of genomic, transcript, and protein sequence records for the human reference sequence (RefSeq) in NCBI, as an additional input vector for our CNN model<sup><xref ref-type="bibr" rid="CR22">22</xref></sup>. The RefSeq data include protein-coding locations and pseudogenes. When researchers manually examine ChIP-seq data to determine the peaks, the genome annotation information, such as transcripts and their corresponding protein records, are commonly viewed together with the given read mapping data. This information often gives a good guess of where peaks might be. To mimic human inspection, we considered this and built our model so that it uses these different annotated types as input. We added this annotation information as a binary vector to represent the presence and absence of transcripts and proteins in each genomic position.</p></sec><sec id="Sec4"><title>Data preprocessing</title><p id="Par12">A preprocessing module is included in our CNN-Peaks pipeline. This module converts all input data, including read mapping BAM files, labeled data, and genome annotation information, to vectors with the right shape to be fed into our CNN architecture. We use bins of a fixed size (12,000 bins by default) to normalize the different window sizes of labeled segments into the same size. If a window is smaller than the target window size, the user of CNN-Peaks should either label an additional region to append to this window using our visual inspection tool, or should adjust the parameter of the target window size, or should simply eliminate the window (Supplementary text S1).</p><p id="Par13">Our preprocessing module also includes functions to smooth read count patterns to reduce noises in read alignment data. This smoothing step also helps make our CNN model close to human visual inspection. Without the smoothing and correction step, (raw) depth patterns are very noisy (Supplementary text S1). We use max-pooling and Gaussian filter convolution operations for smoothing. Gaussian filters are commonly used for denoising and smoothing in various domains, such as image processing<sup><xref ref-type="bibr" rid="CR23">23</xref></sup>. The equations of the convolution and max-pooling operations (Eqs. (<xref rid="Equ1" ref-type="">1</xref>) and (<xref rid="Equ2" ref-type="">2</xref>) respectively) are as follows (note &#x0201c;*&#x0201d; indicates a convolution operation. The strides for convolution and max-pooling are 1).<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$(v\ast u)(n)=\mathop{\sum }\limits_{m=-[\frac{M}{2}]}^{\left[\frac{M}{2}\right]}{v}_{n-m\cdot }{u}_{n}$$\end{document}</tex-math><mml:math id="M2" display="block"><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>v</mml:mi><mml:mo>&#x02217;</mml:mo><mml:mi>u</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mo stretchy="true">[</mml:mo><mml:mfrac><mml:mi>M</mml:mi><mml:mn>2</mml:mn></mml:mfrac><mml:mo stretchy="true">]</mml:mo></mml:mrow><mml:mfenced close="]" open="["><mml:mfrac><mml:mi>M</mml:mi><mml:mn>2</mml:mn></mml:mfrac></mml:mfenced></mml:munderover><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mi>m</mml:mi><mml:mo>&#x022c5;</mml:mo></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math><graphic xlink:href="41598_2020_64655_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ2"><label>2</label><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\max }\,{\_}{poo}{{l}}_{{v}{,}{w}}({n}){=}{{v}}_{{k}}\,\mathrm{where}\,{{\boldsymbol{v}}}_{{\boldsymbol{k}}}\ge {{\boldsymbol{v}}}_{{\boldsymbol{i}}}\,\mathrm{for}\,\mathrm{all}\,{\boldsymbol{n}}-\frac{{\boldsymbol{w}}}{2}\le {\boldsymbol{i}}\le {\boldsymbol{n}}+\frac{{\boldsymbol{w}}}{2}$$\end{document}</tex-math><mml:math id="M4" display="block"><mml:mi mathvariant="italic">max</mml:mi><mml:mspace width=".25em"/><mml:mo mathvariant="italic">_</mml:mo><mml:mi mathvariant="italic">poo</mml:mi><mml:msub><mml:mrow><mml:mi mathvariant="italic">l</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">v</mml:mi><mml:mo mathvariant="italic">,</mml:mo><mml:mi mathvariant="italic">w</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mi mathvariant="italic">n</mml:mi><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo mathvariant="italic">=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="italic">v</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">k</mml:mi></mml:mrow></mml:msub><mml:mspace width=".25em"/><mml:mi>where</mml:mi><mml:mspace width=".25em"/><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">v</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">k</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02265;</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">v</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow></mml:msub><mml:mspace width=".25em"/><mml:mi>for</mml:mi><mml:mspace width=".25em"/><mml:mi>all</mml:mi><mml:mspace width=".25em"/><mml:mi mathvariant="bold-italic">n</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mfrac><mml:mi mathvariant="bold-italic">w</mml:mi><mml:mn>2</mml:mn></mml:mfrac><mml:mo>&#x02264;</mml:mo><mml:mi mathvariant="bold-italic">i</mml:mi><mml:mo>&#x02264;</mml:mo><mml:mi mathvariant="bold-italic">n</mml:mi><mml:mo>+</mml:mo><mml:mfrac><mml:mi mathvariant="bold-italic">w</mml:mi><mml:mn>2</mml:mn></mml:mfrac></mml:math><graphic xlink:href="41598_2020_64655_Article_Equ2.gif" position="anchor"/></alternatives></disp-formula></p><p id="Par14">Above, <inline-formula id="IEq3"><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$M,w\in {Z}^{+}$$\end{document}</tex-math><mml:math id="M6"><mml:mi>M</mml:mi><mml:mo>,</mml:mo><mml:mi>w</mml:mi><mml:mo>&#x02208;</mml:mo><mml:msup><mml:mrow><mml:mi>Z</mml:mi></mml:mrow><mml:mo>+</mml:mo></mml:msup></mml:math><inline-graphic xlink:href="41598_2020_64655_Article_IEq3.gif"/></alternatives></inline-formula> are the filter size of each operation, <italic>v</italic>, <italic>u</italic> are input vectors, and <inline-formula id="IEq4"><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${v}_{i}$$\end{document}</tex-math><mml:math id="M8"><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41598_2020_64655_Article_IEq4.gif"/></alternatives></inline-formula> is the <italic>i</italic>
<sup>th</sup> component of <inline-formula id="IEq5"><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$v$$\end{document}</tex-math><mml:math id="M10"><mml:mi>v</mml:mi></mml:math><inline-graphic xlink:href="41598_2020_64655_Article_IEq5.gif"/></alternatives></inline-formula>. Let <inline-formula id="IEq6"><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$X$$\end{document}</tex-math><mml:math id="M12"><mml:mi>X</mml:mi></mml:math><inline-graphic xlink:href="41598_2020_64655_Article_IEq6.gif"/></alternatives></inline-formula> be a vector of read mapping counts, <inline-formula id="IEq7"><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$filter$$\end{document}</tex-math><mml:math id="M14"><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mi>l</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi></mml:math><inline-graphic xlink:href="41598_2020_64655_Article_IEq7.gif"/></alternatives></inline-formula> a gaussian filter, and <inline-formula id="IEq8"><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${X}_{smoothi{\rm{ng}}}$$\end{document}</tex-math><mml:math id="M16"><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>m</mml:mi><mml:mi>o</mml:mi><mml:mi>o</mml:mi><mml:mi>t</mml:mi><mml:mi>h</mml:mi><mml:mi>i</mml:mi><mml:mi mathvariant="normal">ng</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41598_2020_64655_Article_IEq8.gif"/></alternatives></inline-formula> a smoothed vector of <inline-formula id="IEq9"><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$X$$\end{document}</tex-math><mml:math id="M18"><mml:mi>X</mml:mi></mml:math><inline-graphic xlink:href="41598_2020_64655_Article_IEq9.gif"/></alternatives></inline-formula>, then<disp-formula id="Equ3"><label>3</label><alternatives><tex-math id="M19">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${X}_{pool}=[max\_poo{l}_{X,w}(1),\ldots ,max\_poo{l}_{X,w}(L)],$$\end{document}</tex-math><mml:math id="M20" display="block"><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>o</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="true">[</mml:mo><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mo>_</mml:mo><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>o</mml:mi><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mi>w</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mi>&#x02026;</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mo>_</mml:mo><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>o</mml:mi><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mi>w</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mi>L</mml:mi><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="true">]</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:math><graphic xlink:href="41598_2020_64655_Article_Equ3.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ4"><label>4</label><alternatives><tex-math id="M21">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{\boldsymbol{X}}}_{{\boldsymbol{smoothing}}}=[({{\boldsymbol{X}}}_{{\boldsymbol{pool}}}\,\ast \,{\boldsymbol{filter}})(1),\ldots ,({{\boldsymbol{X}}}_{{\boldsymbol{pool}}}\,\ast \,{\boldsymbol{filter}})({\boldsymbol{L}})].$$\end{document}</tex-math><mml:math id="M22" display="block"><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">X</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">smoothing</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">X</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">pool</mml:mi></mml:mrow></mml:msub><mml:mspace width=".25em"/><mml:mo>&#x0204e;</mml:mo><mml:mspace width=".25em"/><mml:mi mathvariant="bold-italic">filter</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo><mml:mo>,</mml:mo><mml:mi>&#x02026;</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">X</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">pool</mml:mi></mml:mrow></mml:msub><mml:mspace width=".25em"/><mml:mo>&#x0204e;</mml:mo><mml:mspace width=".25em"/><mml:mi mathvariant="bold-italic">filter</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">L</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:math><graphic xlink:href="41598_2020_64655_Article_Equ4.gif" position="anchor"/></alternatives></disp-formula></p></sec><sec id="Sec5"><title>CNN architecture</title><p id="Par15">Our CNN architecture builds upon the Inception module used in GoogLeNet, which extracts diversified features from data via filters of various sizes (see various filters in Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2A</xref>)<sup><xref ref-type="bibr" rid="CR24">24</xref>,<xref ref-type="bibr" rid="CR25">25</xref></sup>. We built three types of modules with a slimmer structure than the original Inception module as Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2B</xref> illustrates. The structure is composed of several hidden layers, such as pooling and convolutional layers, as well as the Inception modules, as Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2</xref> shows. The Inception-style modules are known to lead to inefficacies in terms of prediction accuracy if they are placed at the beginning of the CNN architecture<sup><xref ref-type="bibr" rid="CR24">24</xref></sup>. To avoid this potential problem, we put traditional convolutional filters, and a max-pooling layer, at the beginning of our CNN-Peaks architecture (Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2</xref>). The details of our CNN architecture are described as follows.<fig id="Fig2"><label>Figure 2</label><caption><p>The schema of CNN-peaks model. (<bold>A</bold>) There are three Inception-like modules: Concat-A, Concat-B, and Concat-C. Each yellow box represents a convolution operation with filter size 1 * N, and black boxes concatenate filters, which are constructed by combining several convolution and pooling outputs. (<bold>B</bold>) Our model learns optimal threshold values for calling peaks in local genomic segments of ChIP-seq data and determines the presence or absence of peaks using a subtraction of the threshold from each input signal value, and a sigmoid operation. Blue arrows indicate residual connections between Inception modules, and a purple arrow an operation for expanding output vectors.</p></caption><graphic xlink:href="41598_2020_64655_Fig2_HTML" id="d29e971"/></fig></p><p id="Par16">First, two input vectors for annotation information (RefSeq) and read mapping patterns are transformed through the convolution layers into vectors. Then the max-pooling layer reduces the dimension of these vectors. Then there are seven Inception modules. Each Inception module has a layer that concatenates a list of outputs from the filters. Two of these modules, called A-modules, use three types of filters: convolution, max, and average pooling. They provide information about peak patterns and the scale of strong peak signals to our CNN model. However, since max pooling and average pooling have the same number of features as the previous layer, this increases the vector size exponentially as a function of the depth of pooling layers<sup><xref ref-type="bibr" rid="CR24">24</xref></sup>. To resolve this issue, we use the other three Inception modules, called B-modules, which are composed of convolution filters of three types without an average pooling. Finally, we use two Inception modules, called C-modules, that have four types of convolution filters with a wider size and longer stride than the filters used in A- and B-modules. At the end of the Inception modules, an average pooling layer followed by fully connected layers is added to reduce dimensions.</p><p id="Par17">In addition, we use a <italic>residual structure</italic> between the Inception layers<sup><xref ref-type="bibr" rid="CR26">26</xref></sup>. This helps avoiding vanishing gradient problems. We also use batch normalization as regularization to avoid overfitting<sup><xref ref-type="bibr" rid="CR27">27</xref></sup> while training.</p></sec><sec id="Sec6"><title>Output layer of CNN architecture</title><p id="Par18">To determine the presence or absence of peaks in each individual genomic position, the output layer of the CNN architecture needs a number of neurons that are equal to the number of genome bases. This large number of neurons in the output layer usually causes a significant degradation of learning performance<sup><xref ref-type="bibr" rid="CR28">28</xref></sup>. In order to reduce the number of neurons, we designed our CNN model to learn optimal threshold values for genomic segments based on read mapping patterns in a selected window, rather than computing the p-value or the likelihood of the presence of a peak signal in each individual genomic position. This substantially reduces the number of neurons required in the output layer of our CNN model, and prevents performance degradation. Since the output vector size becomes smaller than the input vector, we add an additional operation to expand the output vector size to be identical to the input vector, so that we can predict the presence or absence of peaks in each individual position (See the purple box named as &#x0201c;Expand&#x0201d; in Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2B</xref>). These expanding vectors are implemented using the &#x0201c;broadcasting vector&#x0201d; standard in Tensorflow and Numpy, which allows operations between vectors of different sizes. The peak calling process of our CNN-Peaks is summarized in Fig.&#x000a0;<xref rid="Fig3" ref-type="fig">3</xref>.<fig id="Fig3"><label>Figure 3</label><caption><p>The process of peak calling with a trained model. The black signal is the read mapping depth in the ChIP-seq input data, and the blue boxes below the signal indicate the presence of genes in RefSeq annotation. An orange box is a window with both read mapping signal and RefSeq annotation in a genomic region. Peaks (in orange underlay) in the window are predicted using the model trained by CNN-Peaks, and generated in BED format.</p></caption><graphic xlink:href="41598_2020_64655_Fig3_HTML" id="d29e1014"/></fig></p></sec><sec id="Sec7"><title>Loss function</title><p id="Par19">Determining the presence or absence of a peak signal is a binary classification problem. We use cross-entropy as a loss function for learning our model. Most methods for classification problems require balancing the trade-off between sensitivity and specificity in performance. Likewise, we need to be careful not to favor only one of these<sup><xref ref-type="bibr" rid="CR29">29</xref></sup>. In peak calling problems with ChIP-seq data, peaks are relatively rare compared to the whole genome size. If a certain method tends to call &#x02018;no-peak&#x02019; (<italic>i.e</italic>. it has low false-positive error rate), it will show high accuracy, although it misses important peaks. Therefore, we use a weighted cross-entropy as our loss, in Eq. (<xref rid="Equ5" ref-type="">5</xref>).<disp-formula id="Equ5"><label>5</label><alternatives><tex-math id="M23">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\ell }_{{\boldsymbol{i}}}({\boldsymbol{X}},{\boldsymbol{\Lambda }},{\boldsymbol{\theta }})={{\boldsymbol{y}}}_{{\boldsymbol{i}}}\,\log ({{\boldsymbol{h}}}_{{\boldsymbol{i}},{\boldsymbol{\theta }}}({\boldsymbol{X}},{\boldsymbol{\Lambda }})){\boldsymbol{w}}+(1-{{\boldsymbol{y}}}_{{\boldsymbol{i}}})\log (1-{{\boldsymbol{h}}}_{{\boldsymbol{i}},{\boldsymbol{\theta }}}({\boldsymbol{X}},{\boldsymbol{\Lambda }})),$$\end{document}</tex-math><mml:math id="M24" display="block"><mml:msub><mml:mrow><mml:mi>&#x02113;</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">X</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold">&#x0039b;</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">&#x003b8;</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow></mml:msub><mml:mspace width=".25em"/><mml:mi>log</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">h</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold">&#x003b8;</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">X</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold">&#x0039b;</mml:mi><mml:mo>)</mml:mo><mml:mo>)</mml:mo><mml:mi mathvariant="bold-italic">w</mml:mi><mml:mo>+</mml:mo><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mi>log</mml:mi><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">h</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold">&#x003b8;</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">X</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold">&#x0039b;</mml:mi><mml:mo>)</mml:mo><mml:mo>)</mml:mo><mml:mo>,</mml:mo></mml:math><graphic xlink:href="41598_2020_64655_Article_Equ5.gif" position="anchor"/></alternatives></disp-formula>where <italic>X</italic> is the input read counts vector, <inline-formula id="IEq10"><alternatives><tex-math id="M25">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\varLambda $$\end{document}</tex-math><mml:math id="M26"><mml:mi>&#x0039b;</mml:mi></mml:math><inline-graphic xlink:href="41598_2020_64655_Article_IEq10.gif"/></alternatives></inline-formula> the annotation vector, <inline-formula id="IEq11"><alternatives><tex-math id="M27">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\theta $$\end{document}</tex-math><mml:math id="M28"><mml:mi>&#x003b8;</mml:mi></mml:math><inline-graphic xlink:href="41598_2020_64655_Article_IEq11.gif"/></alternatives></inline-formula> the set of parameters in our model, <inline-formula id="IEq12"><alternatives><tex-math id="M29">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${y}_{i}$$\end{document}</tex-math><mml:math id="M30"><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41598_2020_64655_Article_IEq12.gif"/></alternatives></inline-formula> the <italic>i</italic><sup>th</sup> element of the input for the labeled data, <inline-formula id="IEq13"><alternatives><tex-math id="M31">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$w\,$$\end{document}</tex-math><mml:math id="M32"><mml:mi>w</mml:mi><mml:mspace width=".25em"/></mml:math><inline-graphic xlink:href="41598_2020_64655_Article_IEq13.gif"/></alternatives></inline-formula> a weight for the importance of false-negative calls relative to false-positives calls in the valuation, and <inline-formula id="IEq14"><alternatives><tex-math id="M33">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${h}_{i,{\rm{\theta }}}(X,\Lambda )$$\end{document}</tex-math><mml:math id="M34"><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">&#x003b8;</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">&#x0039b;</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41598_2020_64655_Article_IEq14.gif"/></alternatives></inline-formula> is the <italic>i</italic><sup>th</sup> element in the output predicted for given input <inline-formula id="IEq15"><alternatives><tex-math id="M35">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$X$$\end{document}</tex-math><mml:math id="M36"><mml:mi>X</mml:mi></mml:math><inline-graphic xlink:href="41598_2020_64655_Article_IEq15.gif"/></alternatives></inline-formula>, <inline-formula id="IEq16"><alternatives><tex-math id="M37">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\Lambda \,$$\end{document}</tex-math><mml:math id="M38"><mml:mi mathvariant="normal">&#x0039b;</mml:mi><mml:mspace width=".25em"/></mml:math><inline-graphic xlink:href="41598_2020_64655_Article_IEq16.gif"/></alternatives></inline-formula> and model parameter <inline-formula id="IEq17"><alternatives><tex-math id="M39">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\theta .$$\end{document}</tex-math><mml:math id="M40"><mml:mi>&#x003b8;</mml:mi><mml:mo>.</mml:mo></mml:math><inline-graphic xlink:href="41598_2020_64655_Article_IEq17.gif"/></alternatives></inline-formula> The weight <inline-formula id="IEq18"><alternatives><tex-math id="M41">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$w$$\end{document}</tex-math><mml:math id="M42"><mml:mi>w</mml:mi></mml:math><inline-graphic xlink:href="41598_2020_64655_Article_IEq18.gif"/></alternatives></inline-formula> is determined by a ratio between negative regions (no peaks) and positive regions (peaks) for given data.</p><p id="Par20">In addition, we apply the Top-<italic>K</italic> method for the loss function<sup><xref ref-type="bibr" rid="CR30">30</xref></sup>. In the Top-<italic>K</italic> method, sensitivity is regarded as more important than specificity for a high value of <italic>K</italic>, while specificity is more important than sensitivity for a low value of <italic>K</italic>. To achieve a balance between sensitivity and specificity, we set <italic>L</italic>&#x02009;=&#x02009;<italic>K</italic>/2, where <italic>L</italic> is the output vector size. Our final loss function is (6)<disp-formula id="Equ6"><label>6</label><alternatives><tex-math id="M43">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{\boldsymbol{ {\mathcal L} }}}_{{\boldsymbol{TopK}}}({\boldsymbol{X}},{\boldsymbol{\Lambda }},{\boldsymbol{\theta }},{\boldsymbol{\kappa }})=\frac{1}{{\boldsymbol{\kappa }}}\mathop{\sum }\limits_{{\boldsymbol{n}}=1}^{{\boldsymbol{\kappa }}}{\ell }_{[{\boldsymbol{n}}]}({\boldsymbol{X}},{\boldsymbol{\Lambda }},{\boldsymbol{\theta }}),$$\end{document}</tex-math><mml:math id="M44" display="block"><mml:msub><mml:mrow><mml:mi mathvariant="bold">&#x02112;</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">TopK</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">X</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold">&#x0039b;</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">&#x003b8;</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">&#x003ba;</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi mathvariant="bold-italic">&#x003ba;</mml:mi></mml:mfrac><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">n</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi mathvariant="bold-italic">&#x003ba;</mml:mi></mml:munderover><mml:msub><mml:mrow><mml:mi>&#x02113;</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="true">[</mml:mo><mml:mi mathvariant="bold-italic">n</mml:mi><mml:mo stretchy="true">]</mml:mo></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">X</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold">&#x0039b;</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">&#x003b8;</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:math><graphic xlink:href="41598_2020_64655_Article_Equ6.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq19"><alternatives><tex-math id="M45">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\ell }_{[n]}(X,\Lambda ,\theta )$$\end{document}</tex-math><mml:math id="M46"><mml:msub><mml:mrow><mml:mi>&#x02113;</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="true">[</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="true">]</mml:mo></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">&#x0039b;</mml:mi><mml:mo>,</mml:mo><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41598_2020_64655_Article_IEq19.gif"/></alternatives></inline-formula> is the <inline-formula id="IEq20"><alternatives><tex-math id="M47">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n$$\end{document}</tex-math><mml:math id="M48"><mml:mi>n</mml:mi></mml:math><inline-graphic xlink:href="41598_2020_64655_Article_IEq20.gif"/></alternatives></inline-formula>
<sup>th</sup> largest individual weighted cross-entropy loss among all <inline-formula id="IEq21"><alternatives><tex-math id="M49">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${l}_{i}$$\end{document}</tex-math><mml:math id="M50"><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41598_2020_64655_Article_IEq21.gif"/></alternatives></inline-formula>. The loss function <inline-formula id="IEq22"><alternatives><tex-math id="M51">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${ {\mathcal L} }_{TopK}$$\end{document}</tex-math><mml:math id="M52"><mml:msub><mml:mrow><mml:mi>&#x02112;</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>o</mml:mi><mml:mi>p</mml:mi><mml:mi>K</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41598_2020_64655_Article_IEq22.gif"/></alternatives></inline-formula> was optimized using the Adam optimizer that uses backpropagation to adjust model the parameters <inline-formula id="IEq23"><alternatives><tex-math id="M53">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\theta $$\end{document}</tex-math><mml:math id="M54"><mml:mi>&#x003b8;</mml:mi></mml:math><inline-graphic xlink:href="41598_2020_64655_Article_IEq23.gif"/></alternatives></inline-formula><sup><xref ref-type="bibr" rid="CR31">31</xref></sup>.</p></sec><sec id="Sec8"><title>Scoring peaks using sigmoid activations</title><p id="Par21">An important task of any peak-calling algorithm is to give a significance score to each peak<sup><xref ref-type="bibr" rid="CR32">32</xref></sup>. We measure the significance of peaks by calculating a <italic>p</italic>-value for each genomic location under the Poisson distribution (note that the counts for each position in the genome-wide tag data for ChIP experiments is known to follow a Poisson distribution)<sup><xref ref-type="bibr" rid="CR32">32</xref>,<xref ref-type="bibr" rid="CR33">33</xref></sup> and by combining these <italic>p</italic>-values with the sigmoid values from the output layer in the CNN-Peaks architecture. The sigmoid function in the output layer of our CNN-Peaks model generates values that can be interpreted as the probability of the presence of a peak. The score value of each peak called by CNN-Peaks is determined by the product of its sigmoid activation value and <inline-formula id="IEq24"><alternatives><tex-math id="M55">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$-{\log }_{10}$$\end{document}</tex-math><mml:math id="M56"><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mrow><mml:mi>log</mml:mi></mml:mrow><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41598_2020_64655_Article_IEq24.gif"/></alternatives></inline-formula> of the <italic>p</italic>-value of the Poisson distribution for that peak (Supplementary text S5). This score can help users assess the significance of a particular peak.</p></sec></sec><sec id="Sec9" sec-type="results"><title>Results</title><sec id="Sec10"><title>Data preparation and creation of labeled data</title><p id="Par22">We downloaded 16 ChIP-seq datasets and one ATAC-seq dataset in BAM format, which were mapped to the human reference sequence. Professional experts examined 3,294 genomic segments that were randomly selected (Table&#x000a0;<xref rid="Tab1" ref-type="table">1</xref>). The datasets were assigned to three experts, each dataset being labeled exclusively by one expert. We expect that there is little experts&#x02019; bias in the labeling process<sup><xref ref-type="bibr" rid="CR8">8</xref></sup>.<table-wrap id="Tab1"><label>Table 1</label><caption><p>A list of the 16 ChIP-seq datasets and the ATAC-seq dataset (in BAM format) downloaded from the ENCODE data portal, and the number of genomic segments labeled as &#x02018;peak&#x02019; or &#x02018;no-peak&#x02019; by professional experts in each dataset.</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Cell line</th><th>Target</th><th># of genomic segments labeled</th><th>Fraction of peaks labeled near RefSeq tss</th><th>ENCODE EXPERIMENT Accession</th></tr></thead><tbody><tr><td>K562</td><td>MAX</td><td>152</td><td>0.74</td><td>ENCSR000EFV</td></tr><tr><td>K562</td><td>H3K9ac</td><td>739</td><td>0.82</td><td>ENCSR000EVZ</td></tr><tr><td>K562</td><td>POLR2A</td><td>33</td><td>0.88</td><td>ENCSR338QZF</td></tr><tr><td>K562</td><td>H3K27me3</td><td>9</td><td>0.33</td><td>ENCSR000EWB</td></tr><tr><td>K562</td><td>GATAD2</td><td>60</td><td>0.71</td><td>ENCSR547LKC</td></tr><tr><td>K562</td><td>H2AFZ</td><td>27</td><td>0.65</td><td>ENCSR000APC</td></tr><tr><td>K562</td><td>Control</td><td>437</td><td>&#x02014;</td><td>ENCSR000AKY</td></tr><tr><td>HepG2</td><td>POLR2A</td><td>34</td><td>0.88</td><td>ENCSR000EEM</td></tr><tr><td>HepG2</td><td>H3K4me2</td><td>447</td><td>0.81</td><td>ENCSR000AMC</td></tr><tr><td>HepG2</td><td>H3K27me3</td><td>15</td><td>0.36</td><td>ENCSR000AOL</td></tr><tr><td>HepG2</td><td>H3K9ac</td><td>103</td><td>0.88</td><td>ENCSR000AMD</td></tr><tr><td>HepG2</td><td>SMARCE1</td><td>67</td><td>0.78</td><td>ENCSR968QDP</td></tr><tr><td>A549</td><td>H2AFZ</td><td>572</td><td>0.81</td><td>ENCSR000AUH</td></tr><tr><td>A549</td><td>H3K9me3</td><td>87</td><td>0.55</td><td>ENCSR775TAI</td></tr><tr><td>HEK293</td><td>H3K9me3</td><td>127</td><td>0.33</td><td>ENCSR000FCJ</td></tr><tr><td>GM12878</td><td>GATAD2</td><td>54</td><td>0.71</td><td>ENCSR828NCB</td></tr><tr><td>A549</td><td>ATAC-Seq</td><td>297</td><td>0.81</td><td>ENCSR220ASC</td></tr><tr><td colspan="5">In total, 3294 segments</td></tr></tbody></table></table-wrap></p><p id="Par23">Part of these data were labeled and used as training data for our model (note that to put CNN-Peaks through a tough test, our test data does not come from Table&#x000a0;<xref rid="Tab1" ref-type="table">1</xref>, but rather from completely different datasets). Our data includes ChIP-seq data for identifying histone modification sites, such as H3K4me3 and H3K27ac, which are known as strong cancer biomarkers<sup><xref ref-type="bibr" rid="CR34">34</xref></sup>. On average, about 66% of the peaks labeled by the experts are near the transcription start sites (TSS) of RefSeq genes, as illustrated in the 4<sup>th</sup> column of Table&#x000a0;<xref rid="Tab1" ref-type="table">1</xref>. This fraction varies from 33% to 88% depending on experiments. We expect that ChIP-seq for H3K9ac histone modification target has a large number of peaks nearby promoters whereas H3K9me3 has much fewer peaks nearby TSS<sup><xref ref-type="bibr" rid="CR35">35</xref></sup>. The labels of &#x02018;peak&#x02019; or &#x02018;no-peak&#x02019; were applied while visualizing the raw read alignments in BAM format, together with the RefSeq annotation data obtained from the UCSC genome browser. The labeled data were easily created using our own graphical interface program included in the CNN-Peaks software package.</p></sec><sec id="Sec11"><title>CNN-Peaks pipeline</title><p id="Par24">We developed the CNN-Peaks pipeline as described in Fig.&#x000a0;<xref rid="Fig4" ref-type="fig">4</xref>. The CNN-Peaks pipeline takes as training input: labeled data in text format; read alignment data in BAM format; and RefSeq annotation information. The input data is converted to vectors of the right shapes for our CNN architecture. CNN-Peaks trains a predictive model based on the data in these vectors. The model is then applied to unlabeled data in the prediction stage. Our trained model can be used to call peaks for narrow histone modifications and transcription factor binding sites in other human ChIP-seq data (i.e. other than the one in Table&#x000a0;<xref rid="Tab1" ref-type="table">1</xref>, part of which was used for training) without additional labeling and training. In addition, peaks in ATAC-seq can also be detected using CNN-Peaks.<fig id="Fig4"><label>Figure 4</label><caption><p>Overview of the CNN-Peaks pipeline. Each parallelogram represents data, a rectangular box an individual module, a rounded rectangle a model trained by CNN-Peaks, and arrows data flow.</p></caption><graphic xlink:href="41598_2020_64655_Fig4_HTML" id="d29e1905"/></fig></p><p id="Par25">Unlike most other peak calling methods, CNN-Peaks needs no additional control ChIP-seq data, usually used as a background signal to reduce false-positive errors. In other words, users can determine the peaks of their target ChIP-seq data with no control data. This is critical when peaks are being called for high-throughput sequencing (HTS) data, such as ATAC-seq and DNase-seq, to capture open chromatin regions, because for the HTS data it is almost impossible to make the control dataset (see the information of ATAC-seq in <ext-link ext-link-type="uri" xlink:href="https://informatics.fas.harvard.edu/atac-seq-guidelines.html">https://informatics.fas.harvard.edu/atac-seq-guidelines.html</ext-link>).</p><p id="Par26">All modules in CNN-Peaks can be run using a single command. Its output, the peaks called out by CNN-Peaks, is provided in BED format. All of our source code is available in a GitHub repository (<ext-link ext-link-type="uri" xlink:href="http://github.com/odb9402/CNNPeaks">http://github.com/odb9402/CNNPeaks</ext-link>). The CNN-Peaks pipeline can be easily installed with Docker, which avoids users having to manually install all prerequisite programs and set up complicated system environments. The graphical interface program for labeling peaks in a given ChIP-seq BAM file is also included in CNN-Peaks. Experienced users can use CNN-Peaks to build a new predictive model, learned from their own labeled data.</p></sec><sec id="Sec12"><title>Optimization of hyperparameters in the CNN architecture</title><p id="Par27">There are several hyper-parameters in our package, as listed in (Supplementary text S2). We manually fine-tuned its various hyperparameters, such as the learning rate and convolution filter feature numbers, although we observe that CNN-peak&#x02019;s performance is not very sensitive to their values. Our CNN architecture uses the Adam Optimizer in TensorFlow-GPU 1.8.0<sup><xref ref-type="bibr" rid="CR36">36</xref></sup>. We trained a predictive model using our CNN-Peaks package with a single Nvidia Quadro P400 GPU within an hour. We used a random subset of all 3,294 genomic segments (see Section 3.1) to train the CNN-peaks model.</p></sec><sec id="Sec13"><title>Evaluation using labeled data</title><p id="Par28">Our labeled data in Table&#x000a0;<xref rid="Tab1" ref-type="table">1</xref> were randomly sampled (90%) to build our training set. ChIP-seq data for peaks labeled in (i) the H3K4me3 histone modification in the K562 human leukemia cell line, and (ii) the H3K27ac histone modification in the GM12878 cell line, <italic>were not used</italic> for training the predictive model (note that professional experts marked 156 labels for the H3K4me3 data in K562 and 150 for H3K27ac in GM12878). To evaluate our CNN-Peaks prediction model, we used (i) and (ii) as test datasets, comparing prediction results using CNN-Peaks with the labels in (i) and (ii). We counted false-positive and false-negative errors, and measured sensitivity and specificity. To account for both sensitivity and specificity, we also calculated the F1 score for performance evaluation.</p><p id="Par29">We compared our CNN-Peaks with widly-used peak calling tools, including MACS2, HOMER, and SICER. We used default parameters when running these software tools. There are peak calling results available at the ENCODE data portal for our test datasets (i) and (ii), so we included these results in our performance comparison as well. Note that the peak calling results from ENCODE were processed using an ENCODE ChIP-seq pipeline that used MACS2, as well as post-processing steps to reduce false-positive errors.</p><p id="Par30">Figure&#x000a0;<xref rid="Fig5" ref-type="fig">5</xref> shows the performance comparison for both test datasets. For the GM12878 cell line data (See Fig.&#x000a0;<xref rid="Fig5" ref-type="fig">5A</xref>), the sensitivity of CNN-Peaks dropped by about 10% compared to the other tools. However, CNN-Peaks improved specificity drastically to almost 97%, while the specificity of the other methods was lower than 76%. As a result, our CNN-Peaks increased the F1 score by at least 8% compared to existing tools. Unlike the GM12878 cell line that is known to have a relatively normal karyotype, the genome of the K562 cell line has more complex karyotypes due to frequent abnormal structural variations<sup><xref ref-type="bibr" rid="CR13">13</xref></sup>. For this reason, calling peaks in the K562 cell line data is more challenging than in the GM12878 data. While the sensitivity of CNN-Peaks dropped by almost 10% for the K562 ChIP-seq data, the specificity increased by 24% compared to the average of the other tools. (see Fig.&#x000a0;<xref rid="Fig5" ref-type="fig">5B</xref>). In addition to the sensitivity and specificity, we measured the portion of peaks overlapped by the CNN-Peaks and the other three peak callers on the H3K4me3 histone modification ChIP-seq data in the K562 cell line. We observed that 97%, 94%, and 96% of peaks called by the CNN-Peaks overlapped with MACS2, SICER, and HOMER (see Supplementary text S7). Most peaks called by the other peak callers were captured by CNN-Peaks, while many of the false-positive peaks generated by all the three peak callers were filtered out by CNN-Peaks.<fig id="Fig5"><label>Figure 5</label><caption><p>Performance comparison of CNN-Peaks to major ChIP-seq peak calling tools using our labeled testing datasets for (<bold>A</bold>) H3K27ac3 histone modification of GM12878 cell line, and (<bold>B</bold>) H3K4me3 histone modification of K562 cell line. Each blue bar represents sensitivity, and the orange bars specificity. Purple bars show the F1 scores of each peak calling software.</p></caption><graphic xlink:href="41598_2020_64655_Fig5_HTML" id="d29e1971"/></fig></p><p id="Par31">We also used the peaks overlapped by all combinations of MACS2, SICER, and HOMER as new predictors, and compared the predictors with the CNN-Peaks. As a result, the intersection of all the three callers showed the highest F1-score (0.7941) for test dataset (i) among all the combinations, but its performance is still not better than that of CNN-Peaks (F1-score 0.8515). In addition, for test dataset (ii), the intersection also showed the highest F1-score (0.8462), but its performance is still not better than CNN-Peaks (F1-score 0.9397). The intersection of peaks called by all the three peak callers may filter out some false-positive peaks, but still contain more false-positive results than our CNN-Peaks.</p></sec><sec id="Sec14"><title>Measuring relative distances between narrow histone modification peaks and transcription start sites</title><p id="Par32">Histone modification H3K4me3 and H3K9ac are commonly used as epigenetic markers. The histone modification markers are highly enriched near transcription start sites (TSS), so the relative distances between histone modification peaks and TSS are used for evaluating ChIP-seq peak callers<sup><xref ref-type="bibr" rid="CR37">37</xref>,<xref ref-type="bibr" rid="CR38">38</xref></sup>. To validate the performance of CNN-Peaks for calling narrow histone modification peaks in the H3K4me3 data of the HepG2 cell line, and H3K9ac of GM12878, we measured the relative distances of our peak intervals and TSS using a similarity metric suggested in<sup><xref ref-type="bibr" rid="CR39">39</xref></sup> (See Supplementary text S4).</p><p id="Par33">Figure&#x000a0;<xref rid="Fig6" ref-type="fig">6A</xref> shows the ideal shape for the empirical distribution of relative distances between highly correlated intervals. Figure&#x000a0;<xref rid="Fig6" ref-type="fig">6B,C</xref> describe the empirical distributions of relative distances between TSS and peaks called by CNN-Peaks, MACS2, SCIER, and HOMER for the H3K4me3 and H3K9ac histone modification data. The plots for CNN-Peaks are more similar to the plots in the ideal case, shown in Fig.&#x000a0;<xref rid="Fig6" ref-type="fig">6A</xref>, than the plots of other peak calling tools in both datasets. In particular, CNN-Peaks&#x02019; plots exhibit an accentuated <italic>y</italic>-value for small relative distances (<italic>x</italic>-value) that then drops. While other tools exhibit a similar behavior, they do not do so as markedly. This indicates that the peaks determined by our CNN-Peaks are more related to TSS than the results of other major tools.<fig id="Fig6"><label>Figure 6</label><caption><p>Relative distances between histone modification ChIP-Seq peak calling results and TSS. (<bold>A</bold>) The ideal distribution of relative distances between highly correlated intervals versus the distribution in intervals with no correlation. (<bold>B</bold>) Relative distances between peak intervals and TSS in H3K4me3 data for the HepG2 cell line. (<bold>C</bold>) Relative distances between peak intervals and TSS in H3K9ac data for the GM12878 cell line.</p></caption><graphic xlink:href="41598_2020_64655_Fig6_HTML" id="d29e2025"/></fig></p></sec><sec id="Sec15"><title>Peak calling for curated ChIP-seq benchmark data</title><p id="Par34">In addition to histone modification ChIP-seq data, we validate our CNN-Peaks pipeline with other benchmark data that are popularly used for validating software tools of transcription factor binding ChIP-seq analysis<sup><xref ref-type="bibr" rid="CR16">16</xref></sup>. Unlike the data labeled from Table&#x000a0;<xref rid="Tab1" ref-type="table">1</xref> labeled by our experts for this study, this manually curated benchmark data have three classes of labels instead of just the classes &#x02018;peak&#x02019; and &#x02018;no-peak&#x02019;. To be specific, they have an additional &#x02018;ambiguous&#x02019; class to mark genomic segments that could not be labeled as either &#x02018;peak&#x02019; or &#x02018;no-peak&#x02019;. In our experiments, we take the &#x02018;ambiguous&#x02019; class as &#x02018;no-peak&#x02019;, which follows the standard of performance measurement for peak calling tools using ChIP-seq benchmark datasets<sup><xref ref-type="bibr" rid="CR16">16</xref></sup>.</p><p id="Par35">We applied our CNN-Peaks, trained with some of our own labeled data from Table&#x000a0;<xref rid="Tab1" ref-type="table">1</xref>, to predict the benchmark data whose peaks were determined by manual curation in<sup><xref ref-type="bibr" rid="CR16">16</xref></sup>. We compare our results with the ones predicted by three peak calling programs, including MACS2, HOMER, and SICER. We measure the sensitivity, specificity, and F1 scores using the results predicted by each method and the peaks of the benchmark data in<sup><xref ref-type="bibr" rid="CR16">16</xref></sup> as ground truth. We ran these three peak calling tools with their default parameters. The whole alignments of all of the ChIP-seq data relative to the reference sequence were fed as their input. While the sensitivity of CNN-Peaks is almost similarly, or slightly smaller, than MACS2, which showed the best sensitivity among the three existing tools, CNN-Peaks&#x02019; specificity is the best among the three existing tools, in both the ChIP-seq experiment data for NRSF and SRF targets. Our CNN-Peaks pipeline has substantially better F1 scores than the other tools.</p></sec><sec id="Sec16"><title>Validation of peak scoring using known binding motifs</title><p id="Par36">Comparing the peaks with statistically significant scores (see Section 2.6) for transcription factor ChIP-seq to known binding motifs is another way to evaluate the performance of ChIP-seq peak calling methods<sup><xref ref-type="bibr" rid="CR31">31</xref>,<xref ref-type="bibr" rid="CR40">40</xref></sup>. We matched peaks determined by four methods, including our CNN-Peaks, to the known binding motifs for several cell lines from ENCODE, including BRCA1 in GM12878, CHD2 in K562, and CTCF in HepG2 (Fig.&#x000a0;<xref rid="Fig8" ref-type="fig">8</xref>)<sup><xref ref-type="bibr" rid="CR40">40</xref></sup>. In this analysis, we determine the genomic position with the highest score as the center of each peak region, and examine only motif matches close to the center of the peak (<italic>i.e</italic>. within 100 bases around the center of each peak). The goal of this approach is to avoid the analysis to be affected by bias introduced because of the different peak lengths. Users can refine the peak regions determined by CNN-Peaks for the transcription binding ChIP-seq data using a script included in our CNN-Peaks package. We note that for the transcription factor binding ChIP-seq data, CNN-peaks consistently calls peaks wider than MACS2 and HOMER data (see Supplementary text 8). SICER seems to always call peaks wider than any other tool. We use the matchPWM function in the &#x0201c;Biostrings&#x0201d; R package to find binding sites of BRCA1, CHD2, and CTCF<sup><xref ref-type="bibr" rid="CR41">41</xref></sup>. This experiment shows a biological relationship between peak significant scores and actual functional genomics. Figure&#x000a0;<xref rid="Fig8" ref-type="fig">8</xref> shows that the scoring system of CNN-Peaks, which uses both the sigmoid activation from the deep learning model and a Poisson distribution, is stable and appropriate. Figure&#x000a0;<xref rid="Fig8" ref-type="fig">8</xref> also shows that our CNN-Peaks results are strongly related to binding motifs, and are almost similar to, or better than, the other three peak calling tools. Figures&#x000a0;<xref rid="Fig7" ref-type="fig">7</xref> and <xref rid="Fig8" ref-type="fig">8</xref> demonstrate that our trained model that was learned using labeled data is quite robust and generalizes well. Indeed, only 12% of total labels came from transcription factor ChIP-seq, and the rest from histone modification ChIP-seq and ATAC-seq.<fig id="Fig7"><label>Figure 7</label><caption><p>Peak calling performance evaluation using ChIP-seq benchmark data manually curated for SRF target with GM12878 cell line (top) and NRSF target with K562 cell line (bottom). The benchmark dataset includes 6 different types of datasets for the SRF target and NRSF target respectively. These datasets were generated using different methods as described in [16]. Each color represents a different dataset.</p></caption><graphic xlink:href="41598_2020_64655_Fig7_HTML" id="d29e2102"/></fig><fig id="Fig8"><label>Figure 8</label><caption><p>(<bold>A</bold>) Fraction of top N peaks within BRCA1 motif from the GM12878 cell line, (<bold>B</bold>) within CHD2 motif from K562 cell line and (<bold>C</bold>) within CTCF motif from the HepG2 cell line. Top N peaks were determined by scoring peaks called by each software. Each plot shows motif enrichment from transcription factor ChIP-seq data for BRCA1, CHD2, and CTCF respectively.</p></caption><graphic xlink:href="41598_2020_64655_Fig8_HTML" id="d29e2120"/></fig></p></sec></sec><sec id="Sec17"><title>Disscussion</title><p id="Par37">As sequencing has become readily available for biological and medical studies, GWAS studies have identified many DNA bases and structural variations linked not only to genetic diseases but also to common diseases. While GWAS suggests what DNA abnormalities are linked to diseases, such studies cannot characterize the functional aspects of such variations. ChIP-seq has been widely used to understand the mechanisms of genome-wide gene regulation involved in developmental biology and various diseases, including cancer. Many computational approaches have been developed and applied to analyze the ChIP-seq data. However, most of them exhibit a high false-positive ratio of peak signals, and can misinterpret data, especially for histone modification ChIP-seq data.</p><p id="Par38">To resolve this issue, we designed a new approach for calling the peaks in ChIP-seq data based on a convolutional neural network architecture that mimics human visual inspection. Our tool uses genome annotation information, labeled data for peaks that are inspected by human researchers, as well as read mapping data in BAM format for ChIP-seq data. Our ChIP-seq data were generated from GM12878 and K565 human cell lines. Our CNN prediction method, which comes integrated with some useful data preprocessing steps, is available as a software package called CNN-Peaks. This package also includes a graphical visualization interface for users to easily set labels &#x02018;peak&#x02019; or &#x02018;no-peak&#x02019; in genomic segments using read mapping BAM files.</p><p id="Par39">We tested our predictive model and reported test errors using both our own labeled data, and benchmark data that were manually curated by other groups, and that are popularly used to evaluate computational methods for calling peaks. Our CNN-Peaks showed a quite conservative peak calling rate and improved specificity compared to other methods, while not dropping sensitivity much. Hocking <italic>et al</italic>. (2017) first proposed the idea of using visual inspection for calling peaks, and showed that manual peak calling could improve the performance of existing peak calling tools. However, they only focused on tuning parameters of existing peak callers using labeled data, while we redefined this idea as a signal processing problem, and designed a new approach based on the convolutional neural network model, which has been successfully used in various signal processing problems. Two important details contribute to its improved filtering out of false-positive peaks: its use of <italic>inception modules</italic> and its use of additional information, such as RefSeq annotation from experts&#x02019; visual. These factors increase the specificity and F1 scores of CNN-Peaks&#x02019; prediction comparing to other existing peak calling tools, even for ChIP-seq data that were generated in the K562 cancer cell line, which is known to be extremely complex due to frequent abnormal structural variations. In addition, we investigated the biological relationship between peak calling results and transcription start site (TSS) for histone ChIP-seq, and with known binding motifs for transcription factor ChIP-seq. Our experiments demonstrate that the peaks of histone modification ChIP-seq data determined by CNN-Peaks are highly correlated with TSS, and that the peaks of transcription factor ChIP-seq are strongly related to known binding motifs.</p><p id="Par40">There is still some room to improve the performance of our pipeline. CNN-peaks can be improved by collecting more labeled data are collected by more experts (see Supplementary text 6). Non-experts&#x02019; opinions can also be used to improve its performance, since their labeling results should be mostly consistent with that of the experts (see Supplementary text 9). We can further include other types of information that professional experts use for inspecting the peaks in ChIP-seq data via our visualization tool. The more thoroughly curated data are available for various types of ChIP-seq datasets, the more we expect that our performance will improve. In addition to calling peaks, we believe that our CNN-Peaks pipeline could be extended to determine if ChIP-seq datasets are problematic or valid. One straighfoward way of doing so is to look at the confidence scores output by CNN-Peaks and determine a dataset to be problematic if most confidence scores are low. This approach is not fail proof, as one could imagine a problematic dataset with very clear (but wrong) peaks. One way to tackle this, would be to ask experts not only to label peaks, but also to label the correctness of different regions in the training data. A CNN could then be trained to minimized a combined loss for (a) predicting the occurences of peaks, and (b) determining the correctness of different regions in the input data. CNN-Peaks can be a useful toolset for the quality control and accurate analyses of high throughput sequencing data in the epigenetic research community.</p></sec><sec sec-type="supplementary-material"><title>Supplementary information</title><sec id="Sec18"><p>
<supplementary-material content-type="local-data" id="MOESM1"><media xlink:href="41598_2020_64655_MOESM1_ESM.docx"><caption><p>Supplementary information.</p></caption></media></supplementary-material>
</p></sec></sec></body><back><fn-group><fn><p><bold>Publisher&#x02019;s note</bold> Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></fn></fn-group><sec><title>Supplementary information</title><p>is available for this paper at 10.1038/s41598-020-64655-4.</p></sec><ack><title>Acknowledgements</title><p>This work was supported by National Research Foundation of Korea Grant funded by the Korean Government (NRF-2017074529), Institute of Information &#x00026; communications Technology Planning &#x00026; Evaluation (IITP) grant funded by the Korea government (MSIT) (No.&#x000a0;2020-0-01450, Artificial Intelligence Convergence Research Center [Pusan National University]),&#x000a0;and the National Research Foundation of Korea (NRF) grant funded by the Korea government (MSIT) (No. NRF-2018R1A5A2023879) to GS.</p></ack><notes notes-type="author-contribution"><title>Author contributions</title><p>D.O. designed the method, implemented the pipeline, and analyzed the results. D.O. and G.S. wrote and finalized the manuscript. J.S. and J.K.H. helped with the method, the analysis, and writing. J.B. helped with the method and writing. A.E.U. and J.M.C. helped with initiation, validation, and writing. G.S. initiated, supervised, and coordinated the work. All authors read and approved the final manuscript.</p></notes><notes id="FPar1" notes-type="COI-statement"><title>Competing interests</title><p id="Par41">The authors declare no competing interests.</p></notes><ref-list id="Bib1"><title>References</title><ref id="CR1"><label>1.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Landt</surname><given-names>SG</given-names></name><etal/></person-group><article-title>ChIP-seq guidelines and practices of the ENCODE and modENCODE consortia</article-title><source>Genome Research</source><year>2012</year><volume>22</volume><fpage>1813</fpage><lpage>1831</lpage><pub-id pub-id-type="doi">10.1101/gr.136184.111</pub-id><pub-id pub-id-type="pmid">22955991</pub-id></element-citation></ref><ref id="CR2"><label>2.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fuery</surname><given-names>TS</given-names></name></person-group><article-title>ChIP&#x02013;seq and beyond: new and improved methodologies to detect and characterize protein&#x02013;DNA interactions</article-title><source>Nature Reviews Genetics</source><year>2012</year><volume>13</volume><fpage>840</fpage><lpage>52</lpage><pub-id pub-id-type="doi">10.1038/nrg3306</pub-id></element-citation></ref><ref id="CR3"><label>3.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Valouev</surname><given-names>A</given-names></name><etal/></person-group><article-title>Genome-wide analysis of transcription factor binding sites based on ChIP-Seq data</article-title><source>Nature Methods</source><year>2008</year><volume>5</volume><fpage>829</fpage><lpage>34</lpage><pub-id pub-id-type="doi">10.1038/nmeth.1246</pub-id><pub-id pub-id-type="pmid">19160518</pub-id></element-citation></ref><ref id="CR4"><label>4.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zang</surname><given-names>C</given-names></name><etal/></person-group><article-title>A clustering approach for identification of enriched domains from histone modification ChIP-Seq data</article-title><source>Bioinformatics</source><year>2009</year><volume>25</volume><fpage>1952</fpage><lpage>1958</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btp340</pub-id><pub-id pub-id-type="pmid">19505939</pub-id></element-citation></ref><ref id="CR5"><label>5.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Greer</surname><given-names>EL</given-names></name><name><surname>Shi</surname><given-names>Y</given-names></name></person-group><article-title>Histone methylation: a dynamic mark in health, disease and inheritance</article-title><source>Nature Reviews Genetics</source><year>2012</year><volume>13</volume><fpage>343</fpage><lpage>57</lpage><pub-id pub-id-type="doi">10.1038/nrg3173</pub-id></element-citation></ref><ref id="CR6"><label>6.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>Y</given-names></name><etal/></person-group><article-title>Model-based analysis of ChIP-Seq (MACS)</article-title><source>Genome Biology</source><year>2008</year><volume>9</volume><fpage>R137</fpage><pub-id pub-id-type="doi">10.1186/gb-2008-9-9-r137</pub-id><pub-id pub-id-type="pmid">18798982</pub-id></element-citation></ref><ref id="CR7"><label>7.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Heinz</surname><given-names>S</given-names></name><etal/></person-group><article-title>Simple Combinations of Lineage-Determining Transcription Factors Prime cis-Regulatory Elements Required for Macrophage and B Cell Identities</article-title><source>Mol Cell</source><year>2010</year><volume>38</volume><fpage>576</fpage><lpage>589</lpage><pub-id pub-id-type="doi">10.1016/j.molcel.2010.05.004</pub-id><pub-id pub-id-type="pmid">20513432</pub-id></element-citation></ref><ref id="CR8"><label>8.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hocking</surname><given-names>TD</given-names></name><etal/></person-group><article-title>Optimizing ChIP-seq peak detectors using visual labels and supervised machine learning</article-title><source>Bioinformatics</source><year>2017</year><volume>33</volume><fpage>491</fpage><lpage>499</lpage><pub-id pub-id-type="pmid">27797775</pub-id></element-citation></ref><ref id="CR9"><label>9.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Koh</surname><given-names>PW</given-names></name><name><surname>Pierson</surname><given-names>E</given-names></name><name><surname>Kundaje</surname><given-names>A</given-names></name></person-group><article-title>Denoising genome-wide histone ChIP-seq with convolutional neural networks</article-title><source>Bioinformatics</source><year>2017</year><volume>33</volume><fpage>i225</fpage><lpage>i233</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btx243</pub-id><pub-id pub-id-type="pmid">28881977</pub-id></element-citation></ref><ref id="CR10"><label>10.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Litchtenberg</surname><given-names>J</given-names></name><name><surname>Elnitski</surname><given-names>L</given-names></name><name><surname>Bodine</surname><given-names>DM</given-names></name></person-group><article-title>SigSeeker: a peak-calling ensemble approach for constructing epigenetic signatures</article-title><source>Bioinformatics</source><year>2017</year><volume>33</volume><fpage>2615</fpage><lpage>2621</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btx276</pub-id><pub-id pub-id-type="pmid">28449120</pub-id></element-citation></ref><ref id="CR11"><label>11.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Consortium</surname><given-names>EncodeProject</given-names></name><etal/></person-group><article-title>An integrated encyclopedia of DNA elements in the human genome</article-title><source>Nature</source><year>2012</year><volume>489</volume><fpage>57</fpage><lpage>74</lpage><pub-id pub-id-type="doi">10.1038/nature11247</pub-id><pub-id pub-id-type="pmid">22955616</pub-id></element-citation></ref><ref id="CR12"><label>12.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nakato</surname><given-names>R</given-names></name><name><surname>Shrahige</surname><given-names>K</given-names></name></person-group><article-title>Recent advances in ChIP-seq analysis: from quality management to whole-genome annotation</article-title><source>Briefings in Bioinformatics</source><year>2016</year><volume>18</volume><fpage>279</fpage><lpage>290</lpage></element-citation></ref><ref id="CR13"><label>13.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhou</surname><given-names>B</given-names></name><etal/></person-group><article-title>Comprehensive, integrated, and phased whole-genome analysis of the primary ENCODE cell line K562</article-title><source>Genome Research</source><year>2019</year><volume>29</volume><fpage>472</fpage><lpage>484</lpage><pub-id pub-id-type="doi">10.1101/gr.234948.118</pub-id><pub-id pub-id-type="pmid">30737237</pub-id></element-citation></ref><ref id="CR14"><label>14.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kent</surname><given-names>WJ</given-names></name><etal/></person-group><article-title>The human genome browser at UCSC</article-title><source>Genome Research</source><year>2002</year><volume>12</volume><fpage>996</fpage><lpage>1006</lpage><pub-id pub-id-type="doi">10.1101/gr.229102</pub-id><pub-id pub-id-type="pmid">12045153</pub-id></element-citation></ref><ref id="CR15"><label>15.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Robinson</surname><given-names>JT</given-names></name><etal/></person-group><article-title>Integrative genomics viewer</article-title><source>Nature Biotechnology</source><year>2011</year><volume>29</volume><fpage>24</fpage><lpage>26</lpage><pub-id pub-id-type="doi">10.1038/nbt.1754</pub-id></element-citation></ref><ref id="CR16"><label>16.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rye</surname><given-names>MB</given-names></name><name><surname>S&#x000e6;trom</surname><given-names>P</given-names></name><name><surname>Drabl&#x000f8;s</surname><given-names>F</given-names></name></person-group><article-title>A manually curated ChIP-seq benchmark demonstrates room for improvement in current peak-finder programs</article-title><source>Nucleic Acids Research</source><year>2010</year><volume>39</volume><fpage>e25</fpage><pub-id pub-id-type="doi">10.1093/nar/gkq1187</pub-id><pub-id pub-id-type="pmid">21113027</pub-id></element-citation></ref><ref id="CR17"><label>17.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Park</surname><given-names>Y</given-names></name><name><surname>Kellis</surname><given-names>M</given-names></name></person-group><article-title>Deep learning for regulatory genomics</article-title><source>Nature Biotechnology</source><year>2015</year><volume>33</volume><fpage>825</fpage><lpage>826</lpage><pub-id pub-id-type="doi">10.1038/nbt.3313</pub-id></element-citation></ref><ref id="CR18"><label>18.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alipanahi</surname><given-names>B</given-names></name><etal/></person-group><article-title>Predicting the sequence specificities of DNA-and RNA-binding proteins by deep learning</article-title><source>Nature Biotechnology</source><year>2015</year><volume>33</volume><fpage>831</fpage><lpage>838</lpage><pub-id pub-id-type="doi">10.1038/nbt.3300</pub-id></element-citation></ref><ref id="CR19"><label>19.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lecun</surname><given-names>Y</given-names></name><name><surname>Bengio</surname><given-names>Y</given-names></name><name><surname>Hinton</surname><given-names>GE</given-names></name></person-group><article-title>Deep learning</article-title><source>Nature</source><year>2015</year><volume>521</volume><fpage>436</fpage><lpage>444</lpage><pub-id pub-id-type="doi">10.1038/nature14539</pub-id><pub-id pub-id-type="pmid">26017442</pub-id></element-citation></ref><ref id="CR20"><label>20.</label><mixed-citation publication-type="other">Krizhevsky, A, Sutskever, I &#x00026; Hinton, G. E. Imagenet classification with deep convolutional neural networks. <italic>Advances in Neural Information Processing Systems</italic>, 1097-1105 (2012).</mixed-citation></ref><ref id="CR21"><label>21.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sloan</surname><given-names>CA</given-names></name><etal/></person-group><article-title>ENCODE data at the ENCODE portal</article-title><source>Nucleic Acids Research</source><year>2015</year><volume>44</volume><fpage>D726</fpage><lpage>D732</lpage><pub-id pub-id-type="doi">10.1093/nar/gkv1160</pub-id><pub-id pub-id-type="pmid">26527727</pub-id></element-citation></ref><ref id="CR22"><label>22.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pruitt</surname><given-names>KD</given-names></name><name><surname>Tatusova</surname><given-names>T</given-names></name><name><surname>Maglott</surname><given-names>DR</given-names></name></person-group><article-title>NCBI reference sequences (RefSeq): a curated non-redundant sequence database of genomes, transcripts and proteins</article-title><source>Nucleic acids research</source><year>2006</year><volume>35</volume><issue>suppl_1</issue><fpage>D61</fpage><lpage>D65</lpage><pub-id pub-id-type="pmid">17130148</pub-id></element-citation></ref><ref id="CR23"><label>23.</label><mixed-citation publication-type="other">Deng, G &#x00026; Cahill, L. W. An adaptive Gaussian filter for noise reduction and edge detection. <italic>IEEE Conference Record Nuclear Science Symposium and Medical Imaging Conference</italic>, 1615-1619 (1993).</mixed-citation></ref><ref id="CR24"><label>24.</label><mixed-citation publication-type="other">Szegedy, C. <italic>et al</italic>. Inception-v4, inception-resnet and the impact of residual connections on learning. <italic>Thirty-First AAAI Conference on Artificial Intelligence</italic>, 4278-4284 (2017).</mixed-citation></ref><ref id="CR25"><label>25.</label><mixed-citation publication-type="other">Szegedy C. <italic>et al</italic>. Going deeper with convolutions. <italic>Proceedings of the IEEE conference on Computer Vision and Pattern Recognition</italic>, 1-9 (2015).</mixed-citation></ref><ref id="CR26"><label>26.</label><mixed-citation publication-type="other">He K, Zhang X, Ren S, Sun J. Deep residual learning for image recognition.<italic>Proceedings of the IEEE conference on Computer Vision and Pattern Recognition</italic>, 770-778 (2016) .</mixed-citation></ref><ref id="CR27"><label>27.</label><mixed-citation publication-type="other">Ioffe, S &#x00026; Szegedy, C. Batch normalization: Accelerating deep network training by reducing internal covariate shift. <italic>International Conference on Machine Learning</italic>, 448-456 (2015).</mixed-citation></ref><ref id="CR28"><label>28.</label><mixed-citation publication-type="other">Deng, J, Berg, A. C. &#x00026; Fei-Fei, L. What does classifying more than 10,000 image categories tell us? <italic>European Conference on Computer Vision</italic>, 71-84 (2010).</mixed-citation></ref><ref id="CR29"><label>29.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nielsen</surname><given-names>H</given-names></name><name><surname>Brunak</surname><given-names>S</given-names></name><name><surname>Hejine</surname><given-names>GV</given-names></name></person-group><article-title>Machine learning approaches for the prediction of signal peptides and other protein sorting signals</article-title><source>Protein Engineering</source><year>1999</year><volume>12</volume><fpage>3</fpage><lpage>9</lpage><pub-id pub-id-type="doi">10.1093/protein/12.1.3</pub-id><pub-id pub-id-type="pmid">10065704</pub-id></element-citation></ref><ref id="CR30"><label>30.</label><mixed-citation publication-type="other">Fan, Y, Lyu, S, Ying, Y &#x00026; Hu, B. Learning with average top-k loss. <italic>Advances in Neural Information Processing Systems</italic>, 497-505 (2017).</mixed-citation></ref><ref id="CR31"><label>31.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kingma</surname><given-names>DP</given-names></name><name><surname>Ba</surname><given-names>J</given-names></name></person-group><article-title>Adam: A method for stochastic optimization</article-title><source>arXiv preprint arXiv</source><year>2014</year><volume>1412</volume><fpage>6980</fpage></element-citation></ref><ref id="CR32"><label>32.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thomas</surname><given-names>R</given-names></name><name><surname>Thomas</surname><given-names>S</given-names></name><name><surname>Holloway</surname><given-names>AK</given-names></name><name><surname>Pollard</surname><given-names>KS</given-names></name></person-group><article-title>Features that define the best ChIP-seq peak calling algorithms</article-title><source>Briefings in bioinformatics</source><year>2016</year><volume>18</volume><fpage>441</fpage><lpage>450</lpage></element-citation></ref><ref id="CR33"><label>33.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mikkelsen</surname><given-names>TS</given-names></name><etal/></person-group><article-title>Genome-wide maps of chromatin state in pluripotent and lineage-committed cells</article-title><source>Nature</source><year>2007</year><volume>448</volume><fpage>553</fpage><lpage>60</lpage><pub-id pub-id-type="doi">10.1038/nature06008</pub-id><pub-id pub-id-type="pmid">17603471</pub-id></element-citation></ref><ref id="CR34"><label>34.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lutz</surname><given-names>L</given-names></name><etal/></person-group><article-title>Histone modifiers and marks define heterogeneous groups of colorectal carcinomas and affect responses to HDAC inhibitors in vitro</article-title><source>American Journal of Cancer Research</source><year>2016</year><volume>6</volume><fpage>664</fpage><lpage>676</lpage><pub-id pub-id-type="pmid">27152243</pub-id></element-citation></ref><ref id="CR35"><label>35.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rosenfeld</surname><given-names>JA</given-names></name><name><surname>Xuan</surname><given-names>Z</given-names></name><name><surname>DeSalle</surname><given-names>R</given-names></name></person-group><article-title>Investigating repetitively matching short sequencing reads: the enigmatic nature of H3K9me3</article-title><source>Epigenetics</source><year>2009</year><volume>4</volume><issue>7</issue><fpage>476</fpage><lpage>486</lpage><pub-id pub-id-type="doi">10.4161/epi.4.7.9809</pub-id><pub-id pub-id-type="pmid">19786836</pub-id></element-citation></ref><ref id="CR36"><label>36.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Abadi</surname><given-names>M</given-names></name><etal/></person-group><source>Tensorflow: A system for large-scale machine learning. in OSDI</source><year>2016</year><volume>16</volume><fpage>265</fpage><lpage>283</lpage></element-citation></ref><ref id="CR37"><label>37.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>RICE</surname><given-names>JuddC</given-names></name><etal/></person-group><article-title>Histone methyltransferases direct different degrees of methylation to define distinct chromatin domains</article-title><source>Molecular cell</source><year>2003</year><volume>12</volume><fpage>1591</fpage><lpage>1598</lpage><pub-id pub-id-type="doi">10.1016/S1097-2765(03)00479-9</pub-id><pub-id pub-id-type="pmid">14690610</pub-id></element-citation></ref><ref id="CR38"><label>38.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>GHOSH</surname><given-names>Sourav</given-names></name><etal/></person-group><article-title>Distinct patterns of epigenetic marks and transcription factor binding sites across promoters of sense-intronic long noncoding RNAs</article-title><source>Journal of genetics</source><year>2015</year><volume>94</volume><fpage>17</fpage><lpage>25</lpage><pub-id pub-id-type="doi">10.1007/s12041-015-0484-2</pub-id><pub-id pub-id-type="pmid">25846873</pub-id></element-citation></ref><ref id="CR39"><label>39.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Favorov</surname><given-names>Alexander</given-names></name><etal/></person-group><article-title>Exploring massive, genome scale datasets with the GenometriCorr package</article-title><source>PLoS computational biology</source><year>2012</year><volume>8</volume><fpage>e1002529</fpage><pub-id pub-id-type="doi">10.1371/journal.pcbi.1002529</pub-id><pub-id pub-id-type="pmid">22693437</pub-id></element-citation></ref><ref id="CR40"><label>40.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kheradpour</surname><given-names>P</given-names></name><name><surname>Kellis</surname><given-names>M</given-names></name></person-group><article-title>Systematic discovery and characterization of regulatory motifs in ENCODE TF binding experiments</article-title><source>Nucleic Acids Research</source><year>2013</year><volume>42</volume><fpage>2976</fpage><lpage>2987</lpage><pub-id pub-id-type="doi">10.1093/nar/gkt1249</pub-id><pub-id pub-id-type="pmid">24335146</pub-id></element-citation></ref><ref id="CR41"><label>41.</label><mixed-citation publication-type="other">Pages, H, Aboyoun, P, Gentleman, R &#x00026; DebRoy, S. Biostrings: string objects representing biological sequences, and matching algorithms. R package version 2.2. R Foundation for Statistical Computing, Vienna, VA. <ext-link ext-link-type="uri" xlink:href="http://www.R-project.org">http://www.R-project.org</ext-link> (2010).</mixed-citation></ref></ref-list></back></article>