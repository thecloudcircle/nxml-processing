
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">Front Psychol</journal-id><journal-id journal-id-type="iso-abbrev">Front Psychol</journal-id><journal-id journal-id-type="publisher-id">Front. Psychol.</journal-id><journal-title-group><journal-title>Frontiers in Psychology</journal-title></journal-title-group><issn pub-type="epub">1664-1078</issn><publisher><publisher-name>Frontiers Media S.A.</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">31249542</article-id><article-id pub-id-type="pmc">6582403</article-id><article-id pub-id-type="doi">10.3389/fpsyg.2019.01326</article-id><article-categories><subj-group subj-group-type="heading"><subject>Psychology</subject><subj-group><subject>Original Research</subject></subj-group></subj-group></article-categories><title-group><article-title>Differential Effects of Valence and Encoding Strategy on Internal Source Memory and Judgments of Source: Exploring the Production and the Self-Reference Effect</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Pereira</surname><given-names>Diana R.</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/661554/overview"/></contrib><contrib contrib-type="author"><name><surname>Sampaio</surname><given-names>Adriana</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/211650/overview"/></contrib><contrib contrib-type="author"><name><surname>Pinheiro</surname><given-names>Ana P.</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="corresp" rid="c001"><sup>*</sup></xref></contrib></contrib-group><aff id="aff1"><sup>1</sup><institution>Psychological Neuroscience Lab, CIPsi, School of Psychology, University of Minho</institution>, <addr-line>Braga</addr-line>, <country>Portugal</country></aff><aff id="aff2"><sup>2</sup><institution>Voice, Affect, and Speech Neuroscience Lab, Faculdade de Psicologia, Universidade de Lisboa</institution>, <addr-line>Lisbon</addr-line>, <country>Portugal</country></aff><author-notes><fn fn-type="edited-by"><p>Edited by: Yiping Zhong, Hunan Normal University, China</p></fn><fn fn-type="edited-by"><p>Reviewed by: Pietro Spataro, Sapienza University of Rome, Italy; Alexandre Schaefer, Monash University Malaysia, Malaysia</p></fn><corresp id="c001">*Correspondence: Ana P. Pinheiro <email>appinheiro@psicologia.ulisboa.pt</email></corresp><fn fn-type="other" id="fn001"><p>This article was submitted to Cognition, a section of the journal Frontiers in Psychology</p></fn></author-notes><pub-date pub-type="epub"><day>12</day><month>6</month><year>2019</year></pub-date><pub-date pub-type="collection"><year>2019</year></pub-date><volume>10</volume><elocation-id>1326</elocation-id><history><date date-type="received"><day>24</day><month>12</month><year>2018</year></date><date date-type="accepted"><day>21</day><month>5</month><year>2019</year></date></history><permissions><copyright-statement>Copyright &#x000a9; 2019 Pereira, Sampaio and Pinheiro.</copyright-statement><copyright-year>2019</copyright-year><copyright-holder>Pereira, Sampaio and Pinheiro</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</license-p></license></permissions><abstract><p>Item memory studies show that emotional stimuli are associated with improved memory performance compared to neutral ones. However, emotion-related effects on source memory are less consistent. The current study probed how emotional valence and specific encoding conditions influence internal source memory performance and judgments of source (JOSs). In two independent experiments, participants were required to read silently/aloud (Experiment 1) or to perform self-reference/common judgments (Experiment 2) on a list of negative/neutral/positive words. They also performed immediate JOSs ratings for each word. The study phase was followed by a test phase in which participants performed old-new judgments. In Experiment 1, the production effect was replicated for item memory, but the effects of valence on item and source memory were not significant. In Experiment 2, self-referential processing effects on item and source memory differed as a function of valence. In both experiments, JOSs ratings were sensitive to valence and encoding conditions, although they were not predictive of objective memory performance. These findings demonstrate that the effects of valence on internal source memory and JOSs are modulated by encoding strategy. Thus, the way information is encoded can shed light on how emotion might enhance, impair or exert no influence on source memory.</p></abstract><kwd-group><kwd>internal source memory</kwd><kwd>valence</kwd><kwd>emotion</kwd><kwd>production effect</kwd><kwd>self-reference effect</kwd><kwd>judgments of source</kwd><kwd>metamemory</kwd></kwd-group><counts><fig-count count="2"/><table-count count="1"/><equation-count count="0"/><ref-count count="115"/><page-count count="17"/><word-count count="14713"/></counts></article-meta></front><body><sec sec-type="intro" id="s1"><title>Introduction</title><p>Evidence for the intricate interactions between emotion and cognition has led to a remarkable shift in the cognitive sciences (Ochsner and Phelps, <xref rid="B75" ref-type="bibr">2007</xref>; Okon-Singer et al., <xref rid="B76" ref-type="bibr">2015</xref>). One example is the relationship between emotion and episodic memory. Specifically, the emotion-enhanced memory (EEM) effect refers to improved memory for emotionally charged (high arousal and/or negative/positive) compared to non-emotional (low arousal and/or neutral) information. This effect has been well documented for different stimulus types, such as single words (e.g., Kensinger and Corkin, <xref rid="B38" ref-type="bibr">2003</xref>; D'Argembeau and Van der Linden, <xref rid="B11" ref-type="bibr">2004</xref>; Davidson et al., <xref rid="B13" ref-type="bibr">2006</xref>; Maddock and Frein, <xref rid="B58" ref-type="bibr">2009</xref>), word pairs (e.g., Maddox et al., <xref rid="B59" ref-type="bibr">2012</xref>), or pictures (e.g., Nashiro and Mather, <xref rid="B70" ref-type="bibr">2011</xref>; Schmidt et al., <xref rid="B91" ref-type="bibr">2011</xref>; Yick et al., <xref rid="B114" ref-type="bibr">2015</xref>; Sch&#x000fc;mann et al., <xref rid="B92" ref-type="bibr">2018</xref>). The EEM has also been extensively reported in the case of item memory (i.e., memory for the central features and relevant content of an event such as the words in a word pair; e.g., Kensinger and Schacter, <xref rid="B44" ref-type="bibr">2008</xref>; Murphy and Isaacowitz, <xref rid="B69" ref-type="bibr">2008</xref>; Levine and Edelstein, <xref rid="B54" ref-type="bibr">2009</xref>; Kensinger and Kark, <xref rid="B41" ref-type="bibr">2018</xref>). Nonetheless, a similar enhancement effect has been less consistent on other aspects of episodic memory such as source memory, i.e., the memory for the origins and conditions in which a certain event occurred (Johnson and Raye, <xref rid="B33" ref-type="bibr">1981</xref>; Johnson et al., <xref rid="B32" ref-type="bibr">1993</xref>; see <xref ref-type="supplementary-material" rid="SM1">Appendix</xref> for a selective review of these studies).</p><p>According to the source-monitoring framework (Johnson et al., <xref rid="B32" ref-type="bibr">1993</xref>), when we try to specify the origins of an event, our decision may rely on qualitative characteristics that are bound to an item during encoding, including semantic detail, cognitive operations (e.g., elaboration; organization; imagery), perceptual (e.g., color; sound), contextual (e.g., time; space) and/or affective (e.g., emotional reactions) features, as well as on previous general knowledge or schemas (e.g., stereotypes; beliefs). The enhanced memory effect for items with emotional features during encoding has been discussed in light of different theoretical approaches, including the Easterbrook's (<xref rid="B19" ref-type="bibr">1959</xref>) cue-utilization hypothesis, the priority-binding theory (Mackay et al., <xref rid="B55" ref-type="bibr">2004</xref>), the object-based binding theory (Mather, <xref rid="B61" ref-type="bibr">2007</xref>), and the arousal-biased competition theory (Mather and Sutherland, <xref rid="B63" ref-type="bibr">2011</xref>; see Bowen et al., <xref rid="B3" ref-type="bibr">2018</xref> for a review of other approaches). For instance, whereas impaired source memory for emotional stimuli might be explained by narrowed attention to central details and reduced capacity to bind central information with peripheral details (Easterbrook, <xref rid="B19" ref-type="bibr">1959</xref>), a source memory enhancement might stem from a stronger activation of item-context binding mechanisms elicited by emotional events (Mackay et al., <xref rid="B55" ref-type="bibr">2004</xref>). In turn, the object-based binding theory (Mather, <xref rid="B61" ref-type="bibr">2007</xref>) conciliates contradictory reports of impairment vs. enhancement vs. null effects, by postulating that arousal facilitates the binding of elements that are an integral part of the emotional object (i.e., intrinsic features such as the color of the object), whereas it impairs or exerts no influence on the binding of an emotional object with other contextual information (i.e., extrinsic features such as the color of the border surrounding the object). Similarly, the arousal-biased competition theory (Mather and Sutherland, <xref rid="B63" ref-type="bibr">2011</xref>) also predicts different outcomes for contextual details depending on the bottom-up (stimulus-driven information, such as its perceptual saliency) and/or top-down (goal-driven information, such as relevance for the current goals, expectations, and prior knowledge) priority of the information. In the latter case, arousal enhances memory for high priority information (i.e., information characterized by salient perceptual features and/or with relevance) while impairing memory for low priority information.</p><p>Even considering the former theoretical frameworks, several other factors may impact upon the relationship between emotion and source memory, including stimulus type (e.g., words or pictures; Phelps et al., <xref rid="B81" ref-type="bibr">1997</xref>), the emotional properties of the stimuli (Boywitt, <xref rid="B4" ref-type="bibr">2015</xref>), and the characteristics of the experimental task (e.g., intentional/incidental encoding, retention interval, encoding duration, type of memory test, sensory modality; D'Argembeau and Van der Linden, <xref rid="B11" ref-type="bibr">2004</xref>; Ferr&#x000e9; et al., <xref rid="B23" ref-type="bibr">2019</xref>) . Additionally, other factors have been relatively ignored in the study of source memory and its interactions with emotion, such as the source monitoring task and the encoding strategy. Regarding the first, Johnson et al. (<xref rid="B32" ref-type="bibr">1993</xref>) proposed three distinct source monitoring processes: external source monitoring, which refers to the discrimination between different external sources (e.g., <italic>something said speaker X or speaker Y?</italic>); internal source monitoring, which relies on the distinction between internally derived information (e.g., <italic>something I said silently or aloud?</italic>); reality monitoring, which comprises the discrimination between internal and external sources (e.g., <italic>something I heard/saw or imagined?</italic>). Externally derived memories usually contain more perceptual, temporal, spatial, and affective information, whereas internally derived memories comprise more information regarding cognitive processes that occur during memory acquisition (Raye and Johnson, <xref rid="B84" ref-type="bibr">1980</xref>; Johnson and Raye, <xref rid="B33" ref-type="bibr">1981</xref>). Moreover, due to the overlap of informative cues in both quantity and quality, the discrimination between two or more external/internal sources is more challenging than the discrimination between an external and an internal source (Raye and Johnson, <xref rid="B84" ref-type="bibr">1980</xref>). Accordingly, the way emotion affects source memory may depend on the contextual features that are manipulated, as already pointed out by previous studies showing that different external source memory tasks can lead to differences in source memory performance (e.g., D'Argembeau and Van der Linden, <xref rid="B11" ref-type="bibr">2004</xref>; Koenig and Mecklinger, <xref rid="B45" ref-type="bibr">2008</xref>; MacKenzie et al., <xref rid="B56" ref-type="bibr">2015</xref>; Kuhlmann and Touron, <xref rid="B48" ref-type="bibr">2017</xref>). For example, Boywitt (<xref rid="B4" ref-type="bibr">2015</xref>) demonstrated that the relationship between arousal and source memory performance is linear in the case of frame color, but it follows an inverted U-shape function for spatial location. Nonetheless, in comparison with external source memory, the study of other contextual features such as the discrimination between cognitive operations (internal source memory) when using emotional stimuli has received less attention (see <xref ref-type="supplementary-material" rid="SM1">Appendix</xref>).</p><p>In the case of encoding strategies, different approaches have been shown to benefit source memory performance such as semantic clustering (Wegesin et al., <xref rid="B109" ref-type="bibr">2000</xref>) and unitization (i.e., the ability to bind items or item-context in a single and meaningful combination; Tu and Diana, <xref rid="B102" ref-type="bibr">2016</xref>; Tu et al., <xref rid="B101" ref-type="bibr">2017</xref>; see also El Haj et al., <xref rid="B20" ref-type="bibr">2016</xref> for a review). Additionally, Kuhlmann and Touron (<xref rid="B47" ref-type="bibr">2012</xref>, <xref rid="B48" ref-type="bibr">2017</xref>) observed that when participants spontaneously used interactive imagery and sentence generation during encoding, source memory performance was improved. Notwithstanding, other encoding factors already known to boost item memory, such as production mode and self-referential processing, may also influence source memory (Hamami et al., <xref rid="B27" ref-type="bibr">2011</xref>; Serbun et al., <xref rid="B93" ref-type="bibr">2011</xref>; Leshikar and Duarte, <xref rid="B51" ref-type="bibr">2012</xref>, <xref rid="B52" ref-type="bibr">2014</xref>; Ozubko et al., <xref rid="B80" ref-type="bibr">2014</xref>; Yin et al., <xref rid="B115" ref-type="bibr">2018</xref>). Specifically, the production effect is a simple mnemonic strategy that shows a memory benefit for vocal production conditions, such as mouthing, reading aloud, reading aloud loudly, and singing, when compared to silent reading conditions (Dodson and Schacter, <xref rid="B14" ref-type="bibr">2001</xref>; MacLeod et al., <xref rid="B57" ref-type="bibr">2010</xref>; Ozubko and MacLeod, <xref rid="B79" ref-type="bibr">2010</xref>; Quinlan and Taylor, <xref rid="B82" ref-type="bibr">2013</xref>). The self-reference effect, in turn, represents a memory benefit for information that is encoded in relation to the self in comparison with information processed in other deep (e.g., semantic; other self-referent) or shallow (e.g., phonemic; perceptual) conditions (Rogers et al., <xref rid="B88" ref-type="bibr">1977</xref>; Kuiper and Rogers, <xref rid="B49" ref-type="bibr">1979</xref>; Symons and Johnson, <xref rid="B98" ref-type="bibr">1997</xref>; Leshikar and Duarte, <xref rid="B51" ref-type="bibr">2012</xref>; Yang et al., <xref rid="B113" ref-type="bibr">2012</xref>; Leshikar et al., <xref rid="B53" ref-type="bibr">2015</xref>).</p><p>Acknowledging the modulatory role of the encoding strategy and type of source memory task in the interaction between emotion and source memory, the first aim of the current study was to explore how stimulus valence influences internal source monitoring, when the encoding strategies (production mode and the self-referential processing) are also manipulated. Regarding the production mode, previous studies revealed that a similar beneficial effect is observed on item and source memories when stimuli are produced aloud (Ozubko et al., <xref rid="B80" ref-type="bibr">2014</xref>). Nonetheless, to the best of our knowledge, no previous study has concomitantly explored the role of emotion and production mode in source memory. In the case of the self-reference effect, previous research demonstrated that both item and source memory are enhanced when a self-referential approach is implemented during encoding (Hamami et al., <xref rid="B27" ref-type="bibr">2011</xref>; Serbun et al., <xref rid="B93" ref-type="bibr">2011</xref>; Leshikar and Duarte, <xref rid="B51" ref-type="bibr">2012</xref>, <xref rid="B52" ref-type="bibr">2014</xref>; Kalenzaga et al., <xref rid="B36" ref-type="bibr">2015</xref>; Yin et al., <xref rid="B115" ref-type="bibr">2018</xref>; Zhang et al., <xref rid="B117" ref-type="bibr">2018</xref>). Also, when stimulus valence is manipulated, both neutral and positive stimuli that are self-referentially encoded are better remembered compared to negative stimuli (e.g., D'Argembeau et al., <xref rid="B10" ref-type="bibr">2005</xref>; Yang et al., <xref rid="B113" ref-type="bibr">2012</xref>; Leshikar et al., <xref rid="B53" ref-type="bibr">2015</xref>; Zhang et al., <xref rid="B117" ref-type="bibr">2018</xref>). This pattern appears to hold partially for positive stimuli in the case of internal source monitoring, but it has been less consistently explored in the case of neutral stimuli (e.g., Durbin et al., <xref rid="B17" ref-type="bibr">2017</xref>). Thus, in the current study, we expected to replicate the self-reference benefit for both item and source memory, and to better qualify this effect when valence is manipulated during encoding.</p><p>Together with objective measures of memory performance, a second aim of this study was to examine how stimulus valence and encoding strategy might modulate subjective metamemory processes, specifically judgements of source (JOSs). Metamemory encompasses specific knowledge and beliefs about memory functioning (Flavell, <xref rid="B24" ref-type="bibr">1979</xref>), such as what we will remember or forget in the future. The study of metamemory often relies on prospective tasks in which participants are required to judge if they will remember/forget previously learned information, or on retrospective tasks in which participants are asked to evaluate their memory performance after remembering some information (Nelson and Narens, <xref rid="B71" ref-type="bibr">1990</xref>). One of the most common measures to assess prospective metamemory relies on judgments of learning (JOLs), in which participants are required to make a prediction about the memorability of specific stimuli, during or after their acquisition, through a rating or numeric scale. So far, few studies have explored the role of emotion on metamemory judgments. The existing evidence suggests that participants deem emotional stimuli to be more memorable than neutral stimuli during the encoding stage. This effect has been observed with odors (J&#x000f6;nsson et al., <xref rid="B34" ref-type="bibr">2005</xref>), faces (Nomi et al., <xref rid="B73" ref-type="bibr">2013</xref>), pictures (Hourihan and Bursey, <xref rid="B29" ref-type="bibr">2017</xref>), and words (Zimmerman and Kelley, <xref rid="B118" ref-type="bibr">2010</xref>; Tauber and Dunlosky, <xref rid="B100" ref-type="bibr">2012</xref>; Hourihan et al., <xref rid="B30" ref-type="bibr">2017</xref>). When considering the influence of emotion on judgments of source (JOSs), the existing data is even more scarce. One of the first studies to introduce the concept of JOSs was led by Dutton and Carroll (<xref rid="B18" ref-type="bibr">2001</xref>), in which they explored how three different emotionally arousing conditions modulated both JOLs and JOSs predictions. These authors found that JOLs and JOSs predictions somehow matched the recall performance, particularly in emotional conditions characterized by high arousal. In this context, the results of the current study can represent a novel contribution to the study of emotion and prospective metamemory, especially in the case of internal source memory monitoring.</p><p>Based on the evidence reviewed above, our first experiment investigated possible interactions between the production effect and stimulus valence in the case of internal source monitoring and JOSs. First, we predicted a replication of the EEM for item memory (Kensinger and Schacter, <xref rid="B44" ref-type="bibr">2008</xref>; Murphy and Isaacowitz, <xref rid="B69" ref-type="bibr">2008</xref>; Levine and Edelstein, <xref rid="B54" ref-type="bibr">2009</xref>; Kensinger and Kark, <xref rid="B41" ref-type="bibr">2018</xref>), i.e., better recognition performance for both negative and positive stimuli in comparison with neutral stimuli regardless of the production mode, based on the assumption that both production modes recruit similar attentional and elaborative processes. Second, in the case of internal source memory, we hypothesized an impairment or, more likely, a null effect of valence (see <xref ref-type="supplementary-material" rid="SM1">Appendix</xref> for a selective review of studies). This prediction is supported by the object-based binding hypothesis (Mather, <xref rid="B61" ref-type="bibr">2007</xref>) as the production mode can be deemed as an extrinsic feature of the stimuli. It is also supported by the arousal-biased competition theory (Mather and Sutherland, <xref rid="B63" ref-type="bibr">2011</xref>): considering that participants were overtly instructed to memorize the stimuli in the current experiment, both emotional and non-emotional stimuli were goal-relevant and received similar top-down priority. Third, we expected JOSs to be sensitive to both mode of production and stimulus valence as previous studies demonstrated that stimuli read aloud receive higher JOLs ratings than stimuli read silently (Castel et al., <xref rid="B7" ref-type="bibr">2013</xref>), and that emotional words are perceived as more memorable (Zimmerman and Kelley, <xref rid="B118" ref-type="bibr">2010</xref>; Tauber and Dunlosky, <xref rid="B100" ref-type="bibr">2012</xref>; Hourihan et al., <xref rid="B30" ref-type="bibr">2017</xref>). In our second experiment, the effects of both self-referential encoding and valence on internal source memory and JOSs were examined. The replication of the self-reference mnemonic benefit for both item and source memory was expected, especially in the case of neutral and positive stimuli (D'Argembeau et al., <xref rid="B10" ref-type="bibr">2005</xref>; Yang et al., <xref rid="B113" ref-type="bibr">2012</xref>; Leshikar et al., <xref rid="B53" ref-type="bibr">2015</xref>; Zhang et al., <xref rid="B117" ref-type="bibr">2018</xref>). Although these predictions contrast with reports of null or impairment effects of emotion on internal source memory (see <xref ref-type="supplementary-material" rid="SM1">Appendix</xref>), they highlight how the encoding strategy and top-down processes, such as motivational relevance (Mather and Sutherland, <xref rid="B63" ref-type="bibr">2011</xref>), might modulate the relationship between emotion and source memory. Regarding the metamemory judgments, we hypothesized JOSs to be sensitive to valence and encoding strategy as in Experiment 1. Specifically, we predicted that positive and neutral stimuli would be judged as more memorable than negative stimuli given that they might be perceived as more relevant self-descriptors (Kuiper and Rogers, <xref rid="B49" ref-type="bibr">1979</xref>; D'Argembeau et al., <xref rid="B10" ref-type="bibr">2005</xref>).</p></sec><sec id="s2"><title>Experiment 1</title><p>In a previous study by Ozubko et al.(<xref rid="B80" ref-type="bibr">2014</xref>, Experiment 3), the production mode benefited internal source memory for items read aloud during encoding. Reading aloud seems to be a distinctive feature that can function as a diagnostic cue during the test phase: if we remember that a specific word was read aloud, we will probably classify the item as &#x0201c;old&#x0201d;. This will be less likely to occur in the case of silent words as they have the same production status as new words during the test (MacLeod et al., <xref rid="B57" ref-type="bibr">2010</xref>; Ozubko and MacLeod, <xref rid="B79" ref-type="bibr">2010</xref>). In the current experiment, the source memory benefit for items read aloud was tested by manipulating both the production mode (silent vs. aloud) and stimulus valence (negative vs. neutral vs. positive). During the study phase, participants were required to read a list of words with different valence properties, half aloud and half silently. For each word, participants were also asked to make JOSs using a six-point rating scale. Immediately after learning, participants performed a test in which they were asked to discriminate between old and new items and to recall the production mode.</p><sec><title>Material and Methods</title><sec><title>Participants</title><p>Thirty-two college students participated in this experiment. However, one was excluded due to self-reported depression diagnosis and use of antidepressants; three other participants were excluded as they scored above 13 in the Portuguese version of the Beck Depression Inventory-II, which is indicative of depressive symptoms (Coelho et al., <xref rid="B8" ref-type="bibr">2002</xref>). The final sample was composed of 28 participants (23 females), aged between 18 and 32 years (<italic>M</italic> = 20.25, <italic>SD</italic> = 3.62), and with an average of 13.54 years of formal education (<italic>SD</italic> = 2.28). There were no self-reports of psychiatric/neurological disorders nor psychoactive drug usage. Participants had normal or corrected-to-normal vision, and they reported no auditory or other sensory and motor problems. They provided informed consent prior to their enrolment in the study and received course credit for their collaboration. The research protocol was approved by the local Ethics Committee (University of Minho, Braga, Portugal).</p><p>In Experiment 3 of Ozubko et al. (<xref rid="B80" ref-type="bibr">2014</xref>), where a superiority source memory effect was found for items studied aloud, a total of 24 participants were enrolled and the effect sizes (partial eta squared - <inline-formula><mml:math id="M1"><mml:msubsup><mml:mrow><mml:mi>&#x003b7;</mml:mi></mml:mrow><mml:mrow><mml:mtext>p</mml:mtext></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></inline-formula>) ranged between 0.24 and 0.77. Based on this information, <italic>a priori</italic> sample size estimation was conducted using G<sup>*</sup>Power-3 statistical software (Faul et al., <xref rid="B22" ref-type="bibr">2007</xref>), considering the within-factors repeated-measures analysis of variance (RMANOVA; 3 valence: negative/neutral/positive x 2 source: aloud/silent design) as the main statistical test. For an alpha significance level of 0.05, a power of 0.80, and an effect size of 0.24 (as calculated in SPSS), a sample of at least 11 participants would be required to allow the detection of differences between modes of production in source memory. Thus, the number of recruited participants was adequate.</p></sec><sec><title>Materials</title><p>A total of 180 words (60 negative/neutral/positive; see <xref ref-type="supplementary-material" rid="SM2">Table S1</xref>) were initially selected from the Portuguese version of the Affective Norms for English Words (ANEW; Soares et al., <xref rid="B97" ref-type="bibr">2012</xref>). Words differed in valence, ranging from 1 to 9, with 9 corresponding to the most positive ratings and 1 to the least positive ratings (positive &#x0003e; neutral; positive &#x0003e; negative; neutral &#x0003e; negative; all <italic>p</italic> &#x0003c; 0.001). In the case of arousal, differences were observed between neutral and both negative and positive stimuli (neutral &#x0003c; negative; neutral &#x0003c; positive; negative = positive; all <italic>p</italic> &#x0003c; 0.001). No significant differences were found in frequency, number of letters and number of syllables as a function of word valence (<italic>p</italic> &#x0003e; 0.05; see <xref ref-type="supplementary-material" rid="SM2">Table S1</xref>). The selected words were randomly distributed across six lists of 30 stimuli each (with 10 stimuli of each valence category) to be used as learning and test items. Lists did not differ in words' valence, arousal, frequency, number of letters, and number of syllables (<italic>p</italic> &#x0003e; 0.05).</p></sec><sec><title>Procedure</title><p>The experimental task was completed in a single session, and it consisted of three study-test cycles. During the study phase, each trial began with a fixation cross (500 ms) followed by a blank screen (250 ms), and then a target word (3,000 ms), which was presented in the center of the screen in a light gray background (Arial, black color, font size 28). Together with each word, the instruction &#x0201c;read silently&#x0201d; or &#x0201c;read aloud&#x0201d; was presented on top of the screen to inform how the word should be read. Participants were then instructed to judge how likely they were to remember that the previous word was read silently or aloud by using a six-point rating scale following Hourihan et al. (<xref rid="B30" ref-type="bibr">2017</xref>), in which &#x0201c;1&#x0201d; represented &#x0201c;Sure I will not remember&#x0201d; and &#x0201c;6&#x0201d; represented &#x0201c;Sure I will remember.&#x0201d; The rating scale remained on the screen until the participant made the JOSs. Lastly, a blank screen appeared during 500 ms (see <xref ref-type="fig" rid="F1">Figure 1</xref>). Thirty stimuli were randomly presented during encoding to be later tested. Four additional words, two at the beginning and two at the end of the list, were used as fillers to mitigate possible primacy and recency effects, but they were not considered in the analysis. No specifications were provided about which fingers the participants should use to provide a response.</p><fig id="F1" position="float"><label>Figure 1</label><caption><p>Schematic illustration of the tasks used in Experiments 1 and 2. Note: JOS, Judgement of Source.</p></caption><graphic xlink:href="fpsyg-10-01326-g0001"/></fig><p>The study phase was immediately followed by a test phase in which the previously 30 read words were randomly mixed with 30 new words. A trial started with a fixation cross (500 ms) and a blank screen (250 ms); then a word was presented in the center of the screen, and participants had to perform old-new judgments regarding the source by choosing one of four response options: (1) &#x0201c;read silently&#x0201d;; (2) &#x0201c;read aloud&#x0201d;; (3) &#x0201c;read, but do not know if silently/aloud&#x0201d;; (4) &#x0201c;new&#x0201d;. The &#x0201c;do not know&#x0201d; option was adopted following previous studies (Sharot and Yonelinas, <xref rid="B95" ref-type="bibr">2008</xref>; Leshikar and Duarte, <xref rid="B51" ref-type="bibr">2012</xref>, <xref rid="B52" ref-type="bibr">2014</xref>; Newsome et al., <xref rid="B72" ref-type="bibr">2012</xref>; Dulas and Duarte, <xref rid="B16" ref-type="bibr">2014</xref>) with the purpose of reducing guessing and response bias. There was no time limit to provide a response. The response keys were counterbalanced across participants. After the old-new judgment, participants were asked to evaluate the degree of confidence in their response using, once again, a six-point rating scale (1 = &#x0201c;No confidence&#x0201d;; 6 = &#x0201c;Complete confidence&#x0201d;). The confidence judgment was also self-paced. The last event of the trial was a blank screen lasting 500 ms (see <xref ref-type="fig" rid="F1">Figure 1</xref>).</p><p>The lists were counterbalanced across participants regarding study/test and read aloud/silent to ensure that each stimulus could be read aloud or silently and could be an old or a new item. Moreover, prior to the experimental task, all participants completed a training period with a brief study-test cycle, and they were instructed to pay attention to the words and their source (aloud or silent), because they would be tested later (intentional learning). Participants were also informed that each study-test cycle was independent, i.e., after finishing a cycle they could forget the stimuli and focus their attention on the new cycle. Stimulus presentation was controlled using SuperLab software (Version 5, Cedrus Corporation, San Pedro, CA, <ext-link ext-link-type="uri" xlink:href="https://www.cedrus.com/superlab/">https://www.cedrus.com/superlab/</ext-link>).</p></sec><sec><title>Data Analysis</title><p>Initially, the proportion of responses during recognition was calculated for six main categories: (1) correct source (the source was correctly identified; for example, the participant recognized an item as &#x0201c;read aloud&#x0201d; when it was indeed paired with a &#x0201c;read aloud&#x0201d; instruction during the study phase); (2) incorrect source (the participant misattributed the source; for example, for an item that was paired with a &#x0201c;read aloud&#x0201d; instruction during encoding, the participant selected &#x0201c;read silently&#x0201d; during test); (3) do not know source (the participant correctly recognized an item as old, but did not remember if it was read silently or aloud); (4) miss (for an item presented during the study phase, the participant misidentified it as &#x0201c;new&#x0201d; during test); (5) correct rejection (the participant correctly identified a new item as &#x0201c;new&#x0201d;); (6) false alarm (the participant considered a new item as &#x0201c;old&#x0201d; by choosing one of the sources or the &#x0201c;do not know&#x0201d; option). The item memory recognition accuracy was then obtained using Pr = ([p(hits) &#x02013; p(false alarms)]) (Snodgrass and Corwin, <xref rid="B96" ref-type="bibr">1988</xref>), wherein the p(hits) resulted from combining both correct and incorrect source responses and the do not know responses. The response bias also followed Snodgrass and Corwin (<xref rid="B96" ref-type="bibr">1988</xref>): Br = ([p(false alarms)/(1 &#x02013; Pr)]). A conservative response bias is considered for Br values below 0.50, whereas a liberal response bias is considered for values above 0.50. In a first attempt to compute the Br, the denominator was equal to zero for some participants. To circumvent this problem, we applied a correction to both hit and false alarm rates, following the same authors [hit rates = (number of hits + 0.5) / (number of old items + 1); false alarm rates = (number of false alarms + 0.5) / (number of new items + 1)]. In the case of source recognition, the discrimination measure was obtained by subtracting incorrect source from correct source responses - [p(correct source) &#x02013; p(incorrect source)] &#x02013; excluding the &#x0201c;do not know&#x0201d; responses and following prior studies (e.g., Newsome et al., <xref rid="B72" ref-type="bibr">2012</xref>; Dulas and Duarte, <xref rid="B16" ref-type="bibr">2014</xref>; Leshikar et al., <xref rid="B53" ref-type="bibr">2015</xref>). Both item and source discrimination measures were submitted to a 3 (valence: negative/neutral/positive) x 2 (source: aloud/silent) RMANOVA.</p><p>It is worth noting that the old-new recognition patterns and the source memory discrimination are somehow superimposed and confounded in this study. Moreover, the computed measures are amenable to response bias. Multinomial models represent a useful approach to separate between old-new detection and source discrimination, by additionally considering the effect of potential biases (Batchelder and Riefer, <xref rid="B2" ref-type="bibr">1990</xref>). Thereby, multinomial models were computed as a supplementary analysis to back up the results of the RMANOVA. A full description of the procedure and results is presented in <xref ref-type="supplementary-material" rid="SM1">Supplementary Material</xref>.</p><p>The effects of source and emotional content on the JOSs during encoding were evaluated through a 3 (valence) x 2 (source) RMANOVA. Moreover, Goodman-Kruskal gamma correlations were used as indices of metamnenomic accuracy for each experimental condition in accordance with previous literature (e.g., Castel et al., <xref rid="B7" ref-type="bibr">2013</xref>). The procedure used to compute gamma is described in <xref ref-type="supplementary-material" rid="SM1">Supplementary Material</xref>. Additional findings regarding the proportion of incorrect source responses, &#x0201c;do not know&#x0201d; responses, misses, correct rejections, (corrected) false alarms, recognition confidence for source judgments and correct rejections, as well as the response times for JOSs and recognition responses are presented in <xref ref-type="supplementary-material" rid="SM1">Supplementary Material</xref>.</p><p>A Bayesian two-way RMANOVA was conducted (JASP Team, <xref rid="B31" ref-type="bibr">2018</xref>, Version 0.9.0.1) to complement the abovementioned analysis (Wagenmakers et al., <xref rid="B103" ref-type="bibr">2018a</xref>,<xref rid="B104" ref-type="bibr">b</xref> see <xref ref-type="supplementary-material" rid="SM2">Tables S7</xref>, <xref ref-type="supplementary-material" rid="SM2">S8</xref>). Specifically, Bayes factors (BF<sub>10</sub>) were considered in favor of the alternative hypothesis if BF<sub>10</sub> was larger than three, whereas a BF<sub>10</sub> lower than 0.3 was interpreted as evidence in favor of the null hypothesis (Quintana and Williams, <xref rid="B83" ref-type="bibr">2018</xref>; Wagenmakers et al., <xref rid="B103" ref-type="bibr">2018a</xref>). Finally, the Greenhouse-Geisser method was used as correction for sphericity violations, and Bonferroni-corrected <italic>post hoc</italic> comparisons were applied to qualify interaction effects.</p></sec></sec><sec><title>Results</title><p>Descriptive statistics regarding the behavioral performance in Experiment 1 are shown in <xref rid="T1" ref-type="table">Table 1</xref>.</p><table-wrap id="T1" position="float"><label>Table 1</label><caption><p>Behavioral performance (source x valence) in Experiments 1 and 2.</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="1" colspan="1"/><th valign="top" align="center" colspan="6" style="border-bottom: thin solid #000000;" rowspan="1"><bold>Experiment 1&#x02013;</bold><italic><bold>M</bold></italic>
<bold>(</bold><italic><bold>SD</bold></italic><bold>)</bold></th><th valign="top" align="center" colspan="6" style="border-bottom: thin solid #000000;" rowspan="1"><bold>Experiment 2&#x02013;</bold><italic><bold>M</bold></italic>
<bold>(</bold><italic><bold>SD</bold></italic><bold>)</bold></th></tr><tr><th rowspan="1" colspan="1"/><th valign="top" align="center" colspan="3" style="border-bottom: thin solid #000000;" rowspan="1"><bold>Aloud</bold></th><th valign="top" align="center" colspan="3" style="border-bottom: thin solid #000000;" rowspan="1"><bold>Silent</bold></th><th valign="top" align="center" colspan="3" style="border-bottom: thin solid #000000;" rowspan="1"><bold>Self</bold></th><th valign="top" align="center" colspan="3" style="border-bottom: thin solid #000000;" rowspan="1"><bold>Common</bold></th></tr><tr><th rowspan="1" colspan="1"/><th valign="top" align="center" rowspan="1" colspan="1"><bold>Negative</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>Neutral</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>Positive</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>Negative</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>Neutral</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>Positive</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>Negative</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>Neutral</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>Positive</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>Negative</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>Neutral</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>Positive</bold></th></tr></thead><tbody><tr><td valign="top" align="left" rowspan="1" colspan="1">Source correct</td><td valign="top" align="center" rowspan="1" colspan="1">0.61 (0.16)</td><td valign="top" align="center" rowspan="1" colspan="1">0.55 (0.20)</td><td valign="top" align="center" rowspan="1" colspan="1">0.58 (0.19)</td><td valign="top" align="center" rowspan="1" colspan="1">0.59 (0.22)</td><td valign="top" align="center" rowspan="1" colspan="1">0.57 (0.24)</td><td valign="top" align="center" rowspan="1" colspan="1">0.55 (0.24)</td><td valign="top" align="center" rowspan="1" colspan="1">0.64 (0.19)</td><td valign="top" align="center" rowspan="1" colspan="1">0.76 (0.20)</td><td valign="top" align="center" rowspan="1" colspan="1">0.79 (0.17)</td><td valign="top" align="center" rowspan="1" colspan="1">0.47 (0.23)</td><td valign="top" align="center" rowspan="1" colspan="1">0.58 (0.26)</td><td valign="top" align="center" rowspan="1" colspan="1">0.44 (0.24)</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Source incorrect</td><td valign="top" align="center" rowspan="1" colspan="1">0.14 (0.12)</td><td valign="top" align="center" rowspan="1" colspan="1">0.11 (0.14)</td><td valign="top" align="center" rowspan="1" colspan="1">0.11 (0.14)</td><td valign="top" align="center" rowspan="1" colspan="1">0.05 (0.08)</td><td valign="top" align="center" rowspan="1" colspan="1">0.05 (0.08)</td><td valign="top" align="center" rowspan="1" colspan="1">0.05 (0.08)</td><td valign="top" align="center" rowspan="1" colspan="1">0.08 (0.10)</td><td valign="top" align="center" rowspan="1" colspan="1">0.05 (0.09)</td><td valign="top" align="center" rowspan="1" colspan="1">0.06 (0.10)</td><td valign="top" align="center" rowspan="1" colspan="1">0.08 (0.08)</td><td valign="top" align="center" rowspan="1" colspan="1">0.04 (0.06)</td><td valign="top" align="center" rowspan="1" colspan="1">0.14 (0.12)</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Source DNK</td><td valign="top" align="center" rowspan="1" colspan="1">0.18 (0.17)</td><td valign="top" align="center" rowspan="1" colspan="1">0.22 (0.19)</td><td valign="top" align="center" rowspan="1" colspan="1">0.21 (0.16)</td><td valign="top" align="center" rowspan="1" colspan="1">0.24 (0.17)</td><td valign="top" align="center" rowspan="1" colspan="1">0.21 (0.22)</td><td valign="top" align="center" rowspan="1" colspan="1">0.22 (0.17)</td><td valign="top" align="center" rowspan="1" colspan="1">0.14 (0.14)</td><td valign="top" align="center" rowspan="1" colspan="1">0.08 (0.10)</td><td valign="top" align="center" rowspan="1" colspan="1">0.08 (0.11)</td><td valign="top" align="center" rowspan="1" colspan="1">0.19 (0.20)</td><td valign="top" align="center" rowspan="1" colspan="1">0.17 (0.19)</td><td valign="top" align="center" rowspan="1" colspan="1">0.21 (0.18)</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Source miss</td><td valign="top" align="center" rowspan="1" colspan="1">0.07 (0.10)</td><td valign="top" align="center" rowspan="1" colspan="1">0.11 (0.08)</td><td valign="top" align="center" rowspan="1" colspan="1">0.09 (0.08)</td><td valign="top" align="center" rowspan="1" colspan="1">0.12 (0.12)</td><td valign="top" align="center" rowspan="1" colspan="1">0.17 (0.16)</td><td valign="top" align="center" rowspan="1" colspan="1">0.17 (0.14)</td><td valign="top" align="center" rowspan="1" colspan="1">0.15 (0.13)</td><td valign="top" align="center" rowspan="1" colspan="1">0.11 (0.10)</td><td valign="top" align="center" rowspan="1" colspan="1">0.07 (0.11)</td><td valign="top" align="center" rowspan="1" colspan="1">0.25 (0.15)</td><td valign="top" align="center" rowspan="1" colspan="1">0.21 (0.15)</td><td valign="top" align="center" rowspan="1" colspan="1">0.21 (0.17)</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Item Pr measure</td><td valign="top" align="center" rowspan="1" colspan="1">0.82 (0.13)</td><td valign="top" align="center" rowspan="1" colspan="1">0.78 (0.13)</td><td valign="top" align="center" rowspan="1" colspan="1">0.76 (0.13)</td><td valign="top" align="center" rowspan="1" colspan="1">0.77 (0.15)</td><td valign="top" align="center" rowspan="1" colspan="1">0.72 (0.16)</td><td valign="top" align="center" rowspan="1" colspan="1">0.68 (0.15)</td><td valign="top" align="center" rowspan="1" colspan="1">0.68 (0.14)</td><td valign="top" align="center" rowspan="1" colspan="1">0.76 (0.14)</td><td valign="top" align="center" rowspan="1" colspan="1">0.74 (0.17)</td><td valign="top" align="center" rowspan="1" colspan="1">0.59 (0.15)</td><td valign="top" align="center" rowspan="1" colspan="1">0.67 (0.17)</td><td valign="top" align="center" rowspan="1" colspan="1">0.60 (0.20)</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Item Br measure</td><td valign="top" align="center" rowspan="1" colspan="1">0.47 (0.22)</td><td valign="top" align="center" rowspan="1" colspan="1">0.36 (0.20)</td><td valign="top" align="center" rowspan="1" colspan="1">0.48 (0.26)</td><td valign="top" align="center" rowspan="1" colspan="1">0.38 (0.23)</td><td valign="top" align="center" rowspan="1" colspan="1">0.33 (0.25)</td><td valign="top" align="center" rowspan="1" colspan="1">0.39 (0.23)</td><td valign="top" align="center" rowspan="1" colspan="1">0.43 (0.25)</td><td valign="top" align="center" rowspan="1" colspan="1">0.43 (0.23)</td><td valign="top" align="center" rowspan="1" colspan="1">0.57 (0.26)</td><td valign="top" align="center" rowspan="1" colspan="1">0.33 (0.21)</td><td valign="top" align="center" rowspan="1" colspan="1">0.33 (0.21)</td><td valign="top" align="center" rowspan="1" colspan="1">0.39 (0.26)</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Source measure</td><td valign="top" align="center" rowspan="1" colspan="1">0.46 (0.20)</td><td valign="top" align="center" rowspan="1" colspan="1">0.44 (0.27)</td><td valign="top" align="center" rowspan="1" colspan="1">0.46 (0.27)</td><td valign="top" align="center" rowspan="1" colspan="1">0.54 (0.24)</td><td valign="top" align="center" rowspan="1" colspan="1">0.52 (0.26)</td><td valign="top" align="center" rowspan="1" colspan="1">0.49 (0.27)</td><td valign="top" align="center" rowspan="1" colspan="1">0.56 (0.25)</td><td valign="top" align="center" rowspan="1" colspan="1">0.71 (0.26)</td><td valign="top" align="center" rowspan="1" colspan="1">0.72 (0.22)</td><td valign="top" align="center" rowspan="1" colspan="1">0.40 (0.27)</td><td valign="top" align="center" rowspan="1" colspan="1">0.54 (0.28)</td><td valign="top" align="center" rowspan="1" colspan="1">0.30 (0.31)</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">JOSs ratings</td><td valign="top" align="center" rowspan="1" colspan="1">4.40 (0.68)</td><td valign="top" align="center" rowspan="1" colspan="1">4.02 (0.71)</td><td valign="top" align="center" rowspan="1" colspan="1">4.26 (0.76)</td><td valign="top" align="center" rowspan="1" colspan="1">3.56 (0.63)</td><td valign="top" align="center" rowspan="1" colspan="1">3.25 (0.52)</td><td valign="top" align="center" rowspan="1" colspan="1">3.50 (0.60)</td><td valign="top" align="center" rowspan="1" colspan="1">4.05 (0.85)</td><td valign="top" align="center" rowspan="1" colspan="1">4.12 (0.85)</td><td valign="top" align="center" rowspan="1" colspan="1">4.34 (0.82)</td><td valign="top" align="center" rowspan="1" colspan="1">3.91 (0.72)</td><td valign="top" align="center" rowspan="1" colspan="1">3.94 (0.69)</td><td valign="top" align="center" rowspan="1" colspan="1">3.96 (0.79)</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Gamma (JOSs)</td><td valign="top" align="center" rowspan="1" colspan="1">0.18 (0.53)</td><td valign="top" align="center" rowspan="1" colspan="1">0.29 (0.51)</td><td valign="top" align="center" rowspan="1" colspan="1">0.31 (0.49)</td><td valign="top" align="center" rowspan="1" colspan="1">0.19 (0.45)</td><td valign="top" align="center" rowspan="1" colspan="1">0.19 (0.58)</td><td valign="top" align="center" rowspan="1" colspan="1">0.14 (0.48)</td><td valign="top" align="center" rowspan="1" colspan="1">0.15 (0.47)</td><td valign="top" align="center" rowspan="1" colspan="1">0.16 (0.50)</td><td valign="top" align="center" rowspan="1" colspan="1">0.14 (0.52)</td><td valign="top" align="center" rowspan="1" colspan="1">0.11 (0.53)</td><td valign="top" align="center" rowspan="1" colspan="1">0.06 (0.45)</td><td valign="top" align="center" rowspan="1" colspan="1">0.07 (0.48)</td></tr><tr><td rowspan="1" colspan="1"/><td valign="top" align="center" colspan="2" rowspan="1">Negative</td><td valign="top" align="center" colspan="2" rowspan="1">Neutral</td><td valign="top" align="center" colspan="2" rowspan="1">Positive</td><td valign="top" align="center" colspan="2" rowspan="1">Negative</td><td valign="top" align="center" colspan="2" rowspan="1">Neutral</td><td valign="top" align="center" colspan="2" rowspan="1">Positive</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">CR</td><td valign="top" align="center" colspan="2" rowspan="1">0.92 (0.09)</td><td valign="top" align="center" colspan="2" rowspan="1">0.93 (0.10)</td><td valign="top" align="center" colspan="2" rowspan="1">0.89 (0.11)</td><td valign="top" align="center" colspan="2" rowspan="1">0.88 (0.12)</td><td valign="top" align="center" colspan="2" rowspan="1">0.91 (0.09)</td><td valign="top" align="center" colspan="2" rowspan="1">0.85 (0.15)</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">FA</td><td valign="top" align="center" colspan="2" rowspan="1">0.08 (0.09)</td><td valign="top" align="center" colspan="2" rowspan="1">0.07 (0.10)</td><td valign="top" align="center" colspan="2" rowspan="1">0.11 (0.11)</td><td valign="top" align="center" colspan="2" rowspan="1">0.12 (0.11)</td><td valign="top" align="center" colspan="2" rowspan="1">0.09 (0.09)</td><td valign="top" align="center" colspan="2" rowspan="1">0.15 (0.15)</td></tr></tbody></table><table-wrap-foot><p><italic>Note: CR, correct rejections; DNK, do not know; FA, false alarms; JOSs, judgments of source</italic>.</p></table-wrap-foot></table-wrap><sec><title>Recognition Accuracy</title><sec><title>Item recognition</title><p>The RMANOVA yielded a main effect of valence, <italic>F</italic><sub>(2, 54)</sub> = 4.08, <italic>p</italic> = 0.022, <inline-formula><mml:math id="M2"><mml:msubsup><mml:mrow><mml:mi>&#x003b7;</mml:mi></mml:mrow><mml:mrow><mml:mtext>p</mml:mtext></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></inline-formula> = 0.13, a main effect of source, <italic>F</italic><sub>(1, 27)</sub> = 15.93, <italic>p</italic> &#x0003c; 0.001, <inline-formula><mml:math id="M3"><mml:msubsup><mml:mrow><mml:mi>&#x003b7;</mml:mi></mml:mrow><mml:mrow><mml:mtext>p</mml:mtext></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></inline-formula> = 0.37, but no interaction effect between the two factors, <italic>F</italic><sub>(2, 54)</sub> = 0.34, <italic>p</italic> = 0.716, <inline-formula><mml:math id="M4"><mml:msubsup><mml:mrow><mml:mi>&#x003b7;</mml:mi></mml:mrow><mml:mrow><mml:mtext>p</mml:mtext></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></inline-formula> = 0.01. Bayes factors (see <xref ref-type="supplementary-material" rid="SM2">Table S7</xref>) favored the two main effects model in relation to the null model (BF<sub>10</sub> = 671.057 &#x000b1; 2.21%). The comparison between this model and the model that adds the interaction term (671.247/82.160 = 8.17) revealed evidence against the interaction as data were 8.17 more likely in the two main effects model than in the model with the interaction. Specifically, the pairwise comparisons showed a marginally significant difference in the recognition of negative and positive words (<italic>p</italic> = 0.060, <italic>d</italic> = 0.47, 95% CI [-0.002, 0.14]): negative words (<italic>M</italic> = 0.79, <italic>SE</italic> = 0.03) were more accurately recognized than positive words (<italic>M</italic> = 0.72, <italic>SE</italic> = 0.02). The words read aloud (<italic>M</italic> = 0.79, <italic>SE</italic> = 0.02) were also more accurately recognized than words read silently (<italic>M</italic> = 0.72, <italic>SE</italic> = 0.02; <italic>p</italic> &#x0003c; 0.001, <italic>d</italic> = 0.75, 95% CI [0.03, 0.10]; see <xref rid="T1" ref-type="table">Table 1</xref> and <xref ref-type="fig" rid="F2">Figure 2B</xref>).</p><fig id="F2" position="float"><label>Figure 2</label><caption><p>Behavioral results for JOSs, item memory and source memory in Experiments 1 and 2. Specifically, the behavioral results for judgments of source (JOSs<bold>; A</bold>,<bold>D</bold>), item memory <bold>(B,E)</bold>, and source memory <bold>(C,F)</bold> are plotted on the y-axis as a function of source (aloud/silence; self-reference/common) and valence (negative/neutral/positive). Note: The error bars indicate the standard errors of the means.</p></caption><graphic xlink:href="fpsyg-10-01326-g0002"/></fig><p>In the case of the corrected item Br measure, the RMANOVA showed a main effect of valence <italic>F</italic><sub>(2, 54)</sub> = 3.64, <italic>p</italic> = 0.033, <inline-formula><mml:math id="M5"><mml:msubsup><mml:mrow><mml:mi>&#x003b7;</mml:mi></mml:mrow><mml:mrow><mml:mtext>p</mml:mtext></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></inline-formula> = 0.12, a main effect of source, <italic>F</italic><sub>(1, 27)</sub> = 11.79, <italic>p</italic> = 0.002, <inline-formula><mml:math id="M6"><mml:msubsup><mml:mrow><mml:mi>&#x003b7;</mml:mi></mml:mrow><mml:mrow><mml:mtext>p</mml:mtext></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></inline-formula> = 0.30, yet no interaction effect, <italic>F</italic><sub>(2, 54)</sub> = 1.03, <italic>p</italic> = 0.363, <inline-formula><mml:math id="M7"><mml:msubsup><mml:mrow><mml:mi>&#x003b7;</mml:mi></mml:mrow><mml:mrow><mml:mtext>p</mml:mtext></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></inline-formula> = 0.04. Again, the Bayesian analysis supported the two main effects model when compared to the null model (BF<sub>10</sub> = 42.206 &#x000b1; 1.50%). Additionally, when compared to the model with the interaction term (42.206/7.965), the data were 5.30 times more likely in the two main effects model (see <xref ref-type="supplementary-material" rid="SM2">Table S7</xref>). Specifically, there was a statistically significant difference between neutral and positive words (<italic>p</italic> = 0.035, <italic>d</italic> = 0.51, 95% CI [0.005, 0.16]), indicating that participants used a less conservative response criterion for positive words (<italic>M</italic> = 0.43, <italic>SE</italic> = 0.04) in comparison with neutral words (<italic>M</italic> = 0.35, <italic>SE</italic> = 0.04). Also, the response criterion was less conservative for words read aloud (<italic>M</italic> = 0.44, <italic>SE</italic> = 0.04) than for words read silently during encoding (<italic>M</italic> = 0.37, <italic>SE</italic> = 0.04; <italic>p</italic> = 0.002, <italic>d</italic> = 0.65, 95% CI [0.029, 0.12]). However, the response criterion for all conditions was on average below or near 0.50, thus indicating a general conservative to neutral response bias (see <xref rid="T1" ref-type="table">Table 1</xref>; Snodgrass and Corwin, <xref rid="B96" ref-type="bibr">1988</xref>).</p></sec><sec><title>Source recognition</title><p>The results regarding the source memory measure did not follow the same pattern as the item memory, as no statistically significant effects were observed [valence: <italic>F</italic><sub>(2, 54)</sub> = 0.42, <italic>p</italic> = 0.657, <inline-formula><mml:math id="M8"><mml:msubsup><mml:mrow><mml:mi>&#x003b7;</mml:mi></mml:mrow><mml:mrow><mml:mtext>p</mml:mtext></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></inline-formula> = 0.02; source: <italic>F</italic><sub>(1, 27)</sub> = 1.37, <italic>p</italic> = 0.252, <inline-formula><mml:math id="M9"><mml:msubsup><mml:mrow><mml:mi>&#x003b7;</mml:mi></mml:mrow><mml:mrow><mml:mtext>p</mml:mtext></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></inline-formula> = 0.05; interaction: <italic>F</italic><sub>(2, 54)</sub> = 0.49, <italic>p</italic> = 0.618, <inline-formula><mml:math id="M10"><mml:msubsup><mml:mrow><mml:mi>&#x003b7;</mml:mi></mml:mrow><mml:mrow><mml:mtext>p</mml:mtext></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></inline-formula> = 0.02)]. Bayesian analysis supported the null effects (valence: BF<sub>10</sub> = 0.072 &#x000b1; 0.86%; source: BF<sub>10</sub> = 1.027 &#x000b1; 4.28%; valence + source + interaction: BF<sub>10</sub> = 0.009 &#x000b1; 1.75%). Thus, the source memory recognition measures were similar irrespective of stimulus valence and of the encoding strategy (see <xref rid="T1" ref-type="table">Table 1</xref> and <xref ref-type="fig" rid="F2">Figure 2C</xref>).</p></sec></sec><sec><title>Judgments of Source (JOSs)</title><p>When assessing how valence and way of production affected the JOSs ratings, we observed a main effect of valence, <italic>F</italic><sub>(2, 54)</sub> = 15.93, <italic>p</italic> &#x0003c; 0.001, <inline-formula><mml:math id="M11"><mml:msubsup><mml:mrow><mml:mi>&#x003b7;</mml:mi></mml:mrow><mml:mrow><mml:mtext>p</mml:mtext></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></inline-formula> = 0.37, a main effect of source, <italic>F</italic><sub>(1, 27)</sub> = 59.61, <italic>p</italic> &#x0003c; 0.001, <inline-formula><mml:math id="M12"><mml:msubsup><mml:mrow><mml:mi>&#x003b7;</mml:mi></mml:mrow><mml:mrow><mml:mtext>p</mml:mtext></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></inline-formula> = 0.69, but no interaction effect, <italic>F</italic><sub>(2, 54)</sub> = 0.44, <italic>p</italic> = 0.649, <inline-formula><mml:math id="M13"><mml:msubsup><mml:mrow><mml:mi>&#x003b7;</mml:mi></mml:mrow><mml:mrow><mml:mtext>p</mml:mtext></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></inline-formula> = 0.02. The Bayes factors supported the two main effects model with no interaction (valence + source: BF<sub>10</sub> = 1.620 x 10<sup>23</sup> &#x000b1; 1.25%; 8.29 times more likely than the interaction model). Specifically, the words read aloud (<italic>M</italic> = 4.23, <italic>SE</italic> = 0.13) were regarded as more memorable than the words read silently (<italic>M</italic> = 3.44, <italic>SE</italic> = 0.10; <italic>p</italic> &#x0003c; 0.001, <italic>d</italic> = 1.46, 95% CI [0.58, 1.00]), and both negative (<italic>M</italic> = 3.98, <italic>SE</italic> = 0.11; <italic>p</italic> &#x0003c; 0.001, <italic>d</italic> = 1.05, 95% CI [0.19, 0.50]) and positive stimuli (<italic>M</italic> = 3.88, <italic>SE</italic> = 0.12; <italic>p</italic> = 0.001, <italic>d</italic> = 0.80, 95% CI [0.10, 0.40]) were rated as more memorable when compared to neutral stimuli (<italic>M</italic> = 3.64, <italic>SE</italic> = 0.10; see <xref rid="T1" ref-type="table">Table 1</xref> and <xref ref-type="fig" rid="F2">Figure 2A</xref>).</p><p>In general, the metacognitive judgments partially agree with the results of item memory, as words read aloud were better recognized than words read silently. However, the predictions in the case of valence were less accurate, since no significant differences were found between emotional conditions. Considering that the JOSs ratings were performed in relation to the source, no match was observed between the predictions and the source memory performance. The analysis of the metamnemonic accuracy revealed that the gamma correlations for neutral/positive words that were read aloud and for negative words read silently were statistically different from zero, <italic>t</italic><sub>(27)</sub> &#x02265; 2.29, <italic>p</italic> &#x02264; 0.03, whereas for the remaining conditions the gamma correlations did not differ from zero, <italic>t</italic><sub>(27)</sub> &#x02264; 1.78, <italic>p</italic> &#x02265; 0.09. On the one hand, some experimental conditions were different from zero, supporting a possible relation between immediate metamemory judgments and recognition. Additionally, even though the mean gamma coefficients were positive and small (see <xref rid="T1" ref-type="table">Table 1</xref>), they resemble what has been reported in the literature of metamnemonic accuracy in the case of source memory (e.g., Carroll et al., <xref rid="B6" ref-type="bibr">1999</xref>). On the other hand, no statistically significant differences between conditions were observed for gamma correlations (valence: <italic>F</italic><sub>(2, 54)</sub> = 0.14, <italic>p</italic> = 0.866, <inline-formula><mml:math id="M14"><mml:msubsup><mml:mrow><mml:mi>&#x003b7;</mml:mi></mml:mrow><mml:mrow><mml:mtext>p</mml:mtext></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></inline-formula> = 0.01; source: <italic>F</italic><sub>(1, 27)</sub> = 1.06, <italic>p</italic> = 0.313, <inline-formula><mml:math id="M15"><mml:msubsup><mml:mrow><mml:mi>&#x003b7;</mml:mi></mml:mrow><mml:mrow><mml:mtext>p</mml:mtext></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></inline-formula> = 0.04; interaction: <italic>F</italic><sub>(2, 54)</sub> = 0.61, <italic>p</italic> = 0.549, <inline-formula><mml:math id="M16"><mml:msubsup><mml:mrow><mml:mi>&#x003b7;</mml:mi></mml:mrow><mml:mrow><mml:mtext>p</mml:mtext></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></inline-formula> = 0.02). Bayes factors were also in agreement (valence: BF<sub>10</sub> = 0.069 &#x000b1; 0.86%; source: BF<sub>10</sub> = 0.296 &#x000b1; 1.18%; valence + source + interaction: BF<sub>10</sub> = 0.003 &#x000b1; 2.86%). Thus, the modulatory role of encoding strategy and valence in the associations between the prospective source predictions and the actual source memory performance was inconclusive.</p></sec></sec><sec><title>Discussion: Experiment 1</title><p>A major finding of Experiment 1 was the absence of a production effect on internal source memory. Nonetheless, as expected, the effect was replicated in the case of item memory (Dodson and Schacter, <xref rid="B14" ref-type="bibr">2001</xref>; MacLeod et al., <xref rid="B57" ref-type="bibr">2010</xref>; Ozubko and MacLeod, <xref rid="B79" ref-type="bibr">2010</xref>; Quinlan and Taylor, <xref rid="B82" ref-type="bibr">2013</xref>). Moreover, there was no interaction between valence and production mode, indicating that the production effect on item memory occurred regardless of whether stimuli had or not an emotional quality. The EEM on item memory was also absent, against our predictions and the main tendency in the literature (see Kensinger and Schacter, <xref rid="B44" ref-type="bibr">2008</xref>; Murphy and Isaacowitz, <xref rid="B69" ref-type="bibr">2008</xref>; Levine and Edelstein, <xref rid="B54" ref-type="bibr">2009</xref>, and Kensinger and Kark, <xref rid="B41" ref-type="bibr">2018</xref>, for overviews), especially if we take into consideration that both positive/negative words were rated as significantly more arousing than neutral words. Even so, this result is not unprecedented (e.g., Hourihan and Bursey, <xref rid="B29" ref-type="bibr">2017</xref>; Ferr&#x000e9; et al., <xref rid="B23" ref-type="bibr">2019</xref>). Considering the response bias, participants revealed a conservative to neutral response criterion (see <xref rid="T1" ref-type="table">Table 1</xref>). Specifically, in cases of uncertainty, participants showed an increased tendency to regard an item as &#x0201c;new&#x0201d; when it was studied in the &#x0201c;read silently&#x0201d; condition than when it was studied in the &#x0201c;read aloud&#x0201d; condition. A similar tendency was observed for neutral items when compared to positive items. Although valence did not significantly affect objective memory indices, the same was not observed for subjective metamemory judgements. In fact, participants regarded the source of emotional words that were read aloud as more memorable, providing support to previous studies with JOLs (J&#x000f6;nsson et al., <xref rid="B34" ref-type="bibr">2005</xref>; Zimmerman and Kelley, <xref rid="B118" ref-type="bibr">2010</xref>; Tauber and Dunlosky, <xref rid="B100" ref-type="bibr">2012</xref>; Castel et al., <xref rid="B7" ref-type="bibr">2013</xref>; Nomi et al., <xref rid="B73" ref-type="bibr">2013</xref>; Hourihan et al., <xref rid="B30" ref-type="bibr">2017</xref>). However, contrary to the findings of Dutton and Carroll (<xref rid="B18" ref-type="bibr">2001</xref>), the JOSs predictions were not associated with internal source memory performance, which favors the notion that metamemory judgments are not always predictive of future memory (e.g., Carroll et al., <xref rid="B6" ref-type="bibr">1999</xref>). Rather, they show that participants were sensitive to variations in the encoding conditions, and that they used these cues to perform metamemory judgments (Mazzoni and Nelson, <xref rid="B64" ref-type="bibr">1995</xref>; Koriat, <xref rid="B46" ref-type="bibr">1997</xref>; Nomi et al., <xref rid="B73" ref-type="bibr">2013</xref>).</p></sec></sec><sec id="s3"><title>Experiment 2</title><p>The experimental design was identical to Experiment 1, although a different encoding strategy was tested: the self-referential processing. Given that in Experiment 1 negative and positive words were more arousing than neutral words, in Experiment 2 arousal ratings were also equated across valence categories. The control of arousal is advantageous considering that the effects of valence and arousal on memory function appear to be supported by different processing mechanisms (valence effects have been associated with more effortful semantic and autobiographical elaboration processes, whereas arousal effects have been related to more automatic processes; Kensinger and Corkin, <xref rid="B39" ref-type="bibr">2004</xref>; Cook et al., <xref rid="B9" ref-type="bibr">2007</xref>). Moreover, these differential effects also seem to be supported by distinct neurofunctional mechanisms (prefrontal cortex-hippocampal interactions in the case of valence, and amygdala-hippocampal interactions in the case of arousal; Kensinger and Corkin, <xref rid="B38" ref-type="bibr">2003</xref>, <xref rid="B39" ref-type="bibr">2004</xref>). Hence, the control of arousal allows isolating valence-related effects. Specifically, in this experiment, emotional (negative/positive) and neutral adjectives with medium arousal ratings were used as stimuli. During the encoding phase, participants performed two types of judgments. In half the trials, they were required to judge if the word was related to them. In the other half, they were asked if the word was commonly used by people in everyday life. The latter task represents a non-self-referential condition that requires a deep, semantic analysis of the word, and it was based on previous research (e.g., Hamami et al., <xref rid="B27" ref-type="bibr">2011</xref>; Serbun et al., <xref rid="B93" ref-type="bibr">2011</xref>; Newsome et al., <xref rid="B72" ref-type="bibr">2012</xref>; Leshikar et al., <xref rid="B53" ref-type="bibr">2015</xref>). Participants were also instructed to perform JOSs for each word. During the test phase, participants performed old-new judgments in which they were additionally asked to identify the source of the item (self-reference vs. common).</p><sec><title>Materials and Methods</title><sec><title>Participants</title><p>A total of 32 young adults (30 females), aged between 18 and 45 years (<italic>M</italic> = 22.59, <italic>SD</italic> = 5.89), and with an average of 14.45 years of formal education (<italic>SD</italic> = 2.35) participated in this experiment. The same inclusion criteria described in Experiment 1 were applied to Experiment 2. The sample size estimation followed the same strategy as described in Experiment 1 (i.e., within factors RMANOVA as the main statistical test, <inline-formula><mml:math id="M17"><mml:msubsup><mml:mrow><mml:mi>&#x003b7;</mml:mi></mml:mrow><mml:mrow><mml:mtext>p</mml:mtext></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></inline-formula> as measure of effect size, similar experimental design, and the same parameters of alpha significance level and power), but a recent study by Durbin et al. (<xref rid="B17" ref-type="bibr">2017</xref>, Experiment 1) was used as reference: here, an effect size of 0.16 was reported for source memory performance (24 participants were tested). G<sup>*</sup>Power (Faul et al., <xref rid="B22" ref-type="bibr">2007</xref>) indicated that a minimum of 16 participants would be necessary to allow the detection of such effects. Hence, an adequate sample size was also tested in the current experiment.</p></sec><sec><title>Materials</title><p>A total of 144 adjectives (48 negative/neutral/positive) were selected from the Portuguese version of the ANEW (Soares et al., <xref rid="B97" ref-type="bibr">2012</xref>). The valence ratings differed between the three types of words (positive &#x0003e; neutral; positive &#x0003e; negative; neutral &#x0003e; negative; all <italic>p</italic> &#x0003c; 0.001), but no further differences were observed regarding arousal, frequency, number of letters and number of syllables (<italic>p</italic> &#x0003e; 0.05; see <xref ref-type="supplementary-material" rid="SM2">Table S1</xref>). The selected stimuli were then equally divided among four lists of 36 words each (12 stimuli from each valence category) to be used in the study and test phases. The lists were similar regarding valence, arousal, frequency, number of letters, and number of syllables (<italic>p</italic> &#x0003e; 0.05).</p></sec><sec><title>Procedure</title><p>The overall procedure, structure, and characteristics of the experimental task were similar to Experiment 1 (see <xref ref-type="fig" rid="F1">Figure 1</xref>), but with the following differences: (a) only two study-test cycles were used; (b) during the encoding phase, the participants performed two different subjective judgments&#x02014;a self-referential judgment (in which they assessed whether each stimulus related somehow to their personal characteristics: self-referential condition) or a common judgment (in which they evaluated whether the word was commonly used by people in their everyday lives: non-self-referential condition); (c) the instructions that appeared together with the words were &#x0201c;Does this word describe me?&#x0201d; or &#x0201c;Is this word common?&#x0201d;; d) during the encoding phase, the participants were prompted to respond &#x0201c;yes&#x0201d; (press key &#x0201c;Z&#x0201d;) or &#x0201c;no&#x0201d; (press key &#x0201c;M&#x0201d;) in accordance to the &#x0201c;self-reference&#x0201d; or &#x0201c;common&#x0201d; instructions, and there was no time limit to produce a response (self-paced); e) during the test phase, the participants were instructed to select one of four response options: &#x0201c;self-description&#x0201d;; &#x0201c;common&#x0201d;; &#x0201c;evaluated, but do not know if self-description/common&#x0201d;; &#x0201c;new&#x0201d;.</p></sec><sec><title>Data Analysis</title><p>The same data analysis procedures planned for Experiment 1 were adopted in Experiment 2.</p></sec></sec><sec><title>Results</title><p>The main descriptive statistics for the behavioral performance in Experiment 2 are shown in <xref rid="T1" ref-type="table">Table 1</xref>.</p><sec><title>Recognition Accuracy</title><sec><title>Item memory</title><p>The analysis of the corrected item memory Pr measure showed a main effect of valence, <italic>F</italic>
<sub>(2, 62)</sub> = 5.46, <italic>p</italic> = 0.012, <inline-formula><mml:math id="M18"><mml:msubsup><mml:mrow><mml:mi>&#x003b7;</mml:mi></mml:mrow><mml:mrow><mml:mtext>p</mml:mtext></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></inline-formula> = 0.15, &#x003b5; = 0.78, a main effect of source, <italic>F</italic><sub>(1, 31)</sub> = 41.63, <italic>p</italic> &#x0003c; 0.001, <inline-formula><mml:math id="M19"><mml:msubsup><mml:mrow><mml:mi>&#x003b7;</mml:mi></mml:mrow><mml:mrow><mml:mtext>p</mml:mtext></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></inline-formula> = 0.57, but no valence x source interaction effect, <italic>F</italic><sub>(2, 62)</sub> = 1.15, <italic>p</italic> = 0.314, <inline-formula><mml:math id="M20"><mml:msubsup><mml:mrow><mml:mi>&#x003b7;</mml:mi></mml:mrow><mml:mrow><mml:mtext>p</mml:mtext></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></inline-formula> = 0.04, &#x003b5; = 0.76. The two main factors model received the strongest support (BF<sub>10</sub> = 8.708 &#x000d7; 10<sup>7</sup> &#x000b1; 1.18%; see <xref ref-type="supplementary-material" rid="SM2">Table S8</xref>), and it was preferred to the interaction model (8.708 x 10<sup>7</sup>/1.582 x 10<sup>7</sup> = 5.50). The participants were better at recognizing neutral words (<italic>M</italic> = 0.71, <italic>SE</italic> = 0.03) relative to negative words (<italic>M</italic> = 0.64, <italic>SE</italic> = 0.02; <italic>p</italic> &#x0003c; 0.001, <italic>d</italic> = 0.82, 95% CI [0.03, 0.11]). They also demonstrated a better recognition performance for words encoded in the self-referential condition (<italic>M</italic> = 0.73, <italic>SE</italic> = 0.02) than for words studied in the common condition (<italic>M</italic> = 0.62, <italic>SE</italic> = 0.03; <italic>p</italic> &#x0003c; 0.001, <italic>d</italic> = 1.14, 95% CI [0.07, 0.14]; see <xref rid="T1" ref-type="table">Table 1</xref> and <xref ref-type="fig" rid="F2">Figure 2E</xref>).</p><p>Regarding the corrected item Br measure, the RMANOVA revealed a main effect of valence, <italic>F</italic>
<sub>(2, 62)</sub> = 9.26, <italic>p</italic> &#x0003c; 0.001, <inline-formula><mml:math id="M21"><mml:msubsup><mml:mrow><mml:mi>&#x003b7;</mml:mi></mml:mrow><mml:mrow><mml:mtext>p</mml:mtext></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></inline-formula> = 0.23, a main effect of source, <italic>F</italic><sub>(1, 31)</sub> = 40.97, <italic>p</italic> &#x0003c; 0.001, <inline-formula><mml:math id="M22"><mml:msubsup><mml:mrow><mml:mi>&#x003b7;</mml:mi></mml:mrow><mml:mrow><mml:mtext>p</mml:mtext></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></inline-formula> = 0.57, yet no interaction effect, <italic>F</italic><sub>(2, 62)</sub> = 2.33, <italic>p</italic> = 0.106, <inline-formula><mml:math id="M23"><mml:msubsup><mml:mrow><mml:mi>&#x003b7;</mml:mi></mml:mrow><mml:mrow><mml:mtext>p</mml:mtext></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></inline-formula> = 0.07. Again, Bayes Factors were in favor of the two main effects model in contrast to the null model (BF<sub>10</sub> = 3.092 x 10<sup>8</sup> &#x000b1; 2.06%; see <xref ref-type="supplementary-material" rid="SM2">Table S8</xref>). This model was also favored when compared to the model with the interaction term (3.092 x 10<sup>8</sup>/1.201 x 10<sup>8</sup> = 2.57). Specifically, the participants demonstrated a more conservative response criterion for both negative (<italic>M</italic> = 0.38, <italic>SE</italic> = 0.04) and neutral words (<italic>M</italic> = 0.38, <italic>SE</italic> = 0.02) when compared to positive words (<italic>M</italic> = 0.48, <italic>SE</italic> = 0.04; <italic>p</italic> = 0.003, <italic>d</italic> = 0.63/0.64, 95% CI [0.03, 0.18] considering both comparisons). Moreover, participants used a less conservative response criterion for words encoded in the self-referential condition (<italic>M</italic> = 0.48, <italic>SE</italic> = 0.04) compared to words studied in the common condition (<italic>M</italic> = 0.35, <italic>SE</italic> = 0.04; <italic>p</italic> &#x0003c; 0.001, <italic>d</italic> = 1.13, 95% CI [0.09, 0.17]; see <xref rid="T1" ref-type="table">Table 1</xref>).</p></sec><sec><title>Source memory</title><p>The RMANOVA yielded a main effect of valence, <italic>F</italic><sub>(2, 62)</sub> = 15.17, <italic>p</italic> &#x0003c; 0.001, <inline-formula><mml:math id="M24"><mml:msubsup><mml:mrow><mml:mi>&#x003b7;</mml:mi></mml:mrow><mml:mrow><mml:mtext>p</mml:mtext></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></inline-formula> = 0.33, &#x003b5; = 0.79, a main effect of source, <italic>F</italic><sub>(1, 31)</sub> = 39.58, <italic>p</italic> &#x0003c; 0.001, <inline-formula><mml:math id="M25"><mml:msubsup><mml:mrow><mml:mi>&#x003b7;</mml:mi></mml:mrow><mml:mrow><mml:mtext>p</mml:mtext></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></inline-formula> = 0.56, and a valence x source interaction effect, <italic>F</italic><sub>(2, 62)</sub> = 10.69, <italic>p</italic> &#x0003c; 0.001, <inline-formula><mml:math id="M26"><mml:msubsup><mml:mrow><mml:mi>&#x003b7;</mml:mi></mml:mrow><mml:mrow><mml:mtext>p</mml:mtext></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></inline-formula> = 0.26. Positive evidence in favor of the interaction model over the two main effects model was also obtained with Bayes factors (1.007 &#x000d7; 10<sup>13</sup>/9.218 &#x000d7; 10<sup>14</sup> = 0.01). Specifically, the interaction effect yielded a differential pattern of results when considering the self-referential and the common condition. Whereas, the source of negative words encoded in the self-referential condition was more poorly recognized than the source of both neutral (95% CI [0.07, 0.23]) and positive words (95% CI [0.05, 0.28]), the source of both negative (95% CI [0.04, 0.25]) and positive words (95% CI [0.13, 0.34]) was less accurately recognized than the source of neutral words in the case of the common condition (<italic>p</italic> &#x0003c; 0.01; see <xref rid="T1" ref-type="table">Table 1</xref> and <xref ref-type="fig" rid="F2">Figure 2F</xref>).</p></sec></sec><sec><title>Judgments of Source (JOSs)</title><p>Concerning the JOSs ratings, the RMANOVA indicated a main effect of valence, <italic>F</italic><sub>(2, 62)</sub> = 4.97, <italic>p</italic> = 0.020, <inline-formula><mml:math id="M27"><mml:msubsup><mml:mrow><mml:mi>&#x003b7;</mml:mi></mml:mrow><mml:mrow><mml:mtext>p</mml:mtext></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></inline-formula> = 0.14, &#x003b5; = 0.72, a main effect of source, <italic>F</italic><sub>(1, 31)</sub> = 9.70, <italic>p</italic> = 0.004, <inline-formula><mml:math id="M28"><mml:msubsup><mml:mrow><mml:mi>&#x003b7;</mml:mi></mml:mrow><mml:mrow><mml:mtext>p</mml:mtext></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></inline-formula> = 0.24, and a valence x source interaction effect, <italic>F</italic><sub>(2, 62)</sub> = 3.39, <italic>p</italic> = 0.040, <inline-formula><mml:math id="M29"><mml:msubsup><mml:mrow><mml:mi>&#x003b7;</mml:mi></mml:mrow><mml:mrow><mml:mtext>p</mml:mtext></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></inline-formula> = 0.10. The Bayes factors did not support the interaction model as the two main effects model gathered the most robust evidence against the null model (BF<sub>10</sub> = 1888.860 &#x000b1; 1.90%; 1888.860/935.928 = 2.02). The results indicate that participants rated self-referentially words as more memorable (<italic>M</italic> = 4.17, <italic>SE</italic> = 0.14) than words studied in the common condition (<italic>M</italic> = 3.94, <italic>SE</italic> = 0.12; <italic>p</italic> = 0.004, <italic>d</italic> = 0.55, 95% CI [0.08, 0.39]; see <xref rid="T1" ref-type="table">Table 1</xref> and <xref ref-type="fig" rid="F2">Figure 2D</xref>). The valence effect was inconclusive: Bayes factors only showed anecdotal evidence in favor of the valence model (BF<sub>10</sub> = 1.029 &#x000b1; 0.73%); the pairwise comparisons revealed marginally significant differences between the JOS ratings of positive words and both neutral (<italic>p</italic> = 0.074, <italic>d</italic> = 0.42, 95%CI [-0.01, 0.25]) and negative words (<italic>p</italic> = 0.064, <italic>d</italic> = 0.43, 95% CI [-0.01, 0.35]).</p><p>The metamnemonic judgments regarding source memory during encoding only partially complied with the pattern of results obtained in the recognition test. Although JOSs ratings indicated that self-referentially encoded words were regarded as more memorable than words studied in the common condition, which was in line with the self-reference benefit observed in the recognition test, the JOS ratings concerning valence were unclear. Additionally, the gamma correlations revealed no reliable association between source judgments and source recognition as the coefficients did not differ from zero, <italic>t</italic><sub>(31)</sub> &#x02264; 1.86, <italic>p</italic> &#x02265; 0.07. Furthermore, no significant differences were found between conditions (valence: <italic>F</italic><sub>(2, 54)</sub> = 0.10, <italic>p</italic> = 0.905, <inline-formula><mml:math id="M30"><mml:msubsup><mml:mrow><mml:mi>&#x003b7;</mml:mi></mml:mrow><mml:mrow><mml:mtext>p</mml:mtext></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></inline-formula> = 0.003; source: <italic>F</italic><sub>(1, 27)</sub> = 0.80, <italic>p</italic> = 0.378, <inline-formula><mml:math id="M31"><mml:msubsup><mml:mrow><mml:mi>&#x003b7;</mml:mi></mml:mrow><mml:mrow><mml:mtext>p</mml:mtext></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></inline-formula> = 0.03; interaction: <italic>F</italic><sub>(2, 54)</sub> = 0.09, <italic>p</italic> = 0.917, <inline-formula><mml:math id="M32"><mml:msubsup><mml:mrow><mml:mi>&#x003b7;</mml:mi></mml:mrow><mml:mrow><mml:mtext>p</mml:mtext></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></inline-formula> = 0.003), and the coefficients remained positive yet small (see <xref rid="T1" ref-type="table">Table 1</xref>). The null effects were supported by the Bayesian analysis (valence: BF<sub>10</sub> = 0.058 &#x000b1; 1.06%; source: BF<sub>10</sub> = 0.287 &#x000b1; 0.72%; interaction: 0.002/0.016 = 0.13). Thus, the results pointed to the lack of an association between source memory predictions and memory performance.</p></sec></sec><sec><title>Discussion: Experiment 2</title><p>By changing the encoding strategy from Experiment 1 to Experiment 2, we observed a differential influence of valence on internal source memory, item memory, and JOSs. As expected, a self-referential benefit on item memory was observed (Rogers et al., <xref rid="B88" ref-type="bibr">1977</xref>; Kuiper and Rogers, <xref rid="B49" ref-type="bibr">1979</xref>; Symons and Johnson, <xref rid="B98" ref-type="bibr">1997</xref>), and this occurred irrespective of stimulus valence. The item memory performance was also enhanced for neutral relative to negative words (yet no significant differences were observed in the case of positive words), and this was observed in both encoding conditions. Thus, we partially replicated prior evidence showing that neutral stimuli encoded in a self-referential manner are better remembered than negative stimuli (Yang et al., <xref rid="B113" ref-type="bibr">2012</xref>). However, the hypothesized difference between negative and positive stimuli (based on prior studies&#x02014;Yang et al., <xref rid="B113" ref-type="bibr">2012</xref>; Leshikar et al., <xref rid="B53" ref-type="bibr">2015</xref>) was not observed. Notwithstanding, the EEM was not replicated in the common condition. The response bias also changed with the encoding strategy: in cases of uncertainty, participants showed an increased tendency to respond &#x0201c;new&#x0201d; for both negative and neutral stimuli relative to positive stimuli; participants also used a more conservative response criterion for stimuli encoded in the common condition than for stimuli encoded in the self-referential condition. On average, participants appeared to show a conservative to neutral response criterion (see <xref rid="T1" ref-type="table">Table 1</xref>). The only exception was observed in the case of self-referentially encoded positive words, whose mean Br was above 0.50. In the case of internal source memory performance, an interaction effect between valence and encoding strategy emerged, revealing that source recognition was improved for both neutral and positive words compared to negative stimuli in the self-reference task, which partially corroborates previous findings (e.g., Durbin et al., <xref rid="B17" ref-type="bibr">2017</xref>; Zhang et al., <xref rid="B117" ref-type="bibr">2018</xref>). A different pattern was observed in the common task, in which emotional words led to reduced source memory accuracy in contrast to neutral words. Specifically, valence impaired internal source memory, in agreement with prior studies (see <xref ref-type="supplementary-material" rid="SM1">Appendix</xref>). The JOSs ratings were also sensitive to self-referential processing as self-referentially encoded words were regarded as more memorable than words studied in the common condition. Regarding valence, the effect was less clear, which stands in contrast with Experiment 1 and previous studies (e.g., Zimmerman and Kelley, <xref rid="B118" ref-type="bibr">2010</xref>; Tauber and Dunlosky, <xref rid="B100" ref-type="bibr">2012</xref>; Hourihan et al., <xref rid="B30" ref-type="bibr">2017</xref>). Nevertheless, no significant associations were found between the JOSs ratings and internal source memory performance.</p></sec></sec><sec id="s4"><title>General Discussion</title><p>The main goal of this study was twofold: to explore how stimulus valence influences internal source monitoring, specifically when the encoding conditions are also characterized by memory enhancing features (production and self-reference effect); to specify the role played by stimulus valence in immediate prospective judgments concerning internal source memory (JOSs ratings). Overall, the results revealed that internal source monitoring, item memory, and JOSs were differently modulated by the encoding strategy, which was supported by participant-based results (RMANOVA), Bayes factors, and multinomial models (see <xref ref-type="supplementary-material" rid="SM1">Supplementary Material</xref>). Specifically, in Experiment 1, the effects of valence on item and source memory were not significant, even though the production effect was replicated for item memory. The JOSs ratings were sensitive to both valence and production mode. In turn, Experiment 2 revealed that the self-referential processing enhanced item and source memory differently as a function of valence. The JOSs ratings were also sensitive to the self-reference effect.</p><p>The current study supported the notion that self-referential conditions benefit both item and internal source memory (Hamami et al., <xref rid="B27" ref-type="bibr">2011</xref>; Serbun et al., <xref rid="B93" ref-type="bibr">2011</xref>; Leshikar and Duarte, <xref rid="B51" ref-type="bibr">2012</xref>, <xref rid="B52" ref-type="bibr">2014</xref>; Kalenzaga et al., <xref rid="B36" ref-type="bibr">2015</xref>; Durbin et al., <xref rid="B17" ref-type="bibr">2017</xref>; Yin et al., <xref rid="B115" ref-type="bibr">2018</xref>; Zhang et al., <xref rid="B117" ref-type="bibr">2018</xref>). Nonetheless, in the case of the production effect, the beneficial effects were only demonstrated for item memory but not for source memory, which stands in contrast with previous evidence (Ozubko et al., <xref rid="B80" ref-type="bibr">2014</xref>). Specific methodological factors may have attenuated the production effect such as intentional encoding instructions, the use of the &#x0201c;do not know&#x0201d; option in the test phase (which may have led to a more conservative response in situations in which the participants were not able to recollect the source but they knew the words were familiar), or the source recognition measure that included the proportion of incorrect source attributions. Indeed, we observed that the proportion of incorrect source attributions for words that were read aloud was significantly higher than for words read silently. As participants believed that words read aloud were more memorable than words read silently (which was reflected in JOSs ratings), they may have been more prone to attribute a specific word read aloud to the other source when they only knew that a specific word was studied before. Nonetheless, a lack of effect was also expected, given that prior studies that probed the effects of valence on internal source memory also reported a null (e.g., Kensinger and Schacter, <xref rid="B42" ref-type="bibr">2006a</xref>; Sharot and Yonelinas, <xref rid="B95" ref-type="bibr">2008</xref>; Ferr&#x000e9; et al., <xref rid="B23" ref-type="bibr">2019</xref>, Experiment 1) or an impairment effect (e.g., Newsome et al., <xref rid="B72" ref-type="bibr">2012</xref>; Otani et al., <xref rid="B77" ref-type="bibr">2012a</xref>,<xref rid="B78" ref-type="bibr">b</xref>; Mao et al., <xref rid="B60" ref-type="bibr">2015</xref>; Ferr&#x000e9; et al., <xref rid="B23" ref-type="bibr">2019</xref>, Experiment 2 and 3; see <xref ref-type="supplementary-material" rid="SM1">Appendix</xref>). Critically, both results were observed in the current study but with distinct encoding conditions, i.e., no effect in Experiment 1 and an impairment effect in the non-self-referential condition in Experiment 2. Furthermore, an enhancement effect emerged for both neutral and positive words studied in a self-referential manner.</p><p>Whereas an impairment or lack of effect might be explained by the object-based binding theory (Mather, <xref rid="B61" ref-type="bibr">2007</xref>), as production mode and cognitive operations (self-referential or common judgments) can be deemed as extrinsic features of the item, this theoretical framework cannot account for the self-referential benefit of source memory in the case of neutral and positive words, especially considering that stimuli in Experiment 2 were matched for arousal. In this context, the arousal-biased competition theory (Mather and Sutherland, <xref rid="B63" ref-type="bibr">2011</xref>) offers a more suitable framework for the source memory effects found in the current study, considering that both emotional and non-emotional information can be prioritized according to the current goals and motivations of the individual. Even though both positive and negative stimuli were more arousing than neutral stimuli in Experiment 1, the participants were instructed to effortfully encode both item and production mode. Hence, even if the items that were read aloud were more perceptually salient, all items were goal-relevant and likely to receive similar processing resources.</p><p>Considering that self-referential processing promotes a more organized, elaborative and efficient processing in comparison with other perceptual and semantic tasks, such as common judgments (which can be deemed as unusual tasks; Symons and Johnson, <xref rid="B98" ref-type="bibr">1997</xref>; D'Argembeau et al., <xref rid="B10" ref-type="bibr">2005</xref>), participants may have prioritized information that was relevant to describe themselves in Experiment 2. In fact, words that are perceived as self-descriptive tend to be better remembered than non-self-descriptive words (Kuiper and Rogers, <xref rid="B49" ref-type="bibr">1979</xref>). Participants also tend to favor positive information and to disregard negative self-referential information (D'Argembeau et al., <xref rid="B10" ref-type="bibr">2005</xref>; Watson et al., <xref rid="B108" ref-type="bibr">2008</xref>; Zhang et al., <xref rid="B117" ref-type="bibr">2018</xref>), a tendency that has been observed irrespective of age, gender, or cultural background (Mezulis et al., <xref rid="B66" ref-type="bibr">2004</xref>). Moreover, the information that fits the current self-scheme may receive a deeper and elaborative processing, whereas non-fitting information may be processed in a shallow manner, which may result in a less successful memory performance (Kuiper and Rogers, <xref rid="B49" ref-type="bibr">1979</xref>; D'Argembeau et al., <xref rid="B10" ref-type="bibr">2005</xref>). Thus, enhanced source memory might be expected for both neutral and positive self-referential words as they are likely to match the current self-schema (the proportion of &#x0201c;yes&#x0201d; responses was also higher for positive and neutral words; see <xref ref-type="supplementary-material" rid="SM1">Supplementary Material</xref>). In contrast, the negative self-referential words may have been neglected as they are less likely to match the current self-schema, leading to a decline in source memory performance.</p><p>In the case of the common condition, a similar result to Experiment 1 could be expected, as identical intentional encoding conditions were required during the learning phase. However, an impairment effect was observed for emotional words encoded in the common condition. This finding might be accounted for the higher proportion of incorrect source attributions found for positive words in comparison with neutral words (see <xref ref-type="supplementary-material" rid="SM1">Supplementary Material</xref>). Although this represents a limitation of the current study, it might be the case that the emotional adjectives selected here were more prototypical self-descriptors than the neutral adjectives. Thereby, participants could be more likely to confound the source of emotional adjectives studied in the common condition. Likewise, the neutral adjectives could offer a more congruent match with the common task, resulting in a better source memory performance. According to the arousal-biased competition theory (Mather and Sutherland, <xref rid="B63" ref-type="bibr">2011</xref>), the former explanations might be related to top-down processes such as the relevance of the stimuli to the current task. Additionally, they also fit with the source-monitoring account (Johnson et al., <xref rid="B32" ref-type="bibr">1993</xref>), as decisions regarding the origin of an event are influenced not only by qualitative characteristics that take place during encoding (e.g., cognitive operations), but also by previous general knowledge and schemas (e.g., stereotypes; beliefs). Thus, when there are few qualitative features to distinguish between sources, which is the case of internal source memory decisions, participants might rely on their beliefs. In the test phase, if participants consider a specific word as a self-descriptor (which might be more likely to happen in the case of positive adjectives), they might be biased to select the self-reference option, especially when they cannot recall other qualitative features associated with the word, even when a &#x0201c;do not know option&#x0201d; is available. In fact, positive adjectives that were self-referentially encoded were also associated with a more liberal response criterion (see <xref rid="T1" ref-type="table">Table 1</xref>), suggesting that participants were biased to deem positive new items as &#x0201c;old&#x0201d;.</p><p>The subjective JOSs ratings were also informative of how sensitive the participants were to both valence and encoding strategy during the encoding phase. In Experiment 1, the source of both positive and negative words was regarded as more memorable than neutral words. This pattern has also been reported in studies using JOLs (e.g., J&#x000f6;nsson et al., <xref rid="B34" ref-type="bibr">2005</xref>; Zimmerman and Kelley, <xref rid="B118" ref-type="bibr">2010</xref>; Tauber and Dunlosky, <xref rid="B100" ref-type="bibr">2012</xref>; Nomi et al., <xref rid="B73" ref-type="bibr">2013</xref>; Hourihan and Bursey, <xref rid="B29" ref-type="bibr">2017</xref>; Hourihan et al., <xref rid="B30" ref-type="bibr">2017</xref>). Here, it was extended to JOSs. As the processing of emotional stimuli shows some advantages in comparison with neutral stimuli in terms of attention, organization, and distinctiveness (D'Argembeau and Van der Linden, <xref rid="B11" ref-type="bibr">2004</xref>; Maddox et al., <xref rid="B59" ref-type="bibr">2012</xref>; Talmi, <xref rid="B99" ref-type="bibr">2013</xref>), these factors may also play a role in metamemory judgments. Furthermore, the source of words that were read aloud was rendered as more memorable than words read silently, following previous studies examining JOLs (Castel et al., <xref rid="B7" ref-type="bibr">2013</xref>). Also, in Experiment 2, JOSs ratings revealed that self-referentially encoded words were judged as more memorable when compared to words studied in the common condition. Notwithstanding, the effect of valence was inconclusive, and our initial predictions were not confirmed as only marginal results supported the preference of the participants for positive information. Overall, both experiments demonstrate that participants were sensitive to the potential advantage of reading items aloud or processing them self-referentially. This finding might be accounted for the cue-utilization hypothesis (Koriat, <xref rid="B46" ref-type="bibr">1997</xref>), which posits that prospective metamemory judgments can be modulated by specific characteristics that provide a sense of how easy/difficult it is to process and learn an item.</p><p>According to the cue-utilization hypothesis, JOLs are inferential in nature and their predictive value depends on whether the cues used to make metamemory judgments converge with variables affecting memory performance. Thus, in some instances immediate metamemory judgments might predict future memory performance (e.g., Mazzoni and Nelson, <xref rid="B64" ref-type="bibr">1995</xref>; Carroll et al., <xref rid="B5" ref-type="bibr">2001</xref>; Dutton and Carroll, <xref rid="B18" ref-type="bibr">2001</xref>), whereas the same may not occur in other situations. For instance, in a previous study by Carroll et al. (<xref rid="B6" ref-type="bibr">1999</xref>), exploring JOLs and JOSs applied to reality monitoring decisions (seen vs. imagined), participants' predictions regarding source memory performance did not differ from chance. In the current study, this result is extended to internal source memory, specifically in Experiment 2 and in some conditions of Experiment 1. Although the predictions for some conditions of Experiment 1 were different from chance, no reliable differences in the gamma coefficients were found between encoding strategy and valence conditions. These findings stand in contrast with the findings of Dutton and Carroll (<xref rid="B18" ref-type="bibr">2001</xref>) but agree with the JOLs findings (Hourihan and Bursey, <xref rid="B29" ref-type="bibr">2017</xref>; Hourihan et al., <xref rid="B30" ref-type="bibr">2017</xref>). As suggested by Kelly et al. (<xref rid="B37" ref-type="bibr">2002</xref>), JOSs can be considered an unfamiliar task and, plausibly, participants might have based their JOSs on item memorability rather than source memory memorability. In fact, it has been previously suggested that JOLs and JOSs are associated and that similar cues might be used to make these predictions (Carroll et al., <xref rid="B6" ref-type="bibr">1999</xref>, <xref rid="B5" ref-type="bibr">2001</xref>; Kelly et al., <xref rid="B37" ref-type="bibr">2002</xref>). As immediate prospective metamemory judgments are performed item by item, participants may rely their decisions on short-term memory and on other factors (e.g., the nature of the elaborative processes) that do not have enough diagnostic value to predict which information will be later remembered or forgotten.</p><p>The indirect analysis of item memory performance did not reveal an EEM effect, contrary to our initial prediction and several prior studies (e.g., Davidson et al., <xref rid="B13" ref-type="bibr">2006</xref>; Kensinger and Schacter, <xref rid="B42" ref-type="bibr">2006a</xref>; Maddock and Frein, <xref rid="B58" ref-type="bibr">2009</xref>; Schmidt et al., <xref rid="B91" ref-type="bibr">2011</xref>; Maddox et al., <xref rid="B59" ref-type="bibr">2012</xref>; Yang et al., <xref rid="B113" ref-type="bibr">2012</xref>; Sch&#x000fc;mann et al., <xref rid="B92" ref-type="bibr">2018</xref>). Specifically, in Experiment 1, no difference was found when emotional words were compared to neutral words. In Experiment 2, neutral words were associated with higher recognition rates than negative words irrespective of the encoding strategy. Enhanced item memory for neutral compared to negative words encoded in the self-referential condition was expected (Yang et al., <xref rid="B113" ref-type="bibr">2012</xref>). Nonetheless, a similar benefit was also expected for positive words that were processed self-referentially in relation to negative words (Yang et al., <xref rid="B113" ref-type="bibr">2012</xref>; Leshikar et al., <xref rid="B53" ref-type="bibr">2015</xref>), even though this prediction was not confirmed by the current study. A failure to observe such effect is rather in agreement with the studies of D'Argembeau et al. (<xref rid="B10" ref-type="bibr">2005</xref>, Experiment 2) and of Zhang et al. (<xref rid="B117" ref-type="bibr">2018</xref>, Experiment 2) that compared positive and negative traits. Even considering the consistency of the EEM effect in the literature (see Murphy and Isaacowitz, <xref rid="B69" ref-type="bibr">2008</xref> for a meta-analysis), other studies have also failed to report significant emotion effects on memory tasks (e.g., Newsome et al., <xref rid="B72" ref-type="bibr">2012</xref>; Hourihan and Bursey, <xref rid="B29" ref-type="bibr">2017</xref>; Ferr&#x000e9; et al., <xref rid="B23" ref-type="bibr">2019</xref>), particularly when using recognition tests (e.g., Doerksen and Shimamura, <xref rid="B15" ref-type="bibr">2001</xref>; D'Argembeau and Van der Linden, <xref rid="B11" ref-type="bibr">2004</xref>; Davidson et al., <xref rid="B13" ref-type="bibr">2006</xref>) and short intervals between study and test (e.g., Mitchell et al., <xref rid="B68" ref-type="bibr">2006</xref>; Sharot and Yonelinas, <xref rid="B95" ref-type="bibr">2008</xref>; Yonelinas and Ritchey, <xref rid="B116" ref-type="bibr">2015</xref>; Wang, <xref rid="B105" ref-type="bibr">2018</xref>). The null effect might also be explained by the higher proneness to false alarms observed in the case of emotionally salient words, especially when they are intentionally studied (D'Argembeau and Van der Linden, <xref rid="B11" ref-type="bibr">2004</xref>; Davidson et al., <xref rid="B13" ref-type="bibr">2006</xref>, Experiment 2B; Cook et al., <xref rid="B9" ref-type="bibr">2007</xref>; Sharot and Yonelinas, <xref rid="B95" ref-type="bibr">2008</xref>). Indeed, this explanation could partially account for the item memory difference between neutral and negative words in Experiment 2, irrespective of the encoding task, as the false alarm rates were higher for emotional compared to neutral words (see <xref ref-type="supplementary-material" rid="SM1">Supplementary Material</xref>). Additionally, the negative adjectives studied in the self-referential condition were also associated with a greater proportion of misses compared to positive adjectives studied in the same condition (see <xref ref-type="supplementary-material" rid="SM1">Supplementary Material</xref>). This last finding might have also contributed to the statistically significant difference between negative and neutral stimuli, and for the intermediate position of positive stimuli, which did not differ from both neutral and negative stimuli.</p><p>Although the former interpretation seems to apply to Experiment 2, the same cannot be assumed for Experiment 1, especially because the false alarm rates did not differ across negative, neutral and positive words (see <xref ref-type="supplementary-material" rid="SM1">Supplementary Material</xref>). In this regard, the short interval between study and test may be an important factor to consider. Prior studies revealed that the relationship between the brain activity during encoding and the subsequent memory performance for neutral stimuli is stronger at a short interval than at a long interval, whereas the same relationship appears to be more stable over time in the case of emotional stimuli (Mickley Steinmetz et al., <xref rid="B67" ref-type="bibr">2012</xref>). Moreover, emotional information seems to be more resistant to forgetting (Sharot and Phelps, <xref rid="B94" ref-type="bibr">2004</xref>; Mitchell et al., <xref rid="B68" ref-type="bibr">2006</xref>; Ritchey et al., <xref rid="B87" ref-type="bibr">2008</xref>; Sharot and Yonelinas, <xref rid="B95" ref-type="bibr">2008</xref>; Weymar et al., <xref rid="B111" ref-type="bibr">2009</xref>, <xref rid="B110" ref-type="bibr">2011</xref>; Schaefer et al., <xref rid="B90" ref-type="bibr">2011</xref>; Yonelinas and Ritchey, <xref rid="B116" ref-type="bibr">2015</xref>). As in Experiment 1 the study phase was immediately followed by the test phase, it could be the case that the EEM effect would emerge if longer study-test intervals were implemented (Sharot and Phelps, <xref rid="B94" ref-type="bibr">2004</xref>; Mitchell et al., <xref rid="B68" ref-type="bibr">2006</xref>; Sharot and Yonelinas, <xref rid="B95" ref-type="bibr">2008</xref>; Schaefer et al., <xref rid="B90" ref-type="bibr">2011</xref>; Yick et al., <xref rid="B114" ref-type="bibr">2015</xref>), consistent with consolidation processes (Hamann, <xref rid="B28" ref-type="bibr">2001</xref>; Talmi, <xref rid="B99" ref-type="bibr">2013</xref>). However, previous studies also indicated that even in immediate conditions, negative arousing stimuli can be better recognized than neutral stimuli (e.g., Wirkner et al., <xref rid="B112" ref-type="bibr">2018</xref>). Whereas in Experiment 2 stimuli were controlled for arousal, in Experiment 1 both negative and positive stimuli had higher arousal ratings than neutral ones (according to Soares et al., <xref rid="B97" ref-type="bibr">2012</xref>). As such, a difference could be at least expected between negative and neutral stimuli in the context of Experiment 1. Nevertheless, we only observed a trend for a beneficial effect of negative information compared to positive information, which is in line with prior evidence showing that memory superiority effects are more consistent for negative information and less clear for positive information (e.g., Ochsner, <xref rid="B74" ref-type="bibr">2000</xref>; Wang and Fu, <xref rid="B107" ref-type="bibr">2011</xref>; Otani et al., <xref rid="B77" ref-type="bibr">2012a</xref>,<xref rid="B78" ref-type="bibr">b</xref>; Rossi-Arnaud et al., <xref rid="B89" ref-type="bibr">2018</xref>; Wang, <xref rid="B105" ref-type="bibr">2018</xref>). In this context, differences in valence/arousal between the original ANEW ratings and the participants' ratings in the current study should be also considered. We cannot rule out the possibility that the findings of this experiment were somehow affected by a mismatch between the original ratings and the subjective evaluations of the words by the participants of the current study (see Davidson et al., <xref rid="B13" ref-type="bibr">2006</xref>, Experiment 1 and 2A, and Koenig and Mecklinger, <xref rid="B45" ref-type="bibr">2008</xref> for examples).</p><p>Another plausible explanation for the lack of an EEM effect may relate to the experimental conditions as participants were aware that their memory would be tested later, and they were overtly instructed to memorize item and source. Thus, despite a processing advantage of emotional words over neutral words in terms of attention, distinctiveness, and organization (D'Argembeau and Van der Linden, <xref rid="B11" ref-type="bibr">2004</xref>; Maddox et al., <xref rid="B59" ref-type="bibr">2012</xref>; Talmi, <xref rid="B99" ref-type="bibr">2013</xref>), the impact of these factors might have been attenuated by intentional learning. Hence, it is possible that valence effects were overshadowed by similar attentional resources and effortful encoding for all types of stimuli (e.g., Ferr&#x000e9; et al., <xref rid="B23" ref-type="bibr">2019</xref>, Experiment 1). When the relevance of the stimuli to the current goals is identical across emotional and neutral conditions, the memory performance may not differ as a function of valence and/or arousal (Ochsner, <xref rid="B74" ref-type="bibr">2000</xref>), in line with the arousal-biased competition theory (Mather and Sutherland, <xref rid="B63" ref-type="bibr">2011</xref>). Furthermore, experimental conditions relying on a recognition test instead of free recall (e.g., Doerksen and Shimamura, <xref rid="B15" ref-type="bibr">2001</xref>; D'Argembeau and Van der Linden, <xref rid="B11" ref-type="bibr">2004</xref>), the type of recognition test (e.g., direct source memory test instead of old/new judgments followed by a source memory test conditioned to old items), different study-test cycles with few trials (e.g., Adelman and Estes, <xref rid="B1" ref-type="bibr">2013</xref>), and the short period between study and test (e.g., Sharot and Phelps, <xref rid="B94" ref-type="bibr">2004</xref>; Mitchell et al., <xref rid="B68" ref-type="bibr">2006</xref>; Sharot and Yonelinas, <xref rid="B95" ref-type="bibr">2008</xref>; Wang, <xref rid="B105" ref-type="bibr">2018</xref>), might have also contributed to the current pattern of findings.</p><sec><title>Limitations</title><p>The manipulation of valence was critical in the current study, but the full control of stimulus arousal was not possible in the case of Experiment 1. Therefore, it is not possible to clearly dissociate valence from arousal effects in this case. Moreover, word selection relied on norms considering the combined ratings of male and female participants, yet the sample was mainly composed of female participants. Considering prior evidence for sex differences in the encoding and recall of emotional events (e.g., Galli et al., <xref rid="B25" ref-type="bibr">2011</xref>; Glaser et al., <xref rid="B26" ref-type="bibr">2012</xref>), this may limit the generalization of the current findings. Also, the role of specific stimulus properties (e.g., familiarity; concreteness; imageability; age of acquisition; self-descriptive/commonness characteristics; Adelman and Estes, <xref rid="B1" ref-type="bibr">2013</xref>; Fan et al., <xref rid="B21" ref-type="bibr">2016</xref>) was not accounted for in this study. Another limitation concerns the lack of control of factors such as attention, organization, distinctiveness, or personal motivations, which may impact upon the emotion-memory dynamics (Talmi, <xref rid="B99" ref-type="bibr">2013</xref>), and are critical for a more thorough discussion of theoretical frameworks such as the object-based binding theory (Mather, <xref rid="B61" ref-type="bibr">2007</xref>) and the arousal-biased competition theory (Mather and Sutherland, <xref rid="B63" ref-type="bibr">2011</xref>). Likewise, it was not possible to clarify whether the results observed in the test phase depended on mechanisms that operated during encoding and/or recognition (see Hamann, <xref rid="B28" ref-type="bibr">2001</xref>, and Levine and Edelstein, <xref rid="B54" ref-type="bibr">2009</xref>, for reviews), even if the experimental manipulations were restricted to the encoding phase and even if the influence of consolidation processes is not expected in conditions of immediate recognition.</p></sec></sec><sec sec-type="conclusions" id="s5"><title>Conclusion</title><p>The current study confirmed the role of task-related factors in the interplay between emotion and memory. Specifically, emotional stimuli encoded in different conditions (read aloud vs. silently; self-reference vs. common) led to distinct findings in terms of internal source memory, item memory, and JOSs ratings. In line with the source-monitoring framework, we showed that emotional events do not always enhance episodic memory recognition, and that their impact is not the same for source and item memory (Johnson et al., <xref rid="B32" ref-type="bibr">1993</xref>; Jurica and Shimamura, <xref rid="B35" ref-type="bibr">1999</xref>). Although the encoding strategies tested here&#x02014;the production and the self-reference effect&#x02014;are known to benefit item memory, a similar benefit was only found for internal source memory in the case of positive and neutral self-referenced words. Further research is needed to clarify the relationship between emotion and source memory, considering that stimulus type (e.g., Durbin et al., <xref rid="B17" ref-type="bibr">2017</xref>), the type of source discrimination (e.g., Boywitt, <xref rid="B4" ref-type="bibr">2015</xref>), and the encoding strategy (e.g., Kuhlmann and Touron, <xref rid="B47" ref-type="bibr">2012</xref>, <xref rid="B48" ref-type="bibr">2017</xref>) may affect this relationship. The same applies to JOSs ratings, which were sensitive to both valence and encoding strategy manipulations, although their predictive value was not confirmed. Together, the current experiments demonstrate how different encoding strategies modulate the effects of valence on distinct features of episodic memory, and on prospective metamemory judgments. Future studies should account for the way information is encoded when probing how emotion influences different facets of episodic memory.</p></sec><sec id="s6"><title>Ethics Statement</title><p>All subjects gave written informed consent in accordance with the Declaration of Helsinki. This study was approved by the local Ethics Committee (Subcomiss&#x000e3;o de &#x000c9;tica para as Ci&#x000ea;ncias da Vida e da Sa&#x000fa;de, Universidade do Minho, Braga, Portugal; SECVS 105/2016).</p></sec><sec id="s7"><title>Author Contributions</title><p>DP conceived the study concept and design under the supervision of AS and AP. DP performed data collection, analysis and interpretation, and drafted the first version of the manuscript. All authors provided a critical review of the manuscript and approved its final version.</p><sec><title>Conflict of Interest Statement</title><p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p></sec></sec></body><back><ack><p>The authors are grateful to all the participants who collaborated in the study.</p></ack><fn-group><fn fn-type="financial-disclosure"><p><bold>Funding.</bold> This work was supported by a Ph.D. Fellowship (PD/BD/105964/2014), awarded to DP, funded by the Portuguese Science Foundation (FCT) through national funds and co-funded by the European Social Fund (ESF) through the Operational Programme for Human Capital (POCH). It was also supported by a research grant (PTDC/MHC-PCN/0101/2014) funded by FCT and awarded to AP. The study was conducted at the Psychology Research Centre (PSI/01662), School of Psychology, University of Minho, and supported by FCT and the Portuguese Ministry of Science, Technology and Higher Education (UID/PSI/01662/2019), through the national funds (PIDDAC) and co-funded by FEDER through COMPETE2020 under the PT2020 Partnership Agreement (POCI-01-0145-FEDER-007653).</p></fn></fn-group><sec sec-type="supplementary-material" id="s8"><title>Supplementary Material</title><p>The Supplementary Material for this article can be found online at: <ext-link ext-link-type="uri" xlink:href="https://www.frontiersin.org/articles/10.3389/fpsyg.2019.01326/full#supplementary-material">https://www.frontiersin.org/articles/10.3389/fpsyg.2019.01326/full#supplementary-material</ext-link></p><supplementary-material content-type="local-data" id="SM1"><media xlink:href="Data_Sheet_1.docx"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="SM2"><media xlink:href="Table_1.pdf"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material></sec><ref-list><title>References</title><ref id="B1"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Adelman</surname><given-names>J. S.</given-names></name><name><surname>Estes</surname><given-names>Z.</given-names></name></person-group> (<year>2013</year>). <article-title>Emotion and memory: a recognition advantage for positive and negative words independent of arousal</article-title>. <source>Cognition</source>
<volume>129</volume>, <fpage>530</fpage>&#x02013;<lpage>535</lpage>. <pub-id pub-id-type="doi">10.1016/j.cognition.2013.08.014</pub-id><pub-id pub-id-type="pmid">24041838</pub-id></mixed-citation></ref><ref id="B2"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Batchelder</surname><given-names>W. H.</given-names></name><name><surname>Riefer</surname><given-names>D. M.</given-names></name></person-group> (<year>1990</year>). <article-title>Multinomial processing models of source monitoring</article-title>. <source>Psychol. Rev.</source>
<volume>97</volume>, <fpage>548</fpage>&#x02013;<lpage>564</lpage>. <pub-id pub-id-type="doi">10.1037/0033-295X.97.4.548</pub-id></mixed-citation></ref><ref id="B3"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bowen</surname><given-names>H. J.</given-names></name><name><surname>Kark</surname><given-names>S. M.</given-names></name><name><surname>Kensinger</surname><given-names>E. A.</given-names></name></person-group> (<year>2018</year>). <article-title>Never forget: negative emotional valence enhances recapitulation</article-title>. <source>Psychon. Bull. Rev.</source>
<volume>25</volume>, <fpage>870</fpage>&#x02013;<lpage>891</lpage>. <pub-id pub-id-type="doi">10.3758/s13423-017-1313-9</pub-id><pub-id pub-id-type="pmid">28695528</pub-id></mixed-citation></ref><ref id="B4"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Boywitt</surname><given-names>C. D.</given-names></name></person-group> (<year>2015</year>). <article-title>Non-monotonic relationships between emotional arousal and memory for color and location</article-title>. <source>Cogn. Emot.</source>
<volume>29</volume>, <fpage>1335</fpage>&#x02013;<lpage>1349</lpage>. <pub-id pub-id-type="doi">10.1080/02699931.2014.977850</pub-id><pub-id pub-id-type="pmid">25387152</pub-id></mixed-citation></ref><ref id="B5"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carroll</surname><given-names>M.</given-names></name><name><surname>Davis</surname><given-names>R.</given-names></name><name><surname>Conway</surname><given-names>M.</given-names></name></person-group> (<year>2001</year>). <article-title>The effects of self-reference on recognition and source attribution</article-title>. <source>Aust. J. Psychol.</source>
<volume>53</volume>, <fpage>140</fpage>&#x02013;<lpage>145</lpage>. <pub-id pub-id-type="doi">10.1080/00049530108255136</pub-id></mixed-citation></ref><ref id="B6"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carroll</surname><given-names>M.</given-names></name><name><surname>Mazzoni</surname><given-names>G.</given-names></name><name><surname>Andrews</surname><given-names>S.</given-names></name><name><surname>Pocock</surname><given-names>P.</given-names></name></person-group> (<year>1999</year>). <article-title>Monitoring the future: object and source memory for real and imagined events</article-title>. <source>Appl. Cogn. Psychol.</source>
<volume>13</volume>, <fpage>373</fpage>&#x02013;<lpage>390</lpage>.</mixed-citation></ref><ref id="B7"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Castel</surname><given-names>A. D.</given-names></name><name><surname>Rhodes</surname><given-names>M. G.</given-names></name><name><surname>Friedman</surname><given-names>M. C.</given-names></name></person-group> (<year>2013</year>). <article-title>Predicting memory benefits in the production effect: the use and misuse of self-generated distinctive cues when making judgments of learning</article-title>. <source>Mem. Cognit.</source>
<volume>41</volume>, <fpage>28</fpage>&#x02013;<lpage>35</lpage>. <pub-id pub-id-type="doi">10.3758/s13421-012-0249-6</pub-id><pub-id pub-id-type="pmid">22915315</pub-id></mixed-citation></ref><ref id="B8"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Coelho</surname><given-names>R.</given-names></name><name><surname>Martins</surname><given-names>A.</given-names></name><name><surname>Barros</surname><given-names>H.</given-names></name></person-group> (<year>2002</year>). <article-title>Clinical profiles relating gender and depressive symptoms among adolescents ascertained by the beck depressive inventory II</article-title>. <source>Eur. Psychiatry</source>
<volume>17</volume>, <fpage>222</fpage>&#x02013;<lpage>226</lpage>. <pub-id pub-id-type="doi">10.1016/S0924-9338(02)00663-6</pub-id><pub-id pub-id-type="pmid">12231268</pub-id></mixed-citation></ref><ref id="B9"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cook</surname><given-names>G. I.</given-names></name><name><surname>Hicks</surname><given-names>J. L.</given-names></name><name><surname>Marsh</surname><given-names>R. L.</given-names></name></person-group> (<year>2007</year>). <article-title>Source monitoring is not always enhanced for valenced material</article-title>. <source>Mem. Cognit.</source>
<volume>35</volume>, <fpage>222</fpage>&#x02013;<lpage>230</lpage>. <pub-id pub-id-type="doi">10.3758/BF03193443</pub-id></mixed-citation></ref><ref id="B10"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>D'Argembeau</surname><given-names>A.</given-names></name><name><surname>Comblain</surname><given-names>C.</given-names></name><name><surname>Linden</surname><given-names>M.</given-names></name></person-group> (<year>2005</year>). <article-title>Affective valence and the self-reference effect: influence of retrieval conditions</article-title>. <source>Br. J. Psychol.</source>
<volume>96</volume>, <fpage>457</fpage>&#x02013;<lpage>466</lpage>. <pub-id pub-id-type="doi">10.1348/000712605X53218</pub-id><pub-id pub-id-type="pmid">16248936</pub-id></mixed-citation></ref><ref id="B11"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>D'Argembeau</surname><given-names>A.</given-names></name><name><surname>Van der Linden</surname><given-names>M.</given-names></name></person-group> (<year>2004</year>). <article-title>Influence of affective meaning on memory for contextual information</article-title>. <source>Emotion</source>
<volume>4</volume>, <fpage>173</fpage>&#x02013;<lpage>188</lpage>. <pub-id pub-id-type="doi">10.1037/1528-3542.4.2.173</pub-id><pub-id pub-id-type="pmid">15222854</pub-id></mixed-citation></ref><ref id="B12"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>D'Argembeau</surname><given-names>A.</given-names></name><name><surname>Van der Linden</surname><given-names>M.</given-names></name></person-group> (<year>2005</year>). <article-title>Influence of emotion on memory for temporal information</article-title>. <source>Emotion</source>
<volume>5</volume>, <fpage>503</fpage>&#x02013;<lpage>507</lpage>. <pub-id pub-id-type="doi">10.1037/1528-3542.5.4.503</pub-id><pub-id pub-id-type="pmid">16366754</pub-id></mixed-citation></ref><ref id="B13"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Davidson</surname><given-names>P. S. R.</given-names></name><name><surname>Mcfarland</surname><given-names>C. P.</given-names></name><name><surname>Glisky</surname><given-names>E. L.</given-names></name></person-group> (<year>2006</year>). <article-title>Effects of emotion on item and source memory in young and older adults</article-title>. <source>Cogn. Affect. Behav. Neurosci.</source>
<volume>6</volume>, <fpage>306</fpage>&#x02013;<lpage>322</lpage>. <pub-id pub-id-type="doi">10.3758/CABN.6.4.306</pub-id><pub-id pub-id-type="pmid">17458446</pub-id></mixed-citation></ref><ref id="B14"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dodson</surname><given-names>C. S.</given-names></name><name><surname>Schacter</surname><given-names>D. L.</given-names></name></person-group> (<year>2001</year>). <article-title>If I had said it I would have remembered it: reducing false memories with a distinctiveness heuristic</article-title>. <source>Psychon. Bull. Rev.</source>
<volume>8</volume>, <fpage>155</fpage>&#x02013;<lpage>161</lpage>. <pub-id pub-id-type="doi">10.3758/BF03196152</pub-id><pub-id pub-id-type="pmid">11340861</pub-id></mixed-citation></ref><ref id="B15"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Doerksen</surname><given-names>S.</given-names></name><name><surname>Shimamura</surname><given-names>A. P.</given-names></name></person-group> (<year>2001</year>). <article-title>Source memory enhancement for emotional words</article-title>. <source>Emotion</source>
<volume>1</volume>, <fpage>5</fpage>&#x02013;<lpage>11</lpage>. <pub-id pub-id-type="doi">10.1037/1528-3542.1.1.5</pub-id><pub-id pub-id-type="pmid">12894807</pub-id></mixed-citation></ref><ref id="B16"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dulas</surname><given-names>M. R.</given-names></name><name><surname>Duarte</surname><given-names>A.</given-names></name></person-group> (<year>2014</year>). <article-title>Aging affects the interaction between attentional control and source memory: an fMRI study</article-title>. <source>J. Cogn. Neurosci.</source>
<volume>26</volume>, <fpage>2653</fpage>&#x02013;<lpage>2669</lpage>. <pub-id pub-id-type="doi">10.1162/jocn_a_00663</pub-id><pub-id pub-id-type="pmid">24800631</pub-id></mixed-citation></ref><ref id="B17"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Durbin</surname><given-names>K. A.</given-names></name><name><surname>Mitchell</surname><given-names>K. J.</given-names></name><name><surname>Johnson</surname><given-names>M. K.</given-names></name></person-group> (<year>2017</year>). <article-title>Source memory that encoding was self-referential: the influence of stimulus characteristics</article-title>. <source>Memory</source>
<volume>25</volume>, <fpage>1191</fpage>&#x02013;<lpage>1200</lpage>. <pub-id pub-id-type="doi">10.1080/09658211.2017.1282517</pub-id><pub-id pub-id-type="pmid">28276984</pub-id></mixed-citation></ref><ref id="B18"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dutton</surname><given-names>A.</given-names></name><name><surname>Carroll</surname><given-names>M.</given-names></name></person-group> (<year>2001</year>). <article-title>Eyewitness testimony: effects of source</article-title>. <source>Aust. J. Psychol.</source>
<volume>53</volume>, <fpage>83</fpage>&#x02013;<lpage>91</lpage>. <pub-id pub-id-type="doi">10.1080/00049530108255128</pub-id></mixed-citation></ref><ref id="B19"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Easterbrook</surname><given-names>J. A.</given-names></name></person-group> (<year>1959</year>). <article-title>The effect of emotion on cue utilization and the organization of behavior</article-title>. <source>Psychol. Rev.</source>
<volume>66</volume>, <fpage>183</fpage>&#x02013;<lpage>201</lpage>. <pub-id pub-id-type="doi">10.1037/H0047707</pub-id><pub-id pub-id-type="pmid">13658305</pub-id></mixed-citation></ref><ref id="B20"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>El Haj</surname><given-names>M.</given-names></name><name><surname>Kessels</surname><given-names>R. P. C.</given-names></name><name><surname>Allain</surname><given-names>P.</given-names></name></person-group> (<year>2016</year>). <article-title>Source memory rehabilitation: a review toward recommendations for setting up a strategy training aimed at the what, where, and when of episodic retrieval</article-title>. <source>Appl. Neuropsychol. Adult</source>
<volume>23</volume>, <fpage>53</fpage>&#x02013;<lpage>60</lpage>. <pub-id pub-id-type="doi">10.1080/23279095.2014.992071</pub-id><pub-id pub-id-type="pmid">25996602</pub-id></mixed-citation></ref><ref id="B21"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fan</surname><given-names>W.</given-names></name><name><surname>Zhong</surname><given-names>Y.</given-names></name><name><surname>Li</surname><given-names>J.</given-names></name><name><surname>Yang</surname><given-names>Z.</given-names></name><name><surname>Zhan</surname><given-names>Y.</given-names></name><name><surname>Cal</surname><given-names>R.</given-names></name><etal/></person-group>. (<year>2016</year>). <article-title>Negative emotion weakens the degree of self-reference effect: evidence from ERPs</article-title>. <source>Front. Psychol.</source>
<volume>7</volume>:<fpage>1408</fpage>. <pub-id pub-id-type="doi">10.3389/fpsyg.2016.01408</pub-id><pub-id pub-id-type="pmid">27733836</pub-id></mixed-citation></ref><ref id="B22"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Faul</surname><given-names>F.</given-names></name><name><surname>Erdfelder</surname><given-names>E.</given-names></name><name><surname>Lang</surname><given-names>A.</given-names></name><name><surname>Buchner</surname><given-names>A.</given-names></name></person-group> (<year>2007</year>). <article-title>G<sup>*</sup>Power 3: a flexible statistical power analysis program for the social, behavioral, and biomedical sciences</article-title>. <source>Behav. Res. Methods</source>
<volume>39</volume>, <fpage>175</fpage>&#x02013;<lpage>191</lpage>. <pub-id pub-id-type="doi">10.3758/BF03193146</pub-id><pub-id pub-id-type="pmid">17695343</pub-id></mixed-citation></ref><ref id="B23"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ferr&#x000e9;</surname><given-names>P.</given-names></name><name><surname>Comesa&#x000f1;a</surname><given-names>M.</given-names></name><name><surname>Guasch</surname><given-names>M.</given-names></name></person-group> (<year>2019</year>). <article-title>Emotional content and source memory for language: impairment in an incidental encoding task</article-title>. <source>Front. Psychol.</source>
<volume>10</volume>:<fpage>65</fpage>. <pub-id pub-id-type="doi">10.3389/fpsyg.2019.00065</pub-id><pub-id pub-id-type="pmid">30761039</pub-id></mixed-citation></ref><ref id="B24"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Flavell</surname><given-names>J. H.</given-names></name></person-group> (<year>1979</year>). <article-title>Metacognition and cognitive monitoring: a new area of cognitive-development inquiry</article-title>. <source>Am. Psychol.</source>
<volume>34</volume>, <fpage>906</fpage>&#x02013;<lpage>911</lpage>. <pub-id pub-id-type="doi">10.1037/0003-066X.34.10.906</pub-id></mixed-citation></ref><ref id="B25"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Galli</surname><given-names>G.</given-names></name><name><surname>Wolpe</surname><given-names>N.</given-names></name><name><surname>Otten</surname><given-names>L. J.</given-names></name></person-group> (<year>2011</year>). <article-title>Sex differences in the use of anticipatory brain activity to encode emotional events</article-title>. <source>J. Neurosci.</source>
<volume>31</volume>, <fpage>12364</fpage>&#x02013;<lpage>12370</lpage>. <pub-id pub-id-type="doi">10.1523/JNEUROSCI.1619-11.2011</pub-id><pub-id pub-id-type="pmid">21865478</pub-id></mixed-citation></ref><ref id="B26"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Glaser</surname><given-names>E.</given-names></name><name><surname>Mendrek</surname><given-names>A.</given-names></name><name><surname>Germain</surname><given-names>M.</given-names></name><name><surname>Lakis</surname><given-names>N.</given-names></name><name><surname>Lavoi</surname><given-names>M. E.</given-names></name></person-group> (<year>2012</year>). <article-title>Sex differences in memory of emotional images: a behavioral and electrophysiological investigation</article-title>. <source>Int. J. Psychophysiol.</source>
<volume>85</volume>, <fpage>17</fpage>&#x02013;<lpage>26</lpage>. <pub-id pub-id-type="doi">10.1016/j.ijpsycho.2012.01.007</pub-id><pub-id pub-id-type="pmid">22265718</pub-id></mixed-citation></ref><ref id="B27"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hamami</surname><given-names>A.</given-names></name><name><surname>Serbun</surname><given-names>S. J.</given-names></name><name><surname>Gutchess</surname><given-names>A. H.</given-names></name></person-group> (<year>2011</year>). <article-title>Self-Referencing enhances memory specificity with age</article-title>. <source>Psychol. Aging</source>
<volume>26</volume>, <fpage>636</fpage>&#x02013;<lpage>646</lpage>. <pub-id pub-id-type="doi">10.1038/jid.2014.371</pub-id><pub-id pub-id-type="pmid">21480719</pub-id></mixed-citation></ref><ref id="B28"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hamann</surname><given-names>S.</given-names></name></person-group> (<year>2001</year>). <article-title>Cognitive and neural mechanisms of emotional memory</article-title>. <source>Trends Cogn. Sci.</source>
<volume>5</volume>, <fpage>394</fpage>&#x02013;<lpage>400</lpage>. <pub-id pub-id-type="doi">10.1016/S1364-6613(00)01707-1</pub-id><pub-id pub-id-type="pmid">11520704</pub-id></mixed-citation></ref><ref id="B29"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hourihan</surname><given-names>K. L.</given-names></name><name><surname>Bursey</surname><given-names>E.</given-names></name></person-group> (<year>2017</year>). <article-title>A misleading feeling of happiness: metamemory for positive emotional and neutral pictures</article-title>. <source>Memory</source>
<volume>25</volume>, <fpage>35</fpage>&#x02013;<lpage>43</lpage>. <pub-id pub-id-type="doi">10.1080/09658211.2015.1122809</pub-id><pub-id pub-id-type="pmid">26673959</pub-id></mixed-citation></ref><ref id="B30"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hourihan</surname><given-names>K. L.</given-names></name><name><surname>Fraundorf</surname><given-names>S. H.</given-names></name><name><surname>Benjamin</surname><given-names>A. S.</given-names></name></person-group> (<year>2017</year>). <article-title>The influences of valence and arousal on judgments of learning and on recall</article-title>. <source>Mem. Cognit.</source>
<volume>45</volume>, <fpage>121</fpage>&#x02013;<lpage>136</lpage>. <pub-id pub-id-type="doi">10.3758/s,13421-016-0646-3</pub-id><pub-id pub-id-type="pmid">27527533</pub-id></mixed-citation></ref><ref id="B31"><mixed-citation publication-type="webpage"><person-group person-group-type="author"><collab>JASP Team</collab></person-group> (<year>2018</year>). <source>JASP (Version 0.9.0.1) [Computer software]</source>. Available online at: <ext-link ext-link-type="uri" xlink:href="https://jasp-stats.org">https://jasp-stats.org</ext-link> (accessed May 27, 2019).</mixed-citation></ref><ref id="B32"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Johnson</surname><given-names>M. K.</given-names></name><name><surname>Hashtroudi</surname><given-names>S.</given-names></name><name><surname>Lindsay</surname><given-names>D. S.</given-names></name></person-group> (<year>1993</year>). <article-title>Source monitoring</article-title>. <source>Psychol. Bull.</source>
<volume>114</volume>, <fpage>3</fpage>&#x02013;<lpage>28</lpage>. <pub-id pub-id-type="doi">10.1037/0033-2909.114.1.3</pub-id><pub-id pub-id-type="pmid">8346328</pub-id></mixed-citation></ref><ref id="B33"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Johnson</surname><given-names>M. K.</given-names></name><name><surname>Raye</surname><given-names>C. L.</given-names></name></person-group> (<year>1981</year>). <article-title>Reality monitoring</article-title>. <source>Psychol. Rev.</source>
<volume>88</volume>, <fpage>67</fpage>&#x02013;<lpage>85</lpage>. <pub-id pub-id-type="doi">10.1037/0033-295X.88.1.67</pub-id></mixed-citation></ref><ref id="B34"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>J&#x000f6;nsson</surname><given-names>F. U.</given-names></name><name><surname>Olsson</surname><given-names>H.</given-names></name><name><surname>Olsson</surname><given-names>M. J.</given-names></name></person-group> (<year>2005</year>). <article-title>Odor emotionality affects the confidence in odor naming</article-title>. <source>Chem. Senses</source>
<volume>30</volume>, <fpage>29</fpage>&#x02013;<lpage>35</lpage>. <pub-id pub-id-type="doi">10.1093/chemse/bjh254</pub-id><pub-id pub-id-type="pmid">15647462</pub-id></mixed-citation></ref><ref id="B35"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jurica</surname><given-names>P. J.</given-names></name><name><surname>Shimamura</surname><given-names>A. P.</given-names></name></person-group> (<year>1999</year>). <article-title>Monitoring item and source information: evidence for a negative generation effect in source memory</article-title>. <source>Mem. Cognit.</source>
<volume>27</volume>, <fpage>648</fpage>&#x02013;<lpage>656</lpage>. <pub-id pub-id-type="doi">10.3758/BF03211558</pub-id><pub-id pub-id-type="pmid">10479823</pub-id></mixed-citation></ref><ref id="B36"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kalenzaga</surname><given-names>S.</given-names></name><name><surname>Sperduti</surname><given-names>M.</given-names></name><name><surname>Anssens</surname><given-names>A.</given-names></name><name><surname>Martinelli</surname><given-names>P.</given-names></name><name><surname>Devauchelle</surname><given-names>A.</given-names></name><name><surname>Gallarda</surname><given-names>T.</given-names></name><etal/></person-group>. (<year>2015</year>). <article-title>Episodic memory and self-reference via semantic autobiographical memory: insights from an fMRI study in younger and older adults</article-title>. <source>Front. Behav. Neurosci.</source>
<volume>8</volume>:<fpage>449</fpage>. <pub-id pub-id-type="doi">10.3389/fnbeh.2014.00449</pub-id><pub-id pub-id-type="pmid">25628546</pub-id></mixed-citation></ref><ref id="B37"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kelly</surname><given-names>A.</given-names></name><name><surname>Carroll</surname><given-names>M.</given-names></name><name><surname>Mazzoni</surname><given-names>G.</given-names></name></person-group> (<year>2002</year>). <article-title>Metamemory and reality monitoring</article-title>. <source>Appl. Cogn. Psychol.</source>
<volume>16</volume>, <fpage>407</fpage>&#x02013;<lpage>428</lpage>. <pub-id pub-id-type="doi">10.1002/acp.803</pub-id></mixed-citation></ref><ref id="B38"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kensinger</surname><given-names>E. A.</given-names></name><name><surname>Corkin</surname><given-names>S.</given-names></name></person-group> (<year>2003</year>). <article-title>Memory enhancement for emotional words: are emotional words more vividly remembered than neutral words?</article-title>
<source>Mem. Cognit.</source>
<volume>31</volume>, <fpage>1169</fpage>&#x02013;<lpage>1180</lpage>. <pub-id pub-id-type="doi">10.3758/BF03195800</pub-id><pub-id pub-id-type="pmid">15058678</pub-id></mixed-citation></ref><ref id="B39"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kensinger</surname><given-names>E. A.</given-names></name><name><surname>Corkin</surname><given-names>S.</given-names></name></person-group> (<year>2004</year>). <article-title>Two routes to emotional memory: distinct neural processes for valence and arousal</article-title>. <source>Proc. Natl. Acad. Sci. U.S.A.</source>
<volume>101</volume>, <fpage>3310</fpage>&#x02013;<lpage>3315</lpage>. <pub-id pub-id-type="doi">10.1073/pnas.0306408101</pub-id><pub-id pub-id-type="pmid">14981255</pub-id></mixed-citation></ref><ref id="B41"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Kensinger</surname><given-names>E. A.</given-names></name><name><surname>Kark</surname><given-names>S. M.</given-names></name></person-group> (<year>2018</year>). <article-title>&#x0201c;Emotion and memory&#x0201d;</article-title> in <source>Stevens' Handbook of Experimental Psychology and Cognitive Neuroscience</source>. <edition>4th Edn</edition> eds E. J. Wagenmakers and J. T. Wixted (<publisher-loc>New York NY</publisher-loc>: <publisher-name>Wiley</publisher-name>, <fpage>1</fpage>&#x02013;<lpage>26</lpage>.</mixed-citation></ref><ref id="B42"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kensinger</surname><given-names>E. A.</given-names></name><name><surname>Schacter</surname><given-names>D. L.</given-names></name></person-group> (<year>2006a</year>). <article-title>Amygdala activity is associated with the successful encoding of item, but not source, information for positive and negative stimuli</article-title>. <source>J. Neurosci.</source>
<volume>26</volume>, <fpage>2564</fpage>&#x02013;<lpage>2570</lpage>. <pub-id pub-id-type="doi">10.1523/JNEUROSCI.5241-05.2006</pub-id><pub-id pub-id-type="pmid">16510734</pub-id></mixed-citation></ref><ref id="B43"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kensinger</surname><given-names>E. A.</given-names></name><name><surname>Schacter</surname><given-names>D. L.</given-names></name></person-group> (<year>2006b</year>). <article-title>Reality monitoring and memory distortion: effects of negative, arousing content</article-title>. <source>Mem. Cognit.</source>
<volume>34</volume>, <fpage>251</fpage>&#x02013;<lpage>260</lpage>. <pub-id pub-id-type="doi">10.3758/BF03193403</pub-id><pub-id pub-id-type="pmid">16752589</pub-id></mixed-citation></ref><ref id="B44"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Kensinger</surname><given-names>E. A.</given-names></name><name><surname>Schacter</surname><given-names>D. L.</given-names></name></person-group> (<year>2008</year>). <article-title>&#x0201c;Memory and emotion&#x0201d;</article-title> in <source>Handbook of emotions</source>. <edition>4th Edn</edition> eds L. F. Barrett, M. Lewis, and J. M. Haviland-Jones (<publisher-loc>New York NY</publisher-loc>: <publisher-name>Guilford</publisher-name>, <fpage>564</fpage>&#x02013;<lpage>578</lpage>.</mixed-citation></ref><ref id="B45"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Koenig</surname><given-names>S.</given-names></name><name><surname>Mecklinger</surname><given-names>A.</given-names></name></person-group> (<year>2008</year>). <article-title>Electrophysiological correlates of encoding and retrieving emotional events</article-title>. <source>Emotion</source>
<volume>8</volume>, <fpage>162</fpage>&#x02013;<lpage>173</lpage>. <pub-id pub-id-type="doi">10.1037/1528-3542.8.2.162</pub-id><pub-id pub-id-type="pmid">18410190</pub-id></mixed-citation></ref><ref id="B46"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Koriat</surname><given-names>A.</given-names></name></person-group> (<year>1997</year>). <article-title>Monitoring one's own knowledge during study: a cue-utilization approach to judgments of learning</article-title>. <source>J. Exp. Psychol. Gen.</source>
<volume>126</volume>, <fpage>349</fpage>&#x02013;<lpage>370</lpage>. <pub-id pub-id-type="doi">10.1037/0096-3445.126.4.349</pub-id></mixed-citation></ref><ref id="B47"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kuhlmann</surname><given-names>B. G.</given-names></name><name><surname>Touron</surname><given-names>D. R.</given-names></name></person-group> (<year>2012</year>). <article-title>Mediator-based encoding strategies in source monitoring in young and older adults</article-title>. <source>J. Exp. Psychol. Learn. Mem. Cogn.</source>
<volume>38</volume>, <fpage>1352</fpage>&#x02013;<lpage>1364</lpage>. <pub-id pub-id-type="doi">10.1037/a0027863</pub-id><pub-id pub-id-type="pmid">22545604</pub-id></mixed-citation></ref><ref id="B48"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kuhlmann</surname><given-names>B. G.</given-names></name><name><surname>Touron</surname><given-names>D. R.</given-names></name></person-group> (<year>2017</year>). <article-title>Relate it! Objective and subjective evaluation of mediator-based strategies for improving source memory in younger and older adults</article-title>. <source>Cortex</source>
<volume>91</volume>, <fpage>25</fpage>&#x02013;<lpage>39</lpage>. <pub-id pub-id-type="doi">10.1016/j.cortex.2016.11.015</pub-id><pub-id pub-id-type="pmid">28012550</pub-id></mixed-citation></ref><ref id="B49"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kuiper</surname><given-names>N. A.</given-names></name><name><surname>Rogers</surname><given-names>T. B.</given-names></name></person-group> (<year>1979</year>). <article-title>Encoding of personal information: self-other differences</article-title>. <source>J. Pers. Soc. Psychol.</source>
<volume>37</volume>, <fpage>499</fpage>&#x02013;<lpage>514</lpage>. <pub-id pub-id-type="doi">10.1037/0022-3514.37.4.499</pub-id></mixed-citation></ref><ref id="B50"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Le Bigot</surname><given-names>L.</given-names></name><name><surname>Knutsen</surname><given-names>D.</given-names></name><name><surname>Gil</surname><given-names>S.</given-names></name></person-group> (<year>2018</year>). <article-title>I remember emotional content better, but I'm struggling to remember who said it</article-title>. <source>Cognition</source>
<volume>180</volume>, <fpage>52</fpage>&#x02013;<lpage>58</lpage>. <pub-id pub-id-type="doi">10.1016/j.cognition.2018.07.001</pub-id><pub-id pub-id-type="pmid">29981968</pub-id></mixed-citation></ref><ref id="B51"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Leshikar</surname><given-names>E. D.</given-names></name><name><surname>Duarte</surname><given-names>A.</given-names></name></person-group> (<year>2012</year>). <article-title>Medial prefrontal cortex supports memory accuracy for self-referenced items</article-title>. <source>Soc. Neurosci.</source>
<volume>7</volume>, <fpage>126</fpage>&#x02013;<lpage>145</lpage>. <pub-id pub-id-type="doi">10.1080/17470919.2011.585242.Medial</pub-id><pub-id pub-id-type="pmid">21936739</pub-id></mixed-citation></ref><ref id="B52"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Leshikar</surname><given-names>E. D.</given-names></name><name><surname>Duarte</surname><given-names>A.</given-names></name></person-group> (<year>2014</year>). <article-title>Medial prefrontal cortex supports source memory for self-referenced materials in young and older adults</article-title>. <source>Cogn. Affect. Behav. Neurosci.</source>
<volume>14</volume>, <fpage>236</fpage>&#x02013;<lpage>252</lpage>. <pub-id pub-id-type="doi">10.3758/s13415-013-0198-y</pub-id><pub-id pub-id-type="pmid">23904335</pub-id></mixed-citation></ref><ref id="B53"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Leshikar</surname><given-names>E. D.</given-names></name><name><surname>Dulas</surname><given-names>M. R.</given-names></name><name><surname>Duarte</surname><given-names>A.</given-names></name></person-group> (<year>2015</year>). <article-title>Self-referencing enhances recollection in both young and older adults</article-title>. <source>Neuropsychol. Dev. Cogn. B Aging Neuropsychol. Cogn.</source>
<volume>22</volume>, <fpage>388</fpage>&#x02013;<lpage>412</lpage>. <pub-id pub-id-type="doi">10.1080/13825585.2014.957150.</pub-id><pub-id pub-id-type="pmid">25264018</pub-id></mixed-citation></ref><ref id="B54"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Levine</surname><given-names>L. J.</given-names></name><name><surname>Edelstein</surname><given-names>R. S.</given-names></name></person-group> (<year>2009</year>). <article-title>Emotion and memory narrowing: a review and goal-relevance approach</article-title>. <source>Cogn. Emot.</source>
<volume>23</volume>, <fpage>833</fpage>&#x02013;<lpage>875</lpage>. <pub-id pub-id-type="doi">10.1080/02699930902738863</pub-id></mixed-citation></ref><ref id="B55"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mackay</surname><given-names>D. G.</given-names></name><name><surname>Shafto</surname><given-names>M.</given-names></name><name><surname>Taylor</surname><given-names>J. K.</given-names></name><name><surname>Marian</surname><given-names>D. E.</given-names></name><name><surname>Abrams</surname><given-names>L.</given-names></name><name><surname>Dyer</surname><given-names>J. R.</given-names></name></person-group> (<year>2004</year>). <article-title>Relations between emotion, memory, and attention: evidence from taboo stroop, lexical decision, and immediate memory tasks</article-title>. <source>Mem. Cognit.</source>
<volume>32</volume>, <fpage>474</fpage>&#x02013;<lpage>488</lpage>. <pub-id pub-id-type="doi">10.3758/BF03195840</pub-id><pub-id pub-id-type="pmid">15285130</pub-id></mixed-citation></ref><ref id="B56"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>MacKenzie</surname><given-names>G.</given-names></name><name><surname>Powell</surname><given-names>T. F.</given-names></name><name><surname>Donaldson</surname><given-names>D. I.</given-names></name></person-group> (<year>2015</year>). <article-title>Positive emotion can protect against source memory impairment</article-title>. <source>Cogn. Emot.</source>
<volume>29</volume>, <fpage>236</fpage>&#x02013;<lpage>250</lpage>. <pub-id pub-id-type="doi">10.1080/02699931.2014.911145</pub-id><pub-id pub-id-type="pmid">24784151</pub-id></mixed-citation></ref><ref id="B57"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>MacLeod</surname><given-names>C. M.</given-names></name><name><surname>Gopie</surname><given-names>N.</given-names></name><name><surname>Hourihan</surname><given-names>K. L.</given-names></name><name><surname>Neary</surname><given-names>K. R.</given-names></name><name><surname>Ozubko</surname><given-names>J. D.</given-names></name></person-group> (<year>2010</year>). <article-title>The production effect: delineation of a phenomenon</article-title>. <source>J. Exp. Psychol. Learn. Mem. Cogn.</source>
<volume>36</volume>, <fpage>671</fpage>&#x02013;<lpage>685</lpage>. <pub-id pub-id-type="doi">10.1037/a0018785</pub-id><pub-id pub-id-type="pmid">20438265</pub-id></mixed-citation></ref><ref id="B58"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maddock</surname><given-names>R. J.</given-names></name><name><surname>Frein</surname><given-names>S. T.</given-names></name></person-group> (<year>2009</year>). <article-title>Reduced memory for the spatial and temporal context of unpleasant words</article-title>. <source>Cogn. Emot.</source>
<volume>23</volume>, <fpage>96</fpage>&#x02013;<lpage>117</lpage>. <pub-id pub-id-type="doi">10.1080/02699930801948977</pub-id></mixed-citation></ref><ref id="B59"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maddox</surname><given-names>G. B.</given-names></name><name><surname>Naveh-Benjamin</surname><given-names>M.</given-names></name><name><surname>Old</surname><given-names>S.</given-names></name><name><surname>Kilb</surname><given-names>A.</given-names></name></person-group> (<year>2012</year>). <article-title>The role of attention in the associative binding of emotionally arousing words</article-title>. <source>Psychon. Bull. Rev.</source>
<volume>19</volume>, <fpage>1128</fpage>&#x02013;<lpage>1134</lpage>. <pub-id pub-id-type="doi">10.3758/s13423-012-0315-x</pub-id><pub-id pub-id-type="pmid">23055140</pub-id></mixed-citation></ref><ref id="B60"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mao</surname><given-names>X.</given-names></name><name><surname>You</surname><given-names>Y.</given-names></name><name><surname>Li</surname><given-names>W.</given-names></name><name><surname>Guo</surname><given-names>C.</given-names></name></person-group> (<year>2015</year>). <article-title>Emotion impairs extrinsic source memory-an ERP study</article-title>. <source>Biol. Psychol.</source>
<volume>110</volume>, <fpage>182</fpage>&#x02013;<lpage>189</lpage>. <pub-id pub-id-type="doi">10.1016/j.biopsycho.2015.07.005</pub-id><pub-id pub-id-type="pmid">26213124</pub-id></mixed-citation></ref><ref id="B61"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mather</surname><given-names>M.</given-names></name></person-group> (<year>2007</year>). <article-title>Emotional arousal and memory binding: an object-based framework</article-title>. <source>Perspect. Psychol. Sci.</source>
<volume>2</volume>, <fpage>33</fpage>&#x02013;<lpage>52</lpage>. <pub-id pub-id-type="doi">10.1111/j.1745-6916.2007.00028.x</pub-id><pub-id pub-id-type="pmid">26151918</pub-id></mixed-citation></ref><ref id="B63"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mather</surname><given-names>M.</given-names></name><name><surname>Sutherland</surname><given-names>M. R.</given-names></name></person-group> (<year>2011</year>). <article-title>Arousal-biased competition in perception and memory</article-title>. <source>Perspect. Psychol. Sci.</source>
<volume>6</volume>, <fpage>114</fpage>&#x02013;<lpage>133</lpage>. <pub-id pub-id-type="doi">10.1177/1745691611400234</pub-id><pub-id pub-id-type="pmid">21660127</pub-id></mixed-citation></ref><ref id="B64"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mazzoni</surname><given-names>G.</given-names></name><name><surname>Nelson</surname><given-names>T. O.</given-names></name></person-group> (<year>1995</year>). <article-title>Judgments of learning are affected by the kind of encoding in ways that cannot be attributed to the level of recall</article-title>. <source>J. Exp. Psychol. Learn. Mem. Cogn.</source>
<volume>21</volume>, <fpage>1263</fpage>&#x02013;<lpage>1274</lpage>. <pub-id pub-id-type="doi">10.1037/0278-7393.21.5.1263</pub-id><pub-id pub-id-type="pmid">8744965</pub-id></mixed-citation></ref><ref id="B65"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McKague</surname><given-names>M.</given-names></name><name><surname>McAnally</surname><given-names>K. I.</given-names></name><name><surname>Skovron</surname><given-names>M.</given-names></name><name><surname>Bendall</surname><given-names>S.</given-names></name><name><surname>Jackson</surname><given-names>H. J.</given-names></name></person-group> (<year>2012</year>). <article-title>Source monitoring and proneness to auditory-verbal hallucinations: a signal detection analysis</article-title>. <source>Cogn. Neuropsychiatry</source>
<volume>17</volume>, <fpage>544</fpage>&#x02013;<lpage>562</lpage>. <pub-id pub-id-type="doi">10.1080/13546805.2012.676311</pub-id><pub-id pub-id-type="pmid">22571352</pub-id></mixed-citation></ref><ref id="B66"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mezulis</surname><given-names>A. H.</given-names></name><name><surname>Abramson</surname><given-names>L. Y.</given-names></name><name><surname>Hyde</surname><given-names>J. S.</given-names></name><name><surname>Hankin</surname><given-names>B. L.</given-names></name></person-group> (<year>2004</year>). <article-title>Is there a universal positivity bias in attributions? a meta-analytic review of individual, developmental, and cultural differences in the self-serving attributional bias</article-title>. <source>Psychol. Bull.</source>
<volume>130</volume>, <fpage>711</fpage>&#x02013;<lpage>747</lpage>. <pub-id pub-id-type="doi">10.1037/0033-2909.130.5.711</pub-id><pub-id pub-id-type="pmid">15367078</pub-id></mixed-citation></ref><ref id="B67"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mickley Steinmetz</surname><given-names>K. R.</given-names></name><name><surname>Schmidt</surname><given-names>K.</given-names></name><name><surname>Zucker</surname><given-names>H. R.</given-names></name><name><surname>Kensinger</surname><given-names>E. A.</given-names></name></person-group> (<year>2012</year>). <article-title>The effect of emotional arousal and retention delay on subsequent-memory effects</article-title>. <source>Cogn. Neurosci.</source>
<volume>3</volume>, <fpage>150</fpage>&#x02013;<lpage>159</lpage>. <pub-id pub-id-type="doi">10.1080/17588928.2012.677421</pub-id><pub-id pub-id-type="pmid">24171733</pub-id></mixed-citation></ref><ref id="B68"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mitchell</surname><given-names>K. J.</given-names></name><name><surname>Mather</surname><given-names>M.</given-names></name><name><surname>Johnson</surname><given-names>M. K.</given-names></name><name><surname>Raye</surname><given-names>C. L.</given-names></name><name><surname>Greene</surname><given-names>E. R.</given-names></name></person-group> (<year>2006</year>). <article-title>A functional magnetic resonance imaging investigation of short-term source and item memory for negative pictures</article-title>. <source>NeuroReport</source>
<volume>17</volume>, <fpage>1543</fpage>&#x02013;<lpage>1547</lpage>. <pub-id pub-id-type="doi">10.1097/01.wnr.0000234743.50442.e5</pub-id><pub-id pub-id-type="pmid">16957605</pub-id></mixed-citation></ref><ref id="B69"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Murphy</surname><given-names>N. A.</given-names></name><name><surname>Isaacowitz</surname><given-names>D. M.</given-names></name></person-group> (<year>2008</year>). <article-title>Preferences for emotional information in older and younger adults: a meta-analysis of memory and attention tasks</article-title>. <source>Psychol. Aging</source>
<volume>23</volume>, <fpage>263</fpage>&#x02013;<lpage>286</lpage>. <pub-id pub-id-type="doi">10.1037/0882-7974.23.2.263</pub-id><pub-id pub-id-type="pmid">18573002</pub-id></mixed-citation></ref><ref id="B70"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nashiro</surname><given-names>K.</given-names></name><name><surname>Mather</surname><given-names>M.</given-names></name></person-group> (<year>2011</year>). <article-title>How arousal affects younger and older adults' memory binding</article-title>. <source>Exp. Aging Res.</source>
<volume>37</volume>, <fpage>108</fpage>&#x02013;<lpage>128</lpage>. <pub-id pub-id-type="doi">10.1080/0361073X.2011.536746</pub-id><pub-id pub-id-type="pmid">21240821</pub-id></mixed-citation></ref><ref id="B71"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nelson</surname><given-names>T. O.</given-names></name><name><surname>Narens</surname><given-names>L.</given-names></name></person-group> (<year>1990</year>). <article-title>Metamemory: a theoretical framework and new findings</article-title>. <source>Psychol. Learn. Motiv.</source>
<volume>26</volume>, <fpage>125</fpage>&#x02013;<lpage>173</lpage>. <pub-id pub-id-type="doi">10.1016/S0079-7421(08)60053-5</pub-id></mixed-citation></ref><ref id="B72"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Newsome</surname><given-names>R. N.</given-names></name><name><surname>Dulas</surname><given-names>M. R.</given-names></name><name><surname>Duarte</surname><given-names>A.</given-names></name></person-group> (<year>2012</year>). <article-title>The effects of aging on emotion-induced modulations of source retrieval ERPs: evidence for valence biases</article-title>. <source>Neuropsychologia</source>
<volume>50</volume>, <fpage>3370</fpage>&#x02013;<lpage>3384</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2012.09.024</pub-id><pub-id pub-id-type="pmid">23017596</pub-id></mixed-citation></ref><ref id="B73"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nomi</surname><given-names>J. S.</given-names></name><name><surname>Rhodes</surname><given-names>M. G.</given-names></name><name><surname>Cleary</surname><given-names>A. M.</given-names></name></person-group> (<year>2013</year>). <article-title>Emotional facial expressions differentially influence predictions and performance for face recognition</article-title>. <source>Cogn. Emot.</source>
<volume>27</volume>, <fpage>141</fpage>&#x02013;<lpage>149</lpage>. <pub-id pub-id-type="doi">10.1080/02699931.2012.679917</pub-id><pub-id pub-id-type="pmid">22712473</pub-id></mixed-citation></ref><ref id="B74"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ochsner</surname><given-names>K. N.</given-names></name></person-group> (<year>2000</year>). <article-title>Are affective events richly recollected or simply familiar? the experience and process of recognizing feelings past</article-title>. <source>J. Exp. Psychol. Gen.</source>
<volume>129</volume>, <fpage>242</fpage>&#x02013;<lpage>261</lpage>. <pub-id pub-id-type="doi">10.1037//0096-3445.129.2.242</pub-id><pub-id pub-id-type="pmid">10868336</pub-id></mixed-citation></ref><ref id="B75"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ochsner</surname><given-names>K. N.</given-names></name><name><surname>Phelps</surname><given-names>E.</given-names></name></person-group> (<year>2007</year>). <article-title>Emerging perspectives on emotion&#x02013;cognition interactions</article-title>. <source>Trends Cogn. Sci.</source>
<volume>11</volume>, <fpage>317</fpage>&#x02013;<lpage>318</lpage>. <pub-id pub-id-type="doi">10.1016/j.tics.2007.06.008</pub-id><pub-id pub-id-type="pmid">17631410</pub-id></mixed-citation></ref><ref id="B76"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Okon-Singer</surname><given-names>H.</given-names></name><name><surname>Hendler</surname><given-names>T.</given-names></name><name><surname>Pessoa</surname><given-names>L.</given-names></name><name><surname>Shackman</surname><given-names>A. J.</given-names></name></person-group> (<year>2015</year>). <article-title>The neurobiology of emotion-cognition interactions: fundamental questions and strategies for future research</article-title>. <source>Front. Hum. Neurosci.</source>
<volume>9</volume>:<fpage>58</fpage>. <pub-id pub-id-type="doi">10.3389/fnhum.2015.00058</pub-id><pub-id pub-id-type="pmid">25774129</pub-id></mixed-citation></ref><ref id="B77"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Otani</surname><given-names>H.</given-names></name><name><surname>Jaffa</surname><given-names>M.</given-names></name><name><surname>Libkuman</surname><given-names>T. M.</given-names></name><name><surname>Goernert</surname><given-names>P. N.</given-names></name><name><surname>Kato</surname><given-names>K.</given-names></name></person-group> (<year>2012a</year>). <article-title>Does source memory impairment associated with emotionally arousing stimuli occur at encoding or retrieval?</article-title>
<source>J. Cogn. Psychol.</source>
<volume>24</volume>, <fpage>796</fpage>&#x02013;<lpage>801</lpage>. <pub-id pub-id-type="doi">10.1080/20445911.2012.693468</pub-id></mixed-citation></ref><ref id="B78"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Otani</surname><given-names>H.</given-names></name><name><surname>Libkuman</surname><given-names>T. M.</given-names></name><name><surname>Goernert</surname><given-names>P. N.</given-names></name><name><surname>Kato</surname><given-names>K.</given-names></name><name><surname>Migita</surname><given-names>M.</given-names></name><name><surname>Freehafer</surname><given-names>S. E.</given-names></name><etal/></person-group>. (<year>2012b</year>). <article-title>Emotion, directed forgetting, and source memory</article-title>. <source>Br. J. Psychol.</source>
<volume>103</volume>, <fpage>343</fpage>&#x02013;<lpage>358</lpage>. <pub-id pub-id-type="doi">10.1111/j.2044-8295.2011.02078.x</pub-id><pub-id pub-id-type="pmid">22804701</pub-id></mixed-citation></ref><ref id="B79"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ozubko</surname><given-names>J. D.</given-names></name><name><surname>MacLeod</surname><given-names>C. M.</given-names></name></person-group> (<year>2010</year>). <article-title>The production effect in memory: evidence that distinctiveness underlies the benefit</article-title>. <source>J. Exp. Psychol. Learn. Mem. Cogn.</source>
<volume>36</volume>, <fpage>1543</fpage>&#x02013;<lpage>1547</lpage>. <pub-id pub-id-type="doi">10.1037/a0020604</pub-id><pub-id pub-id-type="pmid">20804284</pub-id></mixed-citation></ref><ref id="B80"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ozubko</surname><given-names>J. D.</given-names></name><name><surname>Major</surname><given-names>J.</given-names></name><name><surname>MacLeod</surname><given-names>C. M.</given-names></name></person-group> (<year>2014</year>). <article-title>Remembered study mode: support for the distinctiveness account of the production effect</article-title>. <source>Memory</source>
<volume>22</volume>, <fpage>509</fpage>&#x02013;<lpage>524</lpage>. <pub-id pub-id-type="doi">10.1080/09658211.2013.800554</pub-id><pub-id pub-id-type="pmid">23713784</pub-id></mixed-citation></ref><ref id="B81"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Phelps</surname><given-names>E. A.</given-names></name><name><surname>LaBar</surname><given-names>K. S.</given-names></name><name><surname>Spencer</surname><given-names>D. D.</given-names></name></person-group> (<year>1997</year>). <article-title>Memory for emotional words following unilateral temporal lobectomy</article-title>. <source>Brain Cogn.</source>
<volume>35</volume>, <fpage>85</fpage>&#x02013;<lpage>109</lpage>. <pub-id pub-id-type="doi">10.1006/brcg.1997.0929</pub-id><pub-id pub-id-type="pmid">9339304</pub-id></mixed-citation></ref><ref id="B82"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Quinlan</surname><given-names>C. K.</given-names></name><name><surname>Taylor</surname><given-names>T. L.</given-names></name></person-group> (<year>2013</year>). <article-title>Enhancing the production effect in memory</article-title>. <source>Memory</source>
<volume>21</volume>, <fpage>904</fpage>&#x02013;<lpage>915</lpage>. <pub-id pub-id-type="doi">10.1080/09658211.2013.766754</pub-id><pub-id pub-id-type="pmid">23384885</pub-id></mixed-citation></ref><ref id="B83"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Quintana</surname><given-names>D. S.</given-names></name><name><surname>Williams</surname><given-names>D. R.</given-names></name></person-group> (<year>2018</year>). <article-title>Bayesian alternatives for common null hypothesis significance tests in psychiatry: a non-technical guide using JASP</article-title>. <source>BMC Psychiatry</source>
<volume>18</volume>:<fpage>178</fpage>. <pub-id pub-id-type="doi">10.1186/s12888-018-1761-4</pub-id><pub-id pub-id-type="pmid">29879931</pub-id></mixed-citation></ref><ref id="B84"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Raye</surname><given-names>C. L.</given-names></name><name><surname>Johnson</surname><given-names>M. K.</given-names></name></person-group> (<year>1980</year>). <article-title>Reality monitoring vs. discriminating between external sources of memories</article-title>. <source>Bull. Psychon. Soc.</source>
<volume>15</volume>, <fpage>405</fpage>&#x02013;<lpage>408</lpage>. <pub-id pub-id-type="doi">10.3758/BF03334572</pub-id></mixed-citation></ref><ref id="B85"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rimmele</surname><given-names>U.</given-names></name><name><surname>Davachi</surname><given-names>L.</given-names></name><name><surname>Petrov</surname><given-names>R.</given-names></name><name><surname>Dougal</surname><given-names>S.</given-names></name><name><surname>Phelps</surname><given-names>E. A.</given-names></name></person-group> (<year>2011</year>). <article-title>Emotion enhances the subjective feeling of remembering, despite lower accuracy for contextual details</article-title>. <source>Emotion</source>
<volume>11</volume>, <fpage>553</fpage>&#x02013;<lpage>562</lpage>. <pub-id pub-id-type="doi">10.1037/a0024246</pub-id><pub-id pub-id-type="pmid">21668106</pub-id></mixed-citation></ref><ref id="B86"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rimmele</surname><given-names>U.</given-names></name><name><surname>Davachi</surname><given-names>L.</given-names></name><name><surname>Phelps</surname><given-names>E. A.</given-names></name></person-group> (<year>2012</year>). <article-title>Memory for time and place contributes to enhanced confidence in memories for emotional events</article-title>. <source>Emotion</source>
<volume>12</volume>, <fpage>834</fpage>&#x02013;<lpage>846</lpage>. <pub-id pub-id-type="doi">10.1037/a0028003</pub-id><pub-id pub-id-type="pmid">22642353</pub-id></mixed-citation></ref><ref id="B87"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ritchey</surname><given-names>M.</given-names></name><name><surname>Dolcos</surname><given-names>F.</given-names></name><name><surname>Cabeza</surname><given-names>R.</given-names></name></person-group> (<year>2008</year>). <article-title>role of amygdala connectivity in the persistence of emotional memories over time: an event-related fMRI investigation</article-title>. <source>Cereb. Cortex</source>
<volume>18</volume>, <fpage>2494</fpage>&#x02013;<lpage>2504</lpage>. <pub-id pub-id-type="doi">10.1093/cercor/bhm262</pub-id><pub-id pub-id-type="pmid">18375529</pub-id></mixed-citation></ref><ref id="B88"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rogers</surname><given-names>T. B.</given-names></name><name><surname>Kuiper</surname><given-names>N. A.</given-names></name><name><surname>Kirker</surname><given-names>W. S.</given-names></name></person-group> (<year>1977</year>). <article-title>Self-reference and the encoding of personal information</article-title>. <source>J. Pers. Soc. Psychol.</source>
<volume>35</volume>, <fpage>677</fpage>&#x02013;<lpage>688</lpage>. <pub-id pub-id-type="doi">10.1037/0022-3514.35.9.677</pub-id><pub-id pub-id-type="pmid">909043</pub-id></mixed-citation></ref><ref id="B89"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rossi-Arnaud</surname><given-names>C.</given-names></name><name><surname>Spataro</surname><given-names>P.</given-names></name><name><surname>Costanzi</surname><given-names>M.</given-names></name><name><surname>Saraulli</surname><given-names>D.</given-names></name><name><surname>Cestari</surname><given-names>V.</given-names></name></person-group> (<year>2018</year>). <article-title>Divided attention enhances recognition of emotional stimuli: evidence from the attentional boost effect</article-title>. <source>Memory</source>
<volume>26</volume>, <fpage>42</fpage>&#x02013;<lpage>52</lpage>. <pub-id pub-id-type="doi">10.1080/09658211.2017.1319489</pub-id><pub-id pub-id-type="pmid">28436271</pub-id></mixed-citation></ref><ref id="B90"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schaefer</surname><given-names>A.</given-names></name><name><surname>Pottage</surname><given-names>C. L.</given-names></name><name><surname>Rickart</surname><given-names>A. J.</given-names></name></person-group> (<year>2011</year>). <article-title>Electrophysiological correlates of remembering emotional pictures</article-title>. <source>NeuroImage</source>
<volume>54</volume>, <fpage>714</fpage>&#x02013;<lpage>724</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2010.07.030</pub-id><pub-id pub-id-type="pmid">20650320</pub-id></mixed-citation></ref><ref id="B91"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schmidt</surname><given-names>K.</given-names></name><name><surname>Patnaik</surname><given-names>P.</given-names></name><name><surname>Kensinger</surname><given-names>E. A.</given-names></name></person-group> (<year>2011</year>). <article-title>Emotion's influence on memory for spatial and temporal context</article-title>. <source>Cogn. Emot.</source>
<volume>25</volume>, <fpage>229</fpage>&#x02013;<lpage>243</lpage>. <pub-id pub-id-type="doi">10.1080/02699931.2010.483123</pub-id><pub-id pub-id-type="pmid">21379376</pub-id></mixed-citation></ref><ref id="B92"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sch&#x000fc;mann</surname><given-names>D.</given-names></name><name><surname>Bayer</surname><given-names>J.</given-names></name><name><surname>Talmi</surname><given-names>D.</given-names></name><name><surname>Sommer</surname><given-names>T.</given-names></name></person-group> (<year>2018</year>). <article-title>Dissociation of immediate and delayed effects of emotional arousal on episodic memory</article-title>. <source>Neurobiol. Learn. Mem.</source>
<volume>148</volume>, <fpage>11</fpage>&#x02013;<lpage>19</lpage>. <pub-id pub-id-type="doi">10.1016/j.nlm.2017.12.007</pub-id><pub-id pub-id-type="pmid">29289675</pub-id></mixed-citation></ref><ref id="B93"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Serbun</surname><given-names>S. J.</given-names></name><name><surname>Shih</surname><given-names>J. Y.</given-names></name><name><surname>Gutchess</surname><given-names>A. H.</given-names></name></person-group> (<year>2011</year>). <article-title>Memory for details with self-referencing</article-title>. <source>Memory</source>
<volume>19</volume>, <fpage>1004</fpage>&#x02013;<lpage>1014</lpage>. <pub-id pub-id-type="doi">10.1080/09658211.2011.626429</pub-id><pub-id pub-id-type="pmid">22092106</pub-id></mixed-citation></ref><ref id="B94"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sharot</surname><given-names>T.</given-names></name><name><surname>Phelps</surname><given-names>E. A.</given-names></name></person-group> (<year>2004</year>). <article-title>How arousal modulated memory: disentangling the effects of attention and retention</article-title>. <source>Cogn. Affect. Behav. Neurosci.</source>
<volume>4</volume>, <fpage>294</fpage>&#x02013;<lpage>306</lpage>. <pub-id pub-id-type="doi">10.3758/CABN.4.3.294</pub-id><pub-id pub-id-type="pmid">15535165</pub-id></mixed-citation></ref><ref id="B95"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sharot</surname><given-names>T.</given-names></name><name><surname>Yonelinas</surname><given-names>A. P.</given-names></name></person-group> (<year>2008</year>). <article-title>Differential time-dependent effects of emotion on recollective experience and memory for contextual information</article-title>. <source>Cognition</source>
<volume>106</volume>, <fpage>538</fpage>&#x02013;<lpage>547</lpage>. <pub-id pub-id-type="doi">10.1016/j.cognition.2007.03.002</pub-id><pub-id pub-id-type="pmid">17451666</pub-id></mixed-citation></ref><ref id="B96"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Snodgrass</surname><given-names>J. G.</given-names></name><name><surname>Corwin</surname><given-names>J.</given-names></name></person-group> (<year>1988</year>). <article-title>Pragmatics of measuring recognition memory: applications to dementia and amnesia</article-title>. <source>J. Exp. Psychol. Gen.</source>
<volume>117</volume>, <fpage>34</fpage>&#x02013;<lpage>50</lpage>. <pub-id pub-id-type="doi">10.1037/0096-3445.117.1.34</pub-id><pub-id pub-id-type="pmid">2966230</pub-id></mixed-citation></ref><ref id="B97"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Soares</surname><given-names>A. P.</given-names></name><name><surname>Comesa&#x000f1;a</surname><given-names>M.</given-names></name><name><surname>Pinheiro</surname><given-names>A. P.</given-names></name><name><surname>Sim&#x000f5;es</surname><given-names>A.</given-names></name><name><surname>Frade</surname><given-names>C. S.</given-names></name></person-group> (<year>2012</year>). <article-title>The adaptation of the Affective Norms for English Words (ANEW) for European Portuguese</article-title>. <source>Behav. Res. Methods</source>
<volume>44</volume>, <fpage>256</fpage>&#x02013;<lpage>269</lpage>. <pub-id pub-id-type="doi">10.3758/s13428-011-0131-7</pub-id><pub-id pub-id-type="pmid">21751068</pub-id></mixed-citation></ref><ref id="B98"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Symons</surname><given-names>C. S.</given-names></name><name><surname>Johnson</surname><given-names>B. T.</given-names></name></person-group> (<year>1997</year>). <article-title>The self-reference effect in memory: a meta- analysis</article-title>. <source>Psychol. Bull.</source>
<volume>121</volume>, <fpage>371</fpage>&#x02013;<lpage>394</lpage>. <pub-id pub-id-type="doi">10.1037/0033-2909.121.3.371</pub-id><pub-id pub-id-type="pmid">9136641</pub-id></mixed-citation></ref><ref id="B99"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Talmi</surname><given-names>D.</given-names></name></person-group> (<year>2013</year>). <article-title>Enhanced emotional memory</article-title>. <source>Curr. Dir. Psychol. Sci.</source>
<volume>22</volume>, <fpage>430</fpage>&#x02013;<lpage>436</lpage>. <pub-id pub-id-type="doi">10.1177/0963721413498893</pub-id></mixed-citation></ref><ref id="B100"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tauber</surname><given-names>S. K.</given-names></name><name><surname>Dunlosky</surname><given-names>J.</given-names></name></person-group> (<year>2012</year>). <article-title>Can older adults accurately judge their learning of emotional information?</article-title>
<source>Psychol. Aging</source>
<volume>27</volume>, <fpage>924</fpage>&#x02013;<lpage>933</lpage>. <pub-id pub-id-type="doi">10.1037/a0028447</pub-id><pub-id pub-id-type="pmid">22663156</pub-id></mixed-citation></ref><ref id="B101"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tu</surname><given-names>H. W.</given-names></name><name><surname>Alty</surname><given-names>E. E.</given-names></name><name><surname>Diana</surname><given-names>R. A.</given-names></name></person-group> (<year>2017</year>). <article-title>Event-related potentials during encoding: comparing unitization to relational processing</article-title>. <source>Brain Res.</source>
<volume>1667</volume>, <fpage>46</fpage>&#x02013;<lpage>54</lpage>. <pub-id pub-id-type="doi">10.1016/j.brainres.2017.05.003</pub-id><pub-id pub-id-type="pmid">28495307</pub-id></mixed-citation></ref><ref id="B102"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tu</surname><given-names>H. W.</given-names></name><name><surname>Diana</surname><given-names>R. A.</given-names></name></person-group> (<year>2016</year>). <article-title>Two are not better than one: combining unitization and relational encoding strategies</article-title>. <source>J. Exp. Psychol. Learn. Mem. Cogn.</source>
<volume>42</volume>, <fpage>114</fpage>&#x02013;<lpage>126</lpage>. <pub-id pub-id-type="doi">10.1037/xlm0000170</pub-id><pub-id pub-id-type="pmid">26237616</pub-id></mixed-citation></ref><ref id="B103"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wagenmakers</surname><given-names>E.-J.</given-names></name><name><surname>Love</surname><given-names>J.</given-names></name><name><surname>Marsman</surname><given-names>M.</given-names></name><name><surname>Jamil</surname><given-names>T.</given-names></name><name><surname>Ly</surname><given-names>A.</given-names></name><name><surname>Verhagen</surname><given-names>J.</given-names></name><etal/></person-group>. (<year>2018a</year>). <article-title>Bayesian inference for psychology. Part II: example applications with JASP</article-title>. <source>Psychon. Bull. Rev.</source>
<volume>25</volume>, <fpage>58</fpage>&#x02013;<lpage>78</lpage>. <pub-id pub-id-type="doi">10.3758/s13423-017-1323-7</pub-id><pub-id pub-id-type="pmid">28685272</pub-id></mixed-citation></ref><ref id="B104"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wagenmakers</surname><given-names>E.-J.</given-names></name><name><surname>Marsman</surname><given-names>M.</given-names></name><name><surname>Jamil</surname><given-names>T.</given-names></name><name><surname>Ly</surname><given-names>A.</given-names></name><name><surname>Verhagen</surname><given-names>J.</given-names></name><name><surname>Love</surname><given-names>J.</given-names></name><etal/></person-group>. (<year>2018b</year>). <article-title>Bayesian inference for psychology. Part I: theoretical advantages and practical ramifications</article-title>. <source>Psychon. Bull. Rev.</source>
<volume>25</volume>, <fpage>35</fpage>&#x02013;<lpage>57</lpage>. <pub-id pub-id-type="doi">10.3758/s13423-017-1343-3</pub-id><pub-id pub-id-type="pmid">28779455</pub-id></mixed-citation></ref><ref id="B105"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>B.</given-names></name></person-group> (<year>2018</year>). <article-title>Retention interval modulates the effect of negative arousing pictures on recognition memory</article-title>. <source>Memory</source>
<volume>26</volume>, <fpage>1105</fpage>&#x02013;<lpage>1116</lpage>. <pub-id pub-id-type="doi">10.1080/09658211.2018.1427763</pub-id><pub-id pub-id-type="pmid">29357740</pub-id></mixed-citation></ref><ref id="B107"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>B.</given-names></name><name><surname>Fu</surname><given-names>X.</given-names></name></person-group> (<year>2011</year>). <article-title>Time course of effects of emotion on item memory and source memory for chinese words</article-title>. <source>Neurobiol. Learn. Mem.</source>
<volume>95</volume>, <fpage>415</fpage>&#x02013;<lpage>424</lpage>. <pub-id pub-id-type="doi">10.1016/j.nlm.2011.02.001</pub-id><pub-id pub-id-type="pmid">21315166</pub-id></mixed-citation></ref><ref id="B108"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Watson</surname><given-names>L. A.</given-names></name><name><surname>Dritschel</surname><given-names>B.</given-names></name><name><surname>Jentzsch</surname><given-names>I.</given-names></name><name><surname>Obonsawin</surname><given-names>M. C.</given-names></name></person-group> (<year>2008</year>). <article-title>Changes in the relationship between self-reference and emotional valence as a function of dysphoria</article-title>. <source>Br. J. Psychol.</source>
<volume>99</volume>, <fpage>143</fpage>&#x02013;<lpage>152</lpage>. <pub-id pub-id-type="doi">10.1348/000712607X248689</pub-id><pub-id pub-id-type="pmid">18230220</pub-id></mixed-citation></ref><ref id="B109"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wegesin</surname><given-names>D. J.</given-names></name><name><surname>Jacobs</surname><given-names>D. M.</given-names></name><name><surname>Zubin</surname><given-names>N. R.</given-names></name><name><surname>Ventura</surname><given-names>P. R.</given-names></name><name><surname>Stern</surname><given-names>Y.</given-names></name></person-group> (<year>2000</year>). <article-title>Source memory and encoding strategy in normal aging</article-title>. <source>J. Clin. Exp. Neuropsychol.</source>
<volume>22</volume>, <fpage>455</fpage>&#x02013;<lpage>464</lpage>. <pub-id pub-id-type="doi">10.1076/1380-3395(200008)22:4;1-0;FT455</pub-id><pub-id pub-id-type="pmid">10923055</pub-id></mixed-citation></ref><ref id="B110"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Weymar</surname><given-names>M.</given-names></name><name><surname>L&#x000f6;w</surname><given-names>A.</given-names></name><name><surname>Hamm</surname><given-names>A. O.</given-names></name></person-group> (<year>2011</year>). <article-title>Emotional memories are resilient to time: evidence from the parietal ERP old/new effect</article-title>. <source>Hum. Brain Mapp.</source>
<volume>32</volume>, <fpage>632</fpage>&#x02013;<lpage>640</lpage>. <pub-id pub-id-type="doi">10.1002/hbm.21051</pub-id><pub-id pub-id-type="pmid">21391253</pub-id></mixed-citation></ref><ref id="B111"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Weymar</surname><given-names>M.</given-names></name><name><surname>L&#x000f6;w</surname><given-names>A.</given-names></name><name><surname>Melzig</surname><given-names>C. A.</given-names></name><name><surname>Hamm</surname><given-names>A. O.</given-names></name></person-group> (<year>2009</year>). <article-title>Enhanced long-term recollection for emotional pictures: evidence from high-density ERPs</article-title>. <source>Psychophysiology</source>
<volume>46</volume>, <fpage>1200</fpage>&#x02013;<lpage>1207</lpage>. <pub-id pub-id-type="doi">10.1111/j.1469-8986.2009.00869.x</pub-id><pub-id pub-id-type="pmid">19674397</pub-id></mixed-citation></ref><ref id="B112"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wirkner</surname><given-names>J.</given-names></name><name><surname>Ventura-Bort</surname><given-names>C.</given-names></name><name><surname>Schulz</surname><given-names>P.</given-names></name><name><surname>Hamm</surname><given-names>A. O.</given-names></name><name><surname>Weymar</surname><given-names>M.</given-names></name></person-group> (<year>2018</year>). <article-title>Event-related potentials of emotional and neutral memories: the role of encoding position and delayed testing</article-title>. <source>Psychophysiology</source>
<volume>55</volume>:<fpage>e13069</fpage>. <pub-id pub-id-type="doi">10.1111/psyp.13069</pub-id><pub-id pub-id-type="pmid">29457220</pub-id></mixed-citation></ref><ref id="B113"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yang</surname><given-names>L.</given-names></name><name><surname>Truong</surname><given-names>L.</given-names></name><name><surname>Fuss</surname><given-names>S.</given-names></name><name><surname>Bislimovic</surname><given-names>S.</given-names></name></person-group> (<year>2012</year>). <article-title>The effects of ageing and divided attention on the self-reference effect in emotional memory: spontaneous or effortful mnemonic benefits?</article-title>
<source>Memory</source>
<volume>20</volume>, <fpage>596</fpage>&#x02013;<lpage>607</lpage>. <pub-id pub-id-type="doi">10.1080/09658211.2012.690040</pub-id><pub-id pub-id-type="pmid">22702397</pub-id></mixed-citation></ref><ref id="B114"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yick</surname><given-names>Y. Y.</given-names></name><name><surname>Buratto</surname><given-names>L. G.</given-names></name><name><surname>Schaefer</surname><given-names>A.</given-names></name></person-group> (<year>2015</year>). <article-title>The effects of negative emotion on encoding-related neural activity predicting item and source recognition</article-title>. <source>Neuropsychologia</source>
<volume>73</volume>, <fpage>48</fpage>&#x02013;<lpage>59</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2015.04.030</pub-id><pub-id pub-id-type="pmid">25936685</pub-id></mixed-citation></ref><ref id="B115"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yin</surname><given-names>Y.</given-names></name><name><surname>Ma</surname><given-names>Y.</given-names></name><name><surname>Xiaofeng</surname><given-names>X.</given-names></name><name><surname>Yang</surname><given-names>H.</given-names></name></person-group> (<year>2018</year>). <article-title>The effect of self-referencing on memory for different kinds of source information</article-title>. <source>Memory</source>
<volume>27</volume>:<fpage>519</fpage>&#x02013;<lpage>527</lpage>. <pub-id pub-id-type="doi">10.1080/09658211.2018.1532009</pub-id><pub-id pub-id-type="pmid">30295154</pub-id></mixed-citation></ref><ref id="B116"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yonelinas</surname><given-names>A. P.</given-names></name><name><surname>Ritchey</surname><given-names>M.</given-names></name></person-group> (<year>2015</year>). <article-title>The slow forgetting of emotional episodic memories: an emotional binding account</article-title>. <source>Trends Cogn. Sci.</source>
<volume>19</volume>, <fpage>259</fpage>&#x02013;<lpage>267</lpage>. <pub-id pub-id-type="doi">10.1016/j.tics.2015.02.009</pub-id><pub-id pub-id-type="pmid">25836045</pub-id></mixed-citation></ref><ref id="B117"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>Y.</given-names></name><name><surname>Pan</surname><given-names>Z.</given-names></name><name><surname>Li</surname><given-names>K.</given-names></name><name><surname>Guo</surname><given-names>Y.</given-names></name></person-group> (<year>2018</year>). <article-title>Self-serving bias in memories: selectively forgetting the connection between negative information and the self</article-title>. <source>Exp. Psychol.</source>
<volume>65</volume>, <fpage>236</fpage>&#x02013;<lpage>244</lpage>. <pub-id pub-id-type="doi">10.1027/1618-3169/a000409</pub-id><pub-id pub-id-type="pmid">30165808</pub-id></mixed-citation></ref><ref id="B118"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zimmerman</surname><given-names>C. A.</given-names></name><name><surname>Kelley</surname><given-names>C. M.</given-names></name></person-group> (<year>2010</year>). <article-title>&#x0201c;I'll remember this!&#x0201d; effects of emotionality on memory predictions versus memory performance</article-title>. <source>J. Mem. Lang.</source>
<volume>62</volume>, <fpage>240</fpage>&#x02013;<lpage>253</lpage>. <pub-id pub-id-type="doi">10.1016/j.jml.2009.11.004</pub-id></mixed-citation></ref></ref-list></back></article>