
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="data-paper"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">Data Brief</journal-id><journal-id journal-id-type="iso-abbrev">Data Brief</journal-id><journal-title-group><journal-title>Data in Brief</journal-title></journal-title-group><issn pub-type="epub">2352-3409</issn><publisher><publisher-name>Elsevier</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">32984464</article-id><article-id pub-id-type="pmc">7494477</article-id><article-id pub-id-type="publisher-id">S2352-3409(20)31162-8</article-id><article-id pub-id-type="doi">10.1016/j.dib.2020.106268</article-id><article-id pub-id-type="publisher-id">106268</article-id><article-categories><subj-group subj-group-type="heading"><subject>Data Article</subject></subj-group></article-categories><title-group><article-title>MYNursingHome: A fully-labelled image dataset for indoor object classification.</article-title></title-group><contrib-group><contrib contrib-type="author" id="au0001"><name><surname>Ismail</surname><given-names>Asmida</given-names></name><email>asmida@ftv.upsi.edu.my</email><xref rid="aff0001" ref-type="aff">a</xref><xref rid="aff0003" ref-type="aff">c</xref><xref rid="cor0001" ref-type="corresp">&#x0204e;</xref></contrib><contrib contrib-type="author" id="au0002"><name><surname>Ahmad</surname><given-names>Siti Anom</given-names></name><email>sanom@upm.edu.my</email><xref rid="aff0001" ref-type="aff">a</xref><xref rid="aff0004" ref-type="aff">d</xref><xref rid="cor0001" ref-type="corresp">&#x0204e;</xref></contrib><contrib contrib-type="author" id="au0003"><name><surname>Che Soh</surname><given-names>Azura</given-names></name><xref rid="aff0001" ref-type="aff">a</xref></contrib><contrib contrib-type="author" id="au0004"><name><surname>Hassan</surname><given-names>Mohd Khair</given-names></name><xref rid="aff0001" ref-type="aff">a</xref></contrib><contrib contrib-type="author" id="au0005"><name><surname>Harith</surname><given-names>Hazreen Haizi</given-names></name><xref rid="aff0002" ref-type="aff">b</xref></contrib><aff id="aff0001"><label>a</label>Department of Electrical and Electronic Engineering, Faculty of Engineering, Universiti Putra Malaysia, Serdang 43400, Malaysia</aff><aff id="aff0002"><label>b</label>Department of Biological and Agricultural Engineering, Faculty of Engineering, Universiti Putra Malaysia, Serdang 43400, Malaysia</aff><aff id="aff0003"><label>c</label>Department of Engineering &#x00026; Technology, Faculty of Technical &#x00026; Vocational, Universiti Pendidikan Sultan Idris, Tanjung Malim 35900, Malaysia</aff><aff id="aff0004"><label>d</label>Malaysian Research Institute on Ageing (MyAgeing&#x02122;), Universiti Putra Malaysia, Serdang 43400, Malaysia</aff></contrib-group><author-notes><corresp id="cor0001"><label>&#x0204e;</label>Corresponding authors. <email>asmida@ftv.upsi.edu.my</email><email>sanom@upm.edu.my</email></corresp></author-notes><pub-date pub-type="pmc-release"><day>03</day><month>9</month><year>2020</year></pub-date><!-- PMC Release delay is 0 months and 0 days and was based on <pub-date
						pub-type="epub">.--><pub-date pub-type="collection"><month>10</month><year>2020</year></pub-date><pub-date pub-type="epub"><day>03</day><month>9</month><year>2020</year></pub-date><volume>32</volume><elocation-id>106268</elocation-id><history><date date-type="received"><day>17</day><month>7</month><year>2020</year></date><date date-type="rev-recd"><day>19</day><month>8</month><year>2020</year></date><date date-type="accepted"><day>28</day><month>8</month><year>2020</year></date></history><permissions><copyright-statement>&#x000a9; 2020 The Authors</copyright-statement><copyright-year>2020</copyright-year><license license-type="CC BY" xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).</license-p></license></permissions><abstract id="abs0001"><p>A fully labelled image dataset serves as a valuable tool for reproducible research inquiries and data processing in various computational areas, such as machine learning, computer vision, artificial intelligence and deep learning. Today's research on ageing is intended to increase awareness on research results and their applications to assist public and private sectors in selecting the right equipments for the elderlies. Many researches related to development of support devices and care equipment had been done to improve the elderly's quality of life. Indoor object detection and classification for autonomous systems require large annotated indoor images for training and testing of smart computer vision applications. This dataset entitled MYNursingHome is an image dataset for commonly used objects surrounding the elderlies in their home cares. Researchers may use this data to build up a recognition aid for the elderlies. This dataset was collected from several nursing homes in Malaysia comprises 37,500 digital images from 25 different indoor object categories including basket bin, bed, bench, cabinet and others.</p></abstract><kwd-group id="keys0001"><title>Keywords</title><kwd>Image dataset</kwd><kwd>Indoor objects</kwd><kwd>Deep learning</kwd><kwd>Object detection</kwd><kwd>Object classification</kwd></kwd-group></article-meta></front><body><sec id="sec0001a"><title>Specifications Table</title><p id="para0001"><table-wrap position="float" id="utbl0001"><table frame="hsides" rules="groups"><tbody><tr><td valign="top">Subject</td><td valign="top">Electrical and Electronic Engineering</td></tr><tr><td valign="top">Specific subject area</td><td valign="top">Image processing, Image identification, Image classification, object detection, computer vision, artificial intelligence, deep learning</td></tr><tr><td valign="top">Type of data</td><td valign="top">Image</td></tr><tr><td valign="top">How data were acquired</td><td valign="top">Images captured using a single camera.</td></tr><tr><td valign="top">Data format</td><td valign="top">JPG, Raw</td></tr><tr><td valign="top">Parameters for data collection</td><td valign="top">Original data were collected by capturing videos of indoor objects commonly used by elderlies.</td></tr><tr><td valign="top">Description of data collection</td><td valign="top">The data is manually collected with the help of elderly home care management staff. Images are manually cropped to remove any background or surrounding objects during the learning process.</td></tr><tr><td valign="top">Data source location</td><td valign="top">Darul Hanan, Lot 2965, Mukim 6, Pongsu Seribu 13200 Kepala Batas, Pulau Pinang.<break/>Bait Al-Mawaddah, Lot 140452 Jalan Tanjung Pahang, Lorong Haji Mughani, Jalan Kebun Tambahan, Seksyen 30, 40460 Shah Alam, Selangor.</td></tr><tr><td valign="top">Data accessibility</td><td valign="top">Dataset can be accessible at Mendeley data: <break/><ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.17632/fpctx3svzd.1" id="interref0001">http://dx.doi.org/10.17632/fpctx3svzd.1</ext-link></td></tr></tbody></table></table-wrap></p></sec><sec id="sec0001"><title>Value of the Data</title><p id="para9001"><list list-type="simple" id="celist0002"><list-item id="celistitem0002"><label>&#x02022;</label><p id="para0003">MYNursingHome dataset can be used to develop indoor object detection system and navigation assist device for the elderlies. Current indoor datasets mainly focus on scenes and common objects in workplace or house. MYNursingHome dataset focus is on objects in elderly living institutions&#x02019; surrounding.</p></list-item><list-item id="celistitem0003"><label>&#x02022;</label><p id="para0004">MYNursingHome dataset could be a useful resource for researchers in the fields of computer vision, deep learning and advanced image classification community. It can be used to test and compare different computer visions and image processing classifiers in detecting different objects based on their visual features. The proposed dataset is original and can be adopted in designing the perception system for an autonomous robot, humanoid robot or mobility assistive devices. These can facilitate researchers to develop support devices for elderlies with vision constraint and disabilities in healthcare.</p></list-item><list-item id="celistitem0004"><label>&#x02022;</label><p id="para0005">MYNursingHome dataset presented in this paper is a ready-to-use database that can directly be used in the field of computer vision to develop new algorithms that can be easily integrated with many other applications.</p></list-item><list-item id="celistitem0005"><label>&#x02022;</label><p id="para0006">MYNursingHome dataset will be used in the autonomous platform perception system inside the elderlies home care in Malaysia.&#x000a0; The objects presented in this dataset are primarily focused for the elderly use but at the same time it can also benefit general public especially the disabled and visually impaired personnel.</p></list-item></list></p></sec><sec id="sec0002"><label>1</label><title>Data Description</title><p id="para0007">MyNursingHome is a fully labelled image dataset collected from several elderly home care centers in Malaysia to supplement the widespread use of image for a variety of computer processing areas such as classification, recognition, segmentation and detection. In general, the elderly suffers from various problems and disorders such as, memory difficulty, short sightedness and dementia. Most of them are unable to manage their daily routine on their own because of these problems. Intelligent assistive system for indoor object detection and recognition is required to encourage these people to move independently.</p><p id="para0008">There are some related works on elderly object recognition assist system that used standard benchmark dataset to identify objects. In <xref rid="bib0001" ref-type="bibr">[1]</xref> the authors present an indoor object recognition system to classify different indoor objects in order to improve the life quality of the elderlies. The datasets used for these experiments consist of 347 images of eight different indoor objects. In <xref rid="bib0002" ref-type="bibr">[2]</xref>, the authors proposed scene recognition and indoor object detection system using MIT 67 indoor dataset and 15 scene datasets. Authors in <xref rid="bib0003" ref-type="bibr">[3]</xref> proposed a rough understanding of surrounding objects for people with visual impairment, including the elderly, applied to indoor spaces. The dataset was manually built at two different indoor spaces with 130 images for every 15 object classes. However, those small datasets can affect the robustness and efficiency of the system development.</p><p id="para0009">MYNursingHome is very practical as the dataset contains 37,500 digital images from 25 different indoor object categories commonly found in the elderly's home care centers, including basket bin, bed, bench, cabinet, call bell, cane stick, chair, door, electric socket, fan, fire extinguisher, handrail, human being, rack, refrigerator, shower, sink, sofa, table, television, toilet seat, walker, wardrobe, water dispenser and wheelchair. <xref rid="fig0001" ref-type="fig">Fig.&#x000a0;1</xref> presents sample images from the object categories covered by MYNursingHome dataset. These various objects&#x02019; pictures were captured in various positions and angles.&#x000a0; To cater for numerous data variations, the original images were randomly rotated and modified using augmentation process through simple geometric transformation. <xref rid="fig0002" ref-type="fig">Fig.&#x000a0;2</xref> shows one of the objects in the dataset at different orientations after going through augmentation process. There are many potential applications of this dataset in the development of combined computer vision and machine learning algorithms to assist people with visual impairment during mobility, especially in unfamiliar surroundings such as clinics, hospitals and other public areas.<fig id="fig0001"><label>Fig. 1</label><caption><p>Some of the images and categories in MYNursingHome dataset.</p></caption><alt-text id="alt0001">Fig. 1</alt-text><graphic xlink:href="gr1"/></fig><fig id="fig0002"><label>Fig. 2</label><caption><p>Example of an object in MYNursingHome dataset at different orientations.</p></caption><alt-text id="alt0002">Fig. 2</alt-text><graphic xlink:href="gr2"/></fig></p></sec><sec id="sec0003"><label>2</label><title>Experimental Design, Materials, and Methods</title><sec id="sec0004"><label>2.1</label><title>Camera specification</title><p id="para0010">The dataset is gathered using iPhone XS Max main camera.&#x000a0; The dual rear camera lens has 12-megapixel, wide-angle sensor with an f/1.8 aperture and f/2.4 in telephoto, optical image stabilization and 1.4&#x0202f;nm pixel size.&#x000a0;These pixels are much larger and deeper, allowing for more light into the sensor and both rear sensors has OIS feature. Videos captured by this camera has 2160p@24/30/60fps, 1080p@30/60/120/240fps, HDR, stereo sound recording. RGB colour range is chosen for each of these images in the JPG combination.</p></sec><sec id="sec0005"><label>2.2</label><title>Building dataset</title><p id="para0011"><xref rid="fig0003" ref-type="fig">Fig.&#x000a0;3</xref> shows the processes involved in developing a dataset. The videos captured during data collection were processed in real time. After which, the recorded video will be converted into an image using a program that saves frames from a video file to JPG image series. In this conversion process, the image was captured from the video at 3&#x0202f;s/frame. There are some processes that needed to be carried out before the data can be analysed. The first process is filtering out small images. This process is needed to ensure that the images have certain threshold that helps omit super low-quality images. After filtering small images, the next process is data cleaning that filters the data by removing unwanted images for it to be easier to explore, understand and model the images. After cleaning process, the images need to be split into group/classes according to their categories. MYNursingHome consists of 25 classes with 1500 images per class where there are duplicate image from the same class randomly modified using augmentation process. The images were labelled and connected together where images should be called in order or sequence according to its class. For each class, the number of images should approximately be standardized as per the number of images per class.<fig id="fig0003"><label>Fig. 3</label><caption><p>Process flow diagram in developing a dataset.</p></caption><alt-text id="alt0003">Fig. 3</alt-text><graphic xlink:href="gr3"/></fig></p></sec></sec><sec sec-type="COI-statement"><title>Declaration of Competing Interest</title><p id="p0045a">None.</p></sec></body><back><ref-list id="cebibl1"><title>References</title><ref id="bib0001"><label>1</label><element-citation publication-type="journal" id="sbref0001"><person-group person-group-type="author"><name><surname>Elhariri</surname><given-names>E.</given-names></name><name><surname>El-Bendary</surname><given-names>N.</given-names></name><name><surname>Hassanien</surname><given-names>A.E.</given-names></name><name><surname>Snasel</surname><given-names>V.</given-names></name></person-group><article-title>An assistive object recognition system for enhancing seniors quality of life</article-title><source>Procedia Comput. Sci.</source><volume>65</volume><issue>Iccmit</issue><year>2015</year><fpage>691</fpage><lpage>700</lpage><pub-id pub-id-type="doi">10.1016/j.procs.2015.09.013</pub-id></element-citation></ref><ref id="bib0002"><label>2</label><element-citation publication-type="journal" id="sbref0002"><person-group person-group-type="author"><name><surname>Afif</surname><given-names>M.</given-names></name><name><surname>Ayachi</surname><given-names>R.</given-names></name><name><surname>Said</surname><given-names>Y.</given-names></name><name><surname>Atri</surname><given-names>M.</given-names></name></person-group><article-title>Deep learning based application for indoor scene recognition</article-title><source>Neural Process. Lett.</source><volume>51</volume><issue>3</issue><year>2020</year><fpage>2827</fpage><lpage>2837</lpage><pub-id pub-id-type="doi">10.1007/s11063-020-10231-w</pub-id></element-citation></ref><ref id="bib0003"><label>3</label><element-citation publication-type="journal" id="sbref0003"><person-group person-group-type="author"><name><surname>Malek</surname><given-names>S.</given-names></name><name><surname>Melgani</surname><given-names>F.</given-names></name><name><surname>Mekhalfi</surname><given-names>M.L.</given-names></name><name><surname>Bazi</surname><given-names>Y.</given-names></name></person-group><article-title>Real-time indoor scene description for the visually impaired using autoencoder fusion strategies with visible cameras</article-title><source>Sensors (Switzerland)</source><volume>17</volume><issue>11</issue><year>2017</year><pub-id pub-id-type="doi">10.3390/s17112641</pub-id></element-citation></ref></ref-list><sec id="sec0008" sec-type="supplementary-material"><label>Appendix</label><title>Supplementary materials</title><p id="para0012a"><supplementary-material content-type="local-data" id="ecom0001"><media xlink:href="mmc1.xml"><alt-text>Image, application 1</alt-text></media></supplementary-material></p></sec><ack id="ack0001"><title>Acknowledgments</title><p>The authors would like to express their deep gratitude towards Malaysia Social Welfare Department and Lembaga Zakat Selangor especially Darul Hanan and Bait Al-Mawaddah for allowing us to collect data from MYNursingHome at their care centre. Special thanks to Control and Signal Processing group Faculty of Engineering University Putra Malaysia for their support and encouragement during this research. This research is supported by Putra Graduate Initiative (IPS) UPM grant project code GP-IPS/2018/9606100.</p></ack><fn-group><fn id="sec0007" fn-type="supplementary-material"><p id="para0001a">Supplementary material associated with this article can be found, in the online version, at doi:<ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.dib.2020.106268" id="interref0002">10.1016/j.dib.2020.106268</ext-link>.</p></fn></fn-group></back></article>