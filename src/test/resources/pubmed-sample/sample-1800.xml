
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">BMC Bioinformatics</journal-id><journal-id journal-id-type="iso-abbrev">BMC Bioinformatics</journal-id><journal-title-group><journal-title>BMC Bioinformatics</journal-title></journal-title-group><issn pub-type="epub">1471-2105</issn><publisher><publisher-name>BioMed Central</publisher-name><publisher-loc>London</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">31703611</article-id><article-id pub-id-type="pmc">6842142</article-id><article-id pub-id-type="publisher-id">3169</article-id><article-id pub-id-type="doi">10.1186/s12859-019-3169-7</article-id><article-categories><subj-group subj-group-type="heading"><subject>Software</subject></subj-group></article-categories><title-group><article-title>Recommendations for performance optimizations when using GATK3.8 and GATK4</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Heldenbrand</surname><given-names>Jacob R</given-names></name><address><email>jacobrh@illinois.edu</email></address><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author"><name><surname>Baheti</surname><given-names>Saurabh</given-names></name><address><email>Baheti.Saurabh@mayo.edu</email></address><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author"><name><surname>Bockol</surname><given-names>Matthew A</given-names></name><address><email>Bockol.Matthew@mayo.edu</email></address><xref ref-type="aff" rid="Aff3">3</xref></contrib><contrib contrib-type="author"><name><surname>Drucker</surname><given-names>Travis M</given-names></name><address><email>Drucker.Travis@mayo.edu</email></address><xref ref-type="aff" rid="Aff3">3</xref></contrib><contrib contrib-type="author"><name><surname>Hart</surname><given-names>Steven N</given-names></name><address><email>Hart.Steven@mayo.edu</email></address><xref ref-type="aff" rid="Aff4">4</xref></contrib><contrib contrib-type="author"><name><surname>Hudson</surname><given-names>Matthew E</given-names></name><address><email>mhudson@illinois.edu</email></address><xref ref-type="aff" rid="Aff5">5</xref><xref ref-type="aff" rid="Aff9">9</xref></contrib><contrib contrib-type="author"><name><surname>Iyer</surname><given-names>Ravishankar K</given-names></name><address><email>rkiyer@illinois.edu</email></address><xref ref-type="aff" rid="Aff6">6</xref></contrib><contrib contrib-type="author"><name><surname>Kalmbach</surname><given-names>Michael T</given-names></name><address><email>Kalmbach.Michael@mayo.edu</email></address><xref ref-type="aff" rid="Aff3">3</xref></contrib><contrib contrib-type="author"><name><surname>Kendig</surname><given-names>Katherine I</given-names></name><address><email>kkendig2@illinois.edu</email></address><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author"><name><surname>Klee</surname><given-names>Eric W</given-names></name><address><email>Klee.Eric@mayo.edu</email></address><xref ref-type="aff" rid="Aff4">4</xref></contrib><contrib contrib-type="author"><name><surname>Mattson</surname><given-names>Nathan R</given-names></name><address><email>mattson.nathan@mayo.edu</email></address><xref ref-type="aff" rid="Aff3">3</xref></contrib><contrib contrib-type="author"><name><surname>Wieben</surname><given-names>Eric D</given-names></name><address><email>Wieben.Eric@mayo.edu</email></address><xref ref-type="aff" rid="Aff7">7</xref></contrib><contrib contrib-type="author"><name><surname>Wiepert</surname><given-names>Mathieu</given-names></name><address><email>Wiepert.Mathieu@mayo.edu</email></address><xref ref-type="aff" rid="Aff3">3</xref></contrib><contrib contrib-type="author"><name><surname>Wildman</surname><given-names>Derek E</given-names></name><address><email>wildman@illinois.edu</email></address><xref ref-type="aff" rid="Aff8">8</xref><xref ref-type="aff" rid="Aff9">9</xref></contrib><contrib contrib-type="author" corresp="yes"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-7121-0214</contrib-id><name><surname>Mainzer</surname><given-names>Liudmila S</given-names></name><address><email>lmainzer@illinois.edu</email></address><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff9">9</xref></contrib><aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0000 9934 8971</institution-id><institution-id institution-id-type="GRID">grid.505692.d</institution-id><institution>National Center for Supercomputing Applications, University of Illinois at Urbana-Champaign, </institution></institution-wrap>1205 W. Clark St., Urbana, IL, USA </aff><aff id="Aff2"><label>2</label>Mayo Clinic, Department of Research Services, 200 1st St. SW, Rochester, MN, USA </aff><aff id="Aff3"><label>3</label>Mayo Clinic, Department of IT Executive Administration, 200 1st St. SW, Rochester, MN, USA </aff><aff id="Aff4"><label>4</label>Mayo Clinic, Department of Health Sciences Research, 200 1st St. SW, Rochester, MN, USA </aff><aff id="Aff5"><label>5</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0004 1936 9991</institution-id><institution-id institution-id-type="GRID">grid.35403.31</institution-id><institution>Department of Crop Sciences, University of Illinois at Urbana-Champaign, </institution></institution-wrap>1102 S. Goodwin Ave., Urbana, IL, USA </aff><aff id="Aff6"><label>6</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0004 1936 9991</institution-id><institution-id institution-id-type="GRID">grid.35403.31</institution-id><institution>Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign, </institution></institution-wrap>306 N. Wright St., Urbana, IL, USA </aff><aff id="Aff7"><label>7</label>Mayo Clinic, Department of Biochemistry and Molecular Biology, 200 1st St. SW, Rochester, MN, USA </aff><aff id="Aff8"><label>8</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0004 1936 9991</institution-id><institution-id institution-id-type="GRID">grid.35403.31</institution-id><institution>Department of Molecular and Integrative Physiology, University of Illinois at Urbana-Champaign, </institution></institution-wrap>407 S. Goodwin Ave., Urbana, IL, USA </aff><aff id="Aff9"><label>9</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0004 1936 9991</institution-id><institution-id institution-id-type="GRID">grid.35403.31</institution-id><institution>Institute for Genomic Biology, University of Illinois at Urbana-Champaign, </institution></institution-wrap>1206 W Gregory Dr., Urbana, IL, USA </aff></contrib-group><pub-date pub-type="epub"><day>8</day><month>11</month><year>2019</year></pub-date><pub-date pub-type="pmc-release"><day>8</day><month>11</month><year>2019</year></pub-date><pub-date pub-type="collection"><year>2019</year></pub-date><volume>20</volume><elocation-id>557</elocation-id><history><date date-type="received"><day>25</day><month>3</month><year>2019</year></date><date date-type="accepted"><day>22</day><month>10</month><year>2019</year></date></history><permissions><copyright-statement>&#x000a9; The Author(s) 2019</copyright-statement><license license-type="OpenAccess"><license-p>, corrected publication 2019 <bold>Open Access</bold> This article is distributed under the terms of the Creative Commons Attribution 4.0 International License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted use, distribution, and reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver(<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated.</license-p></license></permissions><abstract id="Abs1"><sec><title>Background</title><p id="Par1">Use of the Genome Analysis Toolkit (GATK) continues to be the standard practice in genomic variant calling in both research and the clinic. Recently the toolkit has been rapidly evolving. Significant computational performance improvements have been introduced in GATK3.8 through collaboration with Intel in 2017. The first release of GATK4 in early 2018 revealed rewrites in the code base, as the stepping stone toward a Spark implementation. As the software continues to be a moving target for optimal deployment in highly productive environments, we present a detailed analysis of these improvements, to help the community stay abreast with changes in performance.</p></sec><sec><title>Results</title><p id="Par2">We re-evaluated multiple options, such as threading, parallel garbage collection, I/O options and data-level parallelization. Additionally, we considered the trade-offs of using GATK3.8 and GATK4. We found optimized parameter values that reduce the time of executing the best practices variant calling procedure by 29.3% for GATK3.8 and 16.9% for GATK4. Further speedups can be accomplished by splitting data for parallel analysis, resulting in run time of only a few hours on whole human genome sequenced to the depth of 20X, for both versions of GATK. Nonetheless, GATK4 is already much more cost-effective than GATK3.8. Thanks to significant rewrites of the algorithms, the same analysis can be run largely in a single-threaded fashion, allowing users to process multiple samples on the same CPU.</p></sec><sec><title>Conclusions</title><p id="Par3">In time-sensitive situations, when a patient has a critical or rapidly developing condition, it is useful to minimize the time to process a single sample. In such cases we recommend using GATK3.8 by splitting the sample into chunks and computing across multiple nodes. The resultant walltime will be nnn.4 hours at the cost of $41.60 on 4 c5.18xlarge instances of Amazon Cloud. For cost-effectiveness of routine analyses or for large population studies, it is useful to maximize the number of samples processed per unit time. Thus we recommend GATK4, running multiple samples on one node. The total walltime will be &#x0223c;34.1 hours on 40 samples, with 1.18 samples processed per hour at the cost of $2.60 per sample on c5.18xlarge instance of Amazon Cloud.</p></sec></abstract><kwd-group xml:lang="en"><title>Keywords</title><kwd>GATK</kwd><kwd>Genomic variant calling</kwd><kwd>Best practices</kwd><kwd>Computational performance</kwd><kwd>Cluster computing</kwd><kwd>Parallelization</kwd></kwd-group><custom-meta-group><custom-meta><meta-name>issue-copyright-statement</meta-name><meta-value>&#x000a9; The Author(s) 2019</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="Sec1"><title>Background</title><p>The evolution of sequencing technologies [<xref ref-type="bibr" rid="CR1">1</xref>, <xref ref-type="bibr" rid="CR2">2</xref>] encouraged many applications of Whole Genome Sequencing (WGS) and Whole Exome Sequencing (WES) in genomic research and the clinic [<xref ref-type="bibr" rid="CR3">3</xref>, <xref ref-type="bibr" rid="CR4">4</xref>]. One of these applications is genomic variant calling, commonly performed using the Genome Analysis Toolkit (GATK), maintained by the Broad Institute [<xref ref-type="bibr" rid="CR5">5</xref>&#x02013;<xref ref-type="bibr" rid="CR8">8</xref>]. As sequencing machines become faster and cheaper [<xref ref-type="bibr" rid="CR9">9</xref>], analysis must speed up as well. Yet variant calling analysis using GATK still takes many hours, or even days, on deeply sequenced samples [<xref ref-type="bibr" rid="CR10">10</xref>&#x02013;<xref ref-type="bibr" rid="CR13">13</xref>]. A number of proprietary solutions have emerged in response to this over the last five years, such as Isaac [<xref ref-type="bibr" rid="CR14">14</xref>], Sentieon&#x02019;s DNASeq [<xref ref-type="bibr" rid="CR15">15</xref>, <xref ref-type="bibr" rid="CR16">16</xref>], Genalice [<xref ref-type="bibr" rid="CR17">17</xref>] and Dragen [<xref ref-type="bibr" rid="CR18">18</xref>]. However, they are either closed-source or do not follow the GATK Best Practices [<xref ref-type="bibr" rid="CR7">7</xref>, <xref ref-type="bibr" rid="CR8">8</xref>]. Accelerating the GATK open-source code itself is of tremendous interest to the bioinformatics community, for the sake of reproducibility and openness of biomedical research. To this end the Broad Institute partnered with Intel to introduce computational performance optimizations [<xref ref-type="bibr" rid="CR19">19</xref>&#x02013;<xref ref-type="bibr" rid="CR21">21</xref>]. GATK3.8 is the latest release of the "traditional" Java-based GATK designed to work on regular servers or compute clusters, and was announced to contain significant computational performance improvements through the collaboration with Intel [<xref ref-type="bibr" rid="CR22">22</xref>].</p><p>In addition to optimizations of the traditional variant calling algorithms [<xref ref-type="bibr" rid="CR10">10</xref>&#x02013;<xref ref-type="bibr" rid="CR13">13</xref>], the community also has been calling for a variant calling toolkit that can take advantage of dedicated MapReduce platforms, as Hadoop [<xref ref-type="bibr" rid="CR23">23</xref>] and especially Spark [<xref ref-type="bibr" rid="CR24">24</xref>&#x02013;<xref ref-type="bibr" rid="CR26">26</xref>] are more appropriate for this type of genomic data analysis compared to traditional high performance computing (HPC). Thus GATK4, first officially released in January of 2018, is meant to be eventually deployed on data analytics platforms. At present it contains both Spark and non-Spark implementations of many of the tools and is thus still runnable in traditional HPC clusters. Yet even the non-Spark implementation has been significantly rewritten relatively to the GATK3.x versions, to improve maintainability and speed.</p><p>How do these changes affect the deployment practices of GATK-based variant calling workflows in production clinical and research settings, and what are the optimal patterns of deployment? We are the first to have performed a detailed scalability analysis of these new GATK versions to ascertain the advertised speedup. Based on those results we have developed appropriate sample-based parallelization techniques and deployment recommendations for the end users. Because most of the Spark tools were still in beta at the time of the initial release, we focused our testing on the non-Spark implementations.</p><p>When optimizing a workflow, one can perform two distinct optimizations, and we explore them both:</p><p><bold>maximizing speed</bold> to minimize the time to process a single sample; useful in time-critical situations, i.e. when a patient has a critical or rapidly developing condition;</p><p><bold>maximizing throughput</bold> to maximize the number of samples processed per unit time; cost-effective for routine analyses or large population studies.</p><p>Overall we did find that both GATK versions yield an impressive walltime &#x0003c;4 hours (excluding alignment) on a 20X WGS human data, with appropriate sample-level parallelization.</p></sec><sec id="Sec2"><title>Implementation</title><p>We implemented a battery of benchmarkingscripts to perform the testing of GATK3.8 and GATK4 tools, as described below.</p><sec id="Sec3"><title>Software versions</title><p>GATK3.8 was downloaded from the Broad Institute&#x02019;s softwaredownloadpage , build GATK-3.8-0-ge9d806836. Picard version 2.17.4 and GATK4.0.1.2 were downloaded from GitHub as pre-compiled jar files.</p></sec><sec id="Sec4"><title>Tools</title><p>Our benchmarking focused on the GATK Best Practices [<xref ref-type="bibr" rid="CR7">7</xref>, <xref ref-type="bibr" rid="CR8">8</xref>] starting from the duplicate marking stage through variant calling. The MarkDuplicates tool is not part of GATK3 and was called from a separate toolkit, Picard. MarkDuplicates is included directly into GATK4. Realignment is no longer recommended, and was not tested. The base recalibration process consists of two tools, BaseRecalibrator and PrintReads(GATK3.8)/ApplyBQSR(GATK4). The final tool we benchmarked was HaplotypeCaller, which is common to both versions of GATK.</p></sec><sec id="Sec5"><title>Data</title><p>A dataset corresponding to whole genome sequencing (WGS) performed on NA12878 [<xref ref-type="bibr" rid="CR27">27</xref>, <xref ref-type="bibr" rid="CR28">28</xref>] to &#x0223c;20X depth was downloaded from Illumina BaseSpace on Dec 16, 2016. The paired-ended, 126 nt reads were aligned with BWA MEM [<xref ref-type="bibr" rid="CR29">29</xref>] against the hg38 human reference (Oct 2017 GATK Bundle) and sorted with Novosort [<xref ref-type="bibr" rid="CR30">30</xref>] prior to benchmarking. Some settings required multiple tests and measurements; in those cases we only used the reads that mapped to chromosome 21. For known sites, dbSNP build 146 was used.</p></sec><sec id="Sec6"><title>Hardware</title><p>All tests were conducted on Skylake Xeon Gold 6148 processors with 40 cores, 2.40 GHz. Each node had 192 GB, 2666 MHz RAM. The nodes were stateless, connected to a network-attached IBM GPFS ver. 4.2.1 with custom metadata acceleration. The cluster used EDR InfiniBand with 100 Gb/sec bandwidth, 100 ns latency. Nodes ran Red Hat Enterprise Linux 6.9.</p></sec></sec><sec id="Sec7" sec-type="results"><title>Results</title><sec id="Sec8"><title>GATK3.8 tool-level thread scalability</title><p>Threading is one way of implementing parallelization to speed up a program. Data-level parallelization is frequently used in bioinformatics, by subdividing the input data into smaller chunks that can be worked on in parallel by the threads. It is useful to know how well a program scales with thread count: ideally the run time should decrease proportionately to the number of threads used on the data The non-Spark GATK4 version is entirely single-threaded, except for the PairHMM portion of HaplotypeCaller (&#x0201c;<xref rid="Sec11" ref-type="sec">PairHMM scalability in GATK4 haplotypeCaller</xref>&#x0201d; section below). Picard&#x02019;s MarkDuplicates is also single-threaded. Thus, our thread scalability testing focused on the GATK3.8 tools, which utilizes user-level options (-nct and -nt) to control how many computer cores should be engaged by the program, and how many threads one should deploy per core. We measured the walltime for each tool when invoked with a certain thread count, in the range from 1 to 40. We kept nt at 1 and modified nct, aiming to engage multiple cores on our nodes and varying the number of software threads running on the multi-core CPU. When reporting one thread for HaplotypeCaller, we mean that one thread of each type was used. We tracked the number of cores engaged and the number of threads spawned via the linux top command.</p><p>The tools respond differently to multithreading, and all show suboptimal scalability: run time decreases less than the increase factor of the thread count. Both BaseRecalibrator and HaplotypeCaller experience a 5-fold speedup compared to a single-threaded run when using 16 threads, but do not scale beyond that (Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref>a). PrintReads gains an initial improvement with 3 threads (the apparent optimum for our dataset), and experiences degraded performance at higher thread counts (Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref>b).
<fig id="Fig1"><label>Fig. 1</label><caption><p>GATK3.8 Thread Scalability. <bold>a</bold> Scalability of BaseRecalibrator, PrintReads and HaplotypeCaller. Sample: NA12878 WGS. Fold change refers to the fold difference in walltime between the new measurement when compared to the performance with a single thread ((<italic>newtime</italic>&#x02212;<italic>baselinetime</italic>)/<italic>baselinetime</italic>). <bold>b</bold> Scalability of PrintReads, in more detail. Normally walltime should decrease with thread count, as the computation is performed in parallel by multiple threads. However, in the case of PrintReads the opposite is observed. The increasing walltime as a function of thread count therefore signifies poor scalability and explains the decreasing trend for PrintReads line on panel (a). Sample: NA12878 chr 21. Error bars denote 1 SD around the mean of three replicates</p></caption><graphic xlink:href="12859_2019_3169_Fig1_HTML" id="MO1"/></fig></p><p>Suboptimal scalability can occur for a variety of reasons. In the I/O-heavy bioinformatics applications, which frequently have to repeatedly grab data from disk, do work in RAM, then write back to disk, the performance usually degrades due to disk access latency, network latency in communicating to the filesystem, and thread contention for RAM bandwidth. Thus, requesting many threads is not optimal for the GATK3.8 tools, and one has to balance the number of tools running per-node vs. the number of threads requested per-tool, to ensure full node utilization without degraded performance. Performance gains could be achieved by using internal SSDs on the compute nodes, thus avoiding the network and spinning disk access issues during the computation.</p></sec><sec id="Sec9"><title>GATK4 parallel garbage collection</title><p>Garbage Collection in JAVA is a mechanism to automatically remove from memory the variables and objects that are no longer useful or necessary for computation. This frees the developer from the need to worry about manually destroying those objects in the code, thus reducing the code base and eliminating the possibility of &#x0201d;forgetting&#x0201d; to do this, which otherwise could result in out-of-memory errors. This is a very useful feature in JAVA, and worth paying attention to when optimizing runtime performance in GATK, which is JAVA-based code. A previous study [<xref ref-type="bibr" rid="CR10">10</xref>] found that enabling Java parallel garbage collector (PGC) with up to 32 threads improved the walltime of GATK3.7. We explored this effect in the GATK4 tools.</p><p>The flags enabling PGC are passed to the GATK4 launch script via the &#x0201c;&#x02013;java-options&#x0201d; flag:</p><p>
<graphic position="anchor" xlink:href="12859_2019_3169_Figa_HTML" id="MO7"/>
</p><p>We found that enabling PGC for either ApplyBQSR or HaplotypeCaller had no impact or even degraded performance, depending on the number of threads used (data not shown). However, in MarkDuplicates using 2-4 PGC threads provided optimal performance (Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2</xref>a). For BaseRecalibrator, there is much more variability that we could not link to the state of the cluster (Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2</xref>b). The optimal thread choice appears to be around 24 threads, but the high walltimes at thread counts close to 24 suggest that it may be more reliable for end users to 1) perform a similar thread count sweep on one&#x02019;s own system to find the optimum, or 2) leave parallel garbage collection off to avoid one of the sub-optimal thread counts.
<fig id="Fig2"><label>Fig. 2</label><caption><p>GATK4 thread scalability for Java parallel garbage collection. Sample: NA12878 WGS. The measurements at 1 PGC thread represent the default, meaning that PGC is not enabled. Error bars denote SD around the mean of three replicates. <bold>a</bold> MarkDuplicates. <bold>b</bold> BaseRecalibrator</p></caption><graphic xlink:href="12859_2019_3169_Fig2_HTML" id="MO2"/></fig></p><p>We took a cursory look at PGC scalability in GATK3.8 and did not find significant improvements. In Picard&#x02019;s MarkDuplicates, the optimum lies at approximately 2 PGC threads.</p><p>It is not clear why GATK4 performance could not be improved by using PGC multithreading to the same extent as has been reported for GATK3.7, except that perhaps GATK4 code was still relatively fresh at the time of our testing, and further improvements would have been made later. We recommend users to run a cursory PGC thread scalability analysis on their systems to establish how GATK4 tools behave on their specific hardware. The extra human time spent doing this could buy substantial walltime and therefore financial savings, if the facility must provide high-throughput analysis of large volumes of genomic data on a continuous basis.</p></sec><sec id="Sec10"><title>Asynchronous i/O in GATK 4</title><p>GATK4 has two types of asynchronous read/write options: Samtools I/O and Tribble I/O. &#x0201c;Tribble&#x0201d; is a specialized data format, mainly used for index files. To enable asynchronous I/O, one must edit the following variables in a gatk-properties file, located at src/main/resources/org/broadinstitute/hellbender/utils/config/GATKConfig.properties in the GATK GitHub repository:</p><p>
<graphic position="anchor" xlink:href="12859_2019_3169_Figb_HTML" id="MO8"/>
</p><p>Each of these variables can be either &#x0201c;true&#x0201d; or &#x0201c;false&#x0201d;. The properties file is passed to GATK with the &#x0201c;&#x02013;gatk-config-file&#x0201d; flag. Because GATK4 MarkDuplicates is just a port of Picard&#x02019;s tool of the same name, it does not accept a configuration file. We ran HaplotypeCaller with a single thread for this series of tests.</p><p>We found it best to enable asynchronous I/O for Samtools reading and writing and disable it for Tribble I/O (Table&#x000a0;<xref rid="Tab1" ref-type="table">1</xref>).
<table-wrap id="Tab1"><label>Table 1</label><caption><p>Effects of asynchronous I/O settings on walltime (hours) in GATK4</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"/><th align="left" colspan="3">Async I/O activated?</th></tr></thead><tbody><tr><td align="left">Tool Name</td><td align="left">no</td><td align="left">all</td><td align="left">only for samtools I/O</td></tr><tr><td align="left">BaseRecalibrator</td><td align="left">4.07</td><td align="left">2.95</td><td align="left">2.88</td></tr><tr><td align="left">ApplyBQSR</td><td align="left">2.38</td><td align="left">2.07</td><td align="left">2.08</td></tr><tr><td align="left">HaplotypeCaller</td><td align="left">17.25</td><td align="left">17.31</td><td align="left">17.08</td></tr></tbody></table><table-wrap-foot><p>Sample: NA12878 WGS.</p></table-wrap-foot></table-wrap></p></sec><sec id="Sec11"><title>PairHMM scalability in GATK4 haplotypeCaller</title><p>Intel partnered up with the Broad Institute to create the Genomics Kernel Library (GKL), which includes key optimizations to the HaplotypeCaller algorithm. The library introduces AVX optimized versions of the PairHMM and Smith-Waterman algorithms. Additionally, OpenMP support was added to the PairHMM algorithm to enable multithreading. While the library was developed to be used in GATK4, the AVX capabilities were back propagated to GATK3.8 as well.</p><p>The pre-built GATK4 that we downloaded from the repository was already configured to automatically detect hardware support for AVX. On our Skylake architecture, AVX-512 was utilized automatically.</p><p>The multi-threaded implementation of the PairHMM algorithm can be enabled with the following flags:</p><p>
<graphic position="anchor" xlink:href="12859_2019_3169_Figc_HTML" id="MO9"/>
</p><p>and</p><p>
<graphic position="anchor" xlink:href="12859_2019_3169_Figd_HTML" id="MO10"/>
</p><p>The optimum for GATK4 HaplotypeCaller seems to be around 10 threads (Fig.&#x000a0;<xref rid="Fig3" ref-type="fig">3</xref>).
<fig id="Fig3"><label>Fig. 3</label><caption><p>GATK4 thread scalability in HaplotypeCaller. Sample: NA12878 chr21. Error bars denote 1 SD around the mean of three replicates</p></caption><graphic xlink:href="12859_2019_3169_Fig3_HTML" id="MO3"/></fig></p></sec><sec id="Sec12"><title>Splitting by chromosome</title><p>To achieve the greatest speedup, it is often efficient to split data by chromosome and process each interval in parallel. Here, we split the aligned sorted BAM into varying numbers of roughly equal-size chunks (Table&#x000a0;<xref rid="Tab2" ref-type="table">2</xref>) by using the GATK interval flag (-L) to observe how splitting affected walltime. The chunks were either kept on the same node for maximal utilization of cores (&#x0201c;within-node&#x0201d; parallelization) or spilled to more nodes for even shorter walltime (&#x0201c;across-node&#x0201d; parallelization).
<table-wrap id="Tab2"><label>Table 2</label><caption><p>Splitting the genome by chromosomes</p></caption><graphic position="anchor" xlink:href="12859_2019_3169_Tab1_HTML" id="MO11"/><table-wrap-foot><p>Horizontal lines segregate the chunks. Numbers indicate the total number of nucleotides in each resultant chunk of data.</p></table-wrap-foot></table-wrap></p><p>The previously discussed optimizations were applied in these experiments for both GATK3.8 and GATK4. For &#x0201c;within-node splitting,&#x0201d; we strove to optimally fill up our 40-core Skylake nodes by adjusting optimization parameters based on the number of chunks being processed in parallel within the node. For example, in GATK3.8 the optimal thread count for a tool may be around 10 threads, but we set the thread count for each chunk to 3 when the input is split into 12 chunks, while keeping all computations on the same node. Parallel garbage collection degrades the performance of BaseRecalibrator at lower thread counts and was therefore not used in the splitting experiments. Parallel GC was used with MarkDuplicates, but with only 2 threads, as that was optimal.</p><p><bold>GATK3.8 results</bold>
</p><p>For within-node parallelization beyond three chunks, the benefit of splitting the data begins to be counteracted by the degradation in performance caused by decreasing the thread count of each tool (Fig.&#x000a0;<xref rid="Fig4" ref-type="fig">4</xref>a). Thus it makes sense to spread execution over multiple nodes. We tested processing 6 chunks on 2 nodes, and 12 chunks on 4 nodes - thus keeping to 3 chunks per node (Fig.&#x000a0;<xref rid="Fig4" ref-type="fig">4</xref>b). This further reduced the total walltime, although perhaps at a higher compute cost.
<fig id="Fig4"><label>Fig. 4</label><caption><p>Effects of data-level parallelization in GATK3.8. Sample: NA12878 WGS. The &#x0201c;Baseline&#x0201d; was a naive approach where we gave each tool 40 threads (1 thread per core). The &#x0201c;Baseline Optimized&#x0201d; gave each tool 40 threads, except for PrintReads, which utilized 3 threads. MarkDuplicates and BaseRecalibrator were given 2 and 20 parallel garbage collection threads, respectively. &#x0201c;Split 2,&#x0201d; &#x0201c;Split 3,&#x0201d; etc. means that the aligned sorted BAM was split into 2, 3, etc. chunks, as shown in Table&#x000a0;<xref rid="Tab2" ref-type="table">2</xref>. Panel (<bold>a</bold>) shows experiments with chunks computing on the same node. In panel (<bold>b</bold>) computation was spread across nodes in groups of 3 chunks per node</p></caption><graphic xlink:href="12859_2019_3169_Fig4_HTML" id="MO4"/></fig></p><p><bold>GATK4 results</bold>
</p><p>Splitting the aligned sorted BAM into chunks is simple in GATK4, as the only multithreaded tool is HaplotypeCaller. We again split into 2, 3, 6, and 16 chunks, which were kept on the same node, and the PairHMM thread count for HaplotypeCaller was adjusted accordingly (Fig.&#x000a0;<xref rid="Fig5" ref-type="fig">5</xref>). In contrast to the results we observed for GATK3.8, the walltime keeps improving when splitting all the way down to 16 chunks.
<fig id="Fig5"><label>Fig. 5</label><caption><p>Effects of data-level parallelization in GATK 4. All compute was kept within the same node. Sample: NA12878 WGS. &#x0201c;Split 2,&#x0201d; &#x0201c;Split 3,&#x0201d; etc. means that the aligned sorted BAM was split into 2, 3, etc. chunks, as shown in Table&#x000a0;<xref rid="Tab2" ref-type="table">2</xref></p></caption><graphic xlink:href="12859_2019_3169_Fig5_HTML" id="MO5"/></fig></p></sec><sec id="Sec13"><title>Throughput</title><p>When optimizing throughput, one is maximizing the number of samples processed per unit time, albeit at the cost of higher walltime per sample. Because GATK4 is at present single-threaded by design, it lends itself extremely well to this kind of optimization. We created 40 copies of the NA12878 aligned sorted BAM file and processed them in parallel on a single 40-core node (Fig.&#x000a0;<xref rid="Fig6" ref-type="fig">6</xref>). The overall walltime does increase as one adds more samples to a node, probably due to contention for memory access and possibly disk I/O. However, the overall throughput increases substantially up until around 20 samples per node. Placing more than 20 samples on a 40-core Skylake node is probably not cost-effective.
<fig id="Fig6"><label>Fig. 6</label><caption><p>GATK4 throughput testing. Total walltime was benchmarked while running multiple samples simultaneously on the same node. As more samples are placed on the node, the threads given to HaplotypeCaller were reduced accordingly. Sample: NA12878 WGS. <bold>a</bold> Total walltime for running a batch of many samples on the same node. <bold>b</bold> Number of samples effectively processed per hour</p></caption><graphic xlink:href="12859_2019_3169_Fig6_HTML" id="MO6"/></fig></p></sec></sec><sec id="Sec14" sec-type="discussion"><title>Discussion</title><p>The tested optimizations intended to speed up computation in individual GATK tools are summarized in Table&#x000a0;<xref rid="Tab3" ref-type="table">3</xref>. When applied together, these optimizations significantly reduce the walltime on NA12878 WGS 20X (no splitting by chromosome). In GATK3.8 the MarkDuplicates &#x02192; BaseRecalibrator &#x02192; PrintReads &#x02192; HaplotypeCaller walltime went from 21.7 hours down to 15.3 hours (29.3% improvement). In GATK4 the MarkDuplicates &#x02192; BaseRecalibrator &#x02192; ApplyBQSR &#x02192; HaplotypeCaller walltime went from 24.9 hours to 20.7 hours (16.9% improvement). Note that the walltime is fairly comparable between the two GATK versions despite the single-threaded nature of GATK4, highlighting the performance optimizations introduced into that new release due to complete rewrite of many portions of the code.
<table-wrap id="Tab3"><label>Table 3</label><caption><p>Summary of optimized parameter values</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Tool name</th><th align="left" colspan="2">GATK3.8</th><th align="left" colspan="3">GATK4</th></tr></thead><tbody><tr><td align="left"/><td align="left">PGC</td><td align="left">Tool threads</td><td align="left">PGC</td><td align="center">Async</td><td align="left">AVX threads</td></tr><tr><td align="left">MarkDuplicates</td><td align="left">2 threads</td><td align="left">1</td><td align="left">2 threads</td><td align="center">N/A</td><td align="left">N/A</td></tr><tr><td align="left">BaseRecalibrator</td><td align="left">20 threads</td><td align="left">-nct 40</td><td align="left">20 threads</td><td align="center">Yes for Samtools, No for Tribble</td><td align="left">N/A</td></tr><tr><td align="left">ApplyBQSR</td><td align="left">off</td><td align="left">-nct 3</td><td align="left">off</td><td align="center"/><td align="left">N/A</td></tr><tr><td align="left">HaplotypeCaller</td><td align="left">off</td><td align="left">-nt 1 -nct 39</td><td align="left">off</td><td align="center"/><td align="left">8</td></tr></tbody></table></table-wrap></p><p>Further walltime improvement can be achieved via splitting the aligned sorted BAM by chromosome. In GATK3.8 the walltime is reduced down to 5 hours when BAM is split into 16 chunks running on the same node &#x02013; a 76.9% improvement relative to the unoptimized, unsplit configuration. Further benefit can be achieved by splitting into 12 chunks across 4 nodes: down to 3.4 hours (84.3% total improvement). A similar walltime of 3.6 hours is accomplished in GATK4 by splitting into 16 chunks running on the same node &#x02013; potentially a very cost-effective solution.</p><p>To assess the financial costs and benefits resulting from the various configurations of the pipeline, we calculated the dollar amount for our runs based on AWS pricing. All our nodes are built with 40-core Skylake CPUs and 192 GB of RAM. This does not exactly match any of the AWS Skylake instances: c5.9xlarge gives 36 cores and 72 GB of RAM, and c5.18xlarge gives 72 cores and 144 GB of RAM. Our optimizations do aim to maximally pack our nodes with processes, but 72 GB of RAM would probably be insufficient for some high-throughput configurations. Thus Table&#x000a0;<xref rid="Tab4" ref-type="table">4</xref> gives cost estimates for both types of instances, with the understanding that true values are somewhere in between. The Google cloud provides n1-standard-32 instances with 32 cores and 120 GB of RAM, which are more similar to our nodes and therefore provide a closer benchmark. Their cost is $1.51 per hour, which is very close to the AWS c5.9xlarge at $1.52 per hour, and therefore the same dollar estimates apply.
<table-wrap id="Tab4"><label>Table 4</label><caption><p>Financial costs per sample when running an optimized pipeline, based on AWS on-demand pricing as of August 2019: c5.9xlarge at $1.53 per hour and c5.18xlarge at $3.06 per hour</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">GATK version</th><th align="left">Splitting</th><th align="left">Samples</th><th align="left">Nodes</th><th align="left">Walltime, hrs</th><th align="left">c5.9xlarge</th><th align="left">c5.18xlarge</th></tr></thead><tbody><tr><td align="left">GATK 4.0.1.2</td><td align="left">no splitting</td><td align="left">1</td><td align="left">1</td><td align="left">20.7</td><td align="left">$31.7</td><td align="left">$63.3</td></tr><tr><td align="left">GATK 3.8</td><td align="left">no splitting</td><td align="left">1</td><td align="left">1</td><td align="left">15.3</td><td align="left">$23.4</td><td align="left">$46.8</td></tr><tr><td align="left">GATK 3.8</td><td align="left">12 chunks</td><td align="left">1</td><td align="left">4</td><td align="left">3.4</td><td align="left">$20.8</td><td align="left">$41.6</td></tr><tr><td align="left">GATK 3.8</td><td align="left">6 chunks</td><td align="left">1</td><td align="left">2</td><td align="left">4.7</td><td align="left">$14.4</td><td align="left">$28.8</td></tr><tr><td align="left">GATK 3.8</td><td align="left">16 chunks</td><td align="left">1</td><td align="left">1</td><td align="left">5.0</td><td align="left">$7.7</td><td align="left">$15.3</td></tr><tr><td align="left">GATK 4.0.1.2</td><td align="left">16 chunks</td><td align="left">1</td><td align="left">1</td><td align="left">3.6</td><td align="left">$5.5</td><td align="left">$11.0</td></tr><tr><td align="left">GATK 4.0.1.2</td><td align="left">no splitting</td><td align="left">40</td><td align="left">1</td><td align="left">34.1</td><td align="left">$1.3</td><td align="left">$2.6</td></tr></tbody></table><table-wrap-foot><p>Configurations are sorted by cost.</p></table-wrap-foot></table-wrap></p><p>The data emphasize the trade-off between speed and per-sample cost of the analysis. One could achieve the two types of optimizations outlined in the Background section, using our recommendations as follows. Maximizing speed: to minimize the time to process a single sample, useful in time-critical situations, i.e. when a patient has a critical or rapidly developing condition, use GATK3.8 by splitting the sample into 12 chunks and computing across 4 nodes; resultant walltime is 3.4 hours at the cost of $41.60 on c5.18xlarge. Maximizing throughput: to maximize the number of samples processed per unit time, cost-effective for routine analyses or large population studies, use GATK4.0.1.2 by running 40 samples on one node; total walltime is 34.1 hours with 1.18 samples processed per hour at the cost of $2.60 per sample.</p><p>Our study does not encompass the performance issues of Spark code in GATK4, because that functionality was not ready for use as of the time of this writing.</p></sec><sec id="Sec15" sec-type="conclusion"><title>Conclusions</title><p>In this paper, we presented efficient methodology for running the Best Practices variant calling pipeline in a time-sensitive manner by employing run-time optimizing software parameters and data-level parallelizations. We showed a significant improvement in run time on whole human genome data, compared to previous benchmarking efforts. Both GATK3.8 and GATK4 are still useful, for different purposes. The Spark functionality of GATK4 is expected to bring still further speedups to this widely used and valuable code base.</p></sec></body><back><glossary><title>Abbreviations</title><def-list><def-item><term>AVX</term><def><p>Advanced vector extensions</p></def></def-item><def-item><term>AWS</term><def><p>Amazon web services</p></def></def-item><def-item><term>BQSR</term><def><p>Base quality score recalibration</p></def></def-item><def-item><term>CPU</term><def><p>Central processing unit</p></def></def-item><def-item><term>GATK</term><def><p>Genome analysis toolkit</p></def></def-item><def-item><term>GC</term><def><p>Garbage collection</p></def></def-item><def-item><term>GKL</term><def><p>Genomics kernel library</p></def></def-item><def-item><term>HPC</term><def><p>High performance computing</p></def></def-item><def-item><term>I/O</term><def><p>input-output</p></def></def-item><def-item><term>PGC</term><def><p>Parallel garbage collector</p></def></def-item><def-item><term>RAM</term><def><p>Random access memory</p></def></def-item><def-item><term>SNP</term><def><p>Single nucleotide polymorphism</p></def></def-item><def-item><term>WES</term><def><p>Whole exome sequencing</p></def></def-item><def-item><term>WGS</term><def><p>Whole genome sequencing</p></def></def-item></def-list></glossary><fn-group><fn><p>The original version of this article was revised: Table 2 is displayed correctly.</p></fn><fn><p><bold>Publisher&#x02019;s Note</bold></p><p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></fn><fn><p><bold>Change history</bold></p><p>12/17/2019</p><p>Following publication of the original article [1], the author explained that Table 2 is displayed incorrectly. The correct Table 2 is given below. The original article has been corrected.</p></fn></fn-group><ack><p>We thank Dr. Neil Cohen at Interdisciplinary Health Sciences Institute, as well as the UIUC Institute for Genomic Biology and the National Center for Supercomputing Applications for their generous support and access to resources. We particularly acknowledge the support of Keith Stewart, M.B., Ch.B., Mayo Clinic/Illinois Grand Challenge Sponsor and Director of the Mayo Clinic Center for Individualized Medicine. Many thanks to the GATK team at the Broad Institute for their consultation and advice on the internals of GATK. Special gratitude to Gay Reed and Amy Weckle for outstanding project management.</p></ack><notes notes-type="author-contribution"><title>Authors&#x02019; contributions</title><p>JRH designed the performance metrics, measured walltime improvements, analyzed the results and wrote the manuscript. SB, MAB, TMD, SNH, MEH, RKI, MTK, EWK, NRM, EDW, MW, DEW, LSM conceived of the work and consulted on the various bioinformatics aspects of the project. KIK managed the project and prepared the manuscript. LSM supervised the project, designed experiments, interpreted the results and prepared the manuscript. All authors read and approved the final manuscript.</p></notes><notes notes-type="funding-information"><title>Funding</title><p>This work was a product of the Mayo Clinic and Illinois Strategic Alliance for Technology-Based Healthcare. Major funding was provided by the Mayo Clinic Center for Individualized Medicine and the Todd and Karen Wanek Program for Hypoplastic Left Heart Syndrome. LSM is an H3ABioNet member and is partly supported by the National Institutes of Health Common Fund under grant number U41HG006941. The content is solely the responsibility of the author and does not necessarily represent the official views of the National Institutes of Health. The funding bodies played no role in the design of the study and collection, analysis, and interpretation of data and in writing the manuscript.</p></notes><notes notes-type="data-availability"><title>Availability of data and materials</title><p>The sequencing reads for NA12878 were downloaded from Illumina BaseSpace using a process that requires creation of account as described on theirwebsite . The dbSNP build 146 was downloaded from the NCBI FTP site</p></notes><notes><title>Ethics approval and consent to participate</title><p>Not Applicable</p></notes><notes><title>Consent for publication</title><p>Not Applicable</p></notes><notes notes-type="COI-statement"><title>Competing interests</title><p>The authors declare that they have no competing interests.</p></notes><ref-list id="Bib1"><title>References</title><ref id="CR1"><label>1</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Metzker</surname><given-names>ML</given-names></name></person-group><article-title>Sequencing technologies - the next generation</article-title><source>Nat Rev Genet</source><year>2010</year><volume>11</volume><issue>1</issue><fpage>31</fpage><lpage>46</lpage><pub-id pub-id-type="doi">10.1038/nrg2626</pub-id><pub-id pub-id-type="pmid">19997069</pub-id></element-citation></ref><ref id="CR2"><label>2</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goodwin</surname><given-names>S</given-names></name><name><surname>McPherson</surname><given-names>JD</given-names></name><name><surname>McCombie</surname><given-names>WR</given-names></name></person-group><article-title>Coming of age: ten years of next-generation sequencing technologies</article-title><source>Nat Rev Genet</source><year>2016</year><volume>17</volume><issue>6</issue><fpage>333</fpage><lpage>51</lpage><pub-id pub-id-type="doi">10.1038/nrg.2016.49</pub-id><pub-id pub-id-type="pmid">27184599</pub-id></element-citation></ref><ref id="CR3"><label>3</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rabbani</surname><given-names>B</given-names></name><name><surname>Tekin</surname><given-names>M</given-names></name><name><surname>Mahdieh</surname><given-names>N</given-names></name></person-group><article-title>The promise of whole-exome sequencing in medical genetics</article-title><source>J Hum Genet</source><year>2014</year><volume>59</volume><issue>1</issue><fpage>5</fpage><lpage>15</lpage><pub-id pub-id-type="doi">10.1038/jhg.2013.114</pub-id><pub-id pub-id-type="pmid">24196381</pub-id></element-citation></ref><ref id="CR4"><label>4</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Allard</surname><given-names>MW</given-names></name></person-group><article-title>The future of whole-genome sequencing for public health and the clinic</article-title><source>J Clin Microbiol</source><year>2016</year><volume>54</volume><issue>8</issue><fpage>1946</fpage><lpage>8</lpage><pub-id pub-id-type="doi">10.1128/JCM.01082-16</pub-id><pub-id pub-id-type="pmid">27307454</pub-id></element-citation></ref><ref id="CR5"><label>5</label><mixed-citation publication-type="other">The Broad Institute. GATK |Best Practices. 2017. <ext-link ext-link-type="uri" xlink:href="https://software.broadinstitute.org/gatk/best-practices/">https://software.broadinstitute.org/gatk/best-practices/</ext-link>. Accessed 2017-08-12.</mixed-citation></ref><ref id="CR6"><label>6</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McKenna</surname><given-names>A</given-names></name><name><surname>Hanna</surname><given-names>M</given-names></name><name><surname>Banks</surname><given-names>E</given-names></name><name><surname>Sivachenko</surname><given-names>A</given-names></name><name><surname>Cibulskis</surname><given-names>K</given-names></name><name><surname>Kernytsky</surname><given-names>A</given-names></name><name><surname>Garimella</surname><given-names>K</given-names></name><name><surname>Altshuler</surname><given-names>D</given-names></name><name><surname>Gabriel</surname><given-names>S</given-names></name><name><surname>Daly</surname><given-names>M</given-names></name><name><surname>DePristo</surname><given-names>MA</given-names></name></person-group><article-title>The Genome Analysis Toolkit: A MapReduce framework for analyzing next-generation DNA sequencing data</article-title><source>Genome Res</source><year>2010</year><volume>20</volume><issue>9</issue><fpage>1297</fpage><lpage>303</lpage><pub-id pub-id-type="doi">10.1101/gr.107524.110</pub-id><pub-id pub-id-type="pmid">20644199</pub-id></element-citation></ref><ref id="CR7"><label>7</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>DePristo</surname><given-names>MA</given-names></name><name><surname>Banks</surname><given-names>E</given-names></name><name><surname>Poplin</surname><given-names>R</given-names></name><name><surname>Garimella</surname><given-names>KV</given-names></name><name><surname>Maguire</surname><given-names>JR</given-names></name><name><surname>Hartl</surname><given-names>C</given-names></name><name><surname>Philippakis</surname><given-names>AA</given-names></name><name><surname>del Angel</surname><given-names>G</given-names></name><name><surname>Rivas</surname><given-names>MA</given-names></name><name><surname>Hanna</surname><given-names>M</given-names></name><name><surname>McKenna</surname><given-names>A</given-names></name><name><surname>Fennell</surname><given-names>TJ</given-names></name><name><surname>Kernytsky</surname><given-names>AM</given-names></name><name><surname>Sivachenko</surname><given-names>AY</given-names></name><name><surname>Cibulskis</surname><given-names>K</given-names></name><name><surname>Gabriel</surname><given-names>SB</given-names></name><name><surname>Altshuler</surname><given-names>D</given-names></name><name><surname>Daly</surname><given-names>MJ</given-names></name></person-group><article-title>A framework for variation discovery and genotyping using next-generation dna sequencing data</article-title><source>Nat Genet</source><year>2011</year><volume>43</volume><issue>5</issue><fpage>491</fpage><lpage>8</lpage><pub-id pub-id-type="doi">10.1038/ng.806</pub-id><pub-id pub-id-type="pmid">21478889</pub-id></element-citation></ref><ref id="CR8"><label>8</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Van der Auwera</surname><given-names>GA</given-names></name><name><surname>Carneiro</surname><given-names>MO</given-names></name><name><surname>Hartl</surname><given-names>C</given-names></name><name><surname>Poplin</surname><given-names>R</given-names></name><name><surname>Del Angel</surname><given-names>G</given-names></name><name><surname>Levy-Moonshine</surname><given-names>A</given-names></name><name><surname>Jordan</surname><given-names>T</given-names></name><name><surname>Shakir</surname><given-names>K</given-names></name><name><surname>Roazen</surname><given-names>D</given-names></name><name><surname>Thibault</surname><given-names>J</given-names></name><name><surname>Banks</surname><given-names>E</given-names></name><name><surname>Garimella</surname><given-names>KV</given-names></name><name><surname>Altshuler</surname><given-names>D</given-names></name><name><surname>Gabriel</surname><given-names>S</given-names></name><name><surname>DePristo</surname><given-names>MA</given-names></name></person-group><article-title>From fastq data to high confidence variant calls: the genome analysis toolkit best practices pipeline</article-title><source>Curr Protoc Bioinformatics</source><year>2013</year><volume>11</volume><issue>1110</issue><fpage>11</fpage><lpage>101111033</lpage></element-citation></ref><ref id="CR9"><label>9</label><mixed-citation publication-type="other">Illumina. Illumina sequencing platforms. 2018. <ext-link ext-link-type="uri" xlink:href="https://www.illumina.com/systems/sequencing-platforms.html">https://www.illumina.com/systems/sequencing-platforms.html</ext-link>. Accessed 17 Jun 2018.</mixed-citation></ref><ref id="CR10"><label>10</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kathiresan</surname><given-names>N</given-names></name><name><surname>Temanni</surname><given-names>R</given-names></name><name><surname>Almabrazi</surname><given-names>H</given-names></name><name><surname>Syed</surname><given-names>N</given-names></name><name><surname>Jithesh</surname><given-names>PV</given-names></name><name><surname>Al-Ali</surname><given-names>R</given-names></name></person-group><article-title>Accelerating next generation sequencing data analysis with system level optimizations</article-title><source>Sci Rep</source><year>2017</year><volume>7</volume><issue>1</issue><fpage>9058</fpage><pub-id pub-id-type="doi">10.1038/s41598-017-09089-1</pub-id><pub-id pub-id-type="pmid">28831090</pub-id></element-citation></ref><ref id="CR11"><label>11</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Costa</surname><given-names>CH</given-names></name><name><surname>Misale</surname><given-names>C</given-names></name><name><surname>Liu</surname><given-names>F</given-names></name><name><surname>Silva</surname><given-names>M</given-names></name><name><surname>Franke</surname><given-names>H</given-names></name><name><surname>Crumley</surname><given-names>P</given-names></name><name><surname>D&#x02019;Amora</surname><given-names>B</given-names></name></person-group><article-title>Optimization of genomics analysis pipeline for scalable performance in a cloud environment</article-title><source>2018 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)</source><year>2018</year><publisher-loc>Piscataway</publisher-loc><publisher-name>IEEE</publisher-name></element-citation></ref><ref id="CR12"><label>12</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>S-M</given-names></name><name><surname>Lin</surname><given-names>Z-Y</given-names></name><name><surname>Ju</surname><given-names>J-L</given-names></name><name><surname>Chen</surname><given-names>S-J</given-names></name></person-group><article-title>Acceleration of variant discovery tool in gatk</article-title><source>2018 IEEE 23rd International Conference on Digital Signal Processing (DSP)</source><year>2018</year><publisher-loc>Piscataway</publisher-loc><publisher-name>IEEE</publisher-name></element-citation></ref><ref id="CR13"><label>13</label><mixed-citation publication-type="other">Banerjee SS, Athreya AP, Mainzer LS, Jongeneel CV, Hwu W-M, Kalbarczyk ZT, Iyer RK. Efficient and scalable workflows for genomic analyses. In: Proceedings of the ACM International Workshop on Data-Intensive Distributed Computing: 2016. p. 27&#x02013;36. 10.1145/2912152.2912156.</mixed-citation></ref><ref id="CR14"><label>14</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Raczy</surname><given-names>C</given-names></name><name><surname>Petrovski</surname><given-names>R</given-names></name><name><surname>Saunders</surname><given-names>CT</given-names></name><name><surname>Chorny</surname><given-names>I</given-names></name><name><surname>Kruglyak</surname><given-names>S</given-names></name><name><surname>Margulies</surname><given-names>EH</given-names></name><name><surname>Chuang</surname><given-names>H-Y</given-names></name><name><surname>K&#x000e4;llberg</surname><given-names>M</given-names></name><name><surname>Kumar</surname><given-names>SA</given-names></name><name><surname>Liao</surname><given-names>A</given-names></name><name><surname>Little</surname><given-names>KM</given-names></name><name><surname>Str&#x000f6;mberg</surname><given-names>MP</given-names></name><name><surname>Tanner</surname><given-names>SW</given-names></name></person-group><article-title>Isaac: ultra-fast whole-genome secondary analysis on illumina sequencing platforms</article-title><source>Bioinformatics</source><year>2013</year><volume>29</volume><issue>16</issue><fpage>2041</fpage><lpage>3</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btt314</pub-id><pub-id pub-id-type="pmid">23736529</pub-id></element-citation></ref><ref id="CR15"><label>15</label><mixed-citation publication-type="other">Freed DN, Aldana R, Weber JA, Edwards JS. The sentieon genomics tools-a fast and accurate solution to variant calling from next-generation sequence data. BioRxiv. 2017:115717. 10.1101/115717.</mixed-citation></ref><ref id="CR16"><label>16</label><mixed-citation publication-type="other">Weber JA, Aldana R, Gallagher BD, Edwards JS. Sentieon dna pipeline for variant detection-software-only solution, over 20 &#x000d7; faster than gatk 3.3 with identical results. PeerJ PrePrints 4:e1672v2: 2016. 10.7287/peerj.preprints.1672v2.</mixed-citation></ref><ref id="CR17"><label>17</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pl&#x000fc;ss</surname><given-names>M</given-names></name><name><surname>Kopps</surname><given-names>AM</given-names></name><name><surname>Keller</surname><given-names>I</given-names></name><name><surname>Meienberg</surname><given-names>J</given-names></name><name><surname>Caspar</surname><given-names>SM</given-names></name><name><surname>Dubacher</surname><given-names>N</given-names></name><name><surname>Bruggmann</surname><given-names>R</given-names></name><name><surname>Vogel</surname><given-names>M</given-names></name><name><surname>Matyas</surname><given-names>G</given-names></name></person-group><article-title>Need for speed in accurate whole-genome data analysis: Genalice map challenges bwa/gatk more than pemapper/pecaller and isaac</article-title><source>Proc Nat Acad Sci</source><year>2017</year><volume>114</volume><issue>40</issue><fpage>8320</fpage><lpage>2</lpage><pub-id pub-id-type="doi">10.1073/pnas.1713830114</pub-id></element-citation></ref><ref id="CR18"><label>18</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Miller</surname><given-names>NA</given-names></name><name><surname>Farrow</surname><given-names>EG</given-names></name><name><surname>Gibson</surname><given-names>M</given-names></name><name><surname>Willig</surname><given-names>LK</given-names></name><name><surname>Twist</surname><given-names>G</given-names></name><name><surname>Yoo</surname><given-names>B</given-names></name><name><surname>Marrs</surname><given-names>T</given-names></name><name><surname>Corder</surname><given-names>S</given-names></name><name><surname>Krivohlavek</surname><given-names>L</given-names></name><name><surname>Walter</surname><given-names>A</given-names></name><etal/></person-group><article-title>A 26-hour system of highly sensitive whole genome sequencing for emergency management of genetic diseases</article-title><source>Genome Med</source><year>2015</year><volume>7</volume><issue>1</issue><fpage>100</fpage><pub-id pub-id-type="doi">10.1186/s13073-015-0221-8</pub-id><pub-id pub-id-type="pmid">26419432</pub-id></element-citation></ref><ref id="CR19"><label>19</label><mixed-citation publication-type="other">Intel, Broad Institute Announce Breakthrough Genomics Analytics Stack. <ext-link ext-link-type="uri" xlink:href="https://www.hpcwire.com/off-the-wire/intel-broad-institute-announce-breakthrough-genomics-analytics-stack/">https://www.hpcwire.com/off-the-wire/intel-broad-institute-announce-breakthrough-genomics-analytics-stack/</ext-link>. Accessed 17 Jun 2018.</mixed-citation></ref><ref id="CR20"><label>20</label><mixed-citation publication-type="other">Genomic Research by Intel and Broad Institute. <ext-link ext-link-type="uri" xlink:href="https://www.intel.com/content/www/us/en/healthcare-it/solutions/genomics-broad-data.html">https://www.intel.com/content/www/us/en/healthcare-it/solutions/genomics-broad-data.html</ext-link>. Accessed 17 Jun 2018.</mixed-citation></ref><ref id="CR21"><label>21</label><mixed-citation publication-type="other">GATK: We&#x02019;re Officially BFFs with Intel Now. <ext-link ext-link-type="uri" xlink:href="https://gatkforums.broadinstitute.org/gatk/discussion/8605/were-officially-bffs-with-intel-now">https://gatkforums.broadinstitute.org/gatk/discussion/8605/were-officially-bffs-with-intel-now</ext-link>. Accessed 17 Jun 2018.</mixed-citation></ref><ref id="CR22"><label>22</label><mixed-citation publication-type="other">Version Highlights for GATK Version 3.8. <ext-link ext-link-type="uri" xlink:href="https://gatkforums.broadinstitute.org/gatk/discussion/10063/version-highlights-for-gatk-version-3-8">https://gatkforums.broadinstitute.org/gatk/discussion/10063/version-highlights-for-gatk-version-3-8</ext-link>. Accessed 17 Jun 2018.</mixed-citation></ref><ref id="CR23"><label>23</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Decap</surname><given-names>D</given-names></name><name><surname>Reumers</surname><given-names>J</given-names></name><name><surname>Herzeel</surname><given-names>C</given-names></name><name><surname>Costanza</surname><given-names>P</given-names></name><name><surname>Fostier</surname><given-names>J</given-names></name></person-group><article-title>Halvade: scalable sequence analysis with mapreduce</article-title><source>Bioinformatics</source><year>2015</year><volume>31</volume><issue>15</issue><fpage>2482</fpage><lpage>8</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btv179</pub-id><pub-id pub-id-type="pmid">25819078</pub-id></element-citation></ref><ref id="CR24"><label>24</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Mushtaq</surname><given-names>H</given-names></name><name><surname>Al-Ars</surname><given-names>Z</given-names></name></person-group><article-title>Cluster-based apache spark implementation of the gatk dna analysis pipeline</article-title><source>2015 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)</source><year>2015</year><publisher-loc>Piscataway</publisher-loc><publisher-name>IEEE</publisher-name></element-citation></ref><ref id="CR25"><label>25</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Deng</surname><given-names>L</given-names></name><name><surname>Huang</surname><given-names>G</given-names></name><name><surname>Zhuang</surname><given-names>Y</given-names></name><name><surname>Wei</surname><given-names>J</given-names></name><name><surname>Yan</surname><given-names>Y</given-names></name></person-group><article-title>Higene: A high-performance platform for genomic data analysis</article-title><source>2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)</source><year>2016</year><publisher-loc>Piscataway</publisher-loc><publisher-name>IEEE</publisher-name></element-citation></ref><ref id="CR26"><label>26</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Massie</surname><given-names>M</given-names></name><name><surname>Nothaft</surname><given-names>F</given-names></name><name><surname>Hartl</surname><given-names>C</given-names></name><name><surname>Kozanitis</surname><given-names>C</given-names></name><name><surname>Schumacher</surname><given-names>A</given-names></name><name><surname>Joseph</surname><given-names>AD</given-names></name><name><surname>Patterson</surname><given-names>DA</given-names></name></person-group><article-title>Adam: Genomics formats and processing patterns for cloud scale computing</article-title><source>Univ Cali, Berkeley Tech Rep, No. UCB/EECS-2013</source><year>2013</year><volume>207</volume><fpage>2013</fpage></element-citation></ref><ref id="CR27"><label>27</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zook</surname><given-names>JM</given-names></name><name><surname>Chapman</surname><given-names>B</given-names></name><name><surname>Wang</surname><given-names>J</given-names></name><name><surname>Mittelman</surname><given-names>D</given-names></name><name><surname>Hofmann</surname><given-names>O</given-names></name><name><surname>Hide</surname><given-names>W</given-names></name><name><surname>Salit</surname><given-names>M</given-names></name></person-group><article-title>Integrating human sequence data sets provides a resource of benchmark SNP and indel genotype calls</article-title><source>Nat Biotechnol</source><year>2014</year><volume>32</volume><issue>3</issue><fpage>246</fpage><pub-id pub-id-type="doi">10.1038/nbt.2835</pub-id><pub-id pub-id-type="pmid">24531798</pub-id></element-citation></ref><ref id="CR28"><label>28</label><mixed-citation publication-type="other">Zook J, McDaniel J, Parikh H, Heaton H, Irvine SA, Trigg L, Truty R, McLean CY, De La Vega FM, Xiao C, Sherry S, Salit M. Reproducible integration of multiple sequencing datasets to form high-confidence SNP, indel, and reference calls for five human genome reference materials. bioRxiv. 2018. 10.1101/281006.</mixed-citation></ref><ref id="CR29"><label>29</label><mixed-citation publication-type="other">Li H. Aligning sequence reads, clone sequences and assembly contigs with BWA-MEM. 2013. http://arxiv.org/abs/1303.3997v2.</mixed-citation></ref><ref id="CR30"><label>30</label><mixed-citation publication-type="other">NOVOCRAFT TECHNOLOGIES SDN BHD. Novocraft. 2014. <ext-link ext-link-type="uri" xlink:href="http://www.novocraft.com/">http://www.novocraft.com/</ext-link>. Accessed 2017-06-27.</mixed-citation></ref></ref-list></back></article>