
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article" xml:lang="en"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">BMC Res Notes</journal-id><journal-id journal-id-type="iso-abbrev">BMC Res Notes</journal-id><journal-title-group><journal-title>BMC Research Notes</journal-title></journal-title-group><issn pub-type="epub">1756-0500</issn><publisher><publisher-name>BioMed Central</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">22251818</article-id><article-id pub-id-type="pmc">3398325</article-id><article-id pub-id-type="publisher-id">1756-0500-5-35</article-id><article-id pub-id-type="doi">10.1186/1756-0500-5-35</article-id><article-categories><subj-group subj-group-type="heading"><subject>Technical Note</subject></subj-group></article-categories><title-group><article-title>Performance of a simple chromatin-rich segmentation algorithm in quantifying basal cell carcinoma from histology images</article-title></title-group><contrib-group><contrib contrib-type="author" id="A1"><name><surname>Lesack</surname><given-names>Kyle</given-names></name><xref ref-type="aff" rid="I1">1</xref><email>kjlesack@ucalgary.ca</email></contrib><contrib contrib-type="author" corresp="yes" id="A2"><name><surname>Naugler</surname><given-names>Christopher</given-names></name><xref ref-type="aff" rid="I2">2</xref><email>christopher.naugler@cls.ab.ca</email></contrib></contrib-group><aff id="I1"><label>1</label>Room G503, O'Brien Centre for the BHSc, 3330 Hospital Drive N.W., Calgary, Alberta T2N 4N1, Canada</aff><aff id="I2"><label>2</label>Department of Pathology and Laboratory Medicine, University of Calgary and Calgary Laboratory Services, C414, Diagnostic and Scientific Centre 9, 3535 Research Road NW, Calgary, AB T2L 2 K8, Canada</aff><pub-date pub-type="collection"><year>2012</year></pub-date><pub-date pub-type="epub"><day>17</day><month>1</month><year>2012</year></pub-date><volume>5</volume><fpage>35</fpage><lpage>35</lpage><history><date date-type="received"><day>7</day><month>11</month><year>2011</year></date><date date-type="accepted"><day>17</day><month>1</month><year>2012</year></date></history><permissions><copyright-statement>Copyright &#x000a9;2012 Lesack and Naugler; BioMed Central Ltd.</copyright-statement><copyright-year>2012</copyright-year><copyright-holder>Lesack and Naugler; BioMed Central Ltd.</copyright-holder><license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/2.0"><license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/2.0">http://creativecommons.org/licenses/by/2.0</ext-link>), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p></license></permissions><self-uri xlink:href="http://www.biomedcentral.com/1756-0500/5/35"/><abstract><sec><title>Background</title><p>The use of digital imaging and algorithm-assisted identification of regions of interest is revolutionizing the practice of anatomic pathology. Currently automated methods for extracting the tumour regions in basal cell carcinomas are lacking. In this manuscript a colour-deconvolution based tumour extraction algorithm is presented.</p></sec><sec><title>Findings</title><p>Haematoxylin and eosin stained basal cell carcinoma histology slides were digitized and analyzed using the open source image analysis program ImageJ. The pixels belonging to tumours were identified by the algorithm, and the performance of the algorithm was evaluated by comparing the pixels identified as malignant with a manually determined dataset.</p><p>The algorithm achieved superior results with the nodular tumour subtype. Pre-processing using colour deconvolution resulted in a slight decrease in sensitivity, but a significant increase in specificity. The overall sensitivity and specificity of the algorithm was 91.0% and 86.4% respectively, resulting in a positive predictive value of 63.3% and a negative predictive value of 94.2%</p></sec><sec><title>Conclusions</title><p>The proposed image analysis algorithm demonstrates the feasibility of automatically extracting tumour regions from digitized basal cell carcinoma histology slides. The proposed algorithm may be adaptable to other stain combinations and tumour types.</p></sec></abstract></article-meta></front><body><sec><title>Background</title><p>The interpretation of digital histology images by pathologists (so called 'tele-pathology') is revolutionizing the practice of anatomic pathology [<xref ref-type="bibr" rid="B1">1</xref>,<xref ref-type="bibr" rid="B2">2</xref>]. A natural extension of this use of digital images in histology interpretation is the addition of digital analysis tools to aid in diagnosis or the completion of time-consuming tasks. A prime example of the success of this approach is the utilization of algorithm-assisted identification of abnormal cells in cytology preparations [<xref ref-type="bibr" rid="B3">3</xref>].</p><p>In terms of histology, a number of studies have recently looked at image classification algorithms. One recent use of automated image analysis and processing has been as a part of algorithms used to classify breast cancer tissue. Using a supervised learning method, Petushi et al. developed an algorithm capable of classifying breast cancer carcinomas based on histological tissue micro-texture and spatial position [<xref ref-type="bibr" rid="B4">4</xref>]. Using the commercial software packages Matlab, and LNKnet, the algorithm classified the micro-tissue types as nuclear, extra-cellular, or adipose. The algorithm further classified the nucleus into three separate types, each representing a different nuclear morphology. Similarly, an algorithm developed by Kara&#x000e7;ali and T&#x000f6;zeren was used to classify breast tissue images based upon tissue texture and spatial distribution [<xref ref-type="bibr" rid="B5">5</xref>]. This algorithm was used to classify the tissue images based on the quantity of chromatin and collagen, in addition to a measure of the tissue's spatial heterogeneity. Another breast cancer image analysis algorithm was developed by Hall et al. [<xref ref-type="bibr" rid="B6">6</xref>]. This algorithm was developed to assess human epidermal growth factor receptor 2 (HER2) expression in breast cancer tissue. The team used the open source image processing software ImageJ to separate the diaminobenzidine and haematoxylin stains from each other. This was followed by the extraction of the membrane regions from the digitized breast cancer slides. The HER2 score generated using this method was based upon the extracted membrane pixels. Other automated image analyses include oral epithelial dysplasia and squamous cell carcinoma [<xref ref-type="bibr" rid="B7">7</xref>], and melanoma [<xref ref-type="bibr" rid="B8">8</xref>-<xref ref-type="bibr" rid="B11">11</xref>]. However, the application of these pattern recognition algorithms involves complex programming and may serve to assist only in narrow scopes of diagnostic practice.</p><p>The aim of our study is to define the operational characteristics (sensitivity and specificity) of a simple colour-based segmentation algorithm for quantifying basal cell carcinoma from photomicrographs. The basis of this algorithm is the observation from anatomic pathology practice that cells with dense chromatin (including many cancer cells) have a different colour spectrum than surrounding normal tissues. Our hypothesis was that the operational characteristics would differ among common basal cell carcinoma subtypes (superficial, nodular and infiltrative) with the subtypes exhibiting more compact chromatin (superficial and nodular) demonstrating better operational characteristics than the infiltrative subtypes.</p><p>Basal cell carcinoma was chosen to examine this question as this cancer presents with a well-defined range of histological subtypes and occurs in association with non-neoplastic chromatin-rich cells present in the epidermis and dermis. Finally, because basal cell carcinomas are the most common malignant neoplasm in humans [<xref ref-type="bibr" rid="B12">12</xref>], access to clinical material was not a limiting factor. Although basal cell carcinomas are highly curable by surgical intervention, their sheer number (over one million new cases per year in the United States [<xref ref-type="bibr" rid="B13">13</xref>]) translates into a heavy burden for health care systems. The only previous study that explored the automated analysis of BCCs was performed by Gutierez et al. [<xref ref-type="bibr" rid="B14">14</xref>]. By modelling the visual recognition process, the algorithm used a supervised learning approach to identify regions of interest (ROI). The ROIs identified by the algorithm were found to coincide highly with those selected manually by a pathologist.</p><sec><title>Image analysis overview</title><p>In order to extract and analyse features of a digital image, it is first necessary to identify and separate the ROIs. Image segmentation involves dividing an image into regions of similar characteristics based on features such as brightness or morphology [<xref ref-type="bibr" rid="B15">15</xref>]. Ideally the foreground of the resulting image contains the desired regions. A simple technique for image segmentation involves segmenting grayscale images based on their pixel intensities [<xref ref-type="bibr" rid="B16">16</xref>]. By filtering out pixels above or below a certain threshold value, grayscale images may be segmented into regions of similar brightness. The resulting segmentation can be stored as a new image containing only the black and white values that correspond to the foreground/background regions. More complex thresholding methods are also available. These include the use of multiple thresholds, as well as adaptive thresholding, where the local threshold values are determined according to their neighbouring regions [<xref ref-type="bibr" rid="B17">17</xref>]. Further segmentation methods also exist, including seed growing, and boundary based techniques [<xref ref-type="bibr" rid="B18">18</xref>]. Prior to feature extraction and analysis, further processing may be required once the image has been segmented. For example, disconnected regions of images may be filled in using morphological operations. This may be accomplished by performing a binary closing operation. Another common operation is noise reduction, frequently achieved by applying mean or median filters [<xref ref-type="bibr" rid="B19">19</xref>].</p><p>The slides evaluated with this algorithm were stained with haematoxylin and eosin (H&#x00026;E). Although H&#x00026;E stains are easily distinguished visually by colour, digitally separating regions containing stain co-localisation is difficult. Separation via colour deconvolution provides a means of separating stains with overlapping regions. The basis of this method is to separate the component stains by performing an ortho-normal transformation of the image's RGB information [<xref ref-type="bibr" rid="B20">20</xref>]. Several recent studies have used stain separation by colour deconvolution prior to analyzing cancerous tissue [<xref ref-type="bibr" rid="B21">21</xref>-<xref ref-type="bibr" rid="B23">23</xref>].</p></sec></sec><sec sec-type="methods"><title>Methods</title><p>The algorithm used to extract the BCC tumours consisted of four steps: pre-processing, segmentation, morphological operations, and feature extraction (see Figure <xref ref-type="fig" rid="F1">1</xref>). A copy of the algorithm used is available as a macro in Additional file <xref ref-type="supplementary-material" rid="S1">1</xref>. The macro also provides the specific parameters used in the algorithm. During pre-processing, colour deconvolution was used to separate the haematoxylin stain from each of the images. The resulting image was then segmented based upon pixel intensities. Subsequently, morphological operations were performed to connect the discontinuous regions that resulted from the segmentation process. Finally, area-based particle analysis was used to extract and quantify the ROIs from the image. This analysis allowed the performance of the algorithm to be evaluated.</p><fig id="F1" position="float"><label>Figure 1</label><caption><p><bold>Overview of the tumour extraction algorithm</bold>.</p></caption><graphic xlink:href="1756-0500-5-35-1"/></fig><sec><title>Case selection/image acquisition</title><p>Cases were selected from a convenience sample of basal cell carcinomas reported by the senior author as part of his clinical sign-out practice. Digital images of 30 H&#x00026;E stained BCC histology slides were obtained using a commercial Aperio CS-O slide scanner at 80 &#x000d7; magnification. Sections containing BCC were stored using the JPEG format (1072 &#x000d7; 902 pixels).</p></sec><sec><title>Software</title><p>The open source image processing and analysis program ImageJ was used in this study. First released in 1997 by software developer Wayne Rastban, ImageJ is an open source program based on the National Institutes of Health's NIH Image. Current features consist of numerous image processing and analysis operations, including image segmentation and extraction, noise reduction, image transformations, and particle analysis. These features are further expanded upon by an active user base. There are currently hundreds of downloadable user plugins and macros [<xref ref-type="bibr" rid="B24">24</xref>]. Additional benefits of this software include the support of numerous file formats, and platform independence [<xref ref-type="bibr" rid="B25">25</xref>]. As a result of being platform independent, ImageJ is capable of running on multiple operating systems, including MS Windows, Apple OS, and Linux. The algorithm described below was used in conjunction with version 1.44 of ImageJ. With the exception of the colour deconvolution plugin, all of the processes performed are available using the default ImageJ commands.</p></sec><sec><title>Digital image processing and analysis</title><sec><title>Colour deconvolution</title><p>The colour deconvolution plugin by Gabriel Landini [<xref ref-type="bibr" rid="B26">26</xref>] was used to separate the BCC images into separate images containing the haematoxylin and eosin stain components using the built-in H&#x00026;E vector. The plugin creates an additional image corresponding to the complement of the haematoxylin and eosin stains. Because the chromatin-rich basophilic (nuclear) regions were of interest, only the 8-bit Haematoxylin images were retained. The colour deconvolution process was followed by contrast enhancement in order to facilitate the segmentation process.</p></sec><sec><title>Segmentation</title><p>Thresholding was then used to segment the pixels darker than the threshold value. The ImageJ isodata algorithm [<xref ref-type="bibr" rid="B27">27</xref>] was used along with the automatic thresholding option. This algorithm This process resulted in a binary file containing only black and white pixels, where the black pixels corresponded to the regions above the threshold value.</p></sec><sec><title>Morphological operations</title><p>Due to the lack of intense haematoxylin staining in the non-basaloid cell regions, the binary images produced during the segmentation process frequently contained holes and disconnected regions in the tumour nests. As a result, morphological operations were performed on the segmented images. Hole filling was achieved using a combination of median filtering and binary closing operations. Initially a median filter was applied to the bright outliers using the ImageJ <italic>Remove Outliers </italic>command. This was followed by a binary closing operation, and median filtering of the dark outliers.</p></sec><sec><title>Feature extraction</title><p>As other baseloid and chromatin-rich features (e.g. single lymphocytes, hematoxylin stain precipitates, microcalcifications, etc.) could produce false positive results, we attempted to remove these features through a filtering step using the ImageJ particle analyzer feature. A minimum particle size of 750 pixels was used in order to exclude non-tumour nest particles. The extracted tumour was then obtained by removing all particles outside of the ROIs.</p></sec><sec><title>Analysis</title><p>The evaluation of a given algorithm is inherently subjective and biased towards the author's preferences, as standard methods for evaluating the algorithm do not exist [<xref ref-type="bibr" rid="B28">28</xref>]. For the purpose of this analysis a manual evaluation of tumor nests was used as the ground truth dataset.</p><p>To accomplish this, one of us (CN) manually evaluated printed photomicrographs of the 30 basal cell carcinoma images: 10 each of nodular, infiltrative and superficial subtypes. For each of these images, all tumour nests present were manually delineated with a black marker, scanned and analyzed with a manual approach. The main challenges in evaluating an extraction algorithm are determining the true dataset (ground truth), and the appropriate performance metrics [<xref ref-type="bibr" rid="B29">29</xref>,<xref ref-type="bibr" rid="B30">30</xref>].</p><p>A further challenge is the lack of standardized image extraction algorithms, seeing that most existing algorithms are optimized for a specific task. This causes a further problem for evaluating the algorithm, and the colour deconvolution approach in particular. In order to assess the effect of using colour deconvolution, the same set of histology slides were analyzed using grayscale based thresholding in place of the colour deconvolution step. In the comparison algorithm, the image was first converted to an 8-bit grayscale image, and the colour deconvolution step was omitted. The remaining steps were carried out as described by the proposed algorithm.</p><p>The binary images of the algorithmically extracted tumour nests were subtracted from the binary images obtained by manual evaluation. The resulting image, containing the areas of the image not extracted by the algorithm, was considered to contain only false negative (FN) pixels. Similarly, the binary images of the manually extracted tumours were subtracted from the algorithmically extracted ones. The resulting image quantified the pixels considered to be false positives (FP). In addition, the number of true pixels (TP) was calculated by subtracting the total number of pixels identified by the algorithm from those deemed to be false positives. Finally, the number of true negative (TN) pixels was calculated by subtracting the total number of pixels in the image by the number of pixels identified by the algorithm, and by the number of false negatives.</p><p>Four different metrics were calculated to assess the performance of the algorithm. The sensitivity of the test evaluates the capability of the algorithm to identify pixels belonging to the tumour nests. The sensitivity was calculated as follows:</p><p><disp-formula><mml:math id="M1" name="1756-0500-5-35-i1" overflow="scroll"><mml:mrow><mml:mstyle class="text"><mml:mtext class="textsf" mathvariant="sans-serif">Sensitivity</mml:mtext></mml:mstyle><mml:mrow><mml:mo class="MathClass-open">(</mml:mo><mml:mrow><mml:mstyle class="text"><mml:mtext class="textsf" mathvariant="sans-serif">SE</mml:mtext></mml:mstyle></mml:mrow><mml:mo class="MathClass-close">)</mml:mo></mml:mrow><mml:mo class="MathClass-rel">=</mml:mo><mml:mfrac><mml:mrow><mml:mstyle class="text"><mml:mtext class="textsf" mathvariant="sans-serif">TP</mml:mtext></mml:mstyle></mml:mrow><mml:mrow><mml:mstyle class="text"><mml:mtext class="textsf" mathvariant="sans-serif">TP</mml:mtext></mml:mstyle><mml:mo class="MathClass-bin">+</mml:mo><mml:mstyle class="text"><mml:mtext class="textsf" mathvariant="sans-serif">FN</mml:mtext></mml:mstyle></mml:mrow></mml:mfrac><mml:mo class="MathClass-bin">&#x022c5;</mml:mo><mml:mspace width="2.77695pt" class="tmspace"/><mml:mn>100</mml:mn><mml:mi>%</mml:mi></mml:mrow></mml:math></disp-formula></p><p>The specificity of the test evaluates the capability of the algorithm to correctly identify the pixels not belonging to the tumour nests. The specificity was calculated as follows:</p><p><disp-formula><mml:math id="M2" name="1756-0500-5-35-i2" overflow="scroll"><mml:mrow><mml:mstyle class="text"><mml:mtext class="textsf" mathvariant="sans-serif">Sensitivity</mml:mtext></mml:mstyle><mml:mrow><mml:mo class="MathClass-open">(</mml:mo><mml:mrow><mml:mstyle class="text"><mml:mtext class="textsf" mathvariant="sans-serif">SP</mml:mtext></mml:mstyle></mml:mrow><mml:mo class="MathClass-close">)</mml:mo></mml:mrow><mml:mo class="MathClass-rel">=</mml:mo><mml:mfrac><mml:mrow><mml:mstyle class="text"><mml:mtext class="textsf" mathvariant="sans-serif">TN</mml:mtext></mml:mstyle></mml:mrow><mml:mrow><mml:mstyle class="text"><mml:mtext class="textsf" mathvariant="sans-serif">TN</mml:mtext></mml:mstyle><mml:mo class="MathClass-bin">+</mml:mo><mml:mstyle class="text"><mml:mtext class="textsf" mathvariant="sans-serif">FP</mml:mtext></mml:mstyle></mml:mrow></mml:mfrac><mml:mspace width="2.77695pt" class="tmspace"/><mml:mo class="MathClass-bin">&#x022c5;</mml:mo><mml:mspace width="2.77695pt" class="tmspace"/><mml:mn>100</mml:mn><mml:mi>%</mml:mi></mml:mrow></mml:math></disp-formula></p><p>The proportion of the histology slide occupied by the BCC may vary significantly between different slides. In general, superficial tumours occupy a smaller fraction of the slide compared to the nodular and infiltrative subtypes. For this reason the positive and negative predictive values were calculated. The positive predictive value (PPV) of the test indicates the probability that a positively identified pixel belongs to an actual tumour. As a result, images containing a lower tumour to non-tumour ratio result in lower PPVs. Conversely, the negative predictive value (NPV) is an indication of the probability of a negatively identified pixel actually belonging to non-tumour tissue. The PPV and NPV were calculated as follows:</p><p><disp-formula><mml:math id="M3" name="1756-0500-5-35-i3" overflow="scroll"><mml:mrow><mml:mstyle class="text"><mml:mtext class="textsf" mathvariant="sans-serif">Positive</mml:mtext></mml:mstyle><mml:mspace width="2.77695pt" class="tmspace"/><mml:mstyle class="text"><mml:mtext class="textsf" mathvariant="sans-serif">Predictive</mml:mtext></mml:mstyle><mml:mspace width="2.77695pt" class="tmspace"/><mml:mstyle class="text"><mml:mtext class="textsf" mathvariant="sans-serif">Value</mml:mtext></mml:mstyle><mml:mspace width="2.77695pt" class="tmspace"/><mml:mrow><mml:mo class="MathClass-open">(</mml:mo><mml:mrow><mml:mstyle class="text"><mml:mtext class="textsf" mathvariant="sans-serif">PPV</mml:mtext></mml:mstyle></mml:mrow><mml:mo class="MathClass-close">)</mml:mo></mml:mrow><mml:mo class="MathClass-rel">=</mml:mo><mml:mfrac><mml:mrow><mml:mstyle class="text"><mml:mtext class="textsf" mathvariant="sans-serif">TP</mml:mtext></mml:mstyle></mml:mrow><mml:mrow><mml:mstyle class="text"><mml:mtext class="textsf" mathvariant="sans-serif">TP</mml:mtext></mml:mstyle><mml:mo class="MathClass-bin">+</mml:mo><mml:mstyle class="text"><mml:mtext class="textsf" mathvariant="sans-serif">FP</mml:mtext></mml:mstyle></mml:mrow></mml:mfrac><mml:mspace width="2.77695pt" class="tmspace"/><mml:mo class="MathClass-bin">&#x022c5;</mml:mo><mml:mspace width="2.77695pt" class="tmspace"/><mml:mn>100</mml:mn><mml:mi>%</mml:mi></mml:mrow></mml:math></disp-formula></p><p><disp-formula><mml:math id="M4" name="1756-0500-5-35-i4" overflow="scroll"><mml:mrow><mml:mstyle class="text"><mml:mtext class="textsf" mathvariant="sans-serif">Negative</mml:mtext></mml:mstyle><mml:mspace width="0.3em" class="thinspace"/><mml:mstyle class="text"><mml:mtext class="textsf" mathvariant="sans-serif">Predictive</mml:mtext></mml:mstyle><mml:mspace width="0.3em" class="thinspace"/><mml:mstyle class="text"><mml:mtext class="textsf" mathvariant="sans-serif">Value</mml:mtext></mml:mstyle><mml:mspace width="0.3em" class="thinspace"/><mml:mrow><mml:mo class="MathClass-open">(</mml:mo><mml:mrow><mml:mstyle class="text"><mml:mtext class="textsf" mathvariant="sans-serif">NPV</mml:mtext></mml:mstyle></mml:mrow><mml:mo class="MathClass-close">)</mml:mo></mml:mrow><mml:mo class="MathClass-rel">=</mml:mo><mml:mfrac><mml:mrow><mml:mstyle class="text"><mml:mtext class="textsf" mathvariant="sans-serif">TN</mml:mtext></mml:mstyle></mml:mrow><mml:mrow><mml:mstyle class="text"><mml:mtext class="textsf" mathvariant="sans-serif">TN</mml:mtext></mml:mstyle><mml:mo class="MathClass-bin">+</mml:mo><mml:mstyle class="text"><mml:mtext class="textsf" mathvariant="sans-serif">FN</mml:mtext></mml:mstyle></mml:mrow></mml:mfrac><mml:mspace width="0.3em" class="thinspace"/><mml:mo class="MathClass-bin">&#x022c5;</mml:mo><mml:mspace width="0.3em" class="thinspace"/><mml:mn>100</mml:mn><mml:mi>%</mml:mi></mml:mrow></mml:math></disp-formula></p></sec></sec></sec><sec sec-type="results"><title>Results</title><p>The metrics shown in Table <xref ref-type="table" rid="T1">1</xref> quantify the performance of the algorithm. Overall, the mean sensitivity and specificity of the 30 test images was 91.0% and 86.4% respectively. Furthermore, the mean PPV and NPV of the test images was 63.3% and 94.2%. The algorithm performance depended significantly on the tumour subtype. We hypothesized that the algorithm would perform best on the superficial and nodular basal cell carcinoma subtypes, as these appear to be subjectively more "baseloid" than the infiltrative subtype. This was only partly supported by the data. The superficial subtype had the highest sensitivity (98.1%), but also the lowest specificity (82.5%). The lower specificity value resulted primarily from the extraction of the normal epidermal basal cell layer, in addition to the tumour nests. Consequently, this also resulted in a lower mean PPV (34.3%) for the superficial subtype. The infiltrative subtype had the lowest sensitivity (78.9%). On the other hand, the algorithm was more specific for the infiltrative subtype (87.2%). The algorithm performed the best with the Nodular subtype. The corresponding sensitivities and specificities were 95.8% and 89.3%, resulting in mean PPV and NPV values of 84.5% and 95.0%. A sample extraction of each subtype is shown in Figure <xref ref-type="fig" rid="F2">2</xref>.</p><table-wrap id="T1" position="float"><label>Table 1</label><caption><p>Evaluation of the tumour extraction algorithm in BCC histology slides</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Tumours</th><th align="left">n</th><th align="left">Sensitivity (%)</th><th align="left">Specificity (%)</th><th align="left">PPV (%)</th><th align="left">NPV (%)</th></tr></thead><tbody><tr><td align="left">Infiltrative</td><td align="left">10</td><td align="left">78.95</td><td align="left">87.25</td><td align="left">71.15</td><td align="left">87.88</td></tr><tr><td colspan="6"><hr/></td></tr><tr><td align="left">Superficial</td><td align="left">10</td><td align="left">98.13</td><td align="left">82.50</td><td align="left">34.34</td><td align="left">99.74</td></tr><tr><td colspan="6"><hr/></td></tr><tr><td align="left">Nodular</td><td align="left">10</td><td align="left">95.82</td><td align="left">89.31</td><td align="left">84.53</td><td align="left">94.96</td></tr><tr><td colspan="6"><hr/></td></tr><tr><td align="left">All</td><td align="left">30</td><td align="left">90.97</td><td align="left">86.35</td><td align="left">63.34</td><td align="left">94.19</td></tr></tbody></table><table-wrap-foot><p>PPV: Positive Predictive Value = [True Positive Pixels/(True Positive Pixels + False Positive Pixels)] &#x000b7; 100%; NPV: Negative Predictive Value = [True Negative Pixels/(True Negative Pixels + False Negative Pixels)] &#x000b7; 100%; Sensitivity = [True Positive Pixels/(True Positive Pixels + False Negative Pixels)] &#x000b7; 100%; Specificity = [True Negative Pixels/(True negative Pixels + False Positive Pixels)] &#x000b7; 100%</p></table-wrap-foot></table-wrap><fig id="F2" position="float"><label>Figure 2</label><caption><p><bold>Application of the tumour extraction algorithm to different basal cell carcinoma subtypes</bold>. The algorithm was applied basal cell carcinoma images of the infiltrative (<bold>A</bold>), nodular (<bold>D</bold>), and superficial (<bold>G</bold>) subtypes. The white pixels correspond to the regions identified by the algorithm as tumour nests (<bold>B, E, H</bold>). The performance of the algorithm was evaluated by identifying pixels containing true positive pixels (white), false negative pixels (blue), and false positive pixels (red) in each image (<bold>C, F, I)</bold>.</p></caption><graphic xlink:href="1756-0500-5-35-2"/></fig><p>Surprisingly, when compared to grayscale based segmentation (Table <xref ref-type="table" rid="T2">2</xref>), the use of colour deconvolution resulted in a slightly lower mean sensitivity (91.0% with colour deconvolution; 91.6% with grayscale based segmentation), but increased the mean specificity (86.4% with colour deconvolution; 74.6% with grayscale based segmentation). The use of colour deconvolution prior to segmentation resulted in an improved PPV (63.3% with colour deconvolution; 52.6% with grayscale based segmentation) and NPV (94.2% with colour deconvolution; 93.9% with grayscale based segmentation). Sample extractions with and without colour deconvolution are shown in Figure <xref ref-type="fig" rid="F3">3</xref>.</p><table-wrap id="T2" position="float"><label>Table 2</label><caption><p>Evaluation of the tumour extraction algorithm without colour deconvolution in BCC histology slides</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Tumours</th><th align="left">Sensitivity (%)</th><th align="left">Specificity (%)</th><th align="left">PPV (%)</th><th align="left">NPV (%)</th></tr></thead><tbody><tr><td align="left">Infiltrative</td><td align="left">81.25</td><td align="left">68.72</td><td align="left">53.57</td><td align="left">87.87</td></tr><tr><td colspan="5"><hr/></td></tr><tr><td align="left">Superficial</td><td align="left">98.46</td><td align="left">74.20</td><td align="left">27.34</td><td align="left">99.78</td></tr><tr><td colspan="5"><hr/></td></tr><tr><td align="left">Nodular</td><td align="left">95.11</td><td align="left">80.92</td><td align="left">76.90</td><td align="left">93.92</td></tr><tr><td colspan="5"><hr/></td></tr><tr><td align="left">All</td><td align="left">91.61</td><td align="left">74.61</td><td align="left">52.60</td><td align="left">93.86</td></tr></tbody></table><table-wrap-foot><p>PPV: Positive Predictive Value = [True Positive Pixels/(True Positive Pixels + False Positive Pixels)] &#x000b7; 100%; NPV: Negative Predictive Value = [True Negative Pixels/(True Negative Pixels + False Negative Pixels)] &#x000b7; 100%; Sensitivity = [True Positive Pixels/(True Positive Pixels + False Negative Pixels)] &#x000b7; 100%; Specificity = [True Negative Pixels/(True negative Pixels + False Positive Pixels)] &#x000b7; 100%</p></table-wrap-foot></table-wrap><fig id="F3" position="float"><label>Figure 3</label><caption><p><bold>Application of the tumour extraction algorithm with and without colour deconvolution</bold>. The algorithm was applied basal cell carcinoma images of the infiltrative (<bold>A</bold>), nodular (<bold>D</bold>), and superficial (<bold>G</bold>) subtypes. The performance of the algorithm was evaluated by identifying pixels containing true positive pixels (white), false negative pixels (blue), and false positive pixels (red) in the images pre-processed using colour deconvolution (<bold>B, E, H</bold>), and the images without colour deconvolution (<bold>C, F, I</bold>).</p></caption><graphic xlink:href="1756-0500-5-35-3"/></fig></sec><sec sec-type="discussion"><title>Discussion</title><p>This study evaluated a method for digitally extracting the tumour regions from basal cell carcinoma histopathology slides. A combination of colour deconvolution and intensity based thresholding was used with the goal of extracting the tumour nests from the image. The algorithm was evaluated with 3 separate subtypes of basal cell carcinomas: infiltrative, nodular, and superficial. For comparison, the algorithm was repeated using only grayscale based segmentation in place of the colour deconvolution step.</p><p>The performance of the algorithm varied significantly between the subtypes. The best results were achieved with the nodular subtype, while inferior performance was achieved with the superficial and infiltrative subtypes. One problem encountered with the superficial and infiltrative subtypes was the identification of false positives. This occurred in large part due to the presence of the normal epidermal basal layer in some of the slides which showed similar spectral characteristics to areas of BCC. Because the algorithm uses intensity based segmentation following the colour deconvolution step, regions with similar intensities to the tumour cells were also extracted. Lowering the threshold value would decrease the number of false positives, but would also come at the expense of lower sensitivity. Additional false positives occurred due to the presence of other basaloid elements such as skin adnexae, inflammation, and eccrine glands. A further source of false positives occurred due to blue dye used to mark the deep surgical resection margin of some specimens. Example false positives are displayed in Figure <xref ref-type="fig" rid="F4">4</xref>.</p><fig id="F4" position="float"><label>Figure 4</label><caption><p><bold>False positive regions identified by the tumour extraction algorithm</bold>. The basal cell layer, skin adnexa, and inflammation present in the original image (<bold>A</bold>) were identified as cancerous in the binary file (<bold>B</bold>), and the resulting extraction (<bold>C</bold>).</p></caption><graphic xlink:href="1756-0500-5-35-4"/></fig><p>Another challenge for digital feature extraction algorithms is false negatives. In this study, false negatives resulted mainly from two causes: poor contrast between the tumour nest and its surrounding tissue, as well as inadequate hole filling. Although contrast enhancement was performed, some of the images still contained poor contrast between the tumour and its adjacent tissue. This may have been due in part to variation in the intensities of H&#x00026;E staining of the original sections. One possible approach to this would be to explore the delineation of the tumour based on morphological features, rather than pixel intensities. One possibility would be to use the active contours method in order to evolve a curve representing the boundaries from the ROI [<xref ref-type="bibr" rid="B31">31</xref>]. Recently, this method has been explored in order to segment histology images [<xref ref-type="bibr" rid="B32">32</xref>-<xref ref-type="bibr" rid="B34">34</xref>]. One potential drawback when using active contours is that some implementations require the user to manually specify an initial boundary. Another possible approach would be to use region growing based segmentation [<xref ref-type="bibr" rid="B35">35</xref>]. This method works by adding pixels that surround, and are similar to a given seed pixel. The process is then repeated for each added pixel [<xref ref-type="bibr" rid="B18">18</xref>]. Similar to the active contours method, many region growing algorithms are not fully automated, as the given implementation may require the user's input to specify the seed for the algorithm. However, as we stated in the introduction, our intent was to examine the performance of a simple chromatin-rich segmentation algorithm and so these more complex approaches were not evaluated in the current study.</p><p>Similar to the false positives, the rate of false negatives could be decreased by changing the threshold value. Conversely, lower false negative rates could be achieved at the expense of specificity. Example false negatives are shown in Figure <xref ref-type="fig" rid="F5">5</xref>.</p><fig id="F5" position="float"><label>Figure 5</label><caption><p><bold>False negative regions identified by the tumour extraction algorithm</bold>. The ground truth dataset was determined manually (<bold>A</bold>). The white pixels correspond to the regions identified by the algorithm as tumour nests (<bold>B</bold>). The blue regions correspond to the false negative pixels identified by the algorithm (<bold>C</bold>).</p></caption><graphic xlink:href="1756-0500-5-35-5"/></fig><p>Superior results were achieved by using a colour deconvolution prior to segmentation. Although using colour deconvolution resulted in a slightly lower mean sensitivity, a significant improvement in specificity was gained. This resulted in superior PPV and NPV values. In general, the colour deconvolution decreased the incidence of false positives. This was likely a result of the stain separation achieved using the colour deconvolution plugin.</p><p>Overall, however, the sensitivities of the colour-based approach were not better than a grayscale-based thresholding approach.</p></sec><sec sec-type="conclusions"><title>Conclusions</title><p>This study reports the operational characteristics of a simple colour-based segmentation algorithm using the open-source image analysis program ImageJ. As predicted, the algorithm generally performed best with examples of the nodular basal cell carcinoma subtype. The specificity was unexpectedly low for the superficial basal cell carcinoma examples due to false positive classification of pixels associated with skin adnexae and the normal basal cell carcinoma of the epidermis. However, overall, the finding that the sensitivity of this colour-based approach was not better than a grayscale thresholding approach to the same images suggests that simple colour-based algorithms without the inclusion of more sophisticated texture feature segmentation may have limited utility.</p></sec><sec><title>Competing interests</title><p>The authors declare that they have no competing interests.</p></sec><sec><title>Authors' contributions</title><p>CN devised the original study design. KL designed the algorithm and evaluated the algorithm performance. Both authors participated in drafting the manuscript. Both authors have read and approved the final manuscript.</p></sec><sec><title>Availability of supporting data</title><p>The ImageJ algorithm we used is available as an Additional file to this manuscript.</p></sec><sec sec-type="supplementary-material"><title>Supplementary Material</title><supplementary-material content-type="local-data" id="S1"><caption><title>Additional file 1</title><p><bold>ImageJ Algorithm</bold>.</p></caption><media xlink:href="1756-0500-5-35-S1.DOC" mimetype="application" mime-subtype="msword"><caption><p>Click here for file</p></caption></media></supplementary-material></sec></body><back><sec><title>Acknowledgements</title><p>KL was supported by an O'Brien summer studentship from the University of Calgary and a research grant to CN from the University of Calgary.</p></sec><ref-list><ref id="B1"><mixed-citation publication-type="journal"><name><surname>Pantanowitz</surname><given-names>L</given-names></name><article-title>Digital images and the future of digital pathology</article-title><source>J Pathol Infor</source><year>2010</year><volume>1</volume><fpage>15</fpage><pub-id pub-id-type="doi">10.4103/2153-3539.68332</pub-id></mixed-citation></ref><ref id="B2"><mixed-citation publication-type="journal"><name><surname>Gabril</surname><given-names>MY</given-names></name><name><surname>Yousef</surname><given-names>GM</given-names></name><article-title>Informatics for practicing anatomical pathologists: marking a new era in pathology practice</article-title><source>Mod Pathol</source><year>2010</year><volume>23</volume><fpage>349</fpage><lpage>358</lpage><pub-id pub-id-type="doi">10.1038/modpathol.2009.190</pub-id><pub-id pub-id-type="pmid">20081805</pub-id></mixed-citation></ref><ref id="B3"><mixed-citation publication-type="journal"><name><surname>Dawson</surname><given-names>AE</given-names></name><article-title>Can we change the way we screen?: the ThinPrep Imaging System</article-title><source>Cancer</source><year>2004</year><volume>102</volume><fpage>340</fpage><lpage>4</lpage><pub-id pub-id-type="doi">10.1002/cncr.20721</pub-id><pub-id pub-id-type="pmid">15540250</pub-id></mixed-citation></ref><ref id="B4"><mixed-citation publication-type="journal"><name><surname>Petushi</surname><given-names>S</given-names></name><name><surname>Garcia</surname><given-names>FU</given-names></name><name><surname>Haber</surname><given-names>MM</given-names></name><name><surname>Katsinis</surname><given-names>C</given-names></name><name><surname>Tozeren</surname><given-names>A</given-names></name><article-title>Large-scale computations on histology images reveal grade-differentiating parameters for breast cancer</article-title><source>BMC Med Imaging</source><year>2006</year><volume>6</volume><fpage>14</fpage><pub-id pub-id-type="doi">10.1186/1471-2342-6-14</pub-id><pub-id pub-id-type="pmid">17069651</pub-id></mixed-citation></ref><ref id="B5"><mixed-citation publication-type="journal"><name><surname>Kara&#x000e7;ali</surname><given-names>B</given-names></name><name><surname>T&#x000f6;zeren</surname><given-names>A</given-names></name><article-title>Automated detection of regions of interest for tissue microarray experiments: an image texture analysis</article-title><source>BMC Med Imaging</source><year>2007</year><volume>7</volume><fpage>2</fpage><pub-id pub-id-type="doi">10.1186/1471-2342-7-2</pub-id><pub-id pub-id-type="pmid">17349041</pub-id></mixed-citation></ref><ref id="B6"><mixed-citation publication-type="journal"><name><surname>Hall</surname><given-names>BH</given-names></name><name><surname>Ianosi-Irimie</surname><given-names>M</given-names></name><name><surname>Javidian</surname><given-names>P</given-names></name><name><surname>Chen</surname><given-names>W</given-names></name><name><surname>Ganesan</surname><given-names>S</given-names></name><name><surname>Foran</surname><given-names>DJ</given-names></name><article-title>Computer-assisted assessment of the human epidermal growth factor receptor 2 immunohistochemical assay in imaged histologic sections using a membrane isolation algorithm and quantitative analysis of positive controls</article-title><source>BMC Med Imaging</source><year>2008</year><volume>8</volume><fpage>11</fpage><pub-id pub-id-type="doi">10.1186/1471-2342-8-11</pub-id><pub-id pub-id-type="pmid">18534031</pub-id></mixed-citation></ref><ref id="B7"><mixed-citation publication-type="journal"><name><surname>Safadi</surname><given-names>RA</given-names></name><name><surname>Musleh</surname><given-names>AS</given-names></name><name><surname>Al-Khateeb</surname><given-names>TH</given-names></name><name><surname>Al-Hadi Hamasha</surname><given-names>A</given-names></name><article-title>Analysis of immunohistochemical expression of k19 in oral epithelial dysplasia and oral squamous cell carcinoma using color deconvolution-image analysis method</article-title><source>Head and neck Pathol</source><year>2010</year><volume>4</volume><fpage>282</fpage><lpage>9</lpage><pub-id pub-id-type="doi">10.1007/s12105-010-0210-6</pub-id><pub-id pub-id-type="pmid">20882374</pub-id></mixed-citation></ref><ref id="B8"><mixed-citation publication-type="journal"><name><surname>LeAnder</surname><given-names>R</given-names></name><name><surname>Chindam</surname><given-names>P</given-names></name><name><surname>Das</surname><given-names>M</given-names></name><name><surname>Umbaugh</surname><given-names>SE</given-names></name><article-title>Differentiation of melanoma from benign mimics using the relative-color method</article-title><source>Ski Res Technol</source><year>2010</year><volume>16</volume><fpage>297</fpage><lpage>304</lpage></mixed-citation></ref><ref id="B9"><mixed-citation publication-type="journal"><name><surname>Iyatomi</surname><given-names>H</given-names></name><name><surname>Oka</surname><given-names>H</given-names></name><name><surname>Celebi</surname><given-names>ME</given-names></name><name><surname>Hashimoto</surname><given-names>M</given-names></name><name><surname>Hagiwara</surname><given-names>M</given-names></name><name><surname>Tanaka</surname><given-names>M</given-names></name><name><surname>Ogawa</surname><given-names>K</given-names></name><article-title>An improved Internet-based melanoma screening system with dermatologist-like tumor area extraction algorithm</article-title><source>Comput Med Imaging and Graphics</source><year>2008</year><volume>32</volume><fpage>566</fpage><lpage>79</lpage><pub-id pub-id-type="doi">10.1016/j.compmedimag.2008.06.005</pub-id></mixed-citation></ref><ref id="B10"><mixed-citation publication-type="journal"><name><surname>Abbas</surname><given-names>Q</given-names></name><name><surname>Celebi</surname><given-names>ME</given-names></name><name><surname>Garc&#x000ed;a</surname><given-names>IF</given-names></name><article-title>Skin tumor area extraction using an improved dynamic programming approach</article-title><source>Skin Res Technol</source><year>2011</year><volume>11</volume><fpage>1</fpage><lpage>10</lpage></mixed-citation></ref><ref id="B11"><mixed-citation publication-type="journal"><name><surname>Silveira</surname><given-names>M</given-names></name><name><surname>Nascimento</surname><given-names>JC</given-names></name><name><surname>Marques</surname><given-names>JS</given-names></name><name><surname>Marcal</surname><given-names>ARS</given-names></name><name><surname>Mendonca</surname><given-names>T</given-names></name><name><surname>Yamauchi</surname><given-names>S</given-names></name><name><surname>Maeda</surname><given-names>J</given-names></name><name><surname>Rozeira</surname><given-names>J</given-names></name><article-title>Comparison of segmentation methods for melanoma diagnosis in dermoscopy images</article-title><source>IEEE J Sel Topics in Signal Process</source><year>2009</year><volume>3</volume><fpage>35</fpage><lpage>45</lpage></mixed-citation></ref><ref id="B12"><mixed-citation publication-type="journal"><name><surname>Miller</surname><given-names>SJ</given-names></name><article-title>Biology of basal cell carcinoma (part I)</article-title><source>J Am Acad Dermatol</source><year>1991</year><volume>24</volume><fpage>1</fpage><lpage>13</lpage><pub-id pub-id-type="doi">10.1016/0190-9622(91)70001-I</pub-id><pub-id pub-id-type="pmid">1999506</pub-id></mixed-citation></ref><ref id="B13"><mixed-citation publication-type="journal"><name><surname>Miller</surname><given-names>DL</given-names></name><name><surname>Weinstock</surname><given-names>MA</given-names></name><article-title>Nonmelanoma skin cancer in the United States: Incidence</article-title><source>J Am Acad Dermatol</source><year>1994</year><volume>30</volume><fpage>774</fpage><lpage>778</lpage><pub-id pub-id-type="doi">10.1016/S0190-9622(08)81509-5</pub-id><pub-id pub-id-type="pmid">8176018</pub-id></mixed-citation></ref><ref id="B14"><mixed-citation publication-type="journal"><name><surname>Guti&#x000e9;rrez</surname><given-names>R</given-names></name><name><surname>G&#x000f3;mez</surname><given-names>F</given-names></name><name><surname>Roa-Pe&#x000f1;a</surname><given-names>L</given-names></name><name><surname>Romero</surname><given-names>E</given-names></name><article-title>A supervised visual model for finding regions of interest in basal cell carcinoma images</article-title><source>Diagn Pathol</source><year>2011</year><volume>6</volume><fpage>26</fpage><pub-id pub-id-type="doi">10.1186/1746-1596-6-26</pub-id><pub-id pub-id-type="pmid">21447178</pub-id></mixed-citation></ref><ref id="B15"><mixed-citation publication-type="book"><name><surname>Dougherty</surname><given-names>G</given-names></name><article-title>Image segmentation</article-title><source>Digital Image Process Med Appl</source><year>2009</year><edition>1</edition><publisher-name>Cambridge: Cambridge University Press</publisher-name><fpage>309</fpage><lpage>312</lpage></mixed-citation></ref><ref id="B16"><mixed-citation publication-type="book"><name><surname>Russ</surname><given-names>JC</given-names></name><article-title>Segmentation and thresholding</article-title><source>The Image Processing Handbook</source><year>2002</year><edition>4</edition><publisher-name>Boca Raton: CRC Press</publisher-name><fpage>333</fpage><lpage>335</lpage></mixed-citation></ref><ref id="B17"><mixed-citation publication-type="book"><name><surname>Dougherty</surname><given-names>G</given-names></name><article-title>Image segmentation</article-title><source>Digital Image Processing for Medical Applications</source><year>2009</year><edition>1</edition><publisher-name>Cambridge: Cambridge University Press</publisher-name><fpage>317</fpage><lpage>321</lpage></mixed-citation></ref><ref id="B18"><mixed-citation publication-type="book"><name><surname>Dougherty</surname><given-names>G</given-names></name><article-title>Image segmentation</article-title><source>Digital Image Processing for Medical Applications</source><year>2009</year><edition>1</edition><publisher-name>Cambridge: Cambridge University Press</publisher-name><fpage>321</fpage><lpage>326</lpage></mixed-citation></ref><ref id="B19"><mixed-citation publication-type="book"><name><surname>Dougherty</surname><given-names>G</given-names></name><article-title>Image restoration</article-title><source>Digital Image Processing for Medical Applications</source><year>2009</year><edition>1</edition><publisher-name>Cambridge: Cambridge University Press</publisher-name><fpage>52</fpage><lpage>253</lpage></mixed-citation></ref><ref id="B20"><mixed-citation publication-type="journal"><name><surname>Ruifrok</surname><given-names>AC</given-names></name><name><surname>Johnston</surname><given-names>DA</given-names></name><article-title>Quantification of histochemical staining by color deconvolution</article-title><source>Anal Quant Cytol Histol</source><year>2001</year><volume>23</volume><fpage>291</fpage><lpage>299</lpage><pub-id pub-id-type="pmid">11531144</pub-id></mixed-citation></ref><ref id="B21"><mixed-citation publication-type="journal"><name><surname>Konsti</surname><given-names>J</given-names></name><name><surname>Lundin</surname><given-names>M</given-names></name><name><surname>Joensuu</surname><given-names>H</given-names></name><name><surname>Lehtim&#x000e4;ki</surname><given-names>T</given-names></name><name><surname>Sihto</surname><given-names>H</given-names></name><name><surname>Holli</surname><given-names>K</given-names></name><name><surname>Turpeenniemi-Hujanen</surname><given-names>T</given-names></name><name><surname>Kataja</surname><given-names>V</given-names></name><name><surname>Sailas</surname><given-names>L</given-names></name><name><surname>Isola</surname><given-names>J</given-names></name><name><surname>Lundin</surname><given-names>J</given-names></name><article-title>Development and evaluation of a virtual microscopy application for automated assessment of Ki-67 expression in breast cancer</article-title><source>BMC Clin Pathol</source><year>2011</year><volume>11</volume><fpage>3</fpage><pub-id pub-id-type="doi">10.1186/1472-6890-11-3</pub-id><pub-id pub-id-type="pmid">21262004</pub-id></mixed-citation></ref><ref id="B22"><mixed-citation publication-type="journal"><name><surname>Shah</surname><given-names>M</given-names></name><name><surname>Bhoumik</surname><given-names>A</given-names></name><name><surname>Goel</surname><given-names>V</given-names></name><name><surname>Dewing</surname><given-names>A</given-names></name><name><surname>Breitwieser</surname><given-names>W</given-names></name><name><surname>Kluger</surname><given-names>H</given-names></name><name><surname>Krajewski</surname><given-names>S</given-names></name><name><surname>Krajewska</surname><given-names>M</given-names></name><name><surname>DeHart</surname><given-names>J</given-names></name><name><surname>Lau</surname><given-names>E</given-names></name><name><surname>Kallenberg</surname><given-names>DM</given-names></name><name><surname>Jeong</surname><given-names>H</given-names></name><name><surname>Eroshkin</surname><given-names>A</given-names></name><name><surname>Bennett</surname><given-names>DC</given-names></name><name><surname>Chin</surname><given-names>L</given-names></name><name><surname>Bosenberg</surname><given-names>M</given-names></name><name><surname>Jones</surname><given-names>N</given-names></name><name><surname>Ronai</surname><given-names>ZA</given-names></name><article-title>A Role for ATF2 in Regulating MITF and Melanoma Development</article-title><source>PLoS Genet</source><year>2010</year><volume>6</volume><fpage>e1001258</fpage><pub-id pub-id-type="doi">10.1371/journal.pgen.1001258</pub-id><pub-id pub-id-type="pmid">21203491</pub-id></mixed-citation></ref><ref id="B23"><mixed-citation publication-type="journal"><name><surname>Wang</surname><given-names>CW</given-names></name><article-title>Robust automated tumour segmentation on histological and immunohistochemical tissue images</article-title><source>PLoS One</source><year>2011</year><volume>6</volume><fpage>e15818</fpage><pub-id pub-id-type="doi">10.1371/journal.pone.0015818</pub-id><pub-id pub-id-type="pmid">21386898</pub-id></mixed-citation></ref><ref id="B24"><mixed-citation publication-type="other"><name><surname>Collins</surname><given-names>T</given-names></name><source>ImageJ for Microsc BioTech</source><year>2007</year><volume>43</volume><fpage>S25</fpage><lpage>S30</lpage></mixed-citation></ref><ref id="B25"><mixed-citation publication-type="journal"><name><surname>Abr&#x000e0;moff</surname><given-names>MD</given-names></name><name><surname>Magalhaes</surname><given-names>P</given-names></name><name><surname>Ram</surname><given-names>S</given-names></name><article-title>Image processing with ImageJ</article-title><source>Biophotonics Int</source><year>2004</year><volume>11</volume><fpage>36</fpage><lpage>43</lpage></mixed-citation></ref><ref id="B26"><mixed-citation publication-type="other"><name><surname>Landini</surname><given-names>G</given-names></name><article-title>Colour deconvolution plugin v 1.5</article-title><ext-link ext-link-type="uri" xlink:href="http://www.dentistry.bham.ac.uk/landinig/software/cdeconv/cdeconv.html">http://www.dentistry.bham.ac.uk/landinig/software/cdeconv/cdeconv.html</ext-link></mixed-citation></ref><ref id="B27"><mixed-citation publication-type="other"><article-title>The ImageJ information and documentation portal</article-title><ext-link ext-link-type="uri" xlink:href="http://imagejdocu.tudor.lu/doku.php?id=faq:technical:what_is_the_algorithm_used_in_automatic_thresholding">http://imagejdocu.tudor.lu/doku.php?id=faq:technical:what_is_the_algorithm_used_in_automatic_thresholding</ext-link></mixed-citation></ref><ref id="B28"><mixed-citation publication-type="journal"><name><surname>Zhang</surname><given-names>H</given-names></name><name><surname>Fritts</surname><given-names>J</given-names></name><name><surname>Goldman</surname><given-names>S</given-names></name><article-title>Image segmentation evaluation: A survey of unsupervised methods</article-title><source>Comput Vision and Image Understanding</source><year>2008</year><volume>110</volume><fpage>260</fpage><lpage>280</lpage><pub-id pub-id-type="doi">10.1016/j.cviu.2007.08.003</pub-id></mixed-citation></ref><ref id="B29"><mixed-citation publication-type="journal"><name><surname>Cardoso</surname><given-names>JS</given-names></name><name><surname>Corte-Real</surname><given-names>L</given-names></name><article-title>Toward a generic evaluation of image segmentation</article-title><source>IEEE Trans Image Process</source><year>2005</year><volume>14</volume><fpage>1773</fpage><lpage>82</lpage><pub-id pub-id-type="pmid">16279178</pub-id></mixed-citation></ref><ref id="B30"><mixed-citation publication-type="journal"><name><surname>Udupa</surname><given-names>JK</given-names></name><name><surname>Leblanc</surname><given-names>VR</given-names></name><name><surname>Zhuge</surname><given-names>Y</given-names></name><name><surname>Imielinska</surname><given-names>C</given-names></name><name><surname>Schmidt</surname><given-names>H</given-names></name><name><surname>Currie</surname><given-names>LM</given-names></name><name><surname>Hirsch</surname><given-names>BE</given-names></name><name><surname>Woodburn</surname><given-names>J</given-names></name><article-title>A framework for evaluating image segmentation algorithms</article-title><source>Comput Med Imaging and Graphics</source><year>2006</year><volume>30</volume><fpage>75</fpage><lpage>87</lpage><pub-id pub-id-type="doi">10.1016/j.compmedimag.2005.12.001</pub-id></mixed-citation></ref><ref id="B31"><mixed-citation publication-type="journal"><name><surname>Kass</surname><given-names>M</given-names></name><name><surname>Witkin</surname><given-names>A</given-names></name><name><surname>Terzopoulos</surname><given-names>D</given-names></name><article-title>Snakes: Active contour models</article-title><source>Int J Comput Vis</source><year>1988</year><volume>1</volume><fpage>321</fpage><lpage>331</lpage><pub-id pub-id-type="doi">10.1007/BF00133570</pub-id></mixed-citation></ref><ref id="B32"><mixed-citation publication-type="journal"><name><surname>Xu</surname><given-names>J</given-names></name><name><surname>Janowczyk</surname><given-names>A</given-names></name><name><surname>Chandran</surname><given-names>S</given-names></name><name><surname>Madabhushi</surname><given-names>A</given-names></name><article-title>A high-throughput active contour scheme for segmentation of histopathological imagery</article-title><source>Med Image Anal</source><year>2011</year><volume>15</volume><fpage>851</fpage><lpage>62</lpage><pub-id pub-id-type="doi">10.1016/j.media.2011.04.002</pub-id><pub-id pub-id-type="pmid">21570336</pub-id></mixed-citation></ref><ref id="B33"><mixed-citation publication-type="journal"><name><surname>Fatakdawala</surname><given-names>H</given-names></name><name><surname>Xu</surname><given-names>J</given-names></name><name><surname>Basavanhally</surname><given-names>A</given-names></name><name><surname>Bhanot</surname><given-names>G</given-names></name><name><surname>Ganesan</surname><given-names>S</given-names></name><name><surname>Feldman</surname><given-names>M</given-names></name><name><surname>Tomaszewski</surname><given-names>JE</given-names></name><name><surname>Madabhushi</surname><given-names>A</given-names></name><article-title>Expectation-maximization-driven geodesic active contour with overlap resolution (EMaGACOR): Application to lymphocyte segmentation on breast cancer histopathology</article-title><source>IEEE Trans Biomed Eng</source><year>2010</year><volume>57</volume><fpage>1676</fpage><lpage>89</lpage><pub-id pub-id-type="pmid">20172780</pub-id></mixed-citation></ref><ref id="B34"><mixed-citation publication-type="journal"><name><surname>Hiremath</surname><given-names>PS</given-names></name><name><surname>Iranna</surname><given-names>YH</given-names></name><article-title>Fuzzy rule based classification of microscopic images of squamous cell carcinoma of esophagus</article-title><source>Int J Comput Appl</source><year>2011</year><volume>25</volume><fpage>30</fpage><lpage>33</lpage></mixed-citation></ref><ref id="B35"><mixed-citation publication-type="journal"><name><surname>Mat-Isa</surname><given-names>N</given-names></name><name><surname>Mashor</surname><given-names>M</given-names></name><name><surname>Othman</surname><given-names>N</given-names></name><article-title>Seeded region growing features extraction algorithm; its potential use in improving screening for cervical cancer</article-title><source>Int J Comput Internet and Manage</source><year>2005</year><volume>13</volume><fpage>61</fpage><lpage>70</lpage></mixed-citation></ref></ref-list></back></article>