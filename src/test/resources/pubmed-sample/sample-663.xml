
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">J Transl Med</journal-id><journal-id journal-id-type="iso-abbrev">J Transl Med</journal-id><journal-title-group><journal-title>Journal of Translational Medicine</journal-title></journal-title-group><issn pub-type="epub">1479-5876</issn><publisher><publisher-name>BioMed Central</publisher-name><publisher-loc>London</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">30602368</article-id><article-id pub-id-type="pmc">6317183</article-id><article-id pub-id-type="publisher-id">1758</article-id><article-id pub-id-type="doi">10.1186/s12967-018-1758-2</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research</subject></subj-group></article-categories><title-group><article-title>Prediction of postoperative complications of pediatric cataract patients using data mining</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Zhang</surname><given-names>Kai</given-names></name><address><email>Hugo88315@163.com</email></address><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Liu</surname><given-names>Xiyang</given-names></name><address><phone>+86-029-88204612</phone><email>xyliu@xidian.edu.cn</email><email>xyliuxidian@163.com</email></address><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff3">3</xref><xref ref-type="aff" rid="Aff4">4</xref></contrib><contrib contrib-type="author"><name><surname>Jiang</surname><given-names>Jiewei</given-names></name><address><email>jiangjw924@126.com</email></address><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author"><name><surname>Li</surname><given-names>Wangting</given-names></name><address><email>liwangting@gzzoc.com</email></address><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author"><name><surname>Wang</surname><given-names>Shuai</given-names></name><address><email>shuai_wang93@163.com</email></address><xref ref-type="aff" rid="Aff4">4</xref></contrib><contrib contrib-type="author"><name><surname>Liu</surname><given-names>Lin</given-names></name><address><email>1329611557@qq.com</email></address><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author"><name><surname>Zhou</surname><given-names>Xiaojing</given-names></name><address><email>zhxjxian@163.com</email></address><xref ref-type="aff" rid="Aff5">5</xref></contrib><contrib contrib-type="author"><name><surname>Wang</surname><given-names>Liming</given-names></name><address><email>wanglm@mail.xidian.edu.cn</email></address><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff3">3</xref><xref ref-type="aff" rid="Aff4">4</xref></contrib><aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0001 0707 115X</institution-id><institution-id institution-id-type="GRID">grid.440736.2</institution-id><institution>School of Computer Science and Technology, </institution><institution>Xidian University, </institution></institution-wrap>No.2 South Taibai Rd, Xi&#x02019;an, 710071 China </aff><aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0001 2360 039X</institution-id><institution-id institution-id-type="GRID">grid.12981.33</institution-id><institution>State Key Laboratory of Ophthalmology, Zhongshan Ophthalmic Center, </institution><institution>Sun Yat-sen University, </institution></institution-wrap>Guangzhou, 510060 China </aff><aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0001 0707 115X</institution-id><institution-id institution-id-type="GRID">grid.440736.2</institution-id><institution>Institute of Software Engineering, </institution><institution>Xidian University, </institution></institution-wrap>Xi&#x02019;an, 710071 China </aff><aff id="Aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0001 0707 115X</institution-id><institution-id institution-id-type="GRID">grid.440736.2</institution-id><institution>School of Software, </institution><institution>Xidian University, </institution></institution-wrap>Xi&#x02019;an, 710071 China </aff><aff id="Aff5"><label>5</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0001 0307 1240</institution-id><institution-id institution-id-type="GRID">grid.440588.5</institution-id><institution>School of Computer Science, </institution><institution>Northwestern Polytechnical University, </institution></institution-wrap>Xi&#x02019;an, 710072 China </aff></contrib-group><pub-date pub-type="epub"><day>3</day><month>1</month><year>2019</year></pub-date><pub-date pub-type="pmc-release"><day>3</day><month>1</month><year>2019</year></pub-date><pub-date pub-type="collection"><year>2019</year></pub-date><volume>17</volume><elocation-id>2</elocation-id><history><date date-type="received"><day>1</day><month>10</month><year>2018</year></date><date date-type="accepted"><day>21</day><month>12</month><year>2018</year></date></history><permissions><copyright-statement>&#x000a9; The Author(s) 2019</copyright-statement><license license-type="OpenAccess"><license-p><bold>Open Access</bold>This article is distributed under the terms of the Creative Commons Attribution 4.0 International License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted use, distribution, and reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated.</license-p></license></permissions><abstract id="Abs1"><sec><title>Background</title><p id="Par1">The common treatment for pediatric cataracts is to replace the cloudy lens with an artificial one. However, patients may suffer complications (severe lens proliferation into the visual axis and abnormal high intraocular pressure; SLPVA and AHIP) within 1&#x000a0;year after surgery and factors causing these complications are unknown.</p></sec><sec><title>Methods</title><p id="Par2">Apriori algorithm is employed to find association rules related to complications. We use random forest (RF) and Na&#x000ef;ve Bayesian (NB) to predict the complications with datasets preprocessed by SMOTE (synthetic minority oversampling technique). Genetic feature selection is exploited to find real features related to complications.</p></sec><sec><title>Results</title><p id="Par3">Average classification accuracies in three binary classification problems are over 75%. Second, the relationship between the classification performance and the number of random forest tree is studied. Results show except for gender and age at surgery (AS); other attributes are related to complications. Except for the secondary IOL placement, operation mode, AS and area of cataracts; other attributes are related to SLPVA. Except for the gender, operation mode, and laterality; other attributes are related to the AHIP. Next, the association rules related to the complications are mined out. Then additional 50 data were used to test the performance of RF and NB, both of then obtained the accuracies of over 65% for three classification problems. Finally, we developed a webserver to assist doctors.</p></sec><sec><title>Conclusions</title><p id="Par4">The postoperative complications of pediatric cataracts patients can be predicted. Then the factors related to the complications are found. Finally, the association rules that is about the complications can provide reference to doctors.</p></sec><sec><title>Electronic supplementary material</title><p>The online version of this article (10.1186/s12967-018-1758-2) contains supplementary material, which is available to authorized users.</p></sec></abstract><kwd-group xml:lang="en"><title>Keywords</title><kwd>Random forest</kwd><kwd>Na&#x000ef;ve Bayesian</kwd><kwd>Association rules mining</kwd><kwd>Genetic feature selection</kwd><kwd>Medical decision making system</kwd></kwd-group><funding-group><award-group><funding-source><institution>NSFC</institution></funding-source><award-id>91546101</award-id><award-id>61472311</award-id><principal-award-recipient><name><surname>Liu</surname><given-names>Xiyang</given-names></name></principal-award-recipient></award-group></funding-group><funding-group><award-group><funding-source><institution>Guangdong Provincial Natural Science Foundation</institution></funding-source><award-id>YQ2015006</award-id><award-id>2014TQ01R573</award-id><award-id>2013B020400003</award-id><principal-award-recipient><name><surname>Zhang</surname><given-names>Kai</given-names></name></principal-award-recipient></award-group></funding-group><funding-group><award-group><funding-source><institution>National Key Research and Development Program of China</institution></funding-source><award-id>2018YFC0116500</award-id><principal-award-recipient><name><surname>Liu</surname><given-names>Xiyang</given-names></name></principal-award-recipient></award-group></funding-group><custom-meta-group><custom-meta><meta-name>issue-copyright-statement</meta-name><meta-value>&#x000a9; The Author(s) 2019</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="Sec1"><title>Background</title><p id="Par10">The big data era for medicine is coming. Traditional statistical methods cannot effectively discover hidden laws from numerous medical records, whereas data mining [<xref ref-type="bibr" rid="CR1">1</xref>] and machine learning [<xref ref-type="bibr" rid="CR2">2</xref>], the most promising techniques, can tackle this problem. To investigate the application of data mining and machine learning on clinical records, we focus on pediatric cataracts, which can cause children blindness [<xref ref-type="bibr" rid="CR3">3</xref>]. We obtained the detailed diagnosis and treatment information of 321 patients from one of the largest pediatric cataract databases (CCPMOH) [<xref ref-type="bibr" rid="CR4">4</xref>] and evaluated the disease development in patients.</p><p id="Par11">For children under age of two, pediatric cataracts prevent the light from penetrating into eyes and also delay the development of optic nerve [<xref ref-type="bibr" rid="CR5">5</xref>]. Moreover, it is difficult for both patients and their parents to realize that children are already developing this disease, therefore, subsequent treatment is usually unfortunately delayed. Even if treatment is thankfully given, some unexpected complications (severe lens proliferation into the visual axis and abnormal high intraocular pressure) still arise after such treatment of replacing cloudy lens with artificial ones. Worse still, why and how these complications turn up are unknown according to the present studies. This study aims to adopt some data mining and machine learning techniques to predict these complications automatically within 1&#x000a0;year after surgery and determine which factors are more related to the complications. Because the heterogeneity of different patients is common in many diseases [<xref ref-type="bibr" rid="CR6">6</xref>&#x02013;<xref ref-type="bibr" rid="CR8">8</xref>] and datasets that cover this disease are rare, this problem is difficult to tackle. Doctors and researchers required to circumvent this problem.</p><p id="Par12">Many achievements have been made regarding the application of data mining and machine learning in the field of medical records. For example, Dheeraj Raju et al. used random forest to explore the factors influencing pressure ulcers and built a predictive model that is useful for doctors to predict the complication of this disease with the data collected over time [<xref ref-type="bibr" rid="CR9">9</xref>]. S&#x000f3;nia Pereira et al. used obstetric and pregnancy factors to predict the appropriate delivery type to provide service of high quality, and to decide how to take care of pregnant women and newborn babies [<xref ref-type="bibr" rid="CR10">10</xref>]. Aljumah et al. collected data from WHO (World Health Organization) to study the effectiveness of different treatment types with consideration of the age factor [<xref ref-type="bibr" rid="CR11">11</xref>]. The results show that younger patients should not take medicine immediately to avoid side effects and older patients must take medicine to relieve sickness. Somanchi et al. applied SVM (support vector machine) and logistic regression to predict cardiac arrest in the future with the data from medical records. The result obtained from these methods is better than the results of previous methods and tools [<xref ref-type="bibr" rid="CR12">12</xref>]. All of the above examples show that data mining is a powerful tool to study the medical data and the application of data mining techniques will produce some desirable results.</p><p id="Par13">Inspired by the above researches, we attempted to mine meaningful knowledge from medical records of pediatric cataracts patients and then developed a medical decision making system to help doctors with predicting the complications of pediatric cataract patients. To study which factors contribute to the complications, some pairs of discriminant association rules are mined out using Apriori algorithm with preprocessed dataset. The antecedents of the association rules are combinations of various factors. The consequents of these association rules are whether a patient will have complications or a specific type of complication. According to the characteristics of the dataset, we used a simple discretization method and SMOTE (synthetic minority oversampling technique) to preprocess the dataset. Subsequently the number of positive samples (samples with complications or specific complication) was close to the number of negative samples (samples without complication or specific complication). Then the random forest and na&#x000ef;ve Bayes classifier were used to predict whether patients would be affected by complications of different levels. Experimental result shows that random forest and Na&#x000ef;ve Bayesian achieve accuracies which are above 76% and 75% in three binary classification problems [whether a patient suffers from complications (severe lens proliferation into the visual axis (SLPVA) and abnormal high intraocular pressure (AHIP)]; whether a patient suffers from the SLPVA; whether a patient suffers from AHIP). Then the number of trees of the random forest is investigated to find the most suitable number of trees to optimize the performance of random forest. The genetic feature selection was employed to find out which factors exactly caused the complications. Besides, we used additional 50 data to test the performance of random forest and Na&#x000ef;ve Bayesian classifier, and both of them reach 65% for three classification problems. Finally, we exploited the random forest and association rules mining in the present research to construct an automatic complication prediction system for pediatric cataract patients so that patients with different degrees of complication can be warned and treated earlier.</p></sec><sec id="Sec2"><title>Methods</title><p id="Par14">The dataset used in the current research is from Zhongshan Ophthalmic Center, Sun Yat-sen University, which is the most professional ophthalmic hospital in China and has set up the state of art ophthalmology laboratory [<xref ref-type="bibr" rid="CR13">13</xref>]. There are a total of 321 samples in the dataset, where 26 samples suffer from SLPVA and AHIP simultaneously; 69 patients only suffer from SLPVA; 84 patients only suffer from AHIP, and 194 patients have no complication after surgery. In addition, the detailed information about all the attributes and their possible values are shown in Table&#x000a0;<xref rid="Tab1" ref-type="table">1</xref>.<table-wrap id="Tab1"><label>Table&#x000a0;1</label><caption><p>The specification of attributes in dataset</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">NO. of Attribute (attribute name)</th><th align="left">Values</th></tr></thead><tbody><tr><td align="left">1. Gender</td><td align="left">Male, female</td></tr><tr><td align="left">2. Secondary IOL placement</td><td align="left">Yes, no (primary IOL placement)</td></tr><tr><td align="left">3. Operation mode</td><td align="left">Lens aspiration (I/A), lens aspiration with posterior continuous curvilinear capsulorhexis (I/A&#x02009;+&#x02009;PCCC), lens aspiration with posterior continuous curvilinear capsulorhexis and anterior vitrectomy (I/A&#x02009;+&#x02009;PCCC&#x02009;+&#x02009;A-Vit)</td></tr><tr><td align="left">4. Laterality</td><td align="left">Unilateral cataracts, bilateral cataracts</td></tr><tr><td align="left">5. Age at surgery (AS)</td><td align="left">1, 2, 3, 4, 5, 6, 7</td></tr><tr><td align="left">6. Area of cataracts (AC)</td><td align="left">Large, small</td></tr><tr><td align="left">7. Density of cataracts (DC)</td><td align="left">Dense, sloppy</td></tr><tr><td align="left">8. Position of cataracts (PC)</td><td align="left">Covering the central area of lens, not covering the central area of lens</td></tr><tr><td align="left">9. Nystagmus</td><td align="left">Yes, no</td></tr><tr><td align="left">10. Microphthalmia</td><td align="left">Yes, no</td></tr><tr><td align="left">11. Microcornea</td><td align="left">Yes, no</td></tr><tr><td align="left">12. Persistent hyperplastic primary vitreous (PHPV)</td><td align="left">Yes, no</td></tr></tbody></table></table-wrap>
</p><p id="Par15">Moreover, the sixth, seventh and eighth attributes in Table&#x000a0;<xref rid="Tab1" ref-type="table">1</xref> are marked as the evaluation standards of the severity of pediatric cataracts, which are proposed by pediatric ophthalmologist with over 5&#x000a0;years of working experience in Zhongshan Ophthalmic Center. These three evaluation standards can portray the severity based on the morphology of the cataracts, where the density of the cataract can be classified as dense or sloppy, the spreading area of cataract can be expressed as big or small, and the relative position of the cataract can be assessed by whether focus covers the central area of the lens. Previous work of our team completed the grading (severity evaluation) of pediatric cataracts from these three aspects and made some progress [<xref ref-type="bibr" rid="CR14">14</xref>], but the accuracy still cannot reach 100%. Therefore, we invite pediatric ophthalmologist with over 5&#x000a0;years of working experience to assess the three attributes of these samples in terms of the slit lamp images of patients. The difference among the three grading standards can be illustrated by Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref>.<fig id="Fig1"><label>Fig.&#x000a0;1</label><caption><p>Three grading standards of severity of pediatric cataracts. <bold>a</bold> the area of cataract is small; <bold>b</bold> the area of cataract is large; <bold>c</bold> the density of the cataract is sloppy; <bold>d</bold> the density of the cataract is dense; <bold>e</bold> the cataract covers the central area of lens; <bold>f</bold> the cataract does not covering the central area of lens</p></caption><graphic xlink:href="12967_2018_1758_Fig1_HTML" id="MO1"/></fig>
</p><p id="Par16">In addition, according to relevant literature [<xref ref-type="bibr" rid="CR15">15</xref>], the surgery age is particularly important in the development of the illness. Finally, according to the expert knowledge of three experienced ocular doctors, the operation age for all of the patients is discretized into seven sections: [0, 3], [4, 6], [7, 9], [10, 12], [13, 18], [19, 24], [&#x0003e;&#x02009;24] (the unit is month) to facilitate classification. Except for the first and fifth attributes, the remaining attributes in Table&#x000a0;<xref rid="Tab1" ref-type="table">1</xref> are recorded by doctors.</p><p id="Par17">In current research, there are three main classification problems in this research: whether suffer from complications; whether suffer from SLPVA; whether suffer from AHIP. Therefore, the original dataset were decomposed into three sub datasets accordingly. Because of the classification problems in this research are non-numerical classification problems, random forest and Na&#x000ef;ve Bayesian classifier which can tackle non-numerical classification problems were selected to complete classification tasks. Additionally, the mechanism of these two classification methods are pretty easy to understand and there are so many packages can be directly used to implement.</p><sec id="Sec3"><title>Overview of methods</title><p id="Par18">There are some common ways to tackle an imbalanced dataset, such as over sampling [<xref ref-type="bibr" rid="CR16">16</xref>] (e.g., SMOTE [<xref ref-type="bibr" rid="CR17">17</xref>]), under sampling [<xref ref-type="bibr" rid="CR18">18</xref>] (e.g., clustering based under sampling [<xref ref-type="bibr" rid="CR19">19</xref>]) and cost sensitive classification [<xref ref-type="bibr" rid="CR20">20</xref>, <xref ref-type="bibr" rid="CR21">21</xref>]. Cost-sensitive method requires a cost matrix or a modified algorithm mechanism and architecture, which is more difficult for specific application. Therefore, SMOTE (Synthetic Minority Oversampling Technique) was adopted as an over sampling method to preprocess the dataset. Apriori algorithm and genetic feature selection were used to explore which combinations of factors are more likely to cause complication and which factors are more related with complications, respectively. Because the attributes in the dataset is non-numeric value, we choose Na&#x000ef;ve Bayesian classifier and random forest to predict the postoperative complication of pediatric cataract patients.</p></sec><sec id="Sec4"><title>Apriori algorithm</title><p id="Par19">Association rules mining [<xref ref-type="bibr" rid="CR22">22</xref>] is a useful technology that is first used to analyze the shopping basket to find some shopping habits hidden in the shopping list of consumers and thus is used to promote sales. This method has been applied in many fields to discover the meaningful knowledge in specific problem, such as fault diagnosis of power transformers [<xref ref-type="bibr" rid="CR22">22</xref>] and the detection of industrial intrusion [<xref ref-type="bibr" rid="CR23">23</xref>].</p><p id="Par20">The most commonly used algorithm to mine association rules is Apriori [<xref ref-type="bibr" rid="CR23">23</xref>], which utilizes minimum&#x000a0;support (the frequency of an itemset appeared in dataset for screening out the frequent item-set) to sift out the frequent <italic>k</italic>-item sets and&#x000a0;then selects the association rules whose confidence is larger than the minimum confidence from frequent <italic>k</italic>-item set. In the first stage of the Apriori algorithm, with the assistance of a transcendental property that the nonempty subset of the frequent item set must be frequent, the Apriori algorithm finds the most common occurring mode (<italic>k</italic>-item set) whose support&#x000a0;is larger than or equal to the minimum support that is set ahead until the (<italic>k&#x02009;</italic>+&#x02009;1)-item set produced from <italic>k</italic>-item set is empty; Then Apriori algorithm checks the confidence of every rule and retains only the rules with higher confidence. The confidence of an association rule is computed as Eq.&#x000a0;(<xref rid="Equ1" ref-type="">1</xref>).<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Confidence(a \to b) = \frac{Frequency(a \cup b)}{Frequency(a)}$$\end{document}</tex-math><mml:math id="M2" display="block"><mml:mrow><mml:mi>C</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mo stretchy="false">&#x02192;</mml:mo><mml:mi>b</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>F</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>q</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>c</mml:mi><mml:mi>y</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mo>&#x0222a;</mml:mo><mml:mi>b</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>F</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>q</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>c</mml:mi><mml:mi>y</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:math><graphic xlink:href="12967_2018_1758_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula>
</p><p id="Par21">The association rules will come into being as many implications with the format &#x0201c;<inline-formula id="IEq1"><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$a \to b$$\end{document}</tex-math><mml:math id="M4"><mml:mrow><mml:mi>a</mml:mi><mml:mo stretchy="false">&#x02192;</mml:mo><mml:mi>b</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="12967_2018_1758_Article_IEq1.gif"/></alternatives></inline-formula>&#x0201d; using the Apriori algorithm, where <italic>a</italic> and <italic>b</italic> are the antecedents and consequents of association rules, respectively. The minimum support is set as 0 to let all items combine freely to produce association rules without considering their support and confidence. Because the aim is finding out the combinations of attributes which will or will not bring complication, the rules whose consequents are whether a patient suffers from complications (SLPVA and AHIP) are sifted out preliminarily. At last, the pairs of association rules with the same antecedent and different consequents will be sifted out again with Eq.&#x000a0;(<xref rid="Equ2" ref-type="">2</xref>), which means that the confidence of the pair of association rules should be far from each other mutually, where <italic>threshold</italic> is a parameter.<disp-formula id="Equ2"><label>2</label><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\frac{Confidence(a \to b)}{{Confidence(a \to b^{\prime})}} \ge Threshold, \quad b = \neg b^{\prime}, \quad b \in \{ 1,0\}$$\end{document}</tex-math><mml:math id="M6" display="block"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>C</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mo stretchy="false">&#x02192;</mml:mo><mml:mi>b</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mo stretchy="false">&#x02192;</mml:mo><mml:msup><mml:mi>b</mml:mi><mml:mo>&#x02032;</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mo>&#x02265;</mml:mo><mml:mi>T</mml:mi><mml:mi>h</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>h</mml:mi><mml:mi>o</mml:mi><mml:mi>l</mml:mi><mml:mi>d</mml:mi><mml:mo>,</mml:mo><mml:mspace width="1em"/><mml:mi>b</mml:mi><mml:mo>=</mml:mo><mml:mo>&#x000ac;</mml:mo><mml:msup><mml:mi>b</mml:mi><mml:mo>&#x02032;</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:mspace width="1em"/><mml:mi>b</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:mrow></mml:math><graphic xlink:href="12967_2018_1758_Article_Equ2.gif" position="anchor"/></alternatives></disp-formula>where, <inline-formula id="IEq2"><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$a \to b$$\end{document}</tex-math><mml:math id="M8"><mml:mrow><mml:mi>a</mml:mi><mml:mo stretchy="false">&#x02192;</mml:mo><mml:mi>b</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="12967_2018_1758_Article_IEq2.gif"/></alternatives></inline-formula> and <inline-formula id="IEq3"><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$a \to b^{\prime}$$\end{document}</tex-math><mml:math id="M10"><mml:mrow><mml:mi>a</mml:mi><mml:mo stretchy="false">&#x02192;</mml:mo><mml:msup><mml:mi>b</mml:mi><mml:mo>&#x02032;</mml:mo></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="12967_2018_1758_Article_IEq3.gif"/></alternatives></inline-formula> are a pair of association rules with the same antecedent and different consequents. 1 and 0 refer to suffering from complications (SLPVA and AHIP) and not suffering from complication (SLPVA and AHIP), respectively. The association rules mining is widely applied in biomedical fields, such as microbial energy prospection [<xref ref-type="bibr" rid="CR24">24</xref>], pollution epidemiology [<xref ref-type="bibr" rid="CR25">25</xref>].</p></sec><sec id="Sec5"><title>SMOTE</title><p id="Par23">SMOTE is a commonly used over-sampling technique for tackling imbalanced dataset. It used the <italic>k</italic>-nearest neighbor of each minority sample to produce more minority samples to offset the imbalance between majority class and minority class. The new minority samples is the linear combination of a minority sample and one of its nearest neighbor. Non-numerical minority data can also be preprocessed with SMOTE in a similar manner. In current research, we choose SMOTE as a comparison.</p></sec><sec id="Sec6"><title>Naive Bayesian classifier</title><p id="Par24">Naive Bayes classifier [<xref ref-type="bibr" rid="CR26">26</xref>&#x02013;<xref ref-type="bibr" rid="CR28">28</xref>] based on Bayes theorem and assumes all attributes are independent is a simple yet useful pattern recognition method. Given sample <inline-formula id="IEq4"><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$(x,y)$$\end{document}</tex-math><mml:math id="M12"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12967_2018_1758_Article_IEq4.gif"/></alternatives></inline-formula> is a sample to be classified in multi-class classification problem, where <inline-formula id="IEq5"><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$x = \left[ {x_{1} , \ldots ,x_{s} } \right]$$\end{document}</tex-math><mml:math id="M14"><mml:mrow><mml:mi>x</mml:mi><mml:mo>=</mml:mo><mml:mfenced close="]" open="[" separators=""><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>&#x02026;</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="12967_2018_1758_Article_IEq5.gif"/></alternatives></inline-formula>, <inline-formula id="IEq6"><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$y \in \left\{ {y_{1} , \ldots y_{o} } \right\}$$\end{document}</tex-math><mml:math id="M16"><mml:mrow><mml:mi>y</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mfenced close="}" open="{" separators=""><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>&#x02026;</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>o</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="12967_2018_1758_Article_IEq6.gif"/></alternatives></inline-formula>, S and <italic>o</italic> are the attribute vector, label, the number of attributes and the number of classes, respectively. Naive Bayes classifier compute probabilities <inline-formula id="IEq7"><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$P\left( {y_{1} \left| x \right.} \right), \ldots ,P\left( {y_{o} \left| x \right.} \right)$$\end{document}</tex-math><mml:math id="M18"><mml:mrow><mml:mi>P</mml:mi><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mfenced close="" open="|"><mml:mi>x</mml:mi></mml:mfenced></mml:mrow></mml:mfenced><mml:mo>,</mml:mo><mml:mo>&#x02026;</mml:mo><mml:mo>,</mml:mo><mml:mi>P</mml:mi><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>o</mml:mi></mml:msub><mml:mfenced close="" open="|"><mml:mi>x</mml:mi></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="12967_2018_1758_Article_IEq7.gif"/></alternatives></inline-formula>, and then classify the sample into the class with largest probability. These probabilities could be estimated with Bayes theorem [<xref ref-type="bibr" rid="CR29">29</xref>, <xref ref-type="bibr" rid="CR30">30</xref>] which is shown as Eq.&#x000a0;(<xref rid="Equ3" ref-type="">3</xref>), then the label of a new sample can be computed with Eq.&#x000a0;(<xref rid="Equ4" ref-type="">4</xref>).<disp-formula id="Equ3"><label>3</label><alternatives><tex-math id="M19">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$P\left( {y_{j} \left| x \right.} \right) = \frac{{P\left( {x\left| {y_{j} } \right.} \right)}}{P(x)}\quad j = 1, \ldots ,o$$\end{document}</tex-math><mml:math id="M20" display="block"><mml:mrow><mml:mi>P</mml:mi><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mfenced close="" open="|"><mml:mi>x</mml:mi></mml:mfenced></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>P</mml:mi><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mi>x</mml:mi><mml:mfenced close="" open="|" separators=""><mml:msub><mml:mi>y</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mspace width="1em"/><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>&#x02026;</mml:mo><mml:mo>,</mml:mo><mml:mi>o</mml:mi></mml:mrow></mml:math><graphic xlink:href="12967_2018_1758_Article_Equ3.gif" position="anchor"/></alternatives></disp-formula>
<disp-formula id="Equ4"><label>4</label><alternatives><tex-math id="M21">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Label = \mathop {max}\limits_{j} p\left( {y_{j} \left| x \right.} \right)\quad j = 1, \ldots ,o$$\end{document}</tex-math><mml:math id="M22" display="block"><mml:mrow><mml:mi>L</mml:mi><mml:mi>a</mml:mi><mml:mi>b</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mi mathvariant="italic">max</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:munder><mml:mi>p</mml:mi><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mfenced close="" open="|"><mml:mi>x</mml:mi></mml:mfenced></mml:mrow></mml:mfenced><mml:mspace width="1em"/><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>&#x02026;</mml:mo><mml:mo>,</mml:mo><mml:mi>o</mml:mi></mml:mrow></mml:math><graphic xlink:href="12967_2018_1758_Article_Equ4.gif" position="anchor"/></alternatives></disp-formula>
</p><p id="Par25">Because of the assumption that all attributes are independent and same denominator of Eq.&#x000a0;(<xref rid="Equ3" ref-type="">3</xref>) for all classes, the probabilities could be converted to be Eq.&#x000a0;(<xref rid="Equ5" ref-type="">5</xref>):<disp-formula id="Equ5"><label>5</label><alternatives><tex-math id="M23">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$P\left( {x\left| {y_{j} } \right.} \right) = p(y_{j} ) = P\left( {x_{1} \left| {y_{j} } \right.} \right) \ldots P\left( {x_{S} \left| {y_{j} } \right.} \right)p(y_{j} ) = \prod\limits_{i = 1}^{S} P \left( {x_{i} \left| {y_{j} } \right.} \right)p(y_{j} )\quad j = 1, \ldots ,o$$\end{document}</tex-math><mml:math id="M24" display="block"><mml:mrow><mml:mi>P</mml:mi><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mi>x</mml:mi><mml:mfenced close="" open="|" separators=""><mml:msub><mml:mi>y</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>P</mml:mi><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mfenced close="" open="|" separators=""><mml:msub><mml:mi>y</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:mfenced><mml:mo>&#x02026;</mml:mo><mml:mi>P</mml:mi><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mfenced close="" open="|" separators=""><mml:msub><mml:mi>y</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:mfenced><mml:mi>p</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munderover><mml:mo movablelimits="false">&#x0220f;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>S</mml:mi></mml:munderover><mml:mi>P</mml:mi><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mfenced close="" open="|" separators=""><mml:msub><mml:mi>y</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:mfenced><mml:mi>p</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mspace width="1em"/><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>&#x02026;</mml:mo><mml:mo>,</mml:mo><mml:mi>o</mml:mi></mml:mrow></mml:math><graphic xlink:href="12967_2018_1758_Article_Equ5.gif" position="anchor"/></alternatives></disp-formula>
</p><p id="Par26">Naive Bayes classifier has been applied in a plenty of fields, such as detection of cardiovascular disease risk&#x02019;s level [<xref ref-type="bibr" rid="CR31">31</xref>], identification of hot spots in protein structures [<xref ref-type="bibr" rid="CR32">32</xref>].</p></sec><sec id="Sec7"><title>Random forest</title><p id="Par27">Random forest is an effective ensemble classifier that originates from decision tree, and this classifier can effectively avoid overfitting, which is a common issue with normal decision trees. Therefore, the decision tree is introduced first.</p><p id="Par28">Decision tree [<xref ref-type="bibr" rid="CR33">33</xref>, <xref ref-type="bibr" rid="CR34">34</xref>] is a type of classifier that regards the dataset to be an entire set, yet recursively divides this set into subsets as well according to a certain standard. During the latter process, all subsets are divided to the extent that they have no attributes to divide further or all samples in every subset belong to a uniform category. Decision tree has been applied in many fields, such as industrial safety [<xref ref-type="bibr" rid="CR34">34</xref>], power [<xref ref-type="bibr" rid="CR35">35</xref>] and financial behavior prediction [<xref ref-type="bibr" rid="CR36">36</xref>].</p><p id="Par29">There are three common standards to partition the dataset into subsets, namely, information gain, gain ratio and Gini index [<xref ref-type="bibr" rid="CR37">37</xref>].</p><p id="Par30">Random forest [<xref ref-type="bibr" rid="CR38">38</xref>, <xref ref-type="bibr" rid="CR39">39</xref>] is an excellent ensemble learning algorithm that combines many decision trees with partial samples and partial attributes that are randomly selected from the whole dataset. Finally, the label of a testing sample is decided by voting in accordance with all decision trees of the random forest. Therefore, over-fitting problem can be avoided effectively. The current research adopted this algorithm to predict whether a patient will have complications and to classify the patients whether suffer from a specific complication. Random forest is also popular and widely applied in many disciplines, such as prediction of double-strand DNA breaks [<xref ref-type="bibr" rid="CR40">40</xref>], localization of prostate cancer [<xref ref-type="bibr" rid="CR39">39</xref>] and computational bioinformatics [<xref ref-type="bibr" rid="CR41">41</xref>].</p></sec><sec id="Sec8"><title>Genetic feature selection</title><p id="Par31">Next, genetic feature selection is used to find out which factors are more related with the complications of pediatric cataract patients. Genetic algorithm (GA) [<xref ref-type="bibr" rid="CR42">42</xref>] can be used to select attributes that are useful for classification or more related to complications in the current research, where the fitness evaluation function of GA is the accuracy returned by classifier (random forest in this paper). In the flow of GA, the real factors which are associated with labels are searched out. The number of iteration steps and the size of population are 50 and 30, respectively. Genetic feature selection has been applied in many fields, such as image classification [<xref ref-type="bibr" rid="CR43">43</xref>], text categorization [<xref ref-type="bibr" rid="CR44">44</xref>], image feature extraction [<xref ref-type="bibr" rid="CR45">45</xref>] and signal processing [<xref ref-type="bibr" rid="CR46">46</xref>].</p></sec><sec id="Sec9"><title>Experimental settings and evaluation indicator</title><p id="Par32">Because this classification problem (prediction of postoperative complication of pediatric cataracts patients) is a multi-label learning problem [<xref ref-type="bibr" rid="CR47">47</xref>], common solution for this type of classification problem is to decompose the problem into several binary classification ones. At the same time, the dataset is imbalanced, so the samples of the minority class are fed into SMOTE to produce more minority samples. Consequently, there are three corresponding datasets for three binary classification problems (whether a patient suffers from complications; whether a patient suffers from SLPVA; whether a patient suffers from AHIP). The samples having complications (SLPVA and AHIP) are positive samples and the samples without complications (SLPVA and AHIP) are negative samples. Three-fold cross validation was adopted to permit a fair comparison of these methods.</p><p id="Par33">All of the methods were implemented with MATLAB R2016a on a personal computer with an Intel 2.80&#x000a0;GHz i5 processor, 8G RAM. The objective of our study was to predict the complication of pediatric cataracts patients; the measures that were employed to evaluate the performance are shown as Eqs.&#x000a0;(<xref rid="Equ6" ref-type="">6</xref>&#x02013;<xref rid="Equ11" ref-type="">11</xref>):<disp-formula id="Equ6"><label>6</label><alternatives><tex-math id="M25">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Accuracy = \left( {TP + TN} \right)/\left( {P + N} \right)$$\end{document}</tex-math><mml:math id="M26" display="block"><mml:mrow><mml:mi>A</mml:mi><mml:mi>c</mml:mi><mml:mi>c</mml:mi><mml:mi>u</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>c</mml:mi><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfenced><mml:mo stretchy="false">/</mml:mo><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:math><graphic xlink:href="12967_2018_1758_Article_Equ6.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ7"><label>7</label><alternatives><tex-math id="M27">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Precision = TP/\left( {TP + FP} \right)$$\end{document}</tex-math><mml:math id="M28" display="block"><mml:mrow><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo stretchy="false">/</mml:mo><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:math><graphic xlink:href="12967_2018_1758_Article_Equ7.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ8"><label>8</label><alternatives><tex-math id="M29">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Sensitivity\;\left( {TPR,\;Recall} \right) = TP/\left( {TP + FN} \right)$$\end{document}</tex-math><mml:math id="M30" display="block"><mml:mrow><mml:mi>S</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>y</mml:mi><mml:mspace width="0.277778em"/><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mi>R</mml:mi><mml:mo>,</mml:mo><mml:mspace width="0.277778em"/><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo stretchy="false">/</mml:mo><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:math><graphic xlink:href="12967_2018_1758_Article_Equ8.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ9"><label>9</label><alternatives><tex-math id="M31">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$FNR\;(false\;negative\;rate) = 1 - Sensitivity = FN/\left( {TP + FN} \right)$$\end{document}</tex-math><mml:math id="M32" display="block"><mml:mrow><mml:mi>F</mml:mi><mml:mi>N</mml:mi><mml:mi>R</mml:mi><mml:mspace width="0.277778em"/><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mspace width="0.277778em"/><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>g</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>v</mml:mi><mml:mi>e</mml:mi><mml:mspace width="0.277778em"/><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>S</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi><mml:mo stretchy="false">/</mml:mo><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:math><graphic xlink:href="12967_2018_1758_Article_Equ9.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ10"><label>10</label><alternatives><tex-math id="M33">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Specificity = TN/\left( {TN + FP} \right)$$\end{document}</tex-math><mml:math id="M34" display="block"><mml:mrow><mml:mi>S</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo stretchy="false">/</mml:mo><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:math><graphic xlink:href="12967_2018_1758_Article_Equ10.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ11"><label>11</label><alternatives><tex-math id="M35">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$FNR\;(false\;positive\;rate) = 1 - Sensitivity = FP/\left( {TN + FP} \right)$$\end{document}</tex-math><mml:math id="M36" display="block"><mml:mrow><mml:mi>F</mml:mi><mml:mi>N</mml:mi><mml:mi>R</mml:mi><mml:mspace width="0.277778em"/><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mspace width="0.277778em"/><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>v</mml:mi><mml:mi>e</mml:mi><mml:mspace width="0.277778em"/><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>S</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mo stretchy="false">/</mml:mo><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:math><graphic xlink:href="12967_2018_1758_Article_Equ11.gif" position="anchor"/></alternatives></disp-formula>where P and N are the number of positive samples and negative samples, respectively; TP indicates the number of positive samples classified into the positive class; FN denotes the number of positive samples classified as negative samples; TN is the number of negative samples recognized as negative samples; and FP refers to the number of negative samples identified as positive samples. In addition, the ROC (receiver operating characteristics) curve, which indicates how many positive samples are recognized conditioned on a given false positive rate and AUC (area under curve) which means the area of the zone under ROC curve are also adopted to assess the performance [<xref ref-type="bibr" rid="CR48">48</xref>].</p></sec></sec><sec id="Sec10"><title>Results</title><p id="Par35">At first, we provide a part of the association rules mined out by Apriori algorithm in Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Tables S1&#x02013;S3. Then the postoperative complications of pediatric cataracts patients were predicted with random forest and Na&#x000ef;ve Bayesian classifier. Then the contributing factors for the postoperative complications were found out with genetic feature selection. Finally, we used additional 50 data to verify the performance of random forest and Na&#x000ef;ve Bayesian classifier, the accuracies of them are over 65% for three classification problems.</p><sec id="Sec11"><title>Results of association rules mining</title><p id="Par36">In order to find out the combination of factors which can cause complications with bigger probability, the Apriori algorithm is used to mine out the association rules about the complications.</p></sec><sec id="Sec12"><title>Classification performance of RF and NB</title><p id="Par37">The prediction of postoperative complication of pediatric cataracts patients is carried out with random forest and na&#x000ef;ve Bayes classifier. The evaluation indicators for random forest and Na&#x000ef;ve Bayes classifier with three different datasets that are preprocessed with SMOTE or original datasets in terms of three binary classification problems (whether a patient suffers from complications; whether a patient suffers from SLPVA; whether a patient suffers from AHIP) are shown in Table&#x000a0;<xref rid="Tab2" ref-type="table">2</xref>, where the format of these data is <inline-formula id="IEq8"><alternatives><tex-math id="M37">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mu \pm \delta$$\end{document}</tex-math><mml:math id="M38"><mml:mrow><mml:mi>&#x003bc;</mml:mi><mml:mo>&#x000b1;</mml:mo><mml:mi>&#x003b4;</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="12967_2018_1758_Article_IEq8.gif"/></alternatives></inline-formula> (<inline-formula id="IEq9"><alternatives><tex-math id="M39">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mu$$\end{document}</tex-math><mml:math id="M40"><mml:mi>&#x003bc;</mml:mi></mml:math><inline-graphic xlink:href="12967_2018_1758_Article_IEq9.gif"/></alternatives></inline-formula> is the mean value, <inline-formula id="IEq10"><alternatives><tex-math id="M41">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\delta$$\end{document}</tex-math><mml:math id="M42"><mml:mi>&#x003b4;</mml:mi></mml:math><inline-graphic xlink:href="12967_2018_1758_Article_IEq10.gif"/></alternatives></inline-formula> is the standard deviation). The ROC curves combining AUC values in three binary classification problems with datasets preprocessed with SMOTE are shown in Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2</xref>. The number of trees in random forest influences the classification performance and we investigate the relationship between them. Three classification problems were repeatedly solved with different number of trees and their accuracies are shown as Fig.&#x000a0;<xref rid="Fig3" ref-type="fig">3</xref>.<table-wrap id="Tab2"><label>Table&#x000a0;2</label><caption><p>Performance indicators in three binary classification problems</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" colspan="2">Method</th><th align="left">Accuracy</th><th align="left">FNR</th><th align="left">FPR</th></tr></thead><tbody><tr><td align="left" colspan="5">Problem 1: Whether a patient suffers from complications</td></tr><tr><td align="left" rowspan="2">&#x000a0;Random forest</td><td align="left">&#x02013;</td><td char="&#x000b1;" align="char">0.757&#x02009;&#x000b1;&#x02009;0.025</td><td char="&#x000b1;" align="char">0.414&#x02009;&#x000b1;&#x02009;0.031</td><td char="&#x000b1;" align="char">0.128&#x02009;&#x000b1;&#x02009;0.013</td></tr><tr><td align="left">SMOTE</td><td char="&#x000b1;" align="char">0.762&#x02009;&#x000b1;&#x02009;0.019</td><td char="&#x000b1;" align="char">0.231&#x02009;&#x000b1;&#x02009;0.013</td><td char="&#x000b1;" align="char">0.220&#x02009;&#x000b1;&#x02009;0.037</td></tr><tr><td align="left" rowspan="2">&#x000a0;Na&#x000ef;ve Bayesian</td><td align="left">&#x02013;</td><td char="&#x000b1;" align="char">0.748&#x02009;&#x000b1;&#x02009;0.025</td><td char="&#x000b1;" align="char">0.465&#x02009;&#x000b1;&#x02009;0.042</td><td char="&#x000b1;" align="char">0.887&#x02009;&#x000b1;&#x02009;0.023</td></tr><tr><td align="left">SMOTE</td><td char="&#x000b1;" align="char">0.751&#x02009;&#x000b1;&#x02009;0.032</td><td char="&#x000b1;" align="char">0.270&#x02009;&#x000b1;&#x02009;0.043</td><td char="&#x000b1;" align="char">0.208&#x02009;&#x000b1;&#x02009;0.044</td></tr><tr><td align="left" colspan="5">Problem 2: Whether a patient suffers from SLPVA</td></tr><tr><td align="left" rowspan="2">&#x000a0;Random forest</td><td align="left">&#x02013;</td><td char="&#x000b1;" align="char">0.810&#x02009;&#x000b1;&#x02009;0.014</td><td char="&#x000b1;" align="char">0.621&#x02009;&#x000b1;&#x02009;0.089</td><td char="&#x000b1;" align="char">0.071&#x02009;&#x000b1;&#x02009;0.023</td></tr><tr><td align="left">SMOTE</td><td char="&#x000b1;" align="char">0.753&#x02009;&#x000b1;&#x02009;0.069</td><td char="&#x000b1;" align="char">0.257&#x02009;&#x000b1;&#x02009;0.054</td><td char="&#x000b1;" align="char">0.258&#x02009;&#x000b1;&#x02009;0.044</td></tr><tr><td align="left" rowspan="2">&#x000a0;Na&#x000ef;ve Bayesian</td><td align="left">&#x02013;</td><td char="&#x000b1;" align="char">0.782&#x02009;&#x000b1;&#x02009;0.014</td><td char="&#x000b1;" align="char">0.155&#x02009;&#x000b1;&#x02009;0.043</td><td char="&#x000b1;" align="char">0.449&#x02009;&#x000b1;&#x02009;0.100</td></tr><tr><td align="left">SMOTE</td><td char="&#x000b1;" align="char">0.782&#x02009;&#x000b1;&#x02009;0.043</td><td char="&#x000b1;" align="char">0.244&#x02009;&#x000b1;&#x02009;0.065</td><td char="&#x000b1;" align="char">0.267&#x02009;&#x000b1;&#x02009;0.025</td></tr><tr><td align="left" colspan="5">Problem 3: Whether a patient suffers from AHIP</td></tr><tr><td align="left" rowspan="2">&#x000a0;Random forest</td><td align="left">&#x02013;</td><td char="&#x000b1;" align="char">0.838&#x02009;&#x000b1;&#x02009;0.024</td><td char="&#x000b1;" align="char">0.580&#x02009;&#x000b1;&#x02009;0.050</td><td char="&#x000b1;" align="char">0.015&#x02009;&#x000b1;&#x02009;0.014</td></tr><tr><td align="left">SMOTE</td><td char="&#x000b1;" align="char">0.813&#x02009;&#x000b1;&#x02009;0.016</td><td char="&#x000b1;" align="char">0.228&#x02009;&#x000b1;&#x02009;0.055</td><td char="&#x000b1;" align="char">0.265&#x02009;&#x000b1;&#x02009;0.025</td></tr><tr><td align="left" rowspan="2">&#x000a0;Na&#x000ef;ve Bayesian</td><td align="left">&#x02013;</td><td char="&#x000b1;" align="char">0.847&#x02009;&#x000b1;&#x02009;0.033</td><td char="&#x000b1;" align="char">0&#x02009;&#x000b1;&#x02009;0</td><td char="&#x000b1;" align="char">0.321&#x02009;&#x000b1;&#x02009;0.043</td></tr><tr><td align="left">SMOTE</td><td char="&#x000b1;" align="char">0.816&#x02009;&#x000b1;&#x02009;0.037</td><td char="&#x000b1;" align="char">0.225&#x02009;&#x000b1;&#x02009;0.047</td><td char="&#x000b1;" align="char">0.265&#x02009;&#x000b1;&#x02009;0.074</td></tr></tbody></table></table-wrap>
<fig id="Fig2"><label>Fig.&#x000a0;2</label><caption><p>ROC curves and AUC values in three binary classification problem. (<italic>ROC</italic> receiver operating characteristics curve, <italic>AUC</italic>: area under curve, <italic>RF</italic> random forest; <italic>SMOTE</italic> synthetic minority oversampling technique, <italic>NB</italic> Na&#x000ef;ve Bayesian classifier)</p></caption><graphic xlink:href="12967_2018_1758_Fig2_HTML" id="MO13"/></fig>
<fig id="Fig3"><label>Fig.&#x000a0;3</label><caption><p>The relationship between accuracy and the number of trees of random forest. (RF means random forest)</p></caption><graphic xlink:href="12967_2018_1758_Fig3_HTML" id="MO14"/></fig>
</p></sec><sec id="Sec13"><title>Results of genetic feature selection</title><p id="Par38">Next, we applied genetic algorithm (GA) combined with random forest to study which factors affect the complication, where the classification accuracy is used as the fitness of GA. Because GA is a type of probabilistic heuristic algorithm that involves random factors, the experiment was repeated ten times and the best result was selected as the final result. The experimental result shows that the accuracy for the first binary classification problem (whether suffers from complications) can reach 0.783 without using the gender and age at surgery (AS) attributes. The accuracy of the second binary classification (whether suffers from SLPVA) problem can reach 0.795 without the secondary IOL placement, operation mode, age at surgery and area of cataracts (AC) attributes. The accuracy of the third binary classification problem (whether suffer from AHIP) can reach 0.836 without gender, operation mode and laterality.</p></sec><sec id="Sec14"><title>Additional testing</title><p id="Par39">We used additional 50 samples to test performance of RF and NB, the accuracies reach 65% for three classification problems, respectively. The detailed information about additional testing is shown in Table&#x000a0;<xref rid="Tab3" ref-type="table">3</xref>. Figure&#x000a0;<xref rid="Fig4" ref-type="fig">4</xref> shows the ROC curves for additional testing. There are 27 samples do not suffer from complications; 18 samples suffer from SLPVA; 11 samples suffer from AHIP and five samples suffer both SLPVA and AHIP.<table-wrap id="Tab3"><label>Table&#x000a0;3</label><caption><p>The performance of RF and NB for additional testing</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Problem</th><th align="left">Algorithm</th><th align="left">Accuracy</th><th align="left">Sensitivity</th><th align="left">Specificity</th></tr></thead><tbody><tr><td align="left" rowspan="2">Whether a patient suffers from complications</td><td align="left">Random forest</td><td char="." align="char">0.700</td><td char="." align="char">0.625</td><td char="." align="char">0.769</td></tr><tr><td align="left">Na&#x000ef;ve Bayesian</td><td char="." align="char">0.700</td><td char="." align="char">0.731</td><td char="." align="char">0.667</td></tr><tr><td align="left" rowspan="2">Whether a patient suffers from SLPVA</td><td align="left">Random forest</td><td char="." align="char">0.720</td><td char="." align="char">0.667</td><td char="." align="char">0.722</td></tr><tr><td align="left">Na&#x000ef;ve Bayesian</td><td char="." align="char">0.660</td><td char="." align="char">0.611</td><td char="." align="char">0.688</td></tr><tr><td align="left" rowspan="2">Whether a patient suffers from AHIP</td><td align="left">Random forest</td><td char="." align="char">0.700</td><td char="." align="char">0.636</td><td char="." align="char">0.718</td></tr><tr><td align="left">Na&#x000ef;ve Bayesian</td><td char="." align="char">0.660</td><td char="." align="char">0.545</td><td char="." align="char">0.692</td></tr></tbody></table></table-wrap>
<fig id="Fig4"><label>Fig.&#x000a0;4</label><caption><p>ROC curves and AUC values for additional testing</p></caption><graphic xlink:href="12967_2018_1758_Fig4_HTML" id="MO15"/></fig>
</p></sec><sec id="Sec15"><title>Webserver of decision-making system</title><p id="Par40">We developed and deployed a web based system to facilitate the prediction of complication levels for doctors and to show the association rules about complication. This system serves two functions: judging whether a patient suffers from complications or the specific type of complication using random forest as the flowchart shown in Fig.&#x000a0;<xref rid="Fig5" ref-type="fig">5</xref> and showing the association rules after user inputs parameter <italic>threshold</italic> for three types of problems. We provide two language versions (English and Chinese) for users and this web server is freely available at (English version) <ext-link ext-link-type="uri" xlink:href="http://120.27.126.89:5001/option_xian">http://120.27.126.89:5001/option_xian</ext-link> (Chinese version) <ext-link ext-link-type="uri" xlink:href="http://120.27.126.89:5001/option_xianch">http://120.27.126.89:5001/option_xianch</ext-link>.<fig id="Fig5"><label>Fig.&#x000a0;5</label><caption><p>Flowchart of postoperative complication prediction. (At first, the inputted data is preprocessed with data discretion method. Then one of the three models is applied to distinguish whether a patient suffers from complication. If the patient is not normal, then the remaining two models are used to judge whether the patient has two types of complication. If the patient is judged to be normal, the remaining two models will not be used)</p></caption><graphic xlink:href="12967_2018_1758_Fig5_HTML" id="MO16"/></fig></p></sec></sec><sec id="Sec16"><title>Discussion</title><p id="Par41">The number of association rules that are sifted out decreases while the <italic>threshold</italic> increases. The antecedents, consequents and confidences of all association rules are summarized to be three categories of tables, contributing as a part of experimental result. The reason why these steps are adopted is that we want to obtain some discriminant association rules that can provide some evidence about complications and whose consequences is different, but the reliability of these rules need to be verified with more clinical data. Some discriminant combinations of attributes (antecedent) can reflect the power of attributes for classification, such as secondary IOL replacement and gender used for classifying whether suffers from complications. However, these association rules need to be testified with more clinical data. The relationship between threshold and the number of associations rules is shown as Fig.&#x000a0;<xref rid="Fig6" ref-type="fig">6</xref>.<fig id="Fig6"><label>Fig.&#x000a0;6</label><caption><p>The relationship between <italic>threshold</italic> and the number of association rules</p></caption><graphic xlink:href="12967_2018_1758_Fig6_HTML" id="MO17"/></fig>
</p><p id="Par42">These association rules can provide some reference for doctors to predict postoperative complication of pediatric cataracts. For example, a male patient whose age is between 13 and 18&#x000a0;months will be more unlikely to suffer from AHIP after the surgery on the basis of <italic>threshold&#x02009;</italic>=&#x02009;6, which is shown in Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S3.</p><p id="Par43">SMOTE algorithm<sup>17</sup> is a common over sampling method for imbalance dataset classification, it randomly sampling two samples from dataset and linearly combined them to be a new sample until imbalanced classes become balance. Here we used nominal SMOTE that is the extension of SMOTE in nonnumeric variables. All data were divided into multiple parts for cross-validation and then were preprocessed by SMOTE. Validation dataset is not preprocessed with SMOTE.</p><p id="Par44">Sensitivity and specificity can be computed with FNR and FPR, so values for some sensitivity and specificity indices are not shown. We also use original dataset to perform these classification problems. SMOTE can effectively improve the classification performance. The classification performance with original dataset is so imbalanced, while SMOTE can relieve this condition to a certain extent.</p></sec><sec id="Sec17"><title>Conclusion</title><p id="Par45">To predict the postoperative complication of pediatric cataracts, SMOTE is employed to preprocess dataset and then two types of classifier (random forest and na&#x000ef;ve Bayes classifier) was exploited to classify samples with or without complication (two types of complication). All average accuracies in solving three binary classification problems are over 91%, and one is even reaching 95%. Then real factors that are more related to the complications were identified with genetic feature selection. Besides, the association rules that hide in the dataset can also provide some evidence about complication to assist doctors in treatment. Finally, additional 50 data were used to test the performance of RF and NB, and both the accuracies of them reach 65% for three classification problems. All these verified methods and models were integrated into a medical decision making system to help doctors to predict the postoperative complication of Pediatric Cataract Patients. In the future, more information, such as medication during pregnancy and genetic information, can be put into dataset to predict complications more accurately. As a type of rare disease, the data of pediatric cataracts is not enough. Therefore, we hope the on-line system in current research can assist in collecting more data and support the multicenter study in the future.</p></sec><sec sec-type="supplementary-material"><title>Additional file</title><sec id="Sec18"><p>
<supplementary-material content-type="local-data" id="MOESM1"><media xlink:href="12967_2018_1758_MOESM1_ESM.docx"><caption><p><bold>Additional file 1: Table S1.</bold> Association rules about whether a patient will have complications (<italic>threshold</italic>&#x02009;=&#x02009;6). <bold>Table S2.</bold> Association rules about whether a patient will have the first type of complication (<italic>threshold</italic>&#x02009;=&#x02009;7). <bold>Table S3.</bold> Association rules about whether a patient will have the second type of complication (<italic>threshold</italic>&#x02009;=&#x02009;4).</p></caption></media></supplementary-material>
</p></sec></sec></body><back><glossary><title>Abbreviations</title><def-list><def-item><term>RF</term><def><p id="Par5">random forest</p></def></def-item><def-item><term>NB</term><def><p id="Par6">Na&#x000ef;ve Bayesian Classifier</p></def></def-item><def-item><term>ROC</term><def><p id="Par7">receiver operating characteristics curve</p></def></def-item><def-item><term>AUC</term><def><p id="Par8">area under curve</p></def></def-item><def-item><term>SMOTE</term><def><p id="Par9">synthetic minority over sampling technique</p></def></def-item></def-list></glossary><ack><title>Authors&#x02019; contributions</title><p>XYL designed the research; KZ conducted the study; WTL collected the dataset; KZ were responsible for coding; SW analyzed and finished the experimental results; SW, LL, XJZ and KZ developed the complication prediction system; KZ, JWJ, XYL and LMW co-wrote the manuscript. All authors discussed the results and commented on the manuscript. All authors read and approved the final manuscript.</p><sec id="FPar1"><title>Acknowledgements</title><p id="Par46">Not applicable.</p></sec><sec id="FPar2"><title>Competing interests</title><p id="Par47">The authors declare that they have no competing interests.</p></sec><sec id="FPar3"><title>Availability of data and materials</title><p id="Par48">The data that support the findings of this study are available from the corresponding authors on request. The code are available to readers on request. The code and data in this study can be accessed freely at <ext-link ext-link-type="uri" xlink:href="https://github.com/Hugo0512/Complications">https://github.com/Hugo0512/Complications</ext-link>.</p></sec><sec id="FPar4"><title>Consent for publication</title><p id="Par49">Not applicable.</p></sec><sec id="FPar5"><title>Ethics approval and consent to participate</title><p id="Par50">The study was approved by the Ethics Committee of Xidian University and Zhongshan Ophthalmic Center of Sun Yat-sen University. Written informed consent was obtained from all study participants&#x02019; parents or legal guardian.</p></sec><sec id="FPar6"><title>Funding</title><p id="Par51">This study was funded by the National Key Research and Development Program of China (2018YFC0116500); the NSFC (No. 91546101, 61472311 and 11401454); the Guangdong Provincial Natural Science Foundation (No. YQ2015006, No. 2014A030306030, No. 2014TQ01R573, No. 2013B020400003); the Natural Science Foundation of Guangzhou City (No. 2014J2200060); the State Key Laboratory of Ophthalmology, Zhongshan Ophthalmic Center, Sun Yat-sen University (No. 2015ykzd11, No. 2015QN01); the Special Program for Applied Research on Super Computation of the NSFC-Guangdong Joint Fund (the second phase); and the Clinical Research and Translational Medical Center for Pediatric Cataract in Guangzhou City; the Fundamental Research Funds for the Central Universities (No. BDZ011401, BDZ011401 and JB151005); and the National Defense Basic Research Project of China (jcky2016110c006).</p></sec><sec id="FPar7"><title>Publisher&#x02019;s Note</title><p id="Par52">Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></sec></ack><ref-list id="Bib1"><title>References</title><ref id="CR1"><label>1.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Duggirala</surname><given-names>HJ</given-names></name><name><surname>Tonning</surname><given-names>JM</given-names></name><name><surname>Smith</surname><given-names>E</given-names></name><etal/></person-group><article-title>Use of data mining at the Food and Drug Administration</article-title><source>J Am Med Inform Assoc</source><year>2016</year><volume>23</volume><fpage>428</fpage><pub-id pub-id-type="doi">10.1093/jamia/ocv063</pub-id><pub-id pub-id-type="pmid">26209436</pub-id></element-citation></ref><ref id="CR2"><label>2.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gulshan</surname><given-names>V</given-names></name><name><surname>Peng</surname><given-names>L</given-names></name><name><surname>Coram</surname><given-names>M</given-names></name><etal/></person-group><article-title>Development and validation of a deep learning algorithm for detection of diabetic retinopathy in retinal fundus photographs</article-title><source>JAMA</source><year>2016</year><volume>316</volume><fpage>2402</fpage><pub-id pub-id-type="doi">10.1001/jama.2016.17216</pub-id><pub-id pub-id-type="pmid">27898976</pub-id></element-citation></ref><ref id="CR3"><label>3.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Resnikoff</surname><given-names>S</given-names></name><name><surname>Keys</surname><given-names>TU</given-names></name></person-group><article-title>Future trends in global blindness</article-title><source>Indian J Ophthalmol</source><year>2012</year><volume>60</volume><fpage>387</fpage><lpage>395</lpage><pub-id pub-id-type="doi">10.4103/0301-4738.100532</pub-id><pub-id pub-id-type="pmid">22944747</pub-id></element-citation></ref><ref id="CR4"><label>4.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lin</surname><given-names>H</given-names></name><name><surname>Lin</surname><given-names>D</given-names></name><name><surname>Chen</surname><given-names>J</given-names></name><etal/></person-group><article-title>Distribution of axial length before cataract surgery in chinese pediatric patients</article-title><source>Sci Rep</source><year>2016</year><volume>6</volume><fpage>23862</fpage><pub-id pub-id-type="doi">10.1038/srep23862</pub-id><pub-id pub-id-type="pmid">27022004</pub-id></element-citation></ref><ref id="CR5"><label>5.</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Daw</surname><given-names>NW</given-names></name></person-group><source>Visual development</source><year>2006</year><publisher-loc>US</publisher-loc><publisher-name>Springer</publisher-name></element-citation></ref><ref id="CR6"><label>6.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jackson</surname><given-names>WS</given-names></name><name><surname>Lindquist</surname><given-names>S</given-names></name></person-group><article-title>Illuminating aggregate heterogeneity in neurodegenerative disease</article-title><source>Nat Methods</source><year>2007</year><volume>4</volume><fpage>1000</fpage><lpage>1001</lpage><pub-id pub-id-type="doi">10.1038/nmeth1207-1000</pub-id><pub-id pub-id-type="pmid">18049468</pub-id></element-citation></ref><ref id="CR7"><label>7.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>Z</given-names></name><name><surname>Fillmore</surname><given-names>CM</given-names></name><name><surname>Hammerman</surname><given-names>PS</given-names></name><name><surname>Kim</surname><given-names>CF</given-names></name><name><surname>Wong</surname><given-names>KK</given-names></name></person-group><article-title>Non-small-cell lung cancers: a heterogeneous set of diseases</article-title><source>Nat Rev Cancer</source><year>2014</year><volume>14</volume><fpage>535</fpage><lpage>546</lpage><pub-id pub-id-type="doi">10.1038/nrc3775</pub-id><pub-id pub-id-type="pmid">25056707</pub-id></element-citation></ref><ref id="CR8"><label>8.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bedard</surname><given-names>PL</given-names></name><name><surname>Hansen</surname><given-names>AR</given-names></name><name><surname>Ratain</surname><given-names>MJ</given-names></name><name><surname>Siu</surname><given-names>LL</given-names></name></person-group><article-title>Tumour heterogeneity in the clinic</article-title><source>Nature</source><year>2013</year><volume>501</volume><fpage>355</fpage><lpage>364</lpage><pub-id pub-id-type="doi">10.1038/nature12627</pub-id><pub-id pub-id-type="pmid">24048068</pub-id></element-citation></ref><ref id="CR9"><label>9.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Raju</surname><given-names>D</given-names></name><name><surname>Su</surname><given-names>X</given-names></name><name><surname>Patrician</surname><given-names>PA</given-names></name><name><surname>Loan</surname><given-names>LA</given-names></name><name><surname>McCarthy</surname><given-names>MS</given-names></name></person-group><article-title>Exploring factors associated with pressure ulcers: a data mining approach</article-title><source>Int J Nurs Stud</source><year>2015</year><volume>52</volume><fpage>102</fpage><lpage>111</lpage><pub-id pub-id-type="doi">10.1016/j.ijnurstu.2014.08.002</pub-id><pub-id pub-id-type="pmid">25192963</pub-id></element-citation></ref><ref id="CR10"><label>10.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pereira</surname><given-names>S</given-names></name><name><surname>Portela</surname><given-names>F</given-names></name><name><surname>Santos</surname><given-names>MF</given-names></name><name><surname>Machado</surname><given-names>J</given-names></name><name><surname>Abelha</surname><given-names>A</given-names></name></person-group><article-title>Predicting type of delivery by identification of obstetric risk factors through data mining</article-title><source>Procedia Comput Sci</source><year>2015</year><volume>64</volume><fpage>601</fpage><lpage>609</lpage><pub-id pub-id-type="doi">10.1016/j.procs.2015.08.573</pub-id></element-citation></ref><ref id="CR11"><label>11.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aljumah</surname><given-names>AA</given-names></name><name><surname>Ahamad</surname><given-names>MG</given-names></name><name><surname>Siddiqui</surname><given-names>MK</given-names></name></person-group><article-title>Application of data mining: diabetes health care in young and old patients</article-title><source>J King Saud Univ Comput Inf Sci</source><year>2013</year><volume>25</volume><fpage>127</fpage><lpage>136</lpage></element-citation></ref><ref id="CR12"><label>12.</label><mixed-citation publication-type="other">Somanchi S, Adhikari S, Lin A, Eneva E, Ghani R. Early prediction of cardiac arrest (code blue) using electronic medical records. In: Proceedings of the 21th ACM SIGKDD international conference on knowledge discovery and data mining. New York: ACM; 2015. p. 2119&#x02013;2126.</mixed-citation></ref><ref id="CR13"><label>13.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lin</surname><given-names>H</given-names></name><name><surname>Long</surname><given-names>E</given-names></name><name><surname>Chen</surname><given-names>W</given-names></name><name><surname>Liu</surname><given-names>Y</given-names></name></person-group><article-title>Documenting rare disease data in China</article-title><source>Science</source><year>2015</year><volume>349</volume><fpage>1064</fpage><pub-id pub-id-type="doi">10.1126/science.349.6252.1064-b</pub-id></element-citation></ref><ref id="CR14"><label>14.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>X</given-names></name><name><surname>Jiang</surname><given-names>J</given-names></name><name><surname>Zhang</surname><given-names>K</given-names></name><etal/></person-group><article-title>Localization and diagnosis framework for pediatric cataracts based on slit-lamp images using deep features of a convolutional neural network</article-title><source>PLoS ONE</source><year>2017</year><volume>12</volume><fpage>e0168606</fpage><pub-id pub-id-type="doi">10.1371/journal.pone.0168606</pub-id><pub-id pub-id-type="pmid">28306716</pub-id></element-citation></ref><ref id="CR15"><label>15.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mataftsi</surname><given-names>A</given-names></name><name><surname>Haidich</surname><given-names>AB</given-names></name><name><surname>Kokkali</surname><given-names>S</given-names></name><etal/></person-group><article-title>Postoperative glaucoma following infantile cataract surgery: an individual patient data meta-analysis</article-title><source>Jama Ophthalmol</source><year>2014</year><volume>132</volume><fpage>1059</fpage><lpage>1067</lpage><pub-id pub-id-type="doi">10.1001/jamaophthalmol.2014.1042</pub-id><pub-id pub-id-type="pmid">24921712</pub-id></element-citation></ref><ref id="CR16"><label>16.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barua</surname><given-names>S</given-names></name><name><surname>Islam</surname><given-names>MM</given-names></name><name><surname>Yao</surname><given-names>X</given-names></name><name><surname>Murase</surname><given-names>K</given-names></name></person-group><article-title>MWMOTE&#x02013;majority weighted minority oversampling technique for imbalanced data set learning</article-title><source>IEEE Trans Knowl Data Eng</source><year>2014</year><volume>26</volume><fpage>405</fpage><lpage>425</lpage><pub-id pub-id-type="doi">10.1109/TKDE.2012.232</pub-id></element-citation></ref><ref id="CR17"><label>17.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Verbiest</surname><given-names>N</given-names></name><name><surname>Ramentol</surname><given-names>E</given-names></name><name><surname>Cornelis</surname><given-names>C</given-names></name><name><surname>Herrera</surname><given-names>F</given-names></name></person-group><article-title>Preprocessing noisy imbalanced datasets using SMOTE enhanced with fuzzy rough prototype selection</article-title><source>Appl Soft Comput</source><year>2014</year><volume>22</volume><fpage>511</fpage><lpage>517</lpage><pub-id pub-id-type="doi">10.1016/j.asoc.2014.05.023</pub-id></element-citation></ref><ref id="CR18"><label>18.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burges</surname><given-names>CJC</given-names></name></person-group><article-title>A tutorial on support vector machines for pattern recognition</article-title><source>Data Min Knowl Disc</source><year>1998</year><volume>2</volume><fpage>121</fpage><lpage>167</lpage><pub-id pub-id-type="doi">10.1023/A:1009715923555</pub-id></element-citation></ref><ref id="CR19"><label>19.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yen</surname><given-names>SJ</given-names></name><name><surname>Lee</surname><given-names>YS</given-names></name></person-group><article-title>Cluster-based under-sampling approaches for imbalanced data distributions</article-title><source>Expert Syst Appl</source><year>2009</year><volume>36</volume><fpage>5718</fpage><lpage>5727</lpage><pub-id pub-id-type="doi">10.1016/j.eswa.2008.06.108</pub-id></element-citation></ref><ref id="CR20"><label>20.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ib&#x000e1;&#x000f1;ez</surname><given-names>A</given-names></name><name><surname>Bielza</surname><given-names>C</given-names></name><name><surname>Larra&#x000f1;aga</surname><given-names>P</given-names></name></person-group><article-title>Cost-sensitive selective naive Bayes classifiers for predicting the increase of the h-index for scientific journals</article-title><source>Neurocomputing</source><year>2014</year><volume>135</volume><fpage>42</fpage><lpage>52</lpage><pub-id pub-id-type="doi">10.1016/j.neucom.2013.08.042</pub-id></element-citation></ref><ref id="CR21"><label>21.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zidelmal</surname><given-names>Z</given-names></name><name><surname>Amirou</surname><given-names>A</given-names></name><name><surname>Ould-Abdeslam</surname><given-names>D</given-names></name><name><surname>Merckle</surname><given-names>J</given-names></name></person-group><article-title>ECG beat classification using a cost sensitive classifier</article-title><source>Comput Methods Progr Biomed</source><year>2013</year><volume>111</volume><fpage>570</fpage><lpage>577</lpage><pub-id pub-id-type="doi">10.1016/j.cmpb.2013.05.011</pub-id></element-citation></ref><ref id="CR22"><label>22.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yang</surname><given-names>Z</given-names></name><name><surname>Tang</surname><given-names>WH</given-names></name><name><surname>Shintemirov</surname><given-names>A</given-names></name><name><surname>Wu</surname><given-names>QH</given-names></name></person-group><article-title>Association rule mining-based dissolved gas analysis for fault diagnosis of power transformers</article-title><source>IEEE Trans Syst Man Cybern Part C</source><year>2009</year><volume>39</volume><fpage>597</fpage><lpage>610</lpage><pub-id pub-id-type="doi">10.1109/TSMCC.2009.2021989</pub-id></element-citation></ref><ref id="CR23"><label>23.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Khalili</surname><given-names>A</given-names></name><name><surname>Sami</surname><given-names>A</given-names></name></person-group><article-title>SysDetect: a systematic approach to critical state determination for Industrial Intrusion Detection Systems using Apriori algorithm</article-title><source>J Process Control</source><year>2015</year><volume>32</volume><fpage>154</fpage><lpage>160</lpage><pub-id pub-id-type="doi">10.1016/j.jprocont.2015.04.005</pub-id></element-citation></ref><ref id="CR24"><label>24.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shaheen</surname><given-names>M</given-names></name><name><surname>Shahbaz</surname><given-names>M</given-names></name></person-group><article-title>An algorithm of association rule mining for microbial energy prospection</article-title><source>Sci Rep</source><year>2017</year><volume>7</volume><fpage>46108</fpage><pub-id pub-id-type="doi">10.1038/srep46108</pub-id><pub-id pub-id-type="pmid">28393846</pub-id></element-citation></ref><ref id="CR25"><label>25.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bellinger</surname><given-names>C</given-names></name><name><surname>Mohomed Jabbar</surname><given-names>MS</given-names></name><name><surname>Za&#x000ef;ane</surname><given-names>O</given-names></name><name><surname>Osornio-Vargas</surname><given-names>A</given-names></name></person-group><article-title>A systematic review of data mining and machine learning for air pollution epidemiology</article-title><source>BMC Public Health</source><year>2017</year><volume>17</volume><fpage>907</fpage><pub-id pub-id-type="doi">10.1186/s12889-017-4914-3</pub-id><pub-id pub-id-type="pmid">29179711</pub-id></element-citation></ref><ref id="CR26"><label>26.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jiang</surname><given-names>L</given-names></name><name><surname>Li</surname><given-names>C</given-names></name><name><surname>Wang</surname><given-names>S</given-names></name><name><surname>Zhang</surname><given-names>L</given-names></name></person-group><article-title>Deep feature weighting for naive Bayes and its application to text classification</article-title><source>Eng Appl Artif Intell</source><year>2016</year><volume>52</volume><fpage>26</fpage><lpage>39</lpage><pub-id pub-id-type="doi">10.1016/j.engappai.2016.02.002</pub-id></element-citation></ref><ref id="CR27"><label>27.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kim</surname><given-names>S-B</given-names></name><name><surname>Han</surname><given-names>K-S</given-names></name><name><surname>Rim</surname><given-names>H-C</given-names></name><name><surname>Myaeng</surname><given-names>SH</given-names></name></person-group><article-title>Some effective techniques for naive bayes text classification</article-title><source>IEEE Trans Knowl Data Eng</source><year>2006</year><volume>18</volume><fpage>1457</fpage><lpage>1466</lpage><pub-id pub-id-type="doi">10.1109/TKDE.2006.180</pub-id></element-citation></ref><ref id="CR28"><label>28.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wu</surname><given-names>J</given-names></name><name><surname>Pan</surname><given-names>S</given-names></name><name><surname>Zhu</surname><given-names>X</given-names></name><name><surname>Cai</surname><given-names>Z</given-names></name><name><surname>Zhang</surname><given-names>P</given-names></name><name><surname>Zhang</surname><given-names>C</given-names></name></person-group><article-title>Self-adaptive attribute weighting for Naive Bayes classification</article-title><source>Expert Syst Appl</source><year>2015</year><volume>42</volume><fpage>1487</fpage><lpage>1502</lpage><pub-id pub-id-type="doi">10.1016/j.eswa.2014.09.019</pub-id></element-citation></ref><ref id="CR29"><label>29.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>Y-F</given-names></name><name><surname>Guo</surname><given-names>J-M</given-names></name><name><surname>Lee</surname><given-names>J-D</given-names></name></person-group><article-title>Halftone image classification using LMS algorithm and naive Bayes</article-title><source>IEEE Trans Image Process</source><year>2011</year><volume>20</volume><fpage>2837</fpage><lpage>2847</lpage><pub-id pub-id-type="doi">10.1109/TIP.2011.2118223</pub-id><pub-id pub-id-type="pmid">21926004</pub-id></element-citation></ref><ref id="CR30"><label>30.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marucci-Wellman</surname><given-names>HR</given-names></name><name><surname>Lehto</surname><given-names>MR</given-names></name><name><surname>Corns</surname><given-names>HL</given-names></name></person-group><article-title>A practical tool for public health surveillance: semi-automated coding of short injury narratives from large administrative databases using Na&#x000ef;ve Bayes algorithms</article-title><source>Accid Anal Prev</source><year>2015</year><volume>84</volume><fpage>165</fpage><lpage>176</lpage><pub-id pub-id-type="doi">10.1016/j.aap.2015.06.014</pub-id><pub-id pub-id-type="pmid">26412196</pub-id></element-citation></ref><ref id="CR31"><label>31.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Miranda</surname><given-names>E</given-names></name><name><surname>Irwansyah</surname><given-names>E</given-names></name><name><surname>Amelga</surname><given-names>AY</given-names></name><name><surname>Maribondang</surname><given-names>MM</given-names></name><name><surname>Salim</surname><given-names>M</given-names></name></person-group><article-title>Detection of cardiovascular disease risk&#x02019;s level for adults using Naive Bayes classifier</article-title><source>Healthcare Inform Res</source><year>2016</year><volume>22</volume><fpage>196</fpage><lpage>205</lpage><pub-id pub-id-type="doi">10.4258/hir.2016.22.3.196</pub-id></element-citation></ref><ref id="CR32"><label>32.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>H</given-names></name><name><surname>Jiang</surname><given-names>T</given-names></name><name><surname>Shan</surname><given-names>G</given-names></name></person-group><article-title>Identification of hot spots in protein structures using Gaussian network model and Gaussian Naive Bayes</article-title><source>Biomed Res Int</source><year>2016</year><volume>2016</volume><fpage>4354901</fpage><pub-id pub-id-type="pmid">27882325</pub-id></element-citation></ref><ref id="CR33"><label>33.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Arvind</surname><given-names>V</given-names></name><name><surname>K&#x000f6;bler</surname><given-names>J</given-names></name><name><surname>Kuhnert</surname><given-names>S</given-names></name><name><surname>Rattan</surname><given-names>G</given-names></name><name><surname>Vasudev</surname><given-names>Y</given-names></name></person-group><article-title>On the isomorphism problem for decision trees and decision lists</article-title><source>Theor Comput Sci</source><year>2015</year><volume>590</volume><fpage>38</fpage><lpage>54</lpage><pub-id pub-id-type="doi">10.1016/j.tcs.2015.01.025</pub-id></element-citation></ref><ref id="CR34"><label>34.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mistikoglu</surname><given-names>G</given-names></name><name><surname>Gerek</surname><given-names>IH</given-names></name><name><surname>Erdis</surname><given-names>E</given-names></name><name><surname>Usmen</surname><given-names>PEM</given-names></name><name><surname>Cakan</surname><given-names>H</given-names></name><name><surname>Kazan</surname><given-names>EE</given-names></name></person-group><article-title>Decision tree analysis of construction fall accidents involving roofers</article-title><source>Expert Syst Appl</source><year>2014</year><volume>42</volume><fpage>2256</fpage><lpage>2263</lpage><pub-id pub-id-type="doi">10.1016/j.eswa.2014.10.009</pub-id></element-citation></ref><ref id="CR35"><label>35.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Senroy</surname><given-names>N</given-names></name><name><surname>Heydt</surname><given-names>GT</given-names></name><name><surname>Vittal</surname><given-names>V</given-names></name></person-group><article-title>Decision tree assisted controlled islanding</article-title><source>IEEE Trans Power Syst</source><year>2006</year><volume>21</volume><fpage>1790</fpage><lpage>1797</lpage><pub-id pub-id-type="doi">10.1109/TPWRS.2006.882470</pub-id></element-citation></ref><ref id="CR36"><label>36.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nasseri</surname><given-names>AA</given-names></name><name><surname>Tucker</surname><given-names>A</given-names></name><name><surname>Cesare</surname><given-names>SD</given-names></name></person-group><article-title>Quantifying StockTwits semantic terms&#x02019; trading behavior in financial markets: an effective application of decision tree algorithms</article-title><source>Expert Syst Appl</source><year>2015</year><volume>42</volume><fpage>9192</fpage><lpage>9210</lpage><pub-id pub-id-type="doi">10.1016/j.eswa.2015.08.008</pub-id></element-citation></ref><ref id="CR37"><label>37.</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Jiawei</surname><given-names>H</given-names></name><name><surname>Micheline</surname><given-names>K</given-names></name><name><surname>Jian</surname><given-names>P</given-names></name></person-group><source>Data mining: concepts and techniques</source><year>2012</year><edition>3</edition><publisher-loc>China</publisher-loc><publisher-name>China Machine Press</publisher-name><fpage>217</fpage><lpage>221</lpage></element-citation></ref><ref id="CR38"><label>38.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pei</surname><given-names>S-C</given-names></name><name><surname>Chen</surname><given-names>L-H</given-names></name></person-group><article-title>Image quality assessment using human visual DOG model fused with random forest</article-title><source>IEEE Trans Image Process</source><year>2015</year><volume>24</volume><fpage>3282</fpage><lpage>3292</lpage><pub-id pub-id-type="doi">10.1109/TIP.2015.2440172</pub-id><pub-id pub-id-type="pmid">26054064</pub-id></element-citation></ref><ref id="CR39"><label>39.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Qian</surname><given-names>C</given-names></name><name><surname>Wang</surname><given-names>L</given-names></name><name><surname>Gao</surname><given-names>Y</given-names></name><etal/></person-group><article-title>In vivo MRI based prostate cancer localization with random forests and auto-context model</article-title><source>Comput Med Imaging Gr.</source><year>2016</year><volume>52</volume><fpage>44</fpage><lpage>57</lpage><pub-id pub-id-type="doi">10.1016/j.compmedimag.2016.02.001</pub-id></element-citation></ref><ref id="CR40"><label>40.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mourad</surname><given-names>R</given-names></name><name><surname>Ginalski</surname><given-names>K</given-names></name><name><surname>Legube</surname><given-names>G</given-names></name><name><surname>Cuvier</surname><given-names>O</given-names></name></person-group><article-title>Predicting double-strand DNA breaks using epigenome marks or DNA at kilobase resolution</article-title><source>Genome Biol</source><year>2018</year><volume>19</volume><fpage>34</fpage><pub-id pub-id-type="doi">10.1186/s13059-018-1411-7</pub-id><pub-id pub-id-type="pmid">29544533</pub-id></element-citation></ref><ref id="CR41"><label>41.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wu</surname><given-names>Q</given-names></name><name><surname>Ye</surname><given-names>Y</given-names></name><name><surname>Liu</surname><given-names>Y</given-names></name><name><surname>Ng</surname><given-names>MK</given-names></name></person-group><article-title>SNP selection and classification of genome-wide SNP data using stratified sampling random forests</article-title><source>IEEE Trans Nanobiosci</source><year>2012</year><volume>11</volume><fpage>216</fpage><lpage>227</lpage><pub-id pub-id-type="doi">10.1109/TNB.2012.2214232</pub-id></element-citation></ref><ref id="CR42"><label>42.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yang</surname><given-names>Q</given-names></name><name><surname>Wang</surname><given-names>M</given-names></name><name><surname>Xiao</surname><given-names>H</given-names></name><etal/></person-group><article-title>Feature selection using a combination of genetic algorithm and selection frequency curve analysis</article-title><source>Chemomet Intell Lab Syst</source><year>2015</year><volume>148</volume><fpage>106</fpage><lpage>114</lpage><pub-id pub-id-type="doi">10.1016/j.chemolab.2015.09.007</pub-id></element-citation></ref><ref id="CR43"><label>43.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>L</given-names></name><name><surname>Zhang</surname><given-names>K</given-names></name><name><surname>Liu</surname><given-names>X</given-names></name><etal/></person-group><article-title>Comparative analysis of image classification methods for automatic diagnosis of ophthalmic images</article-title><source>Sci Rep.</source><year>2017</year><volume>7</volume><fpage>41545</fpage><pub-id pub-id-type="doi">10.1038/srep41545</pub-id><pub-id pub-id-type="pmid">28139688</pub-id></element-citation></ref><ref id="CR44"><label>44.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ghareb</surname><given-names>AS</given-names></name><name><surname>Bakar</surname><given-names>AA</given-names></name><name><surname>Hamdan</surname><given-names>AR</given-names></name></person-group><article-title>Hybrid feature selection based on enhanced genetic algorithm for text categorization</article-title><source>Expert Syst Appl</source><year>2016</year><volume>49</volume><fpage>31</fpage><lpage>47</lpage><pub-id pub-id-type="doi">10.1016/j.eswa.2015.12.004</pub-id></element-citation></ref><ref id="CR45"><label>45.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nagarajan</surname><given-names>G</given-names></name><name><surname>Minu</surname><given-names>R</given-names></name><name><surname>Muthukumar</surname><given-names>B</given-names></name><name><surname>Vedanarayanan</surname><given-names>V</given-names></name><name><surname>Sundarsingh</surname><given-names>S</given-names></name></person-group><article-title>Hybrid genetic algorithm for medical image feature extraction and selection</article-title><source>Procedia Comput Sci</source><year>2016</year><volume>85</volume><fpage>455</fpage><lpage>462</lpage><pub-id pub-id-type="doi">10.1016/j.procs.2016.05.192</pub-id></element-citation></ref><ref id="CR46"><label>46.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lu</surname><given-names>L</given-names></name><name><surname>Yan</surname><given-names>J</given-names></name><name><surname>de Silva</surname><given-names>CW</given-names></name></person-group><article-title>Feature selection for ECG signal processing using improved genetic algorithm and empirical mode decomposition</article-title><source>Measurement</source><year>2016</year><volume>94</volume><fpage>372</fpage><lpage>381</lpage><pub-id pub-id-type="doi">10.1016/j.measurement.2016.07.043</pub-id></element-citation></ref><ref id="CR47"><label>47.</label><mixed-citation publication-type="other">Zhang M-L, Zhang K. Multi-label learning by exploiting label dependency. In: Proceedings of the 16th ACM SIGKDD international conference on Knowledge discovery and data mining. New York: ACM; 2010. p. 999&#x02013;1008.</mixed-citation></ref><ref id="CR48"><label>48.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>K</given-names></name><name><surname>Liu</surname><given-names>X</given-names></name><name><surname>Liu</surname><given-names>F</given-names></name><name><surname>He</surname><given-names>L</given-names></name><name><surname>Zhang</surname><given-names>L</given-names></name><name><surname>Yang</surname><given-names>Y</given-names></name><name><surname>Li</surname><given-names>W</given-names></name><name><surname>Wang</surname><given-names>S</given-names></name><name><surname>Liu</surname><given-names>L</given-names></name><name><surname>Liu</surname><given-names>Z</given-names></name><name><surname>Wu</surname><given-names>X</given-names></name><name><surname>Lin</surname><given-names>H</given-names></name></person-group><article-title>An interpretable and expandable deep learning diagnostic system for multiple ocular diseases: qualitative study</article-title><source>J Med Internet Res</source><year>2018</year><volume>20</volume><issue>11</issue><fpage>e11144</fpage><pub-id pub-id-type="doi">10.2196/11144</pub-id><pub-id pub-id-type="pmid">30429111</pub-id></element-citation></ref></ref-list></back></article>