
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">Sensors (Basel)</journal-id><journal-id journal-id-type="iso-abbrev">Sensors (Basel)</journal-id><journal-id journal-id-type="publisher-id">sensors</journal-id><journal-title-group><journal-title>Sensors (Basel, Switzerland)</journal-title></journal-title-group><issn pub-type="epub">1424-8220</issn><publisher><publisher-name>MDPI</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">32824252</article-id><article-id pub-id-type="pmc">7472305</article-id><article-id pub-id-type="doi">10.3390/s20164589</article-id><article-id pub-id-type="publisher-id">sensors-20-04589</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Restoration and Calibration of Tilting Hyperspectral Super-Resolution Image</article-title></title-group><contrib-group><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0001-9394-0461</contrib-id><name><surname>Zhang</surname><given-names>Xizhen</given-names></name><xref ref-type="aff" rid="af1-sensors-20-04589">1</xref><xref ref-type="aff" rid="af2-sensors-20-04589">2</xref><xref ref-type="aff" rid="af3-sensors-20-04589">3</xref></contrib><contrib contrib-type="author"><name><surname>Zhang</surname><given-names>Aiwu</given-names></name><xref ref-type="aff" rid="af1-sensors-20-04589">1</xref><xref ref-type="aff" rid="af2-sensors-20-04589">2</xref><xref ref-type="aff" rid="af3-sensors-20-04589">3</xref><xref rid="c1-sensors-20-04589" ref-type="corresp">*</xref></contrib><contrib contrib-type="author"><name><surname>Li</surname><given-names>Mengnan</given-names></name><xref ref-type="aff" rid="af1-sensors-20-04589">1</xref><xref ref-type="aff" rid="af2-sensors-20-04589">2</xref><xref ref-type="aff" rid="af3-sensors-20-04589">3</xref></contrib><contrib contrib-type="author"><name><surname>Liu</surname><given-names>Lulu</given-names></name><xref ref-type="aff" rid="af1-sensors-20-04589">1</xref><xref ref-type="aff" rid="af2-sensors-20-04589">2</xref><xref ref-type="aff" rid="af3-sensors-20-04589">3</xref></contrib><contrib contrib-type="author"><name><surname>Kang</surname><given-names>Xiaoyan</given-names></name><xref ref-type="aff" rid="af1-sensors-20-04589">1</xref><xref ref-type="aff" rid="af2-sensors-20-04589">2</xref><xref ref-type="aff" rid="af3-sensors-20-04589">3</xref></contrib></contrib-group><aff id="af1-sensors-20-04589"><label>1</label>Key Laboratory of 3D Information Acquisition and Application, Ministry of Education, Capital Normal University, Beijing 100048, China; <email>xzzhang93@163.com</email> (X.Z.); <email>lmn1912601616@163.com</email> (M.L.); <email>liululu@cnu.edu.cn</email> (L.L.); <email>xy.maup.kang@gmail.com</email> (X.K.)</aff><aff id="af2-sensors-20-04589"><label>2</label>Engineering Research Center of Spatial Information Technology, Ministry of Education, Capital Normal University, Beijing 100048, China</aff><aff id="af3-sensors-20-04589"><label>3</label>Center for Geographic Environment Research and Education, Capital Normal University, Beijing 100048, China</aff><author-notes><corresp id="c1-sensors-20-04589"><label>*</label>Correspondence: <email>zhangaw98@163.com</email></corresp></author-notes><pub-date pub-type="epub"><day>15</day><month>8</month><year>2020</year></pub-date><pub-date pub-type="collection"><month>8</month><year>2020</year></pub-date><volume>20</volume><issue>16</issue><elocation-id>4589</elocation-id><history><date date-type="received"><day>23</day><month>6</month><year>2020</year></date><date date-type="accepted"><day>14</day><month>8</month><year>2020</year></date></history><permissions><copyright-statement>&#x000a9; 2020 by the authors.</copyright-statement><copyright-year>2020</copyright-year><license license-type="open-access"><license-p>Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>).</license-p></license></permissions><abstract><p>Tilting sampling is a novel sampling mode for achieving a higher resolution of hyperspectral imagery. However, most studies on the tilting image have only focused on a single band, which loses the features of hyperspectral imagery. This study focuses on the restoration of tilting hyperspectral imagery and the practicality of its results. First, we reduced the huge data of tilting hyperspectral imagery by the <italic>p</italic>-value sparse matrix band selection method (<italic>pSMBS</italic>). Then, we restored the reduced imagery by optimal reciprocal cell combined modulation transfer function (MTF) method. Next, we built the relationship between the restored tilting image and the original normal image. We employed the least square method to solve the calibration equation for each band. Finally, the calibrated tilting image and original normal image were both classified by the unsupervised classification method (K-means) to confirm the practicality of calibrated tilting images in remote sensing applications. The results of classification demonstrate the optimal reciprocal cell combined MTF method can effectively restore the tilting image and the calibrated tiling image can be used in remote sensing applications. The restored and calibrated tilting image has a higher resolution and better spectral fidelity.</p></abstract><kwd-group><kwd>tilting sampling mode</kwd><kwd>optimal reciprocal cell</kwd><kwd>modulation transfer function (MTF)</kwd><kwd>calibration</kwd><kwd>spectral fidelity</kwd><kwd>the least square method</kwd></kwd-group></article-meta></front><body><sec sec-type="intro" id="sec1-sensors-20-04589"><title>1. Introduction</title><p>Tilting sampling is a novel sampling method that can improve the spatial resolution of an image by changing the imaging angle between a charge-coupled device (CCD) line array in a sensor and the sensor&#x02019;s moving direction [<xref rid="B1-sensors-20-04589" ref-type="bibr">1</xref>,<xref rid="B2-sensors-20-04589" ref-type="bibr">2</xref>]. Compared with high-mode sampling and super-mode sampling, tilting sampling only uses a single imaging CCD line array in the sensor, which is easier to manufacture and lower cost, and it can also avoid low registration accuracy problems caused by sampling with two CCD line arrays [<xref rid="B3-sensors-20-04589" ref-type="bibr">3</xref>,<xref rid="B4-sensors-20-04589" ref-type="bibr">4</xref>,<xref rid="B5-sensors-20-04589" ref-type="bibr">5</xref>]. The tilting sampling can effectively improve the image spatial resolution by controlling the imaging angles in the sampling and combining with the appropriate image restoration steps [<xref rid="B2-sensors-20-04589" ref-type="bibr">2</xref>,<xref rid="B5-sensors-20-04589" ref-type="bibr">5</xref>].</p><p>Since the tilting sampling method was proposed, many scholars have focused on the research about the imaging angle and the restoration methods of tiling image. It has been found the aliasing in the tilting image is different from that in the normal image, which can be used to improve the details of the tilting image [<xref rid="B5-sensors-20-04589" ref-type="bibr">5</xref>]. Traditionally, aliasing has been generated in the frequency domain [<xref rid="B6-sensors-20-04589" ref-type="bibr">6</xref>]. Therefore, most anti-aliasing methods were developed in the frequency domain [<xref rid="B7-sensors-20-04589" ref-type="bibr">7</xref>]. It has been proved the reciprocal cell method, which anti-aliasing in frequency&#x02013;domain, can effectively remove the aliasing in the tilting images [<xref rid="B8-sensors-20-04589" ref-type="bibr">8</xref>]. Based on the reciprocal cell methods, the optimal reciprocal cell was proposed for anti-aliasing, and it was found that the optimal reciprocal cell would get better results in the anti-aliasing step [<xref rid="B9-sensors-20-04589" ref-type="bibr">9</xref>]. Compared with normal sampling methods, whose imaging angle is 90&#x000b0;, the spatial resolution can be improved around 1.64 times by using the 45&#x000b0; angle as the imaging angle of tilting sampling [<xref rid="B2-sensors-20-04589" ref-type="bibr">2</xref>]. By sampling with some special imaging angles, and&#x02014;using the reciprocal cell method in the image restoration step&#x02014;the effective resolution of the tilting image can be improved [<xref rid="B3-sensors-20-04589" ref-type="bibr">3</xref>,<xref rid="B10-sensors-20-04589" ref-type="bibr">10</xref>]. The effective resolution is highly relative to the aliasing while establishing the relationship between aliasing and imaging systems [<xref rid="B11-sensors-20-04589" ref-type="bibr">11</xref>]. The restoration based on hybrid reciprocal cell-wavelet can remove the aliasing and the noise of the image and can achieve a better image restoration effect [<xref rid="B12-sensors-20-04589" ref-type="bibr">12</xref>]. However, the noise and blurring in the image are also the main factors that affect the resolution and quality of images [<xref rid="B13-sensors-20-04589" ref-type="bibr">13</xref>]. Therefore, finding a suitable restoration method for tilting image is the key step to obtain a higher resolution image. MTF is widely recognized as the performance of the details about the imaging systems [<xref rid="B14-sensors-20-04589" ref-type="bibr">14</xref>,<xref rid="B15-sensors-20-04589" ref-type="bibr">15</xref>]. MTF, a key characteristic of the imaging system [<xref rid="B16-sensors-20-04589" ref-type="bibr">16</xref>,<xref rid="B17-sensors-20-04589" ref-type="bibr">17</xref>] is also an effective method to remove the blurring and noise in images. MTF, combining with optimal reciprocal cell method which has been used in the restoration of tilting images, has achieved better restoration results because of the special anisotropy of MTF [<xref rid="B18-sensors-20-04589" ref-type="bibr">18</xref>,<xref rid="B19-sensors-20-04589" ref-type="bibr">19</xref>]. The optimal imaging angle of the tilting imaging system has been studied, and the imaging angle of 72&#x000b0; has been chosen as the optimal imaging angle of the tilting imaging system while considering aliasing, field width, sampling grid and the effective resolution of tilting images [<xref rid="B5-sensors-20-04589" ref-type="bibr">5</xref>]. However, most studies about the restoration of tilting images were based on a single band or imaging angles. Therefore, the tensor methods have been studied, and it makes the reciprocal cell methods succeed to be applied for restore the multi-bands tilting image [<xref rid="B20-sensors-20-04589" ref-type="bibr">20</xref>].</p><p>Scholars have done much work on selecting the special imaging angles and the restoration methods of tilting images, making great achievements in tilting sampling. The work of that has greatly promoted a huge development of tilting hyperspectral super-resolution technology. However, most restoration methods of tilting images focus on the single band, which means that the studies had not studied the tilting hyperspectral imagery, even multi-bands tilting images. Moreover, they ignored the spectral distortion of the restored tilting images and the uncertain practicability of tilting hyperspectral imageries. The spectral distortion makes the restored tilting image lose the remote sensing practical meaning. Therefore, this work uses some existing mature methods to restore the tilting hyperspectral imageries to address the problems unconsidered yet and analyses the spectral differences between restored tilting images and original normal images to calibration the restored tilting image for ensuring its practicability.</p><p>This study is organized as follows: The proposed methods are introduced in <xref ref-type="sec" rid="sec2-sensors-20-04589">Section 2</xref>. The restoration of the tilting image which combined the method of reciprocal cell and MTF is shown in <xref ref-type="sec" rid="sec3-sensors-20-04589">Section 3</xref> and the calibration results of the tilting image are shown in <xref ref-type="sec" rid="sec4-sensors-20-04589">Section 4</xref>. Discussions are given in <xref ref-type="sec" rid="sec5-sensors-20-04589">Section 5</xref> and following by the conclusions in <xref ref-type="sec" rid="sec6-sensors-20-04589">Section 6</xref>.</p></sec><sec sec-type="methods" id="sec2-sensors-20-04589"><title>2. Methods</title><sec id="sec2dot1-sensors-20-04589"><title>2.1. Tilting Hyperspectral Super-Resolution Imaging System</title><p>Tilting hyperspectral imaging is system sampling with a single imaging CCD line array that causes an angle between the imaging CCD line array and the moving direction of the sensor&#x02014;called the imaging angle. The tilting sampling diagram is shown in <xref ref-type="fig" rid="sensors-20-04589-f001">Figure 1</xref>.</p><p>Compared with the normal methods that samples in the same field of view, the tilting sampling image method has a smaller pixel dimension and a higher sampling density so that the tilting sampling can achieve a higher resolution of the image.</p><p>The image <inline-formula><mml:math id="mm1"><mml:mrow><mml:mi>g</mml:mi></mml:mrow></mml:math></inline-formula> that sampled by the tilting hyperspectral imaging system can be expressed as:<disp-formula id="FD1-sensors-20-04589"><label>(1)</label><mml:math id="mm2"><mml:mrow><mml:mrow><mml:mi>g</mml:mi><mml:mo>=</mml:mo><mml:mo>&#x02207;</mml:mo><mml:mi mathvariant="sans-serif">&#x00393;</mml:mi><mml:mo>&#x022c5;</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>F</mml:mi><mml:mo>&#x000af;</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mi>H</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x02217;</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:mrow></mml:math></disp-formula>
where the <inline-formula><mml:math id="mm3"><mml:mrow><mml:mrow><mml:mo>&#x02207;</mml:mo><mml:mi mathvariant="sans-serif">&#x00393;</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> is the sampling grid of the tilting imaging system, <inline-formula><mml:math id="mm4"><mml:mrow><mml:mover accent="true"><mml:mi>F</mml:mi><mml:mo>&#x000af;</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> means the inverse Fourier transform, <inline-formula><mml:math id="mm5"><mml:mrow><mml:mi>H</mml:mi></mml:mrow></mml:math></inline-formula> is the MTF of the imaging system, <inline-formula><mml:math id="mm6"><mml:mrow><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> means the ideal image before sampling, and <inline-formula><mml:math id="mm7"><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:math></inline-formula> is the noise from the sensor.</p><p>There are some differences between the normal imaging system and the tilting hyperspectral imaging system at the imaging angle. The imaging angle of the normal imaging system is 90&#x000b0;. The width of the field view for tilting image was different from the different imaging angle <inline-formula><mml:math id="mm8"><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow></mml:math></inline-formula>, and the field of view <inline-formula><mml:math id="mm9"><mml:mrow><mml:mrow><mml:mi>F</mml:mi><mml:mi>O</mml:mi><mml:mi>V</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> will be:<disp-formula id="FD2-sensors-20-04589"><label>(2)</label><mml:math id="mm10"><mml:mrow><mml:mrow><mml:mi>F</mml:mi><mml:mi>O</mml:mi><mml:mi>V</mml:mi><mml:mo>=</mml:mo><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mi>l</mml:mi><mml:mi>sin</mml:mi><mml:mi>&#x003b8;</mml:mi></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mi>&#x003b8;</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>90</mml:mn></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:math></disp-formula>
where the <inline-formula><mml:math id="mm11"><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:math></inline-formula> is the length of the CCD array in the imaging system. The sensor we used in this study has 840 bands, its detective wavelength from 400 nm to 1000 nm and its imaging principle is shown in <xref ref-type="fig" rid="sensors-20-04589-f002">Figure 2</xref>a, the reflected light of objects enters the entrance slit via the objective lens, and is received by the area camera after passing through the beam split module, the data achieved by this sensor has two axes, one for spatial axis, another for spectral axis, which means the data do not only have the spatial information, but also with the spectral information [<xref rid="B21-sensors-20-04589" ref-type="bibr">21</xref>]. While sampling (shown in <xref ref-type="fig" rid="sensors-20-04589-f002">Figure 2</xref>b), it should move at a constant speed and sampling a line data for an image in each sampling frequency, at the end of the scanning, the objects hyperspectral imagery data were achieved. Moreover, its parameters are shown in <xref rid="sensors-20-04589-t001" ref-type="table">Table 1</xref>.</p><p>In <xref rid="sensors-20-04589-t001" ref-type="table">Table 1</xref>, S/N means the signal-noise ratio.</p><p>Second, the tilting imaging system sampled with the irregular hexagonal sampling grid in the common imaging angles [<xref rid="B8-sensors-20-04589" ref-type="bibr">8</xref>], which makes an interpolation step before image restoration, and this step will cause some noise and aliasing that cannot be removed in the restoration step. However, if we choose some special imaging angle and control the sensor moving speed, the square sampling grid could be taken in sampling and these imaging angles could be calculated from:<disp-formula id="FD3-sensors-20-04589"><label>(3)</label><mml:math id="mm12"><mml:mrow><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mi>c</mml:mi><mml:mi>sin</mml:mi><mml:mi>&#x003b8;</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mi>c</mml:mi><mml:mi>N</mml:mi></mml:mfrac><mml:mi>cos</mml:mi><mml:mi>&#x003b8;</mml:mi></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mn>0</mml:mn><mml:mo>&#x0003c;</mml:mo><mml:mi>&#x003b8;</mml:mi><mml:mo>&#x02264;</mml:mo><mml:mfrac><mml:mi>&#x003c0;</mml:mi><mml:mn>4</mml:mn></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mi>c</mml:mi><mml:mi>sin</mml:mi><mml:mi>&#x003b8;</mml:mi><mml:mo>=</mml:mo><mml:mi>N</mml:mi><mml:mi>cos</mml:mi><mml:mi>&#x003b8;</mml:mi></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mfrac><mml:mi>&#x003c0;</mml:mi><mml:mn>4</mml:mn></mml:mfrac><mml:mo>&#x0003c;</mml:mo><mml:mi>&#x003b8;</mml:mi><mml:mo>&#x02264;</mml:mo><mml:mfrac><mml:mi>&#x003c0;</mml:mi><mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm13"><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:math></inline-formula> is the detector size and <inline-formula><mml:math id="mm14"><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:math></inline-formula> is a positive integer. Moreover, Equation (3) can be transformed as:<disp-formula id="FD4-sensors-20-04589"><label>(4)</label><mml:math id="mm15"><mml:mrow><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mi>tan</mml:mi><mml:mi>&#x003b8;</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mn>0</mml:mn><mml:mo>&#x0003c;</mml:mo><mml:mi>&#x003b8;</mml:mi><mml:mo>&#x02264;</mml:mo><mml:mfrac><mml:mi>&#x003c0;</mml:mi><mml:mn>4</mml:mn></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mi>tan</mml:mi><mml:mi>&#x003b8;</mml:mi><mml:mo>=</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mfrac><mml:mi>&#x003c0;</mml:mi><mml:mn>4</mml:mn></mml:mfrac><mml:mo>&#x0003c;</mml:mo><mml:mi>&#x003b8;</mml:mi><mml:mo>&#x02264;</mml:mo><mml:mfrac><mml:mi>&#x003c0;</mml:mi><mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm16"><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:math></inline-formula> is a positive integer, the calculated value of <inline-formula><mml:math id="mm17"><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow></mml:math></inline-formula> are <inline-formula><mml:math id="mm18"><mml:mrow><mml:mrow><mml:mi>&#x003b8;</mml:mi><mml:mo>&#x02248;</mml:mo><mml:mn>18</mml:mn><mml:mo>&#x000b0;</mml:mo><mml:mo>,</mml:mo><mml:mn>27</mml:mn><mml:mo>&#x000b0;</mml:mo><mml:mo>,</mml:mo><mml:mn>45</mml:mn><mml:mo>&#x000b0;</mml:mo><mml:mo>,</mml:mo><mml:mn>63</mml:mn><mml:mo>&#x000b0;</mml:mo><mml:mo>,</mml:mo><mml:mn>72</mml:mn><mml:mo>&#x000b0;</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and we can get the square sampling grid in these angles by controlling the sensor moving speed, the speed <inline-formula><mml:math id="mm19"><mml:mrow><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>s</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is [<xref rid="B11-sensors-20-04589" ref-type="bibr">11</xref>]:<disp-formula id="FD5-sensors-20-04589"><label>(5)</label><mml:math id="mm20"><mml:mrow><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>s</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>M</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mi>b</mml:mi><mml:mi>j</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>&#x022c5;</mml:mo><mml:mi>F</mml:mi><mml:mi>R</mml:mi><mml:mo>&#x022c5;</mml:mo><mml:mi>cos</mml:mi><mml:mi>&#x003b8;</mml:mi></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm21"><mml:mrow><mml:mrow><mml:msub><mml:mi>M</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mi>b</mml:mi><mml:mi>j</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is the real size of the object in a pixel of the image, <inline-formula><mml:math id="mm22"><mml:mrow><mml:mrow><mml:mi>F</mml:mi><mml:mi>R</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> is the sampling frequency of the sensor.</p><p>The image achieved from the tilting imaging system was tilted, therefore, the tilting image should have a special image geometry correction step to rectify it as a normal image. If the achieved tilting image is <inline-formula><mml:math id="mm23"><mml:mrow><mml:mrow><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, the rectifying image is <inline-formula><mml:math id="mm24"><mml:mrow><mml:mrow><mml:msup><mml:mi>g</mml:mi><mml:mo>&#x02032;</mml:mo></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm25"><mml:mrow><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> can be expressed as:<disp-formula id="FD6-sensors-20-04589"><label>(6)</label><mml:math id="mm26"><mml:mrow><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mi>x</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>y</mml:mi><mml:mi>tan</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>&#x003b8;</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>The offset of the different lines in the image was different, the offset for the <italic>i</italic>th column <inline-formula><mml:math id="mm27"><mml:mrow><mml:mrow><mml:mi>o</mml:mi><mml:mi>f</mml:mi><mml:mi>f</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> can be expressed as:<disp-formula id="FD7-sensors-20-04589"><label>(7)</label><mml:math id="mm28"><mml:mrow><mml:mrow><mml:msub><mml:mi mathvariant="italic">offset</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>y</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>tan</mml:mi><mml:mi>&#x003b8;</mml:mi></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Moreover, then, rectify each column of the image:<disp-formula id="FD8-sensors-20-04589"><label>(8)</label><mml:math id="mm29"><mml:mrow><mml:mrow><mml:msup><mml:mi>g</mml:mi><mml:mo>&#x02032;</mml:mo></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mi>o</mml:mi><mml:mi>f</mml:mi><mml:mi>f</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm30"><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:math></inline-formula> means the line of the image.</p></sec><sec id="sec2dot2-sensors-20-04589"><title>2.2. Band Selection of Tilting Hyperspectral Imagery via pSMBS Method</title><p>Hyperspectral imageries have characteristics of large amounts of data and data redundancy, which means that there are massive data in the hyperspectral imagery that cannot be used efficiently [<xref rid="B22-sensors-20-04589" ref-type="bibr">22</xref>]. There are 840 bands of the image data which we used in this research. It makes some aliasing exist in the adjacent bands. Therefore, we reduced the number of bands by selecting the band that has strong independence and great information richness as the characteristic band. Then we can process fewer data and the aliasing between the near bands that can be effectively removed. The adaptive hyperspectral band selection method based on the <italic>p</italic>-value was proved to be suitable for our data.</p><p>Generally, the <italic>p</italic>-value is considered a representation of the probability of result while the hypothesis is true, the <italic>p</italic>-value can be expressed as a statistic <inline-formula><mml:math id="mm31"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula> with the degree of freedom <inline-formula><mml:math id="mm32"><mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:math></inline-formula> [<xref rid="B23-sensors-20-04589" ref-type="bibr">23</xref>]:<disp-formula id="FD9-sensors-20-04589"><label>(9)</label><mml:math id="mm33"><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:mi>A</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>|</mml:mo><mml:mi>v</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm34"><mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>|</mml:mo><mml:mi>v</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> can be expressed as:<disp-formula id="FD10-sensors-20-04589"><label>(10)</label><mml:math id="mm35"><mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>|</mml:mo><mml:mi>v</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msup><mml:mi>V</mml:mi><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:msup><mml:mi>B</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo>,</mml:mo><mml:mfrac><mml:mi>v</mml:mi><mml:mn>2</mml:mn></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:msup><mml:mrow><mml:mstyle displaystyle="true"><mml:mrow><mml:msubsup><mml:mo>&#x0222b;</mml:mo><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msubsup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mi>v</mml:mi></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mstyle></mml:mrow><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mfrac><mml:mrow><mml:mi>v</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:msup><mml:mi>d</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:mrow></mml:math></disp-formula>
<disp-formula id="FD11-sensors-20-04589"><label>(11)</label><mml:math id="mm36"><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mi>r</mml:mi><mml:msqrt><mml:mrow><mml:mfrac><mml:mrow><mml:mi>M</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:msup><mml:mi>r</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:msqrt></mml:mrow></mml:mrow></mml:math></disp-formula>
<disp-formula id="FD12-sensors-20-04589"><label>(12)</label><mml:math id="mm37"><mml:mrow><mml:mrow><mml:mi>v</mml:mi><mml:mo>=</mml:mo><mml:mi>M</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm38"><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:math></inline-formula> is the total number of samples and we can set <inline-formula><mml:math id="mm39"><mml:mrow><mml:mrow><mml:mn>0</mml:mn><mml:mo>&#x02264;</mml:mo><mml:mi>A</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>|</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x02264;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> [<xref rid="B24-sensors-20-04589" ref-type="bibr">24</xref>] and <inline-formula><mml:math id="mm40"><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. Beta function in Equation (10) can be expressed as:<disp-formula id="FD13-sensors-20-04589"><label>(13)</label><mml:math id="mm41"><mml:mrow><mml:mrow><mml:mi>B</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo>,</mml:mo><mml:mfrac><mml:mi>v</mml:mi><mml:mn>2</mml:mn></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:mrow><mml:msubsup><mml:mo>&#x0222b;</mml:mo><mml:mn>0</mml:mn><mml:mn>1</mml:mn></mml:msubsup><mml:mrow><mml:msup><mml:mi>x</mml:mi><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:mstyle><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mfrac><mml:mi>v</mml:mi><mml:mn>2</mml:mn></mml:mfrac><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mi>d</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm42"><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:math></inline-formula> is the Pearson&#x02019;s linear correlation coefficient. While the average of the sample set <inline-formula><mml:math id="mm43"><mml:mrow><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm44"><mml:mrow><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> are <inline-formula><mml:math id="mm45"><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>&#x000af;</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm46"><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>&#x000af;</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> separately, <inline-formula><mml:math id="mm47"><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:math></inline-formula> can be expressed as:<disp-formula id="FD14-sensors-20-04589"><label>(14)</label><mml:math id="mm48"><mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mstyle displaystyle="true"><mml:msubsup><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>&#x000af;</mml:mo></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>&#x000af;</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:mrow><mml:mrow><mml:msqrt><mml:mrow><mml:mstyle displaystyle="true"><mml:msubsup><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup><mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>&#x000af;</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mstyle></mml:mrow></mml:msqrt><mml:msqrt><mml:mrow><mml:mstyle displaystyle="true"><mml:msubsup><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup><mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msup><mml:mo>&#x02212;</mml:mo><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>&#x000af;</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mstyle></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>As usual, <inline-formula><mml:math id="mm49"><mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. In general, the higher the absolute value of <italic>r</italic> is the higher correlation between samples it means.</p></sec><sec id="sec2dot3-sensors-20-04589"><title>2.3. Optimal Reciprocal Cell Anti-Aliasing Deconvolution Operator</title><p>Almansa successfully applied reciprocal cell theory to the image processing field [<xref rid="B8-sensors-20-04589" ref-type="bibr">8</xref>]. Its main idea was to transform the original image data into the frequency domain by Fourier transform and to constrain the image in the frequency domain by reciprocal cell methods. Then the adjacent spectra which are overlapped and dislocated were unwrapped, and finally, the image aliasing was removed.</p><p>After being converted the tilting image into the frequency domain by Fourier operation, the spectra of the image <inline-formula><mml:math id="mm50"><mml:mrow><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> can be expressed as:<disp-formula id="FD15-sensors-20-04589"><label>(15)</label><mml:math id="mm51"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>G</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>G</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mover accent="true"><mml:mi>n</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm52"><mml:mrow><mml:mi>G</mml:mi></mml:mrow></mml:math></inline-formula> is the spectra of the original image, <inline-formula><mml:math id="mm53"><mml:mrow><mml:mrow><mml:msub><mml:mi>G</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is the aliasing spectra of the image, and <inline-formula><mml:math id="mm54"><mml:mrow><mml:mover accent="true"><mml:mi>n</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> is the noise spectra of the image. In the frequency domain, the parts of high-frequency and low-frequency of the image were distributed in different areas, so the aliasing in different positions of the image is different [<xref rid="B11-sensors-20-04589" ref-type="bibr">11</xref>]. A weight function <inline-formula><mml:math id="mm55"><mml:mrow><mml:mrow><mml:mi>&#x003c9;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>G</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>G</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mi>n</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> was proposed to represent noise and aliasing [<xref rid="B8-sensors-20-04589" ref-type="bibr">8</xref>], and it can be expressed as:<disp-formula id="FD16-sensors-20-04589"><label>(16)</label><mml:math id="mm56"><mml:mrow><mml:mrow><mml:mi>&#x003c9;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>G</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>G</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mi>n</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>&#x003c9;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mfrac><mml:mrow><mml:mi>G</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi></mml:mrow><mml:mi>G</mml:mi></mml:mfrac><mml:mo>,</mml:mo><mml:mfrac><mml:mover accent="true"><mml:mi>n</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>G</mml:mi></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>&#x003c9;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mi>G</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mi>G</mml:mi></mml:mfrac><mml:mo>,</mml:mo><mml:mfrac><mml:mover accent="true"><mml:mi>n</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>G</mml:mi></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>W</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>b</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x00026;</mml:mo><mml:mo>&#x00026;</mml:mo><mml:mi>W</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>b</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x02208;</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm57"><mml:mrow><mml:mrow><mml:mi>W</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>b</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> is the weight function of <inline-formula><mml:math id="mm58"><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm59"><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="mm60"><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:math></inline-formula> is relative aliasing and <inline-formula><mml:math id="mm61"><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:math></inline-formula> is relative noise. They can be expressed as [<xref rid="B8-sensors-20-04589" ref-type="bibr">8</xref>]:<disp-formula id="FD17-sensors-20-04589"><label>(17)</label><mml:math id="mm62"><mml:mrow><mml:mrow><mml:msup><mml:mi>a</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>&#x003be;</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mi>H</mml:mi><mml:mi>F</mml:mi></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:msub><mml:mrow/><mml:mrow><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>&#x003be;</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mi>H</mml:mi><mml:mi>F</mml:mi></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>&#x003be;</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:mrow></mml:math></disp-formula>
<disp-formula id="FD18-sensors-20-04589"><label>(18)</label><mml:math id="mm63"><mml:mrow><mml:mrow><mml:msup><mml:mi>b</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>&#x003be;</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mi>N</mml:mi><mml:mo>|</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:msub><mml:mrow/><mml:mrow><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>&#x003be;</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mi>H</mml:mi><mml:mi>F</mml:mi></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>&#x003be;</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm64"><mml:mrow><mml:mi>&#x003be;</mml:mi></mml:mrow></mml:math></inline-formula> is the spectra of the reciprocal cell, <inline-formula><mml:math id="mm65"><mml:mrow><mml:mi>F</mml:mi></mml:mrow></mml:math></inline-formula> is the spectra of the image obtained under the ideal condition and <inline-formula><mml:math id="mm66"><mml:mrow><mml:mi>F</mml:mi></mml:mrow></mml:math></inline-formula> is usually replaced by <inline-formula><mml:math id="mm67"><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mi>&#x003be;</mml:mi><mml:mo>|</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula> [<xref rid="B23-sensors-20-04589" ref-type="bibr">23</xref>]. When <inline-formula><mml:math id="mm68"><mml:mrow><mml:mrow><mml:mi>W</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>b</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>, it means that there are no aliasing and noise in the image, which only has a little impact on the image quality; When <inline-formula><mml:math id="mm69"><mml:mrow><mml:mrow><mml:mi>W</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>b</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>, which has a serious aliasing and noise with a great impact on image quality.</p><p>In this study, by setting the threshold of relative aliasing and relative noise <inline-formula><mml:math id="mm70"><mml:mrow><mml:mrow><mml:msub><mml:mi>&#x003b8;</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm71"><mml:mrow><mml:mrow><mml:msub><mml:mi>&#x003b8;</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>&#x02014;the shape of the reciprocal cell after constraint can be obtained.
<disp-formula id="FD19-sensors-20-04589"><label>(19)</label><mml:math id="mm72"><mml:mrow><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mi>O</mml:mi><mml:mi>R</mml:mi><mml:mi>C</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mi>&#x003be;</mml:mi><mml:mo>:</mml:mo><mml:mi>a</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>&#x003be;</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x0003c;</mml:mo><mml:msub><mml:mi>&#x003b8;</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mo>&#x00026;</mml:mo></mml:mtd><mml:mtd><mml:mrow><mml:mi>b</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>&#x003be;</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x0003c;</mml:mo><mml:msub><mml:mi>&#x003b8;</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm73"><mml:mrow><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mi>O</mml:mi><mml:mi>R</mml:mi><mml:mi>C</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is the region of optimal reciprocal cell. Without considering the Fourier system, the values of <inline-formula><mml:math id="mm74"><mml:mrow><mml:mrow><mml:msub><mml:mi>&#x003b8;</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm75"><mml:mrow><mml:mrow><mml:msub><mml:mi>&#x003b8;</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> should be set as 1 according to theory. However, according to prior knowledge, those values should be <inline-formula><mml:math id="mm76"><mml:mrow><mml:mrow><mml:msub><mml:mi>&#x003b8;</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02248;</mml:mo><mml:mn>0.2</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="mm77"><mml:mrow><mml:mrow><mml:msub><mml:mi>&#x003b8;</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02248;</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> [<xref rid="B8-sensors-20-04589" ref-type="bibr">8</xref>], at this time, the optimal reciprocal cell anti-aliasing deconvolution operator <inline-formula><mml:math id="mm78"><mml:mrow><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mrow><mml:mi>O</mml:mi><mml:mi>R</mml:mi><mml:mi>C</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> can be expressed as:<disp-formula id="FD20-sensors-20-04589"><label>(20)</label><mml:math id="mm79"><mml:mrow><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mrow><mml:mi>O</mml:mi><mml:mi>R</mml:mi><mml:mi>C</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mi>&#x003be;</mml:mi><mml:mo>:</mml:mo><mml:mi>a</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>&#x003be;</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x0003c;</mml:mo><mml:mn>0.2</mml:mn></mml:mrow></mml:mtd><mml:mtd><mml:mo>&#x00026;</mml:mo></mml:mtd><mml:mtd><mml:mrow><mml:mi>b</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>&#x003be;</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable><mml:mo>&#x0003c;</mml:mo><mml:mn>5</mml:mn></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Therefore, the anti-aliasing deconvolution in the frequency domain can be expressed as:<disp-formula id="FD21-sensors-20-04589"><label>(21)</label><mml:math id="mm80"><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo>&#x02217;</mml:mo><mml:msub><mml:mi>H</mml:mi><mml:mrow><mml:mi>O</mml:mi><mml:mi>R</mml:mi><mml:mi>C</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm81"><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is the image frequency spectra after removed the aliasing. The effective resolution <inline-formula><mml:math id="mm82"><mml:mrow><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>f</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> of sampling grid <inline-formula><mml:math id="mm83"><mml:mrow><mml:mi mathvariant="sans-serif">&#x00393;</mml:mi></mml:mrow></mml:math></inline-formula> [<xref rid="B11-sensors-20-04589" ref-type="bibr">11</xref>] was used to measure the resolution in images, which is expressed as:<disp-formula id="FD22-sensors-20-04589"><label>(22)</label><mml:math id="mm84"><mml:mrow><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>f</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="sans-serif">&#x00393;</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi>D</mml:mi><mml:mo>&#x02217;</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:mi>H</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>f</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mi>&#x003c0;</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac><mml:mstyle displaystyle="true"><mml:mrow><mml:msub><mml:mo>&#x0222b;</mml:mo><mml:mrow><mml:msup><mml:mi>D</mml:mi><mml:mo>&#x02217;</mml:mo></mml:msup></mml:mrow></mml:msub><mml:mrow><mml:mi>&#x003c9;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>G</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>&#x003be;</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mi>G</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>&#x003be;</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mi>n</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mi>&#x003be;</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mstyle><mml:mi>d</mml:mi><mml:mi>&#x003be;</mml:mi></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm85"><mml:mrow><mml:mrow><mml:msup><mml:mi>D</mml:mi><mml:mo>&#x02217;</mml:mo></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula> is the spectra support region. Moreover, the spatial effective resolution <inline-formula><mml:math id="mm86"><mml:mrow><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>f</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> of the image is defined as [<xref rid="B11-sensors-20-04589" ref-type="bibr">11</xref>]:<disp-formula id="FD23-sensors-20-04589"><label>(23)</label><mml:math id="mm87"><mml:mrow><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>f</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>f</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mrow/><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>From Equation (23), the larger the <inline-formula><mml:math id="mm88"><mml:mrow><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>f</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> value of the image is, the lower the image resolution is. It can be seen from Formula (22) that both aliasing and noise in the image affect the effective spatial resolution of the image. Therefore, effective restoration of anti-aliasing and the de-noise image is an important factor to improve the spatial resolution of the tilting image.</p></sec><sec id="sec2dot4-sensors-20-04589"><title>2.4. Modulation Transfer Function of Tilting Hyperspectral Super-Resolution Imaging</title><p>The modulation transfer function of the imaging system is not only an important index to evaluate the imaging quality of sensors [<xref rid="B24-sensors-20-04589" ref-type="bibr">24</xref>,<xref rid="B25-sensors-20-04589" ref-type="bibr">25</xref>], but also the main method to remove the blurring and noise in the image. As a function of spatial frequency, it contains factors such as image resolution and modulation contrast, which can indicate the capability of imaging sensor object identification objectively [<xref rid="B14-sensors-20-04589" ref-type="bibr">14</xref>].</p><p>Assuming that the natural scene which collected by the imaging system is <inline-formula><mml:math id="mm89"><mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> and the response function of the tilting hyperspectral imaging system is <inline-formula><mml:math id="mm90"><mml:mrow><mml:mrow><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, the final image <inline-formula><mml:math id="mm91"><mml:mrow><mml:mrow><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> obtained by the imaging system can be expressed as:<disp-formula id="FD24-sensors-20-04589"><label>(24)</label><mml:math id="mm92"><mml:mrow><mml:mrow><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x02217;</mml:mo><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>In the Formula (24), * means deconvolution operator. In general, the response function of the imaging system is <inline-formula><mml:math id="mm93"><mml:mrow><mml:mrow><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, also called <inline-formula><mml:math id="mm94"><mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mi>S</mml:mi><mml:mi>F</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> [<xref rid="B26-sensors-20-04589" ref-type="bibr">26</xref>] which is the response function of the Point Spread Function System [<xref rid="B27-sensors-20-04589" ref-type="bibr">27</xref>] and the transfer function (TF) of the system after the response function is transferred to the frequency domain <inline-formula><mml:math id="mm95"><mml:mrow><mml:mrow><mml:mi>H</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mi>Y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>.</p><p>The Formula (24) is transformed to the frequency domain as follows:<disp-formula id="FD25-sensors-20-04589"><label>(25)</label><mml:math id="mm96"><mml:mrow><mml:mrow><mml:mi>G</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mi>Y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>F</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mi>Y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x02217;</mml:mo><mml:mi>H</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mi>Y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Therefore, the restored image in the frequency domain can be expressed as:<disp-formula id="FD26-sensors-20-04589"><label>(26)</label><mml:math id="mm97"><mml:mrow><mml:mrow><mml:mi>F</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mi>Y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>G</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mi>Y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>H</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mi>Y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>The transfer function of the system can be expressed as:<disp-formula id="FD27-sensors-20-04589"><label>(27)</label><mml:math id="mm98"><mml:mrow><mml:mrow><mml:mi>H</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mi>Y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mi>H</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mi>Y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mo>&#x022c5;</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>&#x003d5;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mi>Y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm99"><mml:mrow><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mi>H</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> is the amplitude and <inline-formula><mml:math id="mm100"><mml:mrow><mml:mrow><mml:mi>&#x003d5;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> is the phase. After normalizing, the amplitude can be expressed as:<disp-formula id="FD28-sensors-20-04589"><label>(28)</label><mml:math id="mm101"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mi>H</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mi>Y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mfrac><mml:mrow><mml:mrow><mml:mo stretchy="true">|</mml:mo><mml:mrow><mml:mi>H</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mo stretchy="true">|</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="true">|</mml:mo><mml:mrow><mml:mi>H</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="true">|</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mi>X</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>&#x022ef;</mml:mo><mml:mo>,</mml:mo><mml:mi>N</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mi>Y</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>&#x022ef;</mml:mo><mml:mo>,</mml:mo><mml:mi>N</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:math></disp-formula>
where <italic>N</italic> is a positive integer and <inline-formula><mml:math id="mm102"><mml:mrow><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mi>H</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> is the value in the zero-frequency domain. If <inline-formula><mml:math id="mm103"><mml:mrow><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mi>H</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>, the normalized system MTF can be expressed as:<disp-formula id="FD29-sensors-20-04589"><label>(29)</label><mml:math id="mm104"><mml:mrow><mml:mrow><mml:mi>MTF</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mi>H</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mi>Y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>If the value of point spread system function <inline-formula><mml:math id="mm105"><mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mi>S</mml:mi><mml:mi>F</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> transformed by two-dimensional Fourier, equals to 1 at the zero-frequency domain, the normalized system MTF will be:<disp-formula id="FD30-sensors-20-04589"><label>(30)</label><mml:math id="mm106"><mml:mrow><mml:mrow><mml:mi>MTF</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mi>H</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mi>Y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Then the restored image can be converted to:<disp-formula id="FD31-sensors-20-04589"><label>(31)</label><mml:math id="mm107"><mml:mrow><mml:mrow><mml:mi>F</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mi>Y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>G</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mi>Y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>MTF</mml:mi><mml:mo>&#x022c5;</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>&#x003d5;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mi>Y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>During processing images, the MTF value at Nyquist frequency is usually used to evaluate the imaging quality of the optical imaging system [<xref rid="B15-sensors-20-04589" ref-type="bibr">15</xref>]. However, the result of MTF function is a curve that cannot measure imaging quality completely and MTFA can measure imaging quality better [<xref rid="B28-sensors-20-04589" ref-type="bibr">28</xref>].
<disp-formula id="FD32-sensors-20-04589"><label>(32)</label><mml:math id="mm108"><mml:mrow><mml:mrow><mml:mi>MTFA</mml:mi><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:mrow><mml:msubsup><mml:mo>&#x0222b;</mml:mo><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:msubsup><mml:mrow><mml:mrow><mml:mo stretchy="true">[</mml:mo><mml:mrow><mml:mi>MTF</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>f</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mi>C</mml:mi><mml:mi>T</mml:mi><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>y</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>f</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="true">]</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mstyle><mml:mi>d</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm109"><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="normal">f</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="normal">f</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the selected spatial frequency range and <inline-formula><mml:math id="mm110"><mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mi>T</mml:mi><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>y</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is the special threshold minimum contrast ratio of the human eye, its value usually is 0.05 [<xref rid="B29-sensors-20-04589" ref-type="bibr">29</xref>]. Therefore, Formula (32) can be expressed as follows:<disp-formula id="FD33-sensors-20-04589"><label>(33)</label><mml:math id="mm111"><mml:mrow><mml:mrow><mml:mi>MTFA</mml:mi><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:mrow><mml:msubsup><mml:mo>&#x0222b;</mml:mo><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:msubsup><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>MTF</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>f</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>0.05</mml:mn></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mstyle><mml:mi>d</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>As usual, the higher value of MTFA is, the higher quality of the image is.</p></sec></sec><sec id="sec3-sensors-20-04589"><title>3. Restoration of Tilting Hyperspectral Imagery</title><p>This section has described the validation of the restoration method based on reciprocal cell and MTF for processing tilting hyperspectral imagery. Moreover, the tilting image was obtained by strictly controlling the sampling distance and the moving speed of the sensor.</p><sec id="sec3dot1-sensors-20-04589"><title>3.1. Band Selection of Tilting Hyperspectral Imagery</title><p>The hyperspectral data used in this work have 840 bands. There is a large amount of redundancy in the data, which means a great restoration work later. Due to the influence of the sensor, the first 10 and last 40 bands of the 840 bands cannot be used because of the awful noise. Moreover, the aliasing not only exists in the single band image, but also exists in the interband of the hyperspectral imagery because of the high correlation between bands.</p><p>Considering these problems, the <italic>p</italic>-value sparse matrix band selection (<italic>pSMBS</italic>) was used in this work [<xref rid="B22-sensors-20-04589" ref-type="bibr">22</xref>]. This method uses a <italic>p</italic>-value of spectral correlation to express the degree of independence between two bands of sample data rather than the band itself. The stronger the independence is, the higher the <italic>p</italic>-value will be and vice versa. The <italic>pSMBS</italic> method was used to select the bands with stronger independence (large <italic>p</italic>-value) and greater richness as the feature bands. The <italic>p</italic>-value results calculated from the original tilting image are shown in <xref ref-type="fig" rid="sensors-20-04589-f003">Figure 3</xref>.</p><p>In <xref ref-type="fig" rid="sensors-20-04589-f003">Figure 3</xref>a, the first 10 and the last 40 bands of the hyperspectral imagery were removed because of serious noise, and then, the <italic>p</italic>-value of it was calculated and its results were shown in (b). To verify the restoration method of tilting hyperspectral imagery, we selected some feature bands with strong independence and higher richness, which indicate by <italic>p</italic>-value. From <xref ref-type="fig" rid="sensors-20-04589-f003">Figure 3</xref>b, we can find that higher <italic>p</italic>-value band ID concentrated between 250 and 450, while the <italic>p</italic>-value higher than 0.013 (the point above the red line) was greater than most bands, therefore, the Corresponding bands were selected as the feature bands to study and the number of the feature bands was 13. Moreover, the information of selected bands is shown in <xref rid="sensors-20-04589-t002" ref-type="table">Table 2</xref>.</p><p>In <xref rid="sensors-20-04589-t002" ref-type="table">Table 2</xref>, the band ID means the numbered of bands, the <italic>p</italic>-value was the results calculated from the original tilting image via pMSBS method, and the wavelength was for the corresponding feature bands. It is not hard to find that the wavelengths of feature bands were in the range from 587.486 nm to 683.974 nm, this phenomenon depends on the spectral reflectance properties of objects because the feature bands we selected has a greater richness which means the object has a better reflectivity in this wavelengths range. Therefore, the band ID and wavelength range will be different for different research areas.</p></sec><sec id="sec3dot2-sensors-20-04589"><title>3.2. Tilting Hyperspectral Imagery Restored by Optimal Reciprocal Cell Combined the MTF Method</title><p>The flow chart of optimal reciprocal cell combined MTF method is shown in <xref ref-type="fig" rid="sensors-20-04589-f004">Figure 4</xref>.</p><p>First, the image was restored according to the flow chart in <xref ref-type="fig" rid="sensors-20-04589-f004">Figure 4</xref>. The restored image is shown in <xref ref-type="fig" rid="sensors-20-04589-f005">Figure 5</xref>:</p><p>As seen in <xref ref-type="fig" rid="sensors-20-04589-f005">Figure 5</xref>, some sawteeth were found on the edge because of some small errors of the imaging angle, the shaking of the sensors while collecting image data and this work has not taken interpolation step to remove the sawteeth for avoiding the quadratic noise and aliasing which cannot be processed in the restoration step.</p><p>The details of the original titling image (<xref ref-type="fig" rid="sensors-20-04589-f005">Figure 5</xref>a) and the restored tilting image (<xref ref-type="fig" rid="sensors-20-04589-f005">Figure 5</xref>b) are shown in <xref ref-type="fig" rid="sensors-20-04589-f006">Figure 6</xref>.</p><p>From <xref ref-type="fig" rid="sensors-20-04589-f006">Figure 6</xref>, it can be easily found that the details of the restored tilting image were much clearer than that of the original tilting image visually, we can distinguish the lines in between 4 to 5 in (b), but that in (a) cannot. To directly analyze the effect of the restoration methods in this work, the evaluation index (AI) and modulation transfer function area(MTFA) were calculated and the values are shown in <xref rid="sensors-20-04589-t003" ref-type="table">Table 3</xref>.</p><p>From <xref rid="sensors-20-04589-t002" ref-type="table">Table 2</xref>, it can be found that the aliasing index of the restored tilting image was much smaller than that of the original tilting image in each band, which indicated that the aliasing in each band was effectively removed. Moreover, the MTFA value of each band after the restoration was higher than that of the original tilting image, which showed that the quality of each band was better after restoration. To analyze the DN-value change of the restored tilting image, the index, the ratio of prediction to deviation (RPD) [<xref rid="B30-sensors-20-04589" ref-type="bibr">30</xref>], which was commonly used in remote sensing inversion, was introduced in this study. The value can be expressed as follows:<disp-formula id="FD34-sensors-20-04589"><label>(34)</label><mml:math id="mm112"><mml:mrow><mml:mrow><mml:mrow><mml:mi>RPD</mml:mi><mml:mo>=</mml:mo></mml:mrow><mml:mfrac><mml:mrow><mml:mi>SD</mml:mi></mml:mrow><mml:mrow><mml:mi>RMSEP</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:mrow></mml:math></disp-formula>
where SD means the standard deviation, RMSEP is the root mean square error of prediction and RPD was usually used to evaluate the predicted value in quantitative remote sensing restored image and the original image. The higher value of RPD represents a better result. It is commonly considered that good results can be obtained when the value is higher than 2 and an ideal result while it higher than 3, but with no prediction meaning while the value less than 1.8 [<xref rid="B31-sensors-20-04589" ref-type="bibr">31</xref>,<xref rid="B32-sensors-20-04589" ref-type="bibr">32</xref>,<xref rid="B33-sensors-20-04589" ref-type="bibr">33</xref>]. First, we calculated the SD and RMSEP between the original tilting image (<xref ref-type="fig" rid="sensors-20-04589-f005">Figure 5</xref>a) and the restored tilting image (<xref ref-type="fig" rid="sensors-20-04589-f005">Figure 5</xref>b) and then get the RPD value. The parameters of each band calculated by the Formula (34) are shown in <xref rid="sensors-20-04589-t004" ref-type="table">Table 4</xref>.</p><p>From <xref rid="sensors-20-04589-t004" ref-type="table">Table 4</xref>, it was found that the RPD values of the original image and restored image were in the range from 2.3067 to 2.6915. All of those values were greater than 2, which showed that the DN-value change of the restored tilting images was consistent as we expected.</p></sec></sec><sec id="sec4-sensors-20-04589"><title>4. Calibration of Restored Tilting Hyperspectral Imagery</title><p>This section describes the calibration methods of the restored tilting image. There were two sets of field scenes which were designed and obtained by tilting sampling mode and normal sampling. One set of scenes was used to verify the spectral fidelity and solve the problem of spectral distortion, while another was used to test the feasibility of the restored tilting hyperspectral data in remote sensing applications. In this work, we strictly controlled the sampling modes in the same distance and the moving speed of the sensor.</p><sec id="sec4dot1-sensors-20-04589"><title>4.1. Calibration of Restored Tilting Hyperspectral Imagery</title><p>The hyperspectral imageries were obtained by normal sampling and tilting sampling mode and the tilting images after the geometric correction are shown in <xref ref-type="fig" rid="sensors-20-04589-f007">Figure 7</xref>.</p><p>First, we selected 13 bands as feature bands from those 2 sets of data by the <italic>pSMBS</italic> method. The same size image of the interest regions was selected from two field scenes, respectively. The final selected regions of interest area in this work are shown in <xref ref-type="fig" rid="sensors-20-04589-f008">Figure 8</xref>.</p><p>From <xref ref-type="fig" rid="sensors-20-04589-f008">Figure 8</xref>a,c both images were the same size, but the field view of (c) was smaller, which means the resolution of the tilting image was higher than that of the normal image. It shows the image resolution was improved to a certain extent by only changing the sampling mode because the tilting sampling reduced the sampling interval and increased the sampling density. Two sets of interesting area images in <xref ref-type="fig" rid="sensors-20-04589-f008">Figure 8</xref> were restored by optimal reciprocal cell combined MTF method. Finally, these restored images are shown in <xref ref-type="fig" rid="sensors-20-04589-f009">Figure 9</xref>.</p><p>From the point of view, the images in <xref ref-type="fig" rid="sensors-20-04589-f009">Figure 9</xref> were much clearer, which fully showed the good effect of this method. However, the brightness of the restored tilting image was slightly getting higher than that of the original tilting image. Therefore, in this work, we have selected three corresponding regions both from the original normal image (<xref ref-type="fig" rid="sensors-20-04589-f008">Figure 8</xref>a) and the restored tilting image (<xref ref-type="fig" rid="sensors-20-04589-f009">Figure 9</xref>c) randomly, to calculate the mean DN-value and get the curves of the mean DN-value. The final mean value curves of the DN-value are shown in <xref ref-type="fig" rid="sensors-20-04589-f010">Figure 10</xref>.</p><p>It was found from <xref ref-type="fig" rid="sensors-20-04589-f010">Figure 10</xref> that the mean DN-value trend of tilting image was the almost same as that of the original normal image, the mean value of restored tilting image pixels was higher than that of the original normal image. The results showed that there were a little spectra distortion in the restored tilting image.</p><p>To solve the distortion problem of tilting hyperspectral data found in the previous section, it needs to ensure that the spectra of the restored tilting image are distorted compared with that of the original normal image. Here, the calibration method for the restored tilting image was adopted. Therefore, for the interest region 1 of the restored tilting image and original normal image, 36 pairs of corresponding regions with the same size of 20 * 20 were selected as the sample points. The pixel values in the restored tilting image were taken as the observation values and that in the original normal image as the reference value and the least square method was used to solve the calibration equation of each band. The research flow chart in this work is shown in <xref ref-type="fig" rid="sensors-20-04589-f011">Figure 11</xref>.</p><p>According to the flow chart in <xref ref-type="fig" rid="sensors-20-04589-f011">Figure 11</xref>, the linear equation fitting maps of 13 bands were obtained and as shown in <xref ref-type="fig" rid="sensors-20-04589-f012">Figure 12</xref>.</p><p>It was found from <xref ref-type="fig" rid="sensors-20-04589-f012">Figure 12</xref> that there was a strong linear relationship between the original normal image and restored tilting image in the DN mean value of each band. According to the pixel mean-value of the same terrain blocks between the original normal image and restored tilting image, the corresponding relationships were established. The linear equations (calibration equation) of those 13 bands were solved by the least square method:<disp-formula id="FD35-sensors-20-04589"><label>(35)</label><mml:math id="mm113"><mml:mrow><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>0.7332</mml:mn><mml:mo>+</mml:mo><mml:mn>0.91840</mml:mn><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></disp-formula>
<disp-formula id="FD36-sensors-20-04589"><label>(36)</label><mml:math id="mm114"><mml:mrow><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mn>1.62060</mml:mn><mml:mo>+</mml:mo><mml:mn>0.94084</mml:mn><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></disp-formula>
<disp-formula id="FD37-sensors-20-04589"><label>(37)</label><mml:math id="mm115"><mml:mrow><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mn>0.00846</mml:mn><mml:mo>+</mml:mo><mml:mn>0.94878</mml:mn><mml:msub><mml:mi>x</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></disp-formula>
<disp-formula id="FD38-sensors-20-04589"><label>(38)</label><mml:math id="mm116"><mml:mrow><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mn>4</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>0.05884</mml:mn><mml:mo>+</mml:mo><mml:mn>0.93780</mml:mn><mml:msub><mml:mi>x</mml:mi><mml:mn>4</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></disp-formula>
<disp-formula id="FD39-sensors-20-04589"><label>(39)</label><mml:math id="mm117"><mml:mrow><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mn>5</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>1.22103</mml:mn><mml:mo>+</mml:mo><mml:mn>0.93155</mml:mn><mml:msub><mml:mi>x</mml:mi><mml:mn>5</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></disp-formula>
<disp-formula id="FD40-sensors-20-04589"><label>(40)</label><mml:math id="mm118"><mml:mrow><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mn>6</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>0.58365</mml:mn><mml:mo>+</mml:mo><mml:mn>0.93949</mml:mn><mml:msub><mml:mi>x</mml:mi><mml:mn>6</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></disp-formula>
<disp-formula id="FD41-sensors-20-04589"><label>(41)</label><mml:math id="mm119"><mml:mrow><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mn>7</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>0.73937</mml:mn><mml:mo>+</mml:mo><mml:mn>0.96379</mml:mn><mml:msub><mml:mi>x</mml:mi><mml:mn>7</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></disp-formula>
<disp-formula id="FD42-sensors-20-04589"><label>(42)</label><mml:math id="mm120"><mml:mrow><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mn>8</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mn>1.40800</mml:mn><mml:mo>+</mml:mo><mml:mn>0.95006</mml:mn><mml:msub><mml:mi>x</mml:mi><mml:mn>8</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></disp-formula>
<disp-formula id="FD43-sensors-20-04589"><label>(43)</label><mml:math id="mm121"><mml:mrow><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mn>9</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mn>3.41084</mml:mn><mml:mo>+</mml:mo><mml:mn>0.93125</mml:mn><mml:msub><mml:mi>x</mml:mi><mml:mn>9</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></disp-formula>
<disp-formula id="FD44-sensors-20-04589"><label>(44)</label><mml:math id="mm122"><mml:mrow><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mn>2.40987</mml:mn><mml:mo>+</mml:mo><mml:mn>0.94204</mml:mn><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></disp-formula>
<disp-formula id="FD45-sensors-20-04589"><label>(45)</label><mml:math id="mm123"><mml:mrow><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mn>11</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mn>0.38730</mml:mn><mml:mo>+</mml:mo><mml:mn>0.93837</mml:mn><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>11</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></disp-formula>
<disp-formula id="FD46-sensors-20-04589"><label>(46)</label><mml:math id="mm124"><mml:mrow><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mn>12</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.61855</mml:mn><mml:mo>+</mml:mo><mml:mn>0.91413</mml:mn><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>12</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></disp-formula>
<disp-formula id="FD47-sensors-20-04589"><label>(47)</label><mml:math id="mm125"><mml:mrow><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mn>13</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mn>0.15475</mml:mn><mml:mo>+</mml:mo><mml:mn>0.90989</mml:mn><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>13</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>According to the calibration equations, the restored tilting image was calibrated. The calibrated image is shown in <xref ref-type="fig" rid="sensors-20-04589-f013">Figure 13</xref>.</p><p>Form <xref ref-type="fig" rid="sensors-20-04589-f013">Figure 13</xref>, it was not hard to find that the (c) is much clearer than (a) and (b) visually. Compared with the reference value, the RPD values of the calibrated tilting image (<xref ref-type="fig" rid="sensors-20-04589-f013">Figure 13</xref>c) and the original normal image (<xref ref-type="fig" rid="sensors-20-04589-f013">Figure 13</xref>a) were calculated. There were the evaluation indices shown in <xref rid="sensors-20-04589-t005" ref-type="table">Table 5</xref>:</p><p>R<sup>2</sup> was the goodness of fit obtained by the least square method.</p><p>From <xref rid="sensors-20-04589-t005" ref-type="table">Table 5</xref>, it can be found that the maximum value of RPD was 5.1937 and the minimum value was 2.4436. All of the values were greater than 2 and some of the value was higher than 3. Furthermore, the minimum value of R<sup>2</sup> is 0.9930 and the maximum value is 0.9954, which showed that the fitting results of calibrated equations were very good. In conclusion, the spectral fidelity of the calibrated tilting image was better. The Contrast graphs of the mean DN-value between the calibrated tilting images and the original normal images are shown in <xref ref-type="fig" rid="sensors-20-04589-f014">Figure 14</xref>.</p><p>From <xref ref-type="fig" rid="sensors-20-04589-f014">Figure 14</xref>, it was found that the pixel mean-values of each band in the calibrated tilting image was not only consistent in trend with the original normal image, but was also very close in value for most points, which showed that the spectral fidelity of calibrated tilting image became better. The calibrated tilting image not only can get higher resolution, but also undistorted spectra.</p></sec><sec id="sec4dot2-sensors-20-04589"><title>4.2. Classification of Calibrated Tilting Hyperspectral Imagery</title><p>This section describes the application of the calibrated tilting image. For this purpose, the calibrated tilting image was used to classify and compare the results of calibrated tilting images and original normal images to prove whether tilting images can be used in actual application in remote sensing. This research chose interesting area 2, which has more distinguishable in features, as the research area. The image was restored and calibrated by the method we selected in this study. Moreover, then, the K-means classification method was applied to classify the calibrated tilting image and original normal image which is less affected by artificial factors. The classification results are shown in <xref ref-type="fig" rid="sensors-20-04589-f015">Figure 15</xref>.</p><p>From <xref ref-type="fig" rid="sensors-20-04589-f015">Figure 15</xref>, it can be found that the leaf of both (a) and (b) were distinguished from the background. Moreover, there was no significant visual difference between those two images. The evaluation accuracy of the classification results was counted and shown in <xref rid="sensors-20-04589-t006" ref-type="table">Table 6</xref> and <xref rid="sensors-20-04589-t007" ref-type="table">Table 7</xref>.</p><p>It can be seen from those two tables that the overall classification accuracy of the original normal image was 96.2848%, and the Kappa coefficient was 0.9365. The overall accuracy and Kappa coefficients of the calibrated tilting image were 98.1016% and 0.9645, respectively, which were higher than that of the original normal image. The reason was that the resolution of the calibrated tilting image was higher. It is fully shown that the calibrated tilting image can be used in the actual application of remote sensing.</p></sec></sec><sec sec-type="discussion" id="sec5-sensors-20-04589"><title>5. Discussion</title><p>In this study, we try to use the existed method the reciprocal cell combined MTF to restore the tilting hyperspectral image and find a possible way to ensuring the spectral fidelity of the restored tilting image.</p><p>Since the tilting sampling was proposed, it was aimed to achieve a higher resolution hyperspectral image [<xref rid="B1-sensors-20-04589" ref-type="bibr">1</xref>,<xref rid="B2-sensors-20-04589" ref-type="bibr">2</xref>,<xref rid="B3-sensors-20-04589" ref-type="bibr">3</xref>] and many restoration methods have been developed for tilting image. The aliasing in tilting image was different with that in normal image [<xref rid="B11-sensors-20-04589" ref-type="bibr">11</xref>], and the reciprocal cell method has an excellent effect in anti-aliasing step [<xref rid="B3-sensors-20-04589" ref-type="bibr">3</xref>,<xref rid="B19-sensors-20-04589" ref-type="bibr">19</xref>]. Therefore, the reciprocal cell method was developed to anti-aliasing of tilting image [<xref rid="B9-sensors-20-04589" ref-type="bibr">9</xref>,<xref rid="B20-sensors-20-04589" ref-type="bibr">20</xref>]. However, the reciprocal cell method has ignored the noise and blurring in the tilting image [<xref rid="B5-sensors-20-04589" ref-type="bibr">5</xref>]. Furthermore, the MTF was introduced to de-noise and de-blurring of tilting image. Therefore, the reciprocal cell combined with the MTF method has widely used to restore the single band tilting image. Furthermore, this study chose this method to restore the tilting hyperspectral image. The restored results showed that the image quality has been improved after restoration, and the evaluation index showed that the DN value change was consistent as we expected. It means that the reciprocal cell combined MTF method can effectively restore the titling image.</p><p>The spectral fidelity of the restored tilting image is an unconsidered problem because most research studied the single band tilting image. This study focused on building the model between the restored tilting image and the original normal image and then, solved the calibrated by the least square method. The results showed that the classification accuracy of the calibrated tilting image has not declined, which means that the proposed calibrated method can ensure its result can be used in the remote sensing application.</p><p>For this study, it was successful to study on the tilting hyperspectral or multispectral tilting image and consider the problem of spectral distortion and practical availability in remote sensing application after restoration. It not only verified the traditional restoration method of tilting image, which named optimal reciprocal cell combined MTF method, can effectively restore the tilting hyperspectral imagery, but also proposed the calibrated method of restored tilting image and ensured its practicality in remote sensing application.</p><p>However, the weight of aliasing, noise and blurring in the tilting images was different, but this study has assumed those are at the same level while the restoration step. Therefore, our group will still work on the restoration method of tilting image to achieve better results of it.</p></sec><sec sec-type="conclusions" id="sec6-sensors-20-04589"><title>6. Conclusions</title><p>This study used the traditional restoration method optimal reciprocal cell combined with MTF to restore the tilting hyperspectral imageries and calibrated the restored tilting image to solve the problem of spectra distortion by the calibrated equation which solved via the least square method. By comparing the classified results between calibrated tilting images and original normal images, it is not hard to find that the classification accuracy has not declined which means the calibrated tilting image can be used in the actual remote sensing applications. The results showed that the optimal reciprocal cell combined with MTF can be used to restore the tilting hyperspectral imageries and the proposed calibrated method can ensure the spectrum of the tilting image. In summary, the tilting image restored by the reciprocal cell combined MTF with the method and calibrated its results by the proposed method has a higher spatial resolution and better spectral fidelity.</p></sec></body><back><ack><title>Acknowledgments</title><p>The authors would like to thank the anonymous reviewers and the editor for their constructive comments and suggestions for this study.</p></ack><notes><title>Author Contributions</title><p>Conceptualization, X.Z. and A.Z.; methodology, X.Z.; software, X.Z. and M.L.; validation, X.Z., M.L. and L.L.; formal analysis, X.Z.; investigation, X.Z.; resources, X.Z.; data curation, X.Z.; writing&#x02014;original draft preparation, X.Z.; writing&#x02014;review and editing, A.Z., L.L. and X.K.; visualization, X.Z.; supervision, A.Z.; project administration, A.Z. All authors have read and agreed to the published version of the manuscript.</p></notes><notes><title>Funding</title><p>This research was funded by the National Natural Science Foundation of China, Grant Number 41571369; Special Foundation for Science and Technology Basic Resource Investigation Program of China, Grant Number 2019FY101304.</p></notes><notes notes-type="COI-statement"><title>Conflicts of Interest</title><p>The authors declare no conflict of interest. The funders had no role in the design of the study; in the collection, analyses or interpretation of data; in the writing of the manuscript or in the decision to publish the results.</p></notes><ref-list><title>References</title><ref id="B1-sensors-20-04589"><label>1.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhou</surname><given-names>F.</given-names></name><name><surname>Wang</surname><given-names>H.-Y.</given-names></name><name><surname>Ma</surname><given-names>W.-P.</given-names></name><name><surname>Liu</surname><given-names>Z.-J.</given-names></name></person-group><article-title>A study on a new method for improving image spatial resolution of sampled optical imager with single array</article-title><source>J. Astronaut.</source><year>2006</year><volume>27</volume><fpage>227</fpage><lpage>232</lpage></element-citation></ref><ref id="B2-sensors-20-04589"><label>2.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhou</surname><given-names>F.</given-names></name><name><surname>Wang</surname><given-names>H.-Y.</given-names></name><name><surname>Ma</surname><given-names>W.-P.</given-names></name><name><surname>Liu</surname><given-names>Z.-J.</given-names></name><name><surname>Zhou</surname><given-names>C.</given-names></name><name><surname>Chen</surname><given-names>Q.</given-names></name><name><surname>Ouyang</surname><given-names>X.</given-names></name><name><surname>Jiang</surname><given-names>B.</given-names></name><name><surname>Xia</surname><given-names>D.</given-names></name></person-group><article-title>Study on Supermode &#x00026; Tilting Mode Sampling Technology for EO</article-title><source>Spacecr. Recovery Remote Sens.</source><year>2005</year><volume>3</volume><fpage>43</fpage><lpage>46</lpage></element-citation></ref><ref id="B3-sensors-20-04589"><label>3.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>J.</given-names></name><name><surname>Xia</surname><given-names>D.</given-names></name></person-group><article-title>Improving the effective resolution of optical remote sensor with adapted reciprocal cell</article-title><source>Proceedings of the International Conference on Systems &#x00026; Computer Science</source><conf-loc>Lille, France</conf-loc><conf-date>29&#x02013;31 August 2012</conf-date></element-citation></ref><ref id="B4-sensors-20-04589"><label>4.</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>J.</given-names></name></person-group><article-title>Research on Acquisition System Modeling Based Remote Sensing Image Resolution Improvement</article-title><source>Ph.D. Thesis</source><publisher-name>Nanjing University of Science and Technology</publisher-name><publisher-loc>Nanjing, China</publisher-loc><year>2012</year></element-citation></ref><ref id="B5-sensors-20-04589"><label>5.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>A.</given-names></name><name><surname>Zhang</surname><given-names>X.</given-names></name><name><surname>Zhao</surname><given-names>J.</given-names></name></person-group><article-title>Optimal angle in tilting mode super resolution imaging</article-title><source>Infrared Laser Eng.</source><year>2019</year><volume>48</volume><fpage>826001</fpage><pub-id pub-id-type="doi">10.3788/IRLA201948.0826001</pub-id></element-citation></ref><ref id="B6-sensors-20-04589"><label>6.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Young</surname><given-names>S.S.</given-names></name></person-group><article-title>Alias-free image subsampling using Fourier-based windowing methods</article-title><source>Opt. Eng.</source><year>2004</year><volume>43</volume><fpage>843</fpage><lpage>855</lpage><pub-id pub-id-type="doi">10.1117/1.1666862</pub-id></element-citation></ref><ref id="B7-sensors-20-04589"><label>7.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fang</surname><given-names>L.</given-names></name><name><surname>Tang</surname><given-names>K.</given-names></name><name><surname>Au</surname><given-names>O.C.</given-names></name><name><surname>Katsaggelos</surname><given-names>A.K.</given-names></name></person-group><article-title>Anti-aliasing Filter Design for Subpixel Down-sampling via Frequency Domain Analysis</article-title><source>IEEE Trans. Image Process.</source><year>2011</year><volume>21</volume><fpage>1</fpage><pub-id pub-id-type="pmid">21724513</pub-id></element-citation></ref><ref id="B8-sensors-20-04589"><label>8.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Almansa</surname><given-names>A.</given-names></name><name><surname>Durand</surname><given-names>S.</given-names></name><name><surname>Roug&#x000e9;</surname><given-names>B.</given-names></name></person-group><article-title>Measuring and Improving Image Resolution by Adaptation of the Reciprocal Cell</article-title><source>J. Math. Imaging Vis.</source><year>2004</year><volume>21</volume><fpage>235</fpage><lpage>279</lpage><pub-id pub-id-type="doi">10.1023/B:JMIV.0000043739.51886.01</pub-id></element-citation></ref><ref id="B9-sensors-20-04589"><label>9.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>J.</given-names></name><name><surname>Xia</surname><given-names>D.</given-names></name></person-group><article-title>Tilting Mode Sampling Image Restoration Based on Optimal Reciprocal Cell</article-title><source>J. Astronaut.</source><year>2011</year><volume>32</volume><fpage>2451</fpage><lpage>2456</lpage></element-citation></ref><ref id="B10-sensors-20-04589"><label>10.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jing</surname><given-names>W.</given-names></name></person-group><article-title>Super-Resolution Restoration of Super-tilting Mode Remote Sensing Image</article-title><source>Spacecr. Recovery Remote Sens.</source><year>2012</year><volume>33</volume><fpage>60</fpage><lpage>66</lpage></element-citation></ref><ref id="B11-sensors-20-04589"><label>11.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>J.-M.</given-names></name><name><surname>Zhang</surname><given-names>A.</given-names></name><name><surname>Zhao</surname><given-names>N.-N.</given-names></name><name><surname>Meng</surname><given-names>X.-G.</given-names></name></person-group><article-title>Influence of tilting angle on tilting sampling aliasing and relationship between aliasing and resolution</article-title><source>Jilin Daxue Xuebao/J. Jilin Univ.</source><year>2015</year><volume>45</volume><fpage>953</fpage><lpage>960</lpage></element-citation></ref><ref id="B12-sensors-20-04589"><label>12.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>Z.</given-names></name><name><surname>Xia</surname><given-names>D.</given-names></name></person-group><article-title>Image Restoration Based on Hybrid Reciprocal Cell-Wavelet</article-title><source>J. Comput. Aided Des. Comput. Graph.</source><year>2008</year><volume>36</volume><fpage>512</fpage><lpage>519</lpage></element-citation></ref><ref id="B13-sensors-20-04589"><label>13.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kligerman</surname><given-names>S.</given-names></name><name><surname>Mehta</surname><given-names>D.</given-names></name><name><surname>Farnadesh</surname><given-names>M.</given-names></name><name><surname>Jeudy</surname><given-names>J.</given-names></name><name><surname>Olsen</surname><given-names>K.</given-names></name><name><surname>White</surname><given-names>C.</given-names></name></person-group><article-title>Use of a Hybrid Iterative Reconstruction Technique to Reduce Image Noise and Improve Image Quality in Obese Patients Undergoing Computed Tomographic Pulmonary Angiography</article-title><source>J. Thorac Imaging</source><year>2013</year><volume>28</volume><fpage>49</fpage><lpage>59</lpage><pub-id pub-id-type="doi">10.1097/RTI.0b013e31825412b2</pub-id><pub-id pub-id-type="pmid">22576762</pub-id></element-citation></ref><ref id="B14-sensors-20-04589"><label>14.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Samei</surname><given-names>E.</given-names></name><name><surname>Ranger</surname><given-names>N.T.</given-names></name><name><surname>Dobbins</surname><given-names>J.T.</given-names><suffix>III</suffix></name><name><surname>Chen</surname><given-names>Y.</given-names></name></person-group><article-title>Intercomparison of methods for image quality characterization. I. Modulation transfer function</article-title><source>Med. Phys.</source><year>2006</year><volume>33</volume><fpage>1454</fpage><pub-id pub-id-type="doi">10.1118/1.2188816</pub-id><pub-id pub-id-type="pmid">16752580</pub-id></element-citation></ref><ref id="B15-sensors-20-04589"><label>15.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>X.</given-names></name><name><surname>Kashti</surname><given-names>T.</given-names></name><name><surname>Kella</surname><given-names>D.</given-names></name><name><surname>Frank</surname><given-names>T.</given-names></name><name><surname>Shaked</surname><given-names>D.</given-names></name><name><surname>Ulichney</surname><given-names>R.</given-names></name><name><surname>Fischer</surname><given-names>M.</given-names></name><name><surname>Allebach</surname><given-names>J.P.</given-names></name></person-group><article-title>Measuring the Modulation Transfer Function of Image Capture Devices: What Do the Numbers Really Mean?</article-title><source>Proc. Spie Int. Soc. Opt. Eng.</source><year>2012</year><volume>8293</volume><fpage>6</fpage></element-citation></ref><ref id="B16-sensors-20-04589"><label>16.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alaruri</surname><given-names>S.D.</given-names></name></person-group><article-title>Practical methods for characterizing the optical performance of digital camera-based imaging systems: Image processing application using image</article-title><source>Optik</source><year>2020</year><comment>in press</comment><pub-id pub-id-type="doi">10.1016/j.ijleo.2020.164487</pub-id></element-citation></ref><ref id="B17-sensors-20-04589"><label>17.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Roland</surname><given-names>J.K.M.</given-names></name></person-group><article-title>A study of slanted-edge MTF stability and repeatability</article-title><source>Proceedings of the IS&#x00026;T/SPIE Electronic Imaging</source><conf-loc>San Francisco, CA, USA</conf-loc><conf-date>8 February 2015</conf-date><fpage>181</fpage><lpage>189</lpage></element-citation></ref><ref id="B18-sensors-20-04589"><label>18.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Yu</surname><given-names>J.</given-names></name><name><surname>Yao</surname><given-names>L.</given-names></name><name><surname>Chang</surname><given-names>Z.-C.</given-names></name><name><surname>Sun</surname><given-names>W.-D.</given-names></name></person-group><article-title>Improving Image Resolution by 45-Degree Tilting-Mode Sampling</article-title><source>Proceedings of the International Conference on Wireless Communication and Sensor Networks</source><conf-loc>Wuhan, China</conf-loc><conf-date>11 December 2017</conf-date></element-citation></ref><ref id="B19-sensors-20-04589"><label>19.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>He</surname><given-names>Y.</given-names></name><name><surname>Zhang</surname><given-names>J.</given-names></name><name><surname>Wang</surname><given-names>S.</given-names></name></person-group><article-title>Sparse Representation based Satellite Image Restoration Using Adaptive Reciprocal Cell</article-title><source>Int. J. Multimed. Ubiquitous Eng.</source><year>2014</year><volume>9</volume><fpage>341</fpage><lpage>348</lpage><pub-id pub-id-type="doi">10.14257/ijmue.2014.9.10.33</pub-id></element-citation></ref><ref id="B20-sensors-20-04589"><label>20.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>A.</given-names></name><name><surname>Zhao</surname><given-names>J.</given-names></name><name><surname>Zhao</surname><given-names>N.</given-names></name><name><surname>Kang</surname><given-names>X.</given-names></name><name><surname>Guo</surname><given-names>C.</given-names></name></person-group><article-title>Hyperspectral image denoising and antialiasing based on tensor space and reciprocal cell</article-title><source>Infrared Laser Eng.</source><year>2018</year><volume>47</volume><fpage>1026002</fpage><pub-id pub-id-type="doi">10.3788/IRLA201847.1026002</pub-id></element-citation></ref><ref id="B21-sensors-20-04589"><label>21.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>A.</given-names></name><name><surname>Hu</surname><given-names>S.</given-names></name><name><surname>Meng</surname><given-names>X.</given-names></name><name><surname>Yang</surname><given-names>Y.</given-names></name><name><surname>Li</surname><given-names>H.</given-names></name></person-group><article-title>Toward High Altitude Airship Ground-Based Boresight Calibration of Hyperspectral Pushbroom Imaging Sensors</article-title><source>Remote Sens.</source><year>2015</year><volume>7</volume><fpage>17297</fpage><lpage>17311</lpage><pub-id pub-id-type="doi">10.3390/rs71215883</pub-id></element-citation></ref><ref id="B22-sensors-20-04589"><label>22.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>A.</given-names></name><name><surname>Kang</surname><given-names>X.</given-names></name></person-group><article-title>Hyperspectral images band selection algorithm through <italic>p</italic>-value statistic modeling independence</article-title><source>Infrared Laser Eng.</source><year>2018</year><volume>47</volume><fpage>401</fpage><lpage>409</lpage></element-citation></ref><ref id="B23-sensors-20-04589"><label>23.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Press</surname><given-names>W.H.</given-names></name><name><surname>Ventolin</surname><given-names>W.T.</given-names></name><name><surname>Bukowski</surname><given-names>S.</given-names></name></person-group><article-title>Numerical Recipes in C: The Art of Scientific Computing</article-title><source>Phys. Today</source><year>1988</year><volume>40</volume><fpage>120</fpage><lpage>122</lpage><pub-id pub-id-type="doi">10.1063/1.2820230</pub-id></element-citation></ref><ref id="B24-sensors-20-04589"><label>24.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Holst</surname><given-names>G.C.</given-names></name></person-group><article-title>Imaging system fundamentals</article-title><source>Opt. Eng.</source><year>2011</year><volume>50</volume><fpage>052601</fpage><pub-id pub-id-type="doi">10.1117/1.3570681</pub-id></element-citation></ref><ref id="B25-sensors-20-04589"><label>25.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>F.</given-names></name><name><surname>Ni</surname><given-names>J.</given-names></name><name><surname>Guo</surname><given-names>R.</given-names></name></person-group><article-title>Modulation transfer function of an imaging system with a hexagonal pixel array detector</article-title><source>Optik</source><year>2019</year><volume>179</volume><fpage>986</fpage><lpage>993</lpage><pub-id pub-id-type="doi">10.1016/j.ijleo.2018.11.035</pub-id></element-citation></ref><ref id="B26-sensors-20-04589"><label>26.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Takacs</surname><given-names>P.Z.</given-names></name><name><surname>Kotov</surname><given-names>I.</given-names></name><name><surname>Frank</surname><given-names>J.</given-names></name><name><surname>O&#x02019;Connor</surname><given-names>P.</given-names></name><name><surname>Radeka</surname><given-names>V.</given-names></name><name><surname>Lawrence</surname><given-names>M.D.</given-names></name></person-group><article-title>PSF and MTF measurement methods for thick CCD sensor characterization</article-title><source>Proc. SPIE Int. Soc. Opt. Eng.</source><year>2010</year><volume>7742</volume><fpage>774207</fpage><lpage>774207-12</lpage></element-citation></ref><ref id="B27-sensors-20-04589"><label>27.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kurt</surname><given-names>R.</given-names></name></person-group><article-title>Point Spread-Function, Line Spread-Function, and Modulation Transfer Function</article-title><source>Radiology</source><year>1969</year><volume>93</volume><fpage>257</fpage><lpage>272</lpage><pub-id pub-id-type="pmid">5822701</pub-id></element-citation></ref><ref id="B28-sensors-20-04589"><label>28.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Infante</surname><given-names>C.</given-names></name></person-group><article-title>Numerical methods for computing modulation transfer-function area</article-title><source>Displays</source><year>1991</year><volume>12</volume><fpage>80</fpage><lpage>83</lpage><pub-id pub-id-type="doi">10.1016/0141-9382(91)90004-W</pub-id></element-citation></ref><ref id="B29-sensors-20-04589"><label>29.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>Y.</given-names></name><name><surname>He</surname><given-names>B.</given-names></name><name><surname>Liu</surname><given-names>T.</given-names></name></person-group><article-title>Comparison and Simulation of Subpixel Imaging Modes for Linear CCD</article-title><source>Appl. Mech. Mater.</source><year>2012</year><volume>236&#x02013;237</volume><fpage>1032</fpage><lpage>1037</lpage><pub-id pub-id-type="doi">10.4028/www.scientific.net/AMM.236-237.1032</pub-id></element-citation></ref><ref id="B30-sensors-20-04589"><label>30.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xia</surname><given-names>Z.</given-names></name><name><surname>Sun</surname><given-names>W.</given-names></name><name><surname>Cen</surname><given-names>Y.</given-names></name><name><surname>Zhang</surname><given-names>L.</given-names></name><name><surname>Wang</surname><given-names>N.</given-names></name></person-group><article-title>Predicting cadmium concentration in soils using laboratory and field reflectance spectroscopy</article-title><source>Sci. Total Environ.</source><year>2019</year><volume>650</volume><fpage>321</fpage><lpage>334</lpage><pub-id pub-id-type="pmid">30199678</pub-id></element-citation></ref><ref id="B31-sensors-20-04589"><label>31.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lu</surname><given-names>Y.</given-names></name><name><surname>Du</surname><given-names>C.</given-names></name><name><surname>Yu</surname><given-names>C.</given-names></name><name><surname>Zhou</surname><given-names>J.</given-names></name></person-group><article-title>Use of FTIR-PAS combined with chemometrics to quantify nutritional information in rapeseeds (Brassica napus)</article-title><source>J. Plant Nutr. Soil Sci.</source><year>2015</year><volume>177</volume><fpage>927</fpage><lpage>933</lpage><pub-id pub-id-type="doi">10.1002/jpln.201300399</pub-id></element-citation></ref><ref id="B32-sensors-20-04589"><label>32.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>J.</given-names></name><name><surname>Han</surname><given-names>J.</given-names></name><name><surname>Xie</surname><given-names>J.</given-names></name><name><surname>Wang</surname><given-names>H.</given-names></name><name><surname>Tong</surname><given-names>W.</given-names></name><name><surname>Ba</surname><given-names>Y.</given-names></name></person-group><article-title>Assessing heavy metal concentrations in earth-cumulic-orthic-anthrosols soils using Vis-NIR spectroscopy transform coupled with chemometrics</article-title><source>Spectrochim. Acta Part A Mol. Biomol. Spectrosc.</source><year>2020</year><volume>226</volume><fpage>117639</fpage><pub-id pub-id-type="doi">10.1016/j.saa.2019.117639</pub-id></element-citation></ref><ref id="B33-sensors-20-04589"><label>33.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>He</surname><given-names>Z.</given-names></name><name><surname>Li</surname><given-names>M.</given-names></name><name><surname>Ma</surname><given-names>Z.</given-names></name></person-group><article-title>Prediction of dry matter, protein, and acidity in corn steep liquor using near infrared spectroscopy</article-title><source>Proceedings of the 2015 IEEE 7th International Conference on Awareness Science and Technology (iCAST)</source><conf-loc>Qinhuangdao, China</conf-loc><conf-date>22&#x02013;24 September 2015</conf-date><publisher-name>IEEE</publisher-name><publisher-loc>Piscataway, NJ, USA</publisher-loc><year>2015</year></element-citation></ref></ref-list></back><floats-group><fig id="sensors-20-04589-f001" orientation="portrait" position="float"><label>Figure 1</label><caption><p>Tilting sampling and normal sampling.</p></caption><graphic xlink:href="sensors-20-04589-g001"/></fig><fig id="sensors-20-04589-f002" orientation="portrait" position="float"><label>Figure 2</label><caption><p>(<bold>a</bold>) Imaging principle of the sensor we used; (<bold>b</bold>) sampling diagram of the sensor we used.</p></caption><graphic xlink:href="sensors-20-04589-g002"/></fig><fig id="sensors-20-04589-f003" orientation="portrait" position="float"><label>Figure 3</label><caption><p>(<bold>a</bold>) Original tilting image; (<bold>b</bold>) <italic>p</italic>-value distribution map.</p></caption><graphic xlink:href="sensors-20-04589-g003"/></fig><fig id="sensors-20-04589-f004" orientation="portrait" position="float"><label>Figure 4</label><caption><p>Flow chart of the optimal reciprocal cell combined the modulation transfer function (MTF) method.</p></caption><graphic xlink:href="sensors-20-04589-g004"/></fig><fig id="sensors-20-04589-f005" orientation="portrait" position="float"><label>Figure 5</label><caption><p>Pseudocolor tilting image. (<bold>a</bold>) Original tilting image; (<bold>b</bold>) restored tilting image.</p></caption><graphic xlink:href="sensors-20-04589-g005"/></fig><fig id="sensors-20-04589-f006" orientation="portrait" position="float"><label>Figure 6</label><caption><p>Details of the original tilting image and the restored tilting image. (<bold>a</bold>) Details of the original tilting image; (<bold>b</bold>) details of the restored tilting image.</p></caption><graphic xlink:href="sensors-20-04589-g006"/></fig><fig id="sensors-20-04589-f007" orientation="portrait" position="float"><label>Figure 7</label><caption><p>Image acquired by normal or tilting sampling. (<bold>a</bold>) Normal image; (<bold>b</bold>) tilting image; (<bold>c</bold>) tilting image after geometric correction.</p></caption><graphic xlink:href="sensors-20-04589-g007"/></fig><fig id="sensors-20-04589-f008" orientation="portrait" position="float"><label>Figure 8</label><caption><p>Pseudocolor image of interest region. (<bold>a</bold>) Normal image of interest region 1; (<bold>b</bold>) normal image of interest region 2; (<bold>c</bold>) tilting image of interest region 1; (<bold>d</bold>) tilting image of interest region 2.</p></caption><graphic xlink:href="sensors-20-04589-g008"/></fig><fig id="sensors-20-04589-f009" orientation="portrait" position="float"><label>Figure 9</label><caption><p>Restored pseudocolor image of the interesting area. (<bold>a</bold>) Restored normal image of interesting area 1; (<bold>b</bold>) restored normal image of interesting area 2; (<bold>c</bold>) restored tilting image of interesting area 1; (<bold>d</bold>) restored tilting image of interesting area 2.</p></caption><graphic xlink:href="sensors-20-04589-g009"/></fig><fig id="sensors-20-04589-f010" orientation="portrait" position="float"><label>Figure 10</label><caption><p>DN Mean-value curve of the same object area both of normal image and restored tilting the image. (<bold>a</bold>) Mean-value curve of corresponding area 1; (<bold>b</bold>) mean-value curve of corresponding area 2; (<bold>c</bold>) mean-value curve of corresponding area 3.</p></caption><graphic xlink:href="sensors-20-04589-g010"/></fig><fig id="sensors-20-04589-f011" orientation="portrait" position="float"><label>Figure 11</label><caption><p>Flow chart of tilting image calibration.</p></caption><graphic xlink:href="sensors-20-04589-g011"/></fig><fig id="sensors-20-04589-f012" orientation="portrait" position="float"><label>Figure 12</label><caption><p>Calibration equation fitting of each restored tilting image band.</p></caption><graphic xlink:href="sensors-20-04589-g012"/></fig><fig id="sensors-20-04589-f013" orientation="portrait" position="float"><label>Figure 13</label><caption><p>Pseudocolor image of tilting image and normal image. (<bold>a</bold>) Pseudocolor original normal image; (<bold>b</bold>) pseudocolor original tilting image; (<bold>c</bold>) pseudocolor calibrated tilting image.</p></caption><graphic xlink:href="sensors-20-04589-g013"/></fig><fig id="sensors-20-04589-f014" orientation="portrait" position="float"><label>Figure 14</label><caption><p>Comparisons maps of mean-value between the calibrated tilting image and the original normal image.</p></caption><graphic xlink:href="sensors-20-04589-g014"/></fig><fig id="sensors-20-04589-f015" orientation="portrait" position="float"><label>Figure 15</label><caption><p>Classification results of original normal images and restored tilting images. (<bold>a</bold>) Results of the original normal image; (<bold>b</bold>) results of calibrated tilting image.</p></caption><graphic xlink:href="sensors-20-04589-g015"/></fig><table-wrap id="sensors-20-04589-t001" orientation="portrait" position="float"><object-id pub-id-type="pii">sensors-20-04589-t001_Table 1</object-id><label>Table 1</label><caption><p>Parameters of the Sensor.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Name</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Parameter</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">Focus</td><td align="center" valign="middle" rowspan="1" colspan="1">23 mm</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Pixel size</td><td align="center" valign="middle" rowspan="1" colspan="1">7.4 um</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Length of CCD array</td><td align="center" valign="middle" rowspan="1" colspan="1">1600 (max)</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Sampling frequency</td><td align="center" valign="middle" rowspan="1" colspan="1">33/15 fps</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">S/N</td><td align="center" valign="middle" rowspan="1" colspan="1">60 dB</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">F-number</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">2.4</td></tr></tbody></table></table-wrap><table-wrap id="sensors-20-04589-t002" orientation="portrait" position="float"><object-id pub-id-type="pii">sensors-20-04589-t002_Table 2</object-id><label>Table 2</label><caption><p>Information of selected bands.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">ID</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Band ID</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1"><italic>p</italic>-Value</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Band Wavelength (nm)</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">1</td><td align="center" valign="middle" rowspan="1" colspan="1">400</td><td align="center" valign="middle" rowspan="1" colspan="1">0.01742</td><td align="center" valign="middle" rowspan="1" colspan="1">673.665</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">2</td><td align="center" valign="middle" rowspan="1" colspan="1">319</td><td align="center" valign="middle" rowspan="1" colspan="1">0.01661</td><td align="center" valign="middle" rowspan="1" colspan="1">614.355</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">3</td><td align="center" valign="middle" rowspan="1" colspan="1">396</td><td align="center" valign="middle" rowspan="1" colspan="1">0.01613</td><td align="center" valign="middle" rowspan="1" colspan="1">670.722</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">4</td><td align="center" valign="middle" rowspan="1" colspan="1">365</td><td align="center" valign="middle" rowspan="1" colspan="1">0.01528</td><td align="center" valign="middle" rowspan="1" colspan="1">647.962</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">5</td><td align="center" valign="middle" rowspan="1" colspan="1">395</td><td align="center" valign="middle" rowspan="1" colspan="1">0.01500</td><td align="center" valign="middle" rowspan="1" colspan="1">669.987</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">6</td><td align="center" valign="middle" rowspan="1" colspan="1">398</td><td align="center" valign="middle" rowspan="1" colspan="1">0.01441</td><td align="center" valign="middle" rowspan="1" colspan="1">672.1934</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">7</td><td align="center" valign="middle" rowspan="1" colspan="1">399</td><td align="center" valign="middle" rowspan="1" colspan="1">0.01412</td><td align="center" valign="middle" rowspan="1" colspan="1">672.929</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">8</td><td align="center" valign="middle" rowspan="1" colspan="1">414</td><td align="center" valign="middle" rowspan="1" colspan="1">0.01408</td><td align="center" valign="middle" rowspan="1" colspan="1">683.975</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">9</td><td align="center" valign="middle" rowspan="1" colspan="1">282</td><td align="center" valign="middle" rowspan="1" colspan="1">0.01381</td><td align="center" valign="middle" rowspan="1" colspan="1">587.486</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">10</td><td align="center" valign="middle" rowspan="1" colspan="1">382</td><td align="center" valign="middle" rowspan="1" colspan="1">0.01357</td><td align="center" valign="middle" rowspan="1" colspan="1">660.433</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">11</td><td align="center" valign="middle" rowspan="1" colspan="1">332</td><td align="center" valign="middle" rowspan="1" colspan="1">0.01336</td><td align="center" valign="middle" rowspan="1" colspan="1">623.831</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">12</td><td align="center" valign="middle" rowspan="1" colspan="1">406</td><td align="center" valign="middle" rowspan="1" colspan="1">0.01330</td><td align="center" valign="middle" rowspan="1" colspan="1">678.081</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">13</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">287</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.01308</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">591.108</td></tr></tbody></table></table-wrap><table-wrap id="sensors-20-04589-t003" orientation="portrait" position="float"><object-id pub-id-type="pii">sensors-20-04589-t003_Table 3</object-id><label>Table 3</label><caption><p>Evaluation index (AI) and MTFA value of the original tilting image and the restored tilting images.</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" colspan="1">ID</th><th colspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">Original Tilting Image</th><th colspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">Restored Tilting Image</th></tr><tr><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Aliasing Index</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">MTFA</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Aliasing Index</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">MTFA</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">1</td><td align="center" valign="middle" rowspan="1" colspan="1">0.5899</td><td align="center" valign="middle" rowspan="1" colspan="1">2.1215</td><td align="center" valign="middle" rowspan="1" colspan="1">0.4945</td><td align="center" valign="middle" rowspan="1" colspan="1">2.4936</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">2</td><td align="center" valign="middle" rowspan="1" colspan="1">0.5881</td><td align="center" valign="middle" rowspan="1" colspan="1">2.2001</td><td align="center" valign="middle" rowspan="1" colspan="1">0.4939</td><td align="center" valign="middle" rowspan="1" colspan="1">2.4656</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">3</td><td align="center" valign="middle" rowspan="1" colspan="1">0.5882</td><td align="center" valign="middle" rowspan="1" colspan="1">2.1331</td><td align="center" valign="middle" rowspan="1" colspan="1">0.4935</td><td align="center" valign="middle" rowspan="1" colspan="1">2.5387</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">4</td><td align="center" valign="middle" rowspan="1" colspan="1">0.5884</td><td align="center" valign="middle" rowspan="1" colspan="1">2.2426</td><td align="center" valign="middle" rowspan="1" colspan="1">0.4928</td><td align="center" valign="middle" rowspan="1" colspan="1">2.5306</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">5</td><td align="center" valign="middle" rowspan="1" colspan="1">0.5888</td><td align="center" valign="middle" rowspan="1" colspan="1">2.1365</td><td align="center" valign="middle" rowspan="1" colspan="1">0.4964</td><td align="center" valign="middle" rowspan="1" colspan="1">2.5427</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">6</td><td align="center" valign="middle" rowspan="1" colspan="1">0.5884</td><td align="center" valign="middle" rowspan="1" colspan="1">2.1717</td><td align="center" valign="middle" rowspan="1" colspan="1">0.4947</td><td align="center" valign="middle" rowspan="1" colspan="1">2.5395</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">7</td><td align="center" valign="middle" rowspan="1" colspan="1">0.5890</td><td align="center" valign="middle" rowspan="1" colspan="1">2.1053</td><td align="center" valign="middle" rowspan="1" colspan="1">0.4963</td><td align="center" valign="middle" rowspan="1" colspan="1">2.4817</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">8</td><td align="center" valign="middle" rowspan="1" colspan="1">0.5892</td><td align="center" valign="middle" rowspan="1" colspan="1">2.1901</td><td align="center" valign="middle" rowspan="1" colspan="1">0.4935</td><td align="center" valign="middle" rowspan="1" colspan="1">2.5288</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">9</td><td align="center" valign="middle" rowspan="1" colspan="1">0.5888</td><td align="center" valign="middle" rowspan="1" colspan="1">2.0792</td><td align="center" valign="middle" rowspan="1" colspan="1">0.4948</td><td align="center" valign="middle" rowspan="1" colspan="1">2.4100</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">10</td><td align="center" valign="middle" rowspan="1" colspan="1">0.5877</td><td align="center" valign="middle" rowspan="1" colspan="1">2.1785</td><td align="center" valign="middle" rowspan="1" colspan="1">0.4951</td><td align="center" valign="middle" rowspan="1" colspan="1">2.5089</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">11</td><td align="center" valign="middle" rowspan="1" colspan="1">0.5889</td><td align="center" valign="middle" rowspan="1" colspan="1">2.1687</td><td align="center" valign="middle" rowspan="1" colspan="1">0.4957</td><td align="center" valign="middle" rowspan="1" colspan="1">2.5400</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">12</td><td align="center" valign="middle" rowspan="1" colspan="1">0.5886</td><td align="center" valign="middle" rowspan="1" colspan="1">2.1259</td><td align="center" valign="middle" rowspan="1" colspan="1">0.4931</td><td align="center" valign="middle" rowspan="1" colspan="1">2.4916</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">13</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.5877</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">2.0730</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.4949</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">2.4199</td></tr></tbody></table></table-wrap><table-wrap id="sensors-20-04589-t004" orientation="portrait" position="float"><object-id pub-id-type="pii">sensors-20-04589-t004_Table 4</object-id><label>Table 4</label><caption><p>Ratio of prediction to deviation (RPD) value of the original tilting image and the restored tilting image.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">ID</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">SD</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">RMSEP</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">RPD</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">1</td><td align="center" valign="middle" rowspan="1" colspan="1">64.7079</td><td align="center" valign="middle" rowspan="1" colspan="1">24.9940</td><td align="center" valign="middle" rowspan="1" colspan="1">2.5889</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">2</td><td align="center" valign="middle" rowspan="1" colspan="1">63.0294</td><td align="center" valign="middle" rowspan="1" colspan="1">23.4184</td><td align="center" valign="middle" rowspan="1" colspan="1">2.6915</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">3</td><td align="center" valign="middle" rowspan="1" colspan="1">66.2383</td><td align="center" valign="middle" rowspan="1" colspan="1">24.8980</td><td align="center" valign="middle" rowspan="1" colspan="1">2.6604</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">4</td><td align="center" valign="middle" rowspan="1" colspan="1">65.1428</td><td align="center" valign="middle" rowspan="1" colspan="1">26.9604</td><td align="center" valign="middle" rowspan="1" colspan="1">2.4162</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">5</td><td align="center" valign="middle" rowspan="1" colspan="1">65.6546</td><td align="center" valign="middle" rowspan="1" colspan="1">24.9530</td><td align="center" valign="middle" rowspan="1" colspan="1">2.6311</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">6</td><td align="center" valign="middle" rowspan="1" colspan="1">65.1358</td><td align="center" valign="middle" rowspan="1" colspan="1">24.6239</td><td align="center" valign="middle" rowspan="1" colspan="1">2.6452</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">7</td><td align="center" valign="middle" rowspan="1" colspan="1">64.5875</td><td align="center" valign="middle" rowspan="1" colspan="1">25.2995</td><td align="center" valign="middle" rowspan="1" colspan="1">2.5529</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">8</td><td align="center" valign="middle" rowspan="1" colspan="1">64.8738</td><td align="center" valign="middle" rowspan="1" colspan="1">28.1241</td><td align="center" valign="middle" rowspan="1" colspan="1">2.3067</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">9</td><td align="center" valign="middle" rowspan="1" colspan="1">61.4836</td><td align="center" valign="middle" rowspan="1" colspan="1">24.2497</td><td align="center" valign="middle" rowspan="1" colspan="1">2.5354</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">10</td><td align="center" valign="middle" rowspan="1" colspan="1">65.3748</td><td align="center" valign="middle" rowspan="1" colspan="1">25.5949</td><td align="center" valign="middle" rowspan="1" colspan="1">2.5542</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">11</td><td align="center" valign="middle" rowspan="1" colspan="1">64.1214</td><td align="center" valign="middle" rowspan="1" colspan="1">25.4107</td><td align="center" valign="middle" rowspan="1" colspan="1">2.5234</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">12</td><td align="center" valign="middle" rowspan="1" colspan="1">64.5751</td><td align="center" valign="middle" rowspan="1" colspan="1">26.7004</td><td align="center" valign="middle" rowspan="1" colspan="1">2.4185</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">13</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">61.3591</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">23.9015</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">2.5672</td></tr></tbody></table></table-wrap><table-wrap id="sensors-20-04589-t005" orientation="portrait" position="float"><object-id pub-id-type="pii">sensors-20-04589-t005_Table 5</object-id><label>Table 5</label><caption><p>Evaluation Indicators for calibrated images and indicators of the goodness of fit.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Band ID</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">RMSE</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">SD</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">RPD</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">R<sup>2</sup></th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">1</td><td align="center" valign="middle" rowspan="1" colspan="1">10.4722</td><td align="center" valign="middle" rowspan="1" colspan="1">43.0816</td><td align="center" valign="middle" rowspan="1" colspan="1">4.1139</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9941</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">2</td><td align="center" valign="middle" rowspan="1" colspan="1">8.8889</td><td align="center" valign="middle" rowspan="1" colspan="1">43.2790</td><td align="center" valign="middle" rowspan="1" colspan="1">4.8689</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9948</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">3</td><td align="center" valign="middle" rowspan="1" colspan="1">11.9998</td><td align="center" valign="middle" rowspan="1" colspan="1">43.6206</td><td align="center" valign="middle" rowspan="1" colspan="1">3.6351</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9939</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">4</td><td align="center" valign="middle" rowspan="1" colspan="1">12.3611</td><td align="center" valign="middle" rowspan="1" colspan="1">43.4579</td><td align="center" valign="middle" rowspan="1" colspan="1">3.5157</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9930</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">5</td><td align="center" valign="middle" rowspan="1" colspan="1">12.7222</td><td align="center" valign="middle" rowspan="1" colspan="1">43.3476</td><td align="center" valign="middle" rowspan="1" colspan="1">3.4072</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9932</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">6</td><td align="center" valign="middle" rowspan="1" colspan="1">11.7500</td><td align="center" valign="middle" rowspan="1" colspan="1">44.1619</td><td align="center" valign="middle" rowspan="1" colspan="1">3.7585</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9938</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">7</td><td align="center" valign="middle" rowspan="1" colspan="1">17.9444</td><td align="center" valign="middle" rowspan="1" colspan="1">43.8490</td><td align="center" valign="middle" rowspan="1" colspan="1">2.4436</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9938</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">8</td><td align="center" valign="middle" rowspan="1" colspan="1">11.4444</td><td align="center" valign="middle" rowspan="1" colspan="1">43.5388</td><td align="center" valign="middle" rowspan="1" colspan="1">3.8044</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9938</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">9</td><td align="center" valign="middle" rowspan="1" colspan="1">7.9444</td><td align="center" valign="middle" rowspan="1" colspan="1">41.2611</td><td align="center" valign="middle" rowspan="1" colspan="1">5.1937</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9953</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">10</td><td align="center" valign="middle" rowspan="1" colspan="1">16.0278</td><td align="center" valign="middle" rowspan="1" colspan="1">43.4253</td><td align="center" valign="middle" rowspan="1" colspan="1">2.6898</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9930</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">11</td><td align="center" valign="middle" rowspan="1" colspan="1">5.1425</td><td align="center" valign="middle" rowspan="1" colspan="1">43.4253</td><td align="center" valign="middle" rowspan="1" colspan="1">5.1425</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9954</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">12</td><td align="center" valign="middle" rowspan="1" colspan="1">4.0982</td><td align="center" valign="middle" rowspan="1" colspan="1">43.8279</td><td align="center" valign="middle" rowspan="1" colspan="1">4.0982</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9943</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">13</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">4.7384</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">41.4607</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">4.7384</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.9950</td></tr></tbody></table></table-wrap><table-wrap id="sensors-20-04589-t006" orientation="portrait" position="float"><object-id pub-id-type="pii">sensors-20-04589-t006_Table 6</object-id><label>Table 6</label><caption><p>Classification accuracy evaluation of original normal image.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Class</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Leaf (%)</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Background (%)</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Others (%)</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Total</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Overall Accuracy</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Kappa Coefficient</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">Class 1</td><td align="center" valign="middle" rowspan="1" colspan="1">92.45</td><td align="center" valign="middle" rowspan="1" colspan="1">0.00</td><td align="center" valign="middle" rowspan="1" colspan="1">0.00</td><td align="center" valign="middle" rowspan="1" colspan="1">45.51</td><td rowspan="4" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">96.2848%</td><td rowspan="4" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0.9365</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Class 2</td><td align="center" valign="middle" rowspan="1" colspan="1">7.55</td><td align="center" valign="middle" rowspan="1" colspan="1">0.00</td><td align="center" valign="middle" rowspan="1" colspan="1">100.00</td><td align="center" valign="middle" rowspan="1" colspan="1">11.92</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Class 3</td><td align="center" valign="middle" rowspan="1" colspan="1">0.00</td><td align="center" valign="middle" rowspan="1" colspan="1">100.00</td><td align="center" valign="middle" rowspan="1" colspan="1">0.00</td><td align="center" valign="middle" rowspan="1" colspan="1">42.57</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Total</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">100.00</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">100.00</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">100.00</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">100.00</td></tr></tbody></table></table-wrap><table-wrap id="sensors-20-04589-t007" orientation="portrait" position="float"><object-id pub-id-type="pii">sensors-20-04589-t007_Table 7</object-id><label>Table 7</label><caption><p>Classification accuracy evaluation of restored tilting images.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Class</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Leaf (%)</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Background (%)</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Others (%)</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Total</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Overall Accuracy</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Kappa Coefficient</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">Class 1</td><td align="center" valign="middle" rowspan="1" colspan="1">100.00</td><td align="center" valign="middle" rowspan="1" colspan="1">0.00</td><td align="center" valign="middle" rowspan="1" colspan="1">38.46</td><td align="center" valign="middle" rowspan="1" colspan="1">52.82</td><td rowspan="4" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">98.1016%</td><td rowspan="4" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0.9645</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Class 2</td><td align="center" valign="middle" rowspan="1" colspan="1">0.00</td><td align="center" valign="middle" rowspan="1" colspan="1">0.00</td><td align="center" valign="middle" rowspan="1" colspan="1">61.54</td><td align="center" valign="middle" rowspan="1" colspan="1">3.04</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Class 3</td><td align="center" valign="middle" rowspan="1" colspan="1">0.00</td><td align="center" valign="middle" rowspan="1" colspan="1">100.00</td><td align="center" valign="middle" rowspan="1" colspan="1">0.00</td><td align="center" valign="middle" rowspan="1" colspan="1">44.14</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Total</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">100.00</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">100.00</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">100.00</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">100.00</td></tr></tbody></table></table-wrap></floats-group></article>