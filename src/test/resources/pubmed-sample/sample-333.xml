
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">Sensors (Basel)</journal-id><journal-id journal-id-type="iso-abbrev">Sensors (Basel)</journal-id><journal-id journal-id-type="publisher-id">sensors</journal-id><journal-title-group><journal-title>Sensors (Basel, Switzerland)</journal-title></journal-title-group><issn pub-type="epub">1424-8220</issn><publisher><publisher-name>MDPI</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">32674497</article-id><article-id pub-id-type="pmc">7412271</article-id><article-id pub-id-type="doi">10.3390/s20143919</article-id><article-id pub-id-type="publisher-id">sensors-20-03919</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>A Novel Method for Objective Selection of Information Sources Using Multi-Kernel SVM and Local Scaling</article-title></title-group><contrib-group><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-8313-7541</contrib-id><name><surname>Areiza-Laverde</surname><given-names>Henry Jho&#x000e1;n</given-names></name><xref ref-type="aff" rid="af1-sensors-20-03919">1</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0003-3893-1137</contrib-id><name><surname>Castro-Ospina</surname><given-names>Andr&#x000e9;s Eduardo</given-names></name><xref ref-type="aff" rid="af1-sensors-20-03919">1</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0001-8186-7391</contrib-id><name><surname>Hern&#x000e1;ndez</surname><given-names>Mar&#x000ed;a Liliana</given-names></name><xref ref-type="aff" rid="af2-sensors-20-03919">2</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0003-1028-9111</contrib-id><name><surname>D&#x000ed;az</surname><given-names>Gloria M.</given-names></name><xref ref-type="aff" rid="af1-sensors-20-03919">1</xref><xref rid="c1-sensors-20-03919" ref-type="corresp">*</xref></contrib></contrib-group><aff id="af1-sensors-20-03919"><label>1</label>MIRP Lab&#x02013;Parque i, Instituto Tecnol&#x000f3;gico Metropolitano (ITM), Medell&#x000ed;n 050013, Colombia; <email>henryareiza135582@correo.itm.edu.co</email> (H.J.A.-L.); <email>andrescastro@itm.edu.co</email> (A.E.C.-O.)</aff><aff id="af2-sensors-20-03919"><label>2</label>Grupo de Investigaci&#x000f3;n del Instituto de Alta Tecnolog&#x000ed;a M&#x000e9;dica (IATM), Ayudas Diagn&#x000f3;sticas Sura, Medell&#x000ed;n 050026, Colombia; <email>mlhernandezp@sura.com.co</email></aff><author-notes><corresp id="c1-sensors-20-03919"><label>*</label>Correspondence: <email>gloriadiaz@itm.edu.co</email></corresp></author-notes><pub-date pub-type="epub"><day>14</day><month>7</month><year>2020</year></pub-date><pub-date pub-type="collection"><month>7</month><year>2020</year></pub-date><volume>20</volume><issue>14</issue><elocation-id>3919</elocation-id><history><date date-type="received"><day>17</day><month>5</month><year>2020</year></date><date date-type="accepted"><day>03</day><month>6</month><year>2020</year></date></history><permissions><copyright-statement>&#x000a9; 2020 by the authors.</copyright-statement><copyright-year>2020</copyright-year><license license-type="open-access"><license-p>Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>).</license-p></license></permissions><abstract><p>Advancement on computer and sensing technologies has generated exponential growth in the data available for the development of systems that support decision-making in fields such as health, entertainment, manufacturing, among others. This fact has made that the fusion of data from multiple and heterogeneous sources became one of the most promising research fields in machine learning. However, in real-world applications, to reduce the number of sources while maintaining optimal system performance is an important task due to the availability of data and implementation costs related to processing, implementation, and development times. In this work, a novel method for the objective selection of relevant information sources in a multimodality system is proposed. This approach takes advantage of the ability of multiple kernel learning (MKL) and the support vector machines (SVM) classifier to perform an optimal fusion of data by assigning weights according to their discriminative value in the classification task; when a kernel is designed for representing each data source, these weights can be used as a measure of their relevance. Moreover, three algorithms for tuning the Gaussian kernel bandwidth in the classifier prediction stage are introduced to reduce the computational cost of searching for an optimal solution; these algorithms are an adaptation of a common technique in unsupervised learning named local scaling. Two real application tasks were used to evaluate the proposed method: the selection of electrodes for a classification task in Brain&#x02013;Computer Interface (BCI) systems and the selection of relevant Magnetic Resonance Imaging (MRI) sequences for detection of breast cancer. The obtained results show that the proposed method allows the selection of a small number of information sources.</p></abstract><kwd-group><kwd>machine learning</kwd><kwd>multimodality</kwd><kwd>multiple kernel learning</kwd><kwd>support vector machines</kwd><kwd>source selection</kwd></kwd-group></article-meta></front><body><sec sec-type="intro" id="sec1-sensors-20-03919"><title>1. Introduction</title><p>In machine learning, multimodality refers to the simultaneous use of different information sources to solve a specific problem [<xref rid="B1-sensors-20-03919" ref-type="bibr">1</xref>]. It is applied to improve some aspects of algorithms, such as the feature generation process or separation between classes, referring specifically to the machine learning area. The use of multimodal sources offers some advantages because it provides additional information about the problem being solved [<xref rid="B2-sensors-20-03919" ref-type="bibr">2</xref>]. However, having multiple information sources can also become a problem as the implementation cost can be substantially increased due to the procedural and financial parts of the solution. Currently, different research fields conduct studies that involve the use of multimodal information sources to improve the performance of their works [<xref rid="B3-sensors-20-03919" ref-type="bibr">3</xref>,<xref rid="B4-sensors-20-03919" ref-type="bibr">4</xref>,<xref rid="B5-sensors-20-03919" ref-type="bibr">5</xref>]; however, at the same time, this trend creates the need for studies into the control and optimization of the use of these sources so that the tasks to be carried out are much more efficient in terms of cost, development, and processing times [<xref rid="B6-sensors-20-03919" ref-type="bibr">6</xref>,<xref rid="B7-sensors-20-03919" ref-type="bibr">7</xref>,<xref rid="B8-sensors-20-03919" ref-type="bibr">8</xref>].</p><p>Taking into account that in recent times machine learning algorithms have proven to be extremely useful for processing large amounts of data, different studies have been conducted to automatically reduce the amount of data. The most similar approach to the automatic selection of relevant information sources is feature selection through machine learning methods [<xref rid="B9-sensors-20-03919" ref-type="bibr">9</xref>]. Such an approach is implemented mainly because an information source can be considered a group of features that share the same nature. The selection of relevant features has been widely addressed in the machine learning field, and it is possible to adapt classical feature selection methods to simultaneously select or delete groups of features, which is known as group feature selection [<xref rid="B10-sensors-20-03919" ref-type="bibr">10</xref>,<xref rid="B11-sensors-20-03919" ref-type="bibr">11</xref>]. The studies that apply group feature selection usually identify and distinguish the information sources in a specific research area, such as electrodes in a Brain&#x02013;Computer Interface (BCI) system [<xref rid="B12-sensors-20-03919" ref-type="bibr">12</xref>] or different frequency bands in multispectral and hyperspectral imaging [<xref rid="B13-sensors-20-03919" ref-type="bibr">13</xref>].</p><p>The most basic group feature selection methods use a defined classification threshold; they take a reference value that must be reached to decide whether or not eliminating a feature group [<xref rid="B11-sensors-20-03919" ref-type="bibr">11</xref>,<xref rid="B14-sensors-20-03919" ref-type="bibr">14</xref>]. Other methods use more advanced procedures to determine the relevance of a set of features based on a penalty imposed during the learning stage of the algorithm [<xref rid="B15-sensors-20-03919" ref-type="bibr">15</xref>]; aiming the self method eliminates or reduces the effect of the least relevant feature groups by decreasing the values of the weights assigned to them [<xref rid="B14-sensors-20-03919" ref-type="bibr">14</xref>,<xref rid="B16-sensors-20-03919" ref-type="bibr">16</xref>]. There is another pair of group feature selection methods known as backward elimination and forward addition [<xref rid="B17-sensors-20-03919" ref-type="bibr">17</xref>]; they are usually presented together and consist of removing or adding features to the classification task, and analyzing the performance curve generated during training, seeking to identify the points where the performance of the algorithm is maximum.</p><p>Although there is a wide variety of strategies that can be implemented to select feature groups, there is a common challenge all these methods share: the fact that the implementation of algorithms based on single feature selection strategies does not guarantee that the whole information source can be seen as a complete and independent block. That is, these methods usually retain an individual notion of the features to determine an apparent relevance of the information source, thus losing the overall properties of the source and causing breaks between some important relationships between the features that compose the source.</p><p>One method that has grown in importance in recent years in the machine learning field, regarding the use of multiple information sources, is Multiple Kernel Learning (MKL) [<xref rid="B18-sensors-20-03919" ref-type="bibr">18</xref>,<xref rid="B19-sensors-20-03919" ref-type="bibr">19</xref>]. MKL allows the implementation of a similarity measure (kernel) associated with each information source in an independent way before each of those sources is integrated into the learning task [<xref rid="B20-sensors-20-03919" ref-type="bibr">20</xref>,<xref rid="B21-sensors-20-03919" ref-type="bibr">21</xref>], thus taking advantage of the information coming from each source. Besides, it enables users to obtain easy-to-interpret results in relation to the analysis of each information source [<xref rid="B22-sensors-20-03919" ref-type="bibr">22</xref>].</p><p>MKL has brought a lot of advantages for different tasks in which it has been implemented, especially when used with the Support Vector Machine (SVM) method [<xref rid="B23-sensors-20-03919" ref-type="bibr">23</xref>] as well as with other types of machine learning algorithms [<xref rid="B24-sensors-20-03919" ref-type="bibr">24</xref>]. In addition, MKL is well documented in the state of the art and has proven to be useful for the identification and selection of relevant information sources [<xref rid="B25-sensors-20-03919" ref-type="bibr">25</xref>,<xref rid="B26-sensors-20-03919" ref-type="bibr">26</xref>]. This is because it allows the user to have a similarity measure of data for each information source without losing the possible internal relationships of the features that compose the source, thus enabling objective studies into relevance analyses that are very easy to interpret.</p><p>In the state of the art, the use of MKL has been reported when weights are assigned to each kernel associated with the information sources [<xref rid="B27-sensors-20-03919" ref-type="bibr">27</xref>], which is an important feature of this methodology since these weights can be used to determine the relevance that each source represents for the implemented solution [<xref rid="B28-sensors-20-03919" ref-type="bibr">28</xref>,<xref rid="B29-sensors-20-03919" ref-type="bibr">29</xref>,<xref rid="B30-sensors-20-03919" ref-type="bibr">30</xref>]. It has been effectively demonstrated that the selection of relevant information sources by penalizing kernel weights is very useful and provides information that is easy to interpret [<xref rid="B31-sensors-20-03919" ref-type="bibr">31</xref>], in addition to being a method that can be taken to different research areas.</p><p>This work proposes a novel method to objectively select the most relevant information sources in a classification task; this method uses the local scaling technique to tune the parameters of Gaussian kernels associated with each information source by using the MKL. Instead of computing a unique kernel bandwidth for all data, the local scaling technique computes a kernel bandwidth for each sample; thus, it exploits local statistics of sample neighborhood, capturing structure in data [<xref rid="B32-sensors-20-03919" ref-type="bibr">32</xref>]. This technique has been used in combination with MKL to perform adaptive unsupervised clustering [<xref rid="B33-sensors-20-03919" ref-type="bibr">33</xref>]. In this paper, three different algorithms were also proposed to adapt the local scaling technique to be used during the prediction stage in a supervised classification task, allowing to reduce the computational complexity of the tuning process of kernel parameters considerably. The proposed method is evaluated over two real application tasks: the selection of electrodes for a classification task in Brain&#x02013;Computer Interface (BCI) systems and the selection of relevant Magnetic Resonance Imaging (MRI) sequences for detection of breast cancer. The obtained results show that the proposed method is stable regarding the sources which are selected as relevant when any of the three proposed algorithms are applied.</p></sec><sec sec-type="methods" id="sec2-sensors-20-03919"><title>2. Methodology</title><p>This paper proposes a novel method to address the problem of identifying and selecting relevant available information sources by solving a binary classification task in an objective way. The proposed method is based on the use of techniques that have been well studied in the machine learning area, but without the joint implementation reported in the literature. This section contains a detailed explanation of the techniques involved in the proposed method, beginning with the theoretical framework of each technique and finishing with the pseudocode of the algorithms designed to apply such a method.</p><sec id="sec2dot1-sensors-20-03919"><title>2.1. Support Vector Machines (SVMs)</title><p>As mentioned before, the proposed method is only applicable to binary classification problems (for now). This restriction is due to the use of an SVM classifier as base learner in the machine learning task. The SVM is a well-known classifier designed adopting the structural risk minimization theory in order to produce a successful generalization of the prediction using unknown data [<xref rid="B34-sensors-20-03919" ref-type="bibr">34</xref>]. The SVM classifier finds the boundary line that better discriminates the training samples contained in a database represented by <inline-formula><mml:math id="mm1"><mml:mrow><mml:msubsup><mml:mfenced separators="" open="{" close="}"><mml:mfenced separators="" open="(" close=")"><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mfenced></mml:mfenced><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula>. As a result of this property, SVMs are known as large margin classifiers [<xref rid="B35-sensors-20-03919" ref-type="bibr">35</xref>]. Each <inline-formula><mml:math id="mm2"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> in the database is an input vector of dimension <italic>D</italic>, and <inline-formula><mml:math id="mm3"><mml:mrow><mml:mrow><mml:mi>y</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mo>{</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the label vector which has <italic>N</italic> elements.</p><p>The classification function <inline-formula><mml:math id="mm4"><mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mo>&#x02329;</mml:mo><mml:mi>w</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo>&#x0232a;</mml:mo><mml:mo>+</mml:mo><mml:mi>b</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> defines the distance to the hyperplane which can be seen as a membership degree assigned by the SVM to a test sample, where <italic>w</italic> is the weight associated with each sample <inline-formula><mml:math id="mm5"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, <italic>b</italic> is the hyperplane bias term, and the <inline-formula><mml:math id="mm6"><mml:mrow><mml:mrow><mml:mo>&#x02329;</mml:mo><mml:mo>&#x000b7;</mml:mo><mml:mo>,</mml:mo><mml:mo>&#x000b7;</mml:mo><mml:mo>&#x0232a;</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> operator refers to the dot product between vectors. The primal optimization problem of the SVM is presented in Equation (<xref ref-type="disp-formula" rid="FD1-sensors-20-03919">1</xref>), and <italic>w</italic> and <italic>b</italic> are computed when this problem is solved.
<disp-formula id="FD1-sensors-20-03919"><label>(1)</label><mml:math id="mm7"><mml:mrow><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mspace width="1.em"/></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:msup><mml:mi>w</mml:mi><mml:mo>*</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:munder><mml:mo movablelimits="true" form="prefix">min</mml:mo><mml:mi>w</mml:mi></mml:munder><mml:mspace width="5.69054pt"/><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:msubsup><mml:mfenced open="&#x02225;" close="&#x02225;"><mml:mi>w</mml:mi></mml:mfenced><mml:mn>2</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:mi>C</mml:mi><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:msub><mml:mi>&#x003be;</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right"><mml:mspace width="1.em"/></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mi>s</mml:mi><mml:mo>.</mml:mo><mml:mi>t</mml:mi><mml:mo>.</mml:mo><mml:mspace width="8.53581pt"/><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>&#x02329;</mml:mo><mml:mi>w</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo>&#x0232a;</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x02265;</mml:mo><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>&#x003be;</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula>
where <italic>C</italic> is a regularization parameter defined by the user, and <inline-formula><mml:math id="mm8"><mml:mrow><mml:mi>&#x003be;</mml:mi></mml:mrow></mml:math></inline-formula> is the vector of slack variables.</p><p>Lagrange Multipliers are used to solve the quadratic optimization problem in Equation (<xref ref-type="disp-formula" rid="FD1-sensors-20-03919">1</xref>) [<xref rid="B34-sensors-20-03919" ref-type="bibr">34</xref>], changing the classification function to <inline-formula><mml:math id="mm9"><mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msubsup><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup><mml:mrow><mml:msub><mml:mi>&#x003b1;</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>b</mml:mi></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> and creating the final objective function presented in Equation (<xref ref-type="disp-formula" rid="FD2-sensors-20-03919">2</xref>), namely, the dual function of the SVM.
<disp-formula id="FD2-sensors-20-03919"><label>(2)</label><mml:math id="mm10"><mml:mrow><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mspace width="1.em"/></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:munder><mml:mo movablelimits="true" form="prefix">max</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>&#x02264;</mml:mo><mml:mi>&#x003b1;</mml:mi><mml:mo>&#x02264;</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:munder><mml:mspace width="5.69054pt"/><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:msub><mml:mi>&#x003b1;</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:mrow><mml:msub><mml:mi>&#x003b1;</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>&#x003b1;</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>y</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mi>K</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right"><mml:mspace width="1.em"/></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mi>s</mml:mi><mml:mo>.</mml:mo><mml:mi>t</mml:mi><mml:mo>.</mml:mo><mml:mspace width="8.53581pt"/><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:mrow><mml:msub><mml:mi>&#x003b1;</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm11"><mml:mrow><mml:mi>&#x003b1;</mml:mi></mml:mrow></mml:math></inline-formula> is the dual variables vector originated by applying Lagrange Multipliers. The term <inline-formula><mml:math id="mm12"><mml:mrow><mml:mrow><mml:mi>K</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> in Equation (<xref ref-type="disp-formula" rid="FD2-sensors-20-03919">2</xref>) is known as the kernel function; it also appears in the classification function. It is essential for the performance of the SVM since it generalizes the SVM classifier to solve non-linear problems by allowing the calculation of non-linear decision boundaries. A kernel represents a similarity measure (dot product) between two samples and is commonly expressed as <inline-formula><mml:math id="mm13"><mml:mrow><mml:mrow><mml:mi>K</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="mm14"><mml:mrow><mml:mrow><mml:mi>K</mml:mi><mml:mo>:</mml:mo><mml:mspace width="3.33333pt"/><mml:msup><mml:mi mathvariant="double-struck">R</mml:mi><mml:mi>D</mml:mi></mml:msup><mml:mo>&#x000d7;</mml:mo><mml:mspace width="3.33333pt"/><mml:msup><mml:mi mathvariant="double-struck">R</mml:mi><mml:mi>D</mml:mi></mml:msup><mml:mo>&#x027f6;</mml:mo><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>. Such dot products are made implicitly in a high-dimensional Hilbert Space by using the kernel trick, without the explicit knowledge or use of a mapping function to a high-dimensional space [<xref rid="B36-sensors-20-03919" ref-type="bibr">36</xref>].</p><p>There are different types of representations of a kernel function, which to be valid and represent dot products on Hilbert spaces must fulfill Mercer&#x02019;s condition [<xref rid="B36-sensors-20-03919" ref-type="bibr">36</xref>]. The simplest one is the dot product (<inline-formula><mml:math id="mm15"><mml:mrow><mml:mrow><mml:mo>&#x02329;</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>&#x0232a;</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>), namely, linear kernel, and one of the most commonly used is the Gaussian kernel, also known as radial basis function kernel, which is defined by <inline-formula><mml:math id="mm16"><mml:mrow><mml:mrow><mml:mi>K</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo form="prefix">exp</mml:mo><mml:mfenced separators="" open="(" close=")"><mml:mfrac><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:msubsup><mml:mfenced separators="" open="&#x02225;" close="&#x02225;"><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mfenced><mml:mn>2</mml:mn><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:msup><mml:mi>&#x003c3;</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mfrac></mml:mfenced></mml:mrow></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="mm17"><mml:mrow><mml:mi>&#x003c3;</mml:mi></mml:mrow></mml:math></inline-formula> is the kernel bandwidth and must be a positive real number.</p><p>The algorithm most commonly used to handle the dual function of the SVM is the Sequential Minimal Optimization (SMO) algorithm [<xref rid="B37-sensors-20-03919" ref-type="bibr">37</xref>]. There are a lot of programming libraries designed to successfully apply the SMO algorithm, e.g., the LIBSVM library is one the most widely implemented in the literature [<xref rid="B38-sensors-20-03919" ref-type="bibr">38</xref>] because it has a cutting-edge repository that can be used over different programming languages and is well supported by the scientific community.</p></sec><sec id="sec2dot2-sensors-20-03919"><title>2.2. Kernel Bandwidth Tuning with Local&#x000a0;Scaling</title><p>A recurrent challenge found in the literature is the correct tuning of the <inline-formula><mml:math id="mm18"><mml:mrow><mml:mi>&#x003c3;</mml:mi></mml:mrow></mml:math></inline-formula> parameter when a Gaussian kernel is used in the SVM [<xref rid="B39-sensors-20-03919" ref-type="bibr">39</xref>,<xref rid="B40-sensors-20-03919" ref-type="bibr">40</xref>,<xref rid="B41-sensors-20-03919" ref-type="bibr">41</xref>]. This problem has been addressed with different strategies, mainly metaheuristic optimization techniques that consume significant time and computational resources, which is why it remains an open issue in the machine learning area.</p><p>Zelnik-Manor and Perona [<xref rid="B32-sensors-20-03919" ref-type="bibr">32</xref>] proposed a clever and intuitive method for tuning the <inline-formula><mml:math id="mm19"><mml:mrow><mml:mi>&#x003c3;</mml:mi></mml:mrow></mml:math></inline-formula> parameter without using metaheuristic methods. Furthermore, their strategy allowed them to define a different <inline-formula><mml:math id="mm20"><mml:mrow><mml:msub><mml:mi>&#x003c3;</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> value related to each sample in the database instead of a global <inline-formula><mml:math id="mm21"><mml:mrow><mml:mi>&#x003c3;</mml:mi></mml:mrow></mml:math></inline-formula>; this strategy is known as local scaling. To compute the local scaling parameter for each <inline-formula><mml:math id="mm22"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> in the database, it is necessary to analyze the local statistics of its neighborhood because the value of <inline-formula><mml:math id="mm23"><mml:mrow><mml:msub><mml:mi>&#x003c3;</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is defined by Equation (<xref ref-type="disp-formula" rid="FD3-sensors-20-03919">3</xref>).
<disp-formula id="FD3-sensors-20-03919"><label>(3)</label><mml:math id="mm24"><mml:mrow><mml:mrow><mml:msub><mml:mi>&#x003c3;</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>d</mml:mi><mml:mfenced separators="" open="(" close=")"><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>K</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm25"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>K</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is the K-th nearest neighbor of sample <inline-formula><mml:math id="mm26"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm27"><mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>(</mml:mo><mml:mo>&#x000b7;</mml:mo><mml:mo>,</mml:mo><mml:mo>&#x000b7;</mml:mo><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is some distance function used to evaluate the local statistics of the data. This work uses the Euclidean distance following the proposal of Zelnik-Manor and Perona [<xref rid="B32-sensors-20-03919" ref-type="bibr">32</xref>]. The <italic>K</italic> value determines the neighborhood size and relies on the scale or density of the samples space, i.e., a larger <italic>K</italic> value represents a larger similarity among samples, while a small <italic>K</italic> value focuses on local similarities. Therefore, a new parameter should be tuned when local scaling is used. This parameter is the correct neighbor <italic>K</italic> to compute the distance that defines each <inline-formula><mml:math id="mm28"><mml:mrow><mml:msub><mml:mi>&#x003c3;</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> value.</p><p>If any optimization algorithm is used for tuning the <inline-formula><mml:math id="mm29"><mml:mrow><mml:mi>&#x003c3;</mml:mi></mml:mrow></mml:math></inline-formula> value in the general radial basis function kernel, it should deal with an infinite searching space of real values. Otherwise, when the local scaling technique is used, even if <italic>K</italic> remains as a free parameter, the optimization problem is reduced to a limited space of integer values considering that <inline-formula><mml:math id="mm30"><mml:mrow><mml:mrow><mml:mi>K</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mi mathvariant="double-struck">Z</mml:mi><mml:mo>:</mml:mo><mml:mn>1</mml:mn><mml:mo>&#x02a7d;</mml:mo><mml:mi>K</mml:mi><mml:mo>&#x0003c;</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>. Besides, the neighborhood of <inline-formula><mml:math id="mm31"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> will be defined for a small number of samples because using a large <italic>K</italic> value would cause the loss of the local scaling property. When the local scaling strategy is applied, the Gaussian kernel is computed using Equation (<xref ref-type="disp-formula" rid="FD4-sensors-20-03919">4</xref>).
<disp-formula id="FD4-sensors-20-03919"><label>(4)</label><mml:math id="mm32"><mml:mrow><mml:mrow><mml:mi>K</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo form="prefix">exp</mml:mo><mml:mfenced separators="" open="(" close=")"><mml:mfrac><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:msubsup><mml:mfenced separators="" open="&#x02225;" close="&#x02225;"><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mfenced><mml:mn>2</mml:mn><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mrow><mml:msub><mml:mi>&#x003c3;</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>&#x003c3;</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mfenced></mml:mrow></mml:mrow></mml:math></disp-formula></p></sec><sec id="sec2dot3-sensors-20-03919"><title>2.3. Multiple Kernel Learning (MKL)</title><p>In recent years, MKL has attracted interest in different research areas, especially because it allows users to take advantage of multiple information sources to solve machine learning problems, even when each information source has a different nature [<xref rid="B25-sensors-20-03919" ref-type="bibr">25</xref>,<xref rid="B42-sensors-20-03919" ref-type="bibr">42</xref>]. The MKL methodology establishes that multiple linear or non-linear combinations of kernels can be used instead of one single kernel. One of the most commonly used MKL functions is a weighted sum of kernels as shown in Equation (<xref ref-type="disp-formula" rid="FD5-sensors-20-03919">5</xref>). This function enables the use of the individual information provided by each data source, in addition to keeping the internal relationships between the features that compose the whole source.
<disp-formula id="FD5-sensors-20-03919"><label>(5)</label><mml:math id="mm33"><mml:mrow><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mi>&#x003b7;</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>P</mml:mi></mml:munderover><mml:mrow><mml:msub><mml:mi>&#x003b7;</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:msub><mml:mi>K</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mi>i</mml:mi><mml:mi>m</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mi>j</mml:mi><mml:mi>m</mml:mi></mml:msubsup><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula>
where <italic>P</italic> is the number of information sources that compose the database and <inline-formula><mml:math id="mm34"><mml:mrow><mml:msub><mml:mi>&#x003b7;</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> represents the weight assigned to each kernel function <inline-formula><mml:math id="mm35"><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>.</p><p>An important detail of the MKL function presented in Equation (<xref ref-type="disp-formula" rid="FD5-sensors-20-03919">5</xref>) is the possibility of applying a penalization to the weights <inline-formula><mml:math id="mm36"><mml:mrow><mml:mi>&#x003b7;</mml:mi></mml:mrow></mml:math></inline-formula> in order to identify the most relevant information sources, i.e., the possibility of selecting the sources that provide the most useful information to solve the classification task that is being studied [<xref rid="B43-sensors-20-03919" ref-type="bibr">43</xref>]. One of the types of penalization most commonly applied to the <inline-formula><mml:math id="mm37"><mml:mrow><mml:mi>&#x003b7;</mml:mi></mml:mrow></mml:math></inline-formula> weights is the <inline-formula><mml:math id="mm38"><mml:mrow><mml:msub><mml:mi>&#x02113;</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>-norm penalization. The latter provides a straightforward interpretation of results because it fulfills the characteristic of being a sparse penalization type, making some weights equal zero and thus eliminating the least useful information sources [<xref rid="B44-sensors-20-03919" ref-type="bibr">44</xref>]. The <inline-formula><mml:math id="mm39"><mml:mrow><mml:msub><mml:mi>&#x02113;</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>-norm penalization satisfies the condition <inline-formula><mml:math id="mm40"><mml:mrow><mml:mrow><mml:mi>&#x003b7;</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mo>&#x00394;</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="mm41"><mml:mrow><mml:mo>&#x00394;</mml:mo></mml:mrow></mml:math></inline-formula> is the domain of <inline-formula><mml:math id="mm42"><mml:mrow><mml:mi>&#x003b7;</mml:mi></mml:mrow></mml:math></inline-formula> and is defined by Equation (<xref ref-type="disp-formula" rid="FD6-sensors-20-03919">6</xref>), which corresponds to a convex sum, namely, the simplex condition.
<disp-formula id="FD6-sensors-20-03919"><label>(6)</label><mml:math id="mm43"><mml:mrow><mml:mrow><mml:mo>&#x00394;</mml:mo><mml:mo>=</mml:mo><mml:mfenced separators="" open="{" close="}"><mml:mi>&#x003b7;</mml:mi><mml:mo>&#x02208;</mml:mo><mml:msubsup><mml:mi mathvariant="double-struck">R</mml:mi><mml:mo>+</mml:mo><mml:mi>P</mml:mi></mml:msubsup><mml:mo>:</mml:mo><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>P</mml:mi></mml:munderover><mml:msub><mml:mi>&#x003b7;</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mspace width="4pt"/><mml:msub><mml:mi>&#x003b7;</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>&#x02265;</mml:mo><mml:mn>0</mml:mn></mml:mfenced></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Equation (<xref ref-type="disp-formula" rid="FD6-sensors-20-03919">6</xref>) clearly defines how the <inline-formula><mml:math id="mm44"><mml:mrow><mml:mi>&#x003b7;</mml:mi></mml:mrow></mml:math></inline-formula> weights can be interpreted as relevance measures because each one of them is associated with an individual kernel, which, in turn, is associated with an independent information source. Additionally, all the information sources could be different in terms of nature and number of features without affecting the implementation of the strategy. Kloft et al. [<xref rid="B45-sensors-20-03919" ref-type="bibr">45</xref>] and Xu et al. [<xref rid="B42-sensors-20-03919" ref-type="bibr">42</xref>] conducted two different studies to find the correct way to train the <inline-formula><mml:math id="mm45"><mml:mrow><mml:mi>&#x003b7;</mml:mi></mml:mrow></mml:math></inline-formula> weights using a generalized penalization of the <inline-formula><mml:math id="mm46"><mml:mrow><mml:msub><mml:mi>&#x02113;</mml:mi><mml:mi>p</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>-norms with <inline-formula><mml:math id="mm47"><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>&#x02265;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>. Although the analysis in the two studies was performed in a different way, the result was the same. They found an iterative optimization strategy that solves an SVM and updates the kernel weights with Equation (<xref ref-type="disp-formula" rid="FD7-sensors-20-03919">7</xref>) until a tolerance measure is satisfied.
<disp-formula id="FD7-sensors-20-03919"><label>(7)</label><mml:math id="mm48"><mml:mrow><mml:mrow><mml:msub><mml:mi>&#x003b7;</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:msubsup><mml:mfenced separators="" open="&#x02225;" close="&#x02225;"><mml:msub><mml:mi>w</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:mfenced><mml:mn>2</mml:mn><mml:mfrac><mml:mn>2</mml:mn><mml:mrow><mml:mi>p</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac></mml:msubsup><mml:msup><mml:mfenced separators="" open="(" close=")"><mml:msubsup><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>h</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>P</mml:mi></mml:msubsup><mml:msubsup><mml:mfenced separators="" open="&#x02225;" close="&#x02225;"><mml:msub><mml:mi>w</mml:mi><mml:mi>h</mml:mi></mml:msub></mml:mfenced><mml:mn>2</mml:mn><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac></mml:msubsup></mml:mfenced><mml:mfrac><mml:mn>1</mml:mn><mml:mi>p</mml:mi></mml:mfrac></mml:msup></mml:mfrac></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm49"><mml:mrow><mml:mrow><mml:msubsup><mml:mfenced separators="" open="&#x02225;" close="&#x02225;"><mml:msub><mml:mi>w</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:mfenced><mml:mn>2</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>&#x003b7;</mml:mi><mml:mi>m</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:msubsup><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup><mml:msubsup><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup><mml:mrow><mml:msub><mml:mi>&#x003b1;</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>&#x003b1;</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>y</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:msub><mml:mi>K</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mfenced separators="" open="(" close=")"><mml:msubsup><mml:mi>x</mml:mi><mml:mi>i</mml:mi><mml:mi>m</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mi>j</mml:mi><mml:mi>m</mml:mi></mml:msubsup></mml:mfenced></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, which is computed from the dual function of the SVM.</p></sec><sec id="sec2dot4-sensors-20-03919"><title>2.4. Description of the Proposed&#x000a0;Method</title><p>The proposed method uses MKL to select relevant sources from multimodal data, i.e., the multiple sources available for the classification task. One matrix represents each information source with <italic>N</italic> columns corresponding to the samples and an independent number of rows corresponding to the features. The local scaling technique is used to compute the <inline-formula><mml:math id="mm50"><mml:mrow><mml:msub><mml:mi>&#x003c3;</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> values representing the local statistics of the data, what is necessary to compute the <italic>P</italic> kernels associated with the information sources. Then, the global kernel <inline-formula><mml:math id="mm51"><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mi>&#x003b7;</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> obtained after applying the MKL function based on the weighted sum of kernels is fed into an SVM classifier to complete a training process and solve the task. Thus, obtaining a trained predictive model with the definitive <inline-formula><mml:math id="mm52"><mml:mrow><mml:mi>&#x003b7;</mml:mi></mml:mrow></mml:math></inline-formula> values associated with the relevance measures of the information sources. <xref ref-type="fig" rid="sensors-20-03919-f001">Figure 1</xref> shows a rough representation of the proposed method as a flowchart.</p><p>Because the local scaling strategy was proposed to be applied over unsupervised learning tasks [<xref rid="B32-sensors-20-03919" ref-type="bibr">32</xref>], there is no defined process to apply this technique in a supervised learning approach, where labeled data is used to create a predictive model and avoid using all the training information at the prediction stage. Explicitly using the SVM classifier, it is necessary to define a way to compute or estimate each <inline-formula><mml:math id="mm53"><mml:mrow><mml:mi>&#x003c3;</mml:mi></mml:mrow></mml:math></inline-formula> value associated with the test samples, contemplating that an SVM only requires the information of some samples (support vectors) to classify unknown data, whereby there is missing information about the original local statistics in the prediction stage. This work proposes three different algorithms to expand local scaling applications to supervised learning tasks; these algorithms are described below.</p><sec id="sec2dot4dot1-sensors-20-03919"><title>2.4.1. Prediction without Data&#x000a0;Reduction</title><p>The first idea that comes to mind in order to avoid this problem is to compute the distance between the test and training samples and assign the <inline-formula><mml:math id="mm54"><mml:mrow><mml:mi>&#x003c3;</mml:mi></mml:mrow></mml:math></inline-formula> values to the test samples using the distance of the K-th neighbor. A clear disadvantage of this solution is that all the training samples will be necessary in the prediction stage in order to correctly compute the <inline-formula><mml:math id="mm55"><mml:mrow><mml:mi>&#x003c3;</mml:mi></mml:mrow></mml:math></inline-formula> values of the test samples. Algorithm 1 describes how this solution can be applied.
<array orientation="portrait"><tbody><tr><td align="left" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1"><bold>Algorithm 1:</bold> Algorithm without data reduction</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1"><graphic xlink:href="sensors-20-03919-i001.jpg" position="float" orientation="portrait"/></td></tr></tbody></array></p></sec><sec id="sec2dot4dot2-sensors-20-03919"><title>2.4.2. Prediction with Support Vectors&#x000a0;Only</title><p>Although the first algorithm represents the most accurate approach to compute the <inline-formula><mml:math id="mm56"><mml:mrow><mml:mi>&#x003c3;</mml:mi></mml:mrow></mml:math></inline-formula> values of the test samples, it wastes one of the most important characteristics of the SVM: its ability to implement only a few training samples, known as support vectors, in the prediction stage. The second algorithm was designed with the aim of avoiding this issue, using only the <inline-formula><mml:math id="mm57"><mml:mrow><mml:mi>&#x003c3;</mml:mi></mml:mrow></mml:math></inline-formula> values of the support vectors. In this algorithm, the distance between the test samples and support vectors is computed, assigning to each test sample the corresponding <inline-formula><mml:math id="mm58"><mml:mrow><mml:mi>&#x003c3;</mml:mi></mml:mrow></mml:math></inline-formula> of its nearest support vector. Algorithm 2 describes how this strategy can be applied.
<array orientation="portrait"><tbody><tr><td align="left" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1"><bold>Algorithm 2:</bold> Algorithm with data reduction by support vectors only</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1"><graphic xlink:href="sensors-20-03919-i002.jpg" position="float" orientation="portrait"/></td></tr></tbody></array></p></sec><sec id="sec2dot4dot3-sensors-20-03919"><title>2.4.3. Prediction with Mean <inline-formula><mml:math id="mm59"><mml:mrow><mml:mi>&#x003c3;</mml:mi></mml:mrow></mml:math></inline-formula> Values of Support&#x000a0;Vectors</title><p>The second algorithm presents the best solution with respect to data processing and memory consumption, but it appears to ignore information that belongs to the training samples that were not selected as support vectors and could be important to determine the <inline-formula><mml:math id="mm60"><mml:mrow><mml:mi>&#x003c3;</mml:mi></mml:mrow></mml:math></inline-formula> values of the test data. The third algorithm was designed to avoid this issue. In this algorithm, a new step is added to the training stage. It consists in identifying all the training samples that had not been selected as support vectors, assigning to each one of them the nearest support vector, and, finally, computing, for each support vector, a new <inline-formula><mml:math id="mm61"><mml:mrow><mml:mi>&#x003c3;</mml:mi></mml:mrow></mml:math></inline-formula> value composed of the mean of the <inline-formula><mml:math id="mm62"><mml:mrow><mml:mi>&#x003c3;</mml:mi></mml:mrow></mml:math></inline-formula> values belonging to its nearest training samples. In the prediction stage, the distance between the test samples and support vectors is computed, assigning to each test sample the <inline-formula><mml:math id="mm63"><mml:mrow><mml:mi>&#x003c3;</mml:mi></mml:mrow></mml:math></inline-formula> mean associated with its nearest support vector. This process is described in Algorithm 3.
<array orientation="portrait"><tbody><tr><td align="left" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1"><bold>Algorithm 3:</bold> Data reduction by the mean of <inline-formula><mml:math id="mm64"><mml:mrow><mml:mi>&#x003c3;</mml:mi></mml:mrow></mml:math></inline-formula> values related to the samples nearest to the support vectors</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1"><graphic xlink:href="sensors-20-03919-i003.jpg" position="float" orientation="portrait"/></td></tr></tbody></array></p></sec></sec></sec><sec id="sec3-sensors-20-03919"><title>3. Experimental&#x000a0;Setup</title><p>The proposed method can be applied to any well-structured classification task with a multimodal designation. For this reason, we decided to test it in two different tasks and thus demonstrate its usefulness. The first application scenario was a well-known state-of-the-art problem: the selection of relevant electroencephalography (EEG) channels in a Brain&#x02013;Computer Interface (BCI) classification task. The second scenario was a problem that has not been addressed by the machine learning field: the objective selection of relevant information sources, more specifically, the selection of relevant Magnetic Resonance Imaging (MRI) sequences for breast cancer detection. This section describes the configuration of the datasets and the structure of all the experiments conducted here to evaluate the proposed method.</p><sec id="sec3dot1-sensors-20-03919"><title>3.1. BCI&#x000a0;Dataset</title><p>This dataset was published for the BCI competition IV dataset 2a, held in 2008 by the Graz University of Technology in Austria [<xref rid="B46-sensors-20-03919" ref-type="bibr">46</xref>]. The dataset is composed of EEG signals taken from 9 healthy subjects. The EEG signals can be categorized into 4 classes of motor imagery: left hand, right hand, feet, and tongue. Each subject completed two sessions on different days; each session consisted of 6 runs separated by short time lapses. A total of 48 trials were recorded in each run (12 per class), thus conducting 288 trials per session. In this study, only the motor imagery of the left and right hands was used since the proposed method is restricted to binary classification problems only. Besides, only the trials of one session were provided with their corresponding labels. Finally, 72 trials were carried out for imaging the movement of the left hand and 72 for the right hand of each subject. In order for the method (which is based on an SVM) to carry out an adequate classification task, the left hand signals were assigned to class <inline-formula><mml:math id="mm65"><mml:mrow><mml:mn mathvariant="bold">1</mml:mn></mml:mrow></mml:math></inline-formula> and the right hand signals were assigned to class <inline-formula><mml:math id="mm66"><mml:mrow><mml:mrow><mml:mo mathvariant="bold">&#x02212;</mml:mo><mml:mn mathvariant="bold">1</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>.</p><p>The signals were acquired with a sampling frequency of 250 Hz using 22 electrodes with an inter-electrode distance of <inline-formula><mml:math id="mm67"><mml:mrow><mml:mrow><mml:mn>3</mml:mn><mml:mo>.</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> cm based on the international 10&#x02013;20 system (see <xref ref-type="fig" rid="sensors-20-03919-f002">Figure 2</xref>). In this case, each electrode was an independent information source that provided descriptive data to be used in the problem solution. Hence, this dataset was composed of 22 information sources in relation to the notation presented in this document. In addition to the 22 electrodes, three electrooculography (EOG) channels were added to the setup during data acquisition. The data provided by these EOG channels were not used as information sources for the classification task; they were only used for applying a preprocessing step to remove artifacts from the EEG signals. Besides, two filters were applied to all the signals (including EOG) as another preprocessing step: (1) a bandpass between <inline-formula><mml:math id="mm68"><mml:mrow><mml:mrow><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> Hz and 100 Hz and (2) a 50 Hz notch filter.</p><p>A feature generation process was applied to the preprocessed signals. Such process allowed us to extract descriptive measures and information to represent the signals in a compressed way. The mother wavelet transformation Daubechies of order 2 (db2) has proven to be efficient in describing EEG signals for classification tasks [<xref rid="B47-sensors-20-03919" ref-type="bibr">47</xref>]; thus, it was selected to generate the features of the BCI dataset in this study. Different decomposition levels were considered, taking into account that this dataset is composed of motor imagery signals. As a bandpass filter between 0.5 Hz and 100 Hz was applied to the signals, the detail coefficients of the third (D3) and fourth (D4) decomposition levels are associated with the mu (6.25&#x02013;12.50 Hz) and beta (12.50&#x02013;25.00 Hz) rhythms, respectively. These rhythms are commonly used to process motor imagery EEG signals in the state of the art [<xref rid="B48-sensors-20-03919" ref-type="bibr">48</xref>,<xref rid="B49-sensors-20-03919" ref-type="bibr">49</xref>,<xref rid="B50-sensors-20-03919" ref-type="bibr">50</xref>]; hence, they were computed in this dataset. Additionally, the frequency ranges 0.5&#x02013;3.13 Hz and 3.13&#x02013;6.25 Hz are also highlighted in the literature. They are associated with approximation (A5) and detail (D5) coefficients of the fifth decomposition level, respectively [<xref rid="B50-sensors-20-03919" ref-type="bibr">50</xref>]. Thus, they were also used in this study.</p><p>After computing the wavelet coefficients D3, D4, D5, and A5, six statistical measures of each coefficient and the original signal were calculated: mean, median, mode, variance, kurtosis, and standard deviation [<xref rid="B51-sensors-20-03919" ref-type="bibr">51</xref>]. Additionally, the energy of each coefficient and the original signal was also computed. As a result, we obtained a total of 35 features per information source.</p></sec><sec id="sec3dot2-sensors-20-03919"><title>3.2. Breast Cancer&#x000a0;Dataset</title><p>The MRI breast cancer dataset was developed by Instituto Tecnol&#x000f3;gico Metropolitano (ITM) in collaboration with Instituto de Alta Tecnolog&#x000ed;a M&#x000e9;dica (IATM) in Medell&#x000ed;n, Colombia. It is composed of 87 studies, and each study corresponds to one subject and presents at least one Region of Interest (ROI). In total, 146 ROIs were extracted from the entire dataset. Each study in the dataset is represented by nine information sources, and each source corresponds to an MRI sequence. The sequences included in the dataset are the relaxations T1 and T2, Diffusion-Weighted Imaging (DWI), Apparent Diffusion Coefficient (ADC), and subtractions 1 to 5 obtained from Dynamic Contrast Enhanced (DCE) sequences [<xref rid="B52-sensors-20-03919" ref-type="bibr">52</xref>]. Each MRI sequence highlights different three-dimensional information from the tissue under analysis so that it can be ensured that each sequence corresponds to an independent information source. <xref ref-type="fig" rid="sensors-20-03919-f003">Figure 3</xref> shows an example of the visualization of these sequences.</p><p>The complete dataset was evaluated by two expert radiologists from IATM, who classified each finding in the sequences using the Breast Imaging Reporting and Data System (BI-RADS) [<xref rid="B53-sensors-20-03919" ref-type="bibr">53</xref>]. This system enabled them to assign a probability level of a finding to be cancer, where 5 is the highest level: highly suggestive of malignancy. In order to adapt the dataset to the classification method proposed in this paper, the ROIs were separated into two classes: class <inline-formula><mml:math id="mm69"><mml:mrow><mml:mrow><mml:mo mathvariant="bold">&#x02212;</mml:mo><mml:mn mathvariant="bold">1</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> for all the ROIs with a BI-RADS less than 3 and class <inline-formula><mml:math id="mm70"><mml:mrow><mml:mn mathvariant="bold">1</mml:mn></mml:mrow></mml:math></inline-formula> for the ROIs with a BI-RADS equal to or greater than 3. A total of 61 ROIs were associated with class <inline-formula><mml:math id="mm71"><mml:mrow><mml:mrow><mml:mo mathvariant="bold">&#x02212;</mml:mo><mml:mn mathvariant="bold">1</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> and 85 with class <inline-formula><mml:math id="mm72"><mml:mrow><mml:mn mathvariant="bold">1</mml:mn></mml:mrow></mml:math></inline-formula> applying this configuration.</p><p>Two different set of features were implemented to describe the information of the findings in each sequence, i.e., perceptual and radiomic features. Perceptual features refer to the properties of an image that can be captured by human perception [<xref rid="B54-sensors-20-03919" ref-type="bibr">54</xref>], while radiomic features represent a quantitative approach to the analysis of medical images aimed at explaining the morphological and functional properties of a lesion [<xref rid="B55-sensors-20-03919" ref-type="bibr">55</xref>].</p><p>A total of 10 perceptual features and 86 radiomic features were computed for each image sequence. Perceptual features were computed as the first five statistical moments from both the salient maps generated by the Graph-Based Visual Saliency method [<xref rid="B56-sensors-20-03919" ref-type="bibr">56</xref>,<xref rid="B57-sensors-20-03919" ref-type="bibr">57</xref>] and the original images; while radiomic features were extracted using the Pyradiomics toolbox of Python [<xref rid="B58-sensors-20-03919" ref-type="bibr">58</xref>]. As described below, the experimental stage was performed by considering both each set of features as an independent information source and the combination of the two sets of features as one unique information source. Thus, a total of 18 information sources per instance were obtained, i.e., nine sources that correspond to the set of perceptual features for each sequence (P_T1, P_T2, P_ADC, P_DWI, P_SUB1, P_SUB2, P_SUB3, P_SUB4, and nine other sources that correspond to each set of radiomic features (R_T1, R_T2, R_ADC, R_DWI, R_SUB1, R_SUB2, R_SUB3, R_SUB4 and R_SUB5).</p><p>The main objective of integrating perceptual and radiomic features in this study is to obtain relevant results for both machines and radiologists.</p></sec><sec id="sec3dot3-sensors-20-03919"><title>3.3. Test&#x000a0;Settings</title><p>The tests conducted here to evaluate the performance of the proposed method take into account different variations that it may present. They are mainly associated with the three algorithms proposed to adapt the local scaling method to the supervised learning task, the types of features generated from the MRI sequences, the number of subjects in the BCI dataset, and the two main types of penalties that can be applied to the <inline-formula><mml:math id="mm73"><mml:mrow><mml:mi>&#x003b7;</mml:mi></mml:mrow></mml:math></inline-formula> weights associated with the kernels (which correspond to the <inline-formula><mml:math id="mm74"><mml:mrow><mml:msub><mml:mi>&#x02113;</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>-norm and the <inline-formula><mml:math id="mm75"><mml:mrow><mml:msub><mml:mi>&#x02113;</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>-norm). Therefore, it is necessary to explain how the tests were configured for each dataset.</p><sec id="sec3dot3dot1-sensors-20-03919"><title>3.3.1. BCI Dataset&#x000a0;Configuration</title><p>The tests performed using the BCI dataset were divided into two large groups determined by the penalty types (<inline-formula><mml:math id="mm76"><mml:mrow><mml:msub><mml:mi>&#x02113;</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>-norm and <inline-formula><mml:math id="mm77"><mml:mrow><mml:msub><mml:mi>&#x02113;</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>-norm). Then, each of these groups was divided into three subgroups determined by the three algorithms proposed here to adapt the local scaling method. Finally, a test was conducted on each subgroup using each one of the nine subjects that compose the dataset. This resulted in a total of 54 different tests taken into account to evaluate the performance of the proposed method with the BCI dataset.</p></sec><sec id="sec3dot3dot2-sensors-20-03919"><title>3.3.2. MRI Dataset&#x000a0;Configuration</title><p>In the same way, as with the BCI dataset, the tests with the MRI dataset were divided into two large groups determined by the penalty types (<inline-formula><mml:math id="mm78"><mml:mrow><mml:msub><mml:mi>&#x02113;</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>-norm and <inline-formula><mml:math id="mm79"><mml:mrow><mml:msub><mml:mi>&#x02113;</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>-norm). Then, each test group was divided into three subgroups determined by the available feature types. The first subgroup included only perceptual features; the second, only radiomic features; and the third, both feature types. Finally, a test was applied to each subgroup using each one of the three proposed algorithms. This resulted in a total of 18 different tests taken into account to evaluate the performance of the proposed method with the MRI dataset.</p></sec><sec id="sec3dot3dot3-sensors-20-03919"><title>3.3.3. General Configuration of the&#x000a0;Tests</title><p>Although the purpose of the proposed method is the objective selection of relevant information sources, it is necessary to evaluate the effectiveness of the method based on its performance in terms of the classification task. Therefore, we decided to implement 4 well-known performance measures for classification tasks [<xref rid="B59-sensors-20-03919" ref-type="bibr">59</xref>]: accuracy, sensitivity, specificity, and geometric mean (Geo-Mean). They were computed using Equations (<xref ref-type="disp-formula" rid="FD8-sensors-20-03919">8</xref>) to (<xref ref-type="disp-formula" rid="FD11-sensors-20-03919">11</xref>), respectively.
<disp-formula id="FD8-sensors-20-03919"><label>(8)</label><mml:math id="mm80"><mml:mrow><mml:mrow><mml:mi mathvariant="bold">Accuracy</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>Correctly</mml:mi><mml:mtext>&#x000a0;</mml:mtext><mml:mi>predicted</mml:mi><mml:mtext>&#x000a0;</mml:mtext><mml:mi>samples</mml:mi></mml:mrow><mml:mrow><mml:mi>Total</mml:mi><mml:mtext>&#x000a0;</mml:mtext><mml:mi>number</mml:mi><mml:mtext>&#x000a0;</mml:mtext><mml:mi>of</mml:mi><mml:mtext>&#x000a0;</mml:mtext><mml:mi>samples</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:mrow></mml:math></disp-formula>
<disp-formula id="FD9-sensors-20-03919"><label>(9)</label><mml:math id="mm81"><mml:mrow><mml:mrow><mml:mi mathvariant="bold">Sensitivity</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>True</mml:mi><mml:mtext>&#x000a0;</mml:mtext><mml:mi>positives</mml:mi></mml:mrow><mml:mrow><mml:mi>True</mml:mi><mml:mtext>&#x000a0;</mml:mtext><mml:mi>positives</mml:mi><mml:mtext>&#x000a0;</mml:mtext><mml:mo>+</mml:mo><mml:mtext>&#x000a0;</mml:mtext><mml:mi>False</mml:mi><mml:mtext>&#x000a0;</mml:mtext><mml:mi>negatives</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:mrow></mml:math></disp-formula>
<disp-formula id="FD10-sensors-20-03919"><label>(10)</label><mml:math id="mm82"><mml:mrow><mml:mrow><mml:mi mathvariant="bold">Specificity</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>True</mml:mi><mml:mtext>&#x000a0;</mml:mtext><mml:mi>negatives</mml:mi></mml:mrow><mml:mrow><mml:mi>True</mml:mi><mml:mtext>&#x000a0;</mml:mtext><mml:mi>negatives</mml:mi><mml:mtext>&#x000a0;</mml:mtext><mml:mo>+</mml:mo><mml:mtext>&#x000a0;</mml:mtext><mml:mi>False</mml:mi><mml:mtext>&#x000a0;</mml:mtext><mml:mi>positives</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:mrow></mml:math></disp-formula>
<disp-formula id="FD11-sensors-20-03919"><label>(11)</label><mml:math id="mm83"><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="bold">Geo</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mi mathvariant="bold">Mean</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:msqrt><mml:mrow><mml:mi>Sensitivity</mml:mi><mml:mtext>&#x000a0;</mml:mtext><mml:mo>&#x000b7;</mml:mo><mml:mtext>&#x000a0;</mml:mtext><mml:mi>Specificity</mml:mi></mml:mrow></mml:msqrt></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Each dataset was divided maintaining a <inline-formula><mml:math id="mm84"><mml:mrow><mml:mrow><mml:mn>20</mml:mn><mml:mo>%</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> of the samples outside the training and validation stage to use them as test samples, while the remaining <inline-formula><mml:math id="mm85"><mml:mrow><mml:mrow><mml:mn>80</mml:mn><mml:mo>%</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> was used to train the model. For the training and validation process, the cross-validation method K-Fold was implemented with a total of 10 folds in order to be able to train the method in such a way that it could correctly generalize the predictions about test data.</p><p>Although the method proposed by Zelnik-Manor and Perona [<xref rid="B32-sensors-20-03919" ref-type="bibr">32</xref>] set the <italic>K</italic> value to 7 because it produced good general results, in this work, <italic>K</italic> was defined as a parameter to be optimized, in addition to the regularization parameter <italic>C</italic>, and the parameter for the SMO algorithm <inline-formula><mml:math id="mm86"><mml:mrow><mml:mi>&#x003c4;</mml:mi></mml:mrow></mml:math></inline-formula>. The Particle Swarm Optimization (PSO) algorithm was implemented to find the optimal values of these parameters. The PSO is one of the most commonly used optimization algorithms in the state of the art [<xref rid="B60-sensors-20-03919" ref-type="bibr">60</xref>,<xref rid="B61-sensors-20-03919" ref-type="bibr">61</xref>,<xref rid="B62-sensors-20-03919" ref-type="bibr">62</xref>]. It uses cooperative and stochastic methods to find the optimal parameters of the function to be optimized; in this case, the performance of the classifier. In all the tests, we used 40 search particles and individual and social learning coefficients equal to <inline-formula><mml:math id="mm87"><mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>.</mml:mo><mml:mn>1931</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> [<xref rid="B63-sensors-20-03919" ref-type="bibr">63</xref>], and the inertia value was dynamically established between <inline-formula><mml:math id="mm88"><mml:mrow><mml:mrow><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm89"><mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>.</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> with a maximum value of 60 iterations. The cost function used for the optimization process was the geometric mean because it was the performance measure that showed the best stability and quick convergence regarding the optimal values that are found.</p><p>Once the optimization process was completed using the PSO and cross-validation in each test, the optimal parameters found were used to train a global model using the total training data. This model was finally employed to make the prediction on the test data that had been initially separated, thus obtaining the trained values of the <inline-formula><mml:math id="mm90"><mml:mrow><mml:mi>&#x003b7;</mml:mi></mml:mrow></mml:math></inline-formula> weights that determine the relevance of the information sources and the predictions on the test data that would allow us to measure the performance of the method as a classifier.</p><p>Furthermore, Equation (<xref ref-type="disp-formula" rid="FD12-sensors-20-03919">12</xref>) was implemented in order to measure the effectiveness of the method in terms of the reduction rate of the number of information sources, taking into account that the ideal situation is to obtain a high reduction rate because it means the use of a minimal number of sources to solve the classification task.
<disp-formula id="FD12-sensors-20-03919"><label>(12)</label><mml:math id="mm91"><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="bold">Reduction</mml:mi><mml:mo>&#x000a0;</mml:mo><mml:mi mathvariant="bold">rate</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:mfrac><mml:mrow><mml:mi>Number</mml:mi><mml:mtext>&#x000a0;</mml:mtext><mml:mi>of</mml:mi><mml:mtext>&#x000a0;</mml:mtext><mml:mi>sources</mml:mi><mml:mtext>&#x000a0;</mml:mtext><mml:mi>selected</mml:mi></mml:mrow><mml:mrow><mml:mi>Total</mml:mi><mml:mtext>&#x000a0;</mml:mtext><mml:mi>number</mml:mi><mml:mtext>&#x000a0;</mml:mtext><mml:mi>of</mml:mi><mml:mtext>&#x000a0;</mml:mtext><mml:mi>sources</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:mrow></mml:math></disp-formula></p></sec></sec></sec><sec sec-type="results" id="sec4-sensors-20-03919"><title>4. Results and&#x000a0;Discussion</title><p>This section reports the results obtained with the BCI and the MRI datasets. Such results are analyzed in detail and discussed taking into account some relevant studies in the literature that present reference points to assess the performance of the proposed method.</p><sec sec-type="results" id="sec4dot1-sensors-20-03919"><title>4.1. Results Obtained with the BCI&#x000a0;Dataset</title><p>A total of 54 tests were conducted with this dataset, as described in the previous section. After completing the training stage and obtaining the optimal values for the free parameters, a prediction process was performed with the test data while a sequential reduction as applied to the number of information sources. This was possible because the global model obtained after the training stage contained the <inline-formula><mml:math id="mm92"><mml:mrow><mml:mi>&#x003b7;</mml:mi></mml:mrow></mml:math></inline-formula> values of each information source (each electrode), and these values are directly associated with the relevance measure obtained for each source. As a result, the most relevant information sources can be identified and sequentially eliminated from least to most relevant when the <inline-formula><mml:math id="mm93"><mml:mrow><mml:mi>&#x003b7;</mml:mi></mml:mrow></mml:math></inline-formula> values are sorted from highest to lowest.</p><p><xref ref-type="fig" rid="sensors-20-03919-f004">Figure 4</xref> shows the curves obtained with the process of reduction of information sources. Taking into account that there is a lot of information, the results were condensed in three different figures that represent the application of the three proposed algorithms. Such figures show the average value and standard deviation of the accuracy obtained for the nine subjects, separated by the application of the <inline-formula><mml:math id="mm94"><mml:mrow><mml:msub><mml:mi>&#x02113;</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>-norm and <inline-formula><mml:math id="mm95"><mml:mrow><mml:msub><mml:mi>&#x02113;</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>-norm.</p><p><xref ref-type="fig" rid="sensors-20-03919-f004">Figure 4</xref>a shows the performance curves of Algorithm 1. In it, the highest mean performance with the lowest number of sources is obtained using the <inline-formula><mml:math id="mm96"><mml:mrow><mml:msub><mml:mi>&#x02113;</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>-norm; nevertheless, the <inline-formula><mml:math id="mm97"><mml:mrow><mml:msub><mml:mi>&#x02113;</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>-norm shows a very similar behavior, reaching a high performance when only 2 information sources are used. <xref ref-type="fig" rid="sensors-20-03919-f004">Figure 4</xref>b shows the performance curves of Algorithm 2. In this case, the <inline-formula><mml:math id="mm98"><mml:mrow><mml:msub><mml:mi>&#x02113;</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>-norm achieves the highest performance with the lowest number of sources, more specifically, between 4 and 6 sources. Finally, <xref ref-type="fig" rid="sensors-20-03919-f004">Figure 4</xref>c shows the performance curves of Algorithm 3. Again, both the <inline-formula><mml:math id="mm99"><mml:mrow><mml:msub><mml:mi>&#x02113;</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>-norm and the <inline-formula><mml:math id="mm100"><mml:mrow><mml:msub><mml:mi>&#x02113;</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>-norm exhibit similar behavior, although the <inline-formula><mml:math id="mm101"><mml:mrow><mml:msub><mml:mi>&#x02113;</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>-norm slightly outperforms the <inline-formula><mml:math id="mm102"><mml:mrow><mml:msub><mml:mi>&#x02113;</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>-norm when only 5 information sources are used. Based on these results, we decided to include only the detailed performance specifications of the method using the <inline-formula><mml:math id="mm103"><mml:mrow><mml:msub><mml:mi>&#x02113;</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>-norm because the performance of both penalization types was very similar, and including all the detailed performance results could seem redundant.</p><p><xref rid="sensors-20-03919-t001" ref-type="table">Table 1</xref> details the classification performance results obtained with the BCI dataset when Algorithm 1 was applied with the <inline-formula><mml:math id="mm104"><mml:mrow><mml:msub><mml:mi>&#x02113;</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>-norm. Said table compares the results obtained when the 22 information sources were used and the best result obtained per subject with the lowest number of sources that could be used. These sources are sorted by relevance from high to low. Evidently, the performance measures always improve when the number of sources is reduced. It is also important to highlight that each subject requires a different number of information sources and that the selected electrodes are different for each subject (with some coincidences in several cases). <xref rid="sensors-20-03919-t001" ref-type="table">Table 1</xref> also shows the time required by the computer to train the global model and make predictions with the test data. All these tests were conducted on a work station with an Intel processor of 16 cores at <inline-formula><mml:math id="mm105"><mml:mrow><mml:mrow><mml:mn>3</mml:mn><mml:mo>.</mml:mo><mml:mn>00</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> GHz and 16 GB of RAM. The last column in the table shows the number of samples required by the algorithm to compute the prediction with the test data. In this case, all the training samples were required by the algorithm because that is precisely the main feature of Algorithm 1 and also its worst disadvantage. The last row shows the average computed using all the information obtained from all the subjects with its corresponding standard deviation. The relevant electrodes were selected by analyzing which of them were the most voted among all the subjects.</p><p><xref rid="sensors-20-03919-t002" ref-type="table">Table 2</xref> details the results obtained with the BCI dataset when Algorithm 2 was used with the <inline-formula><mml:math id="mm106"><mml:mrow><mml:msub><mml:mi>&#x02113;</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>-norm. These results are very similar to those obtained in <xref rid="sensors-20-03919-t001" ref-type="table">Table 1</xref>. The most important aspect to highlight in this table is the fact that all the most relevant electrodes selected in the average results were also selected by Algorithm 1, which means high stability in the method among the algorithms. Furthermore, the results show again that the proposed method can improve the performance (measures) of the classification task and, at the same time, produce a reduction in the required number of samples (nearly <inline-formula><mml:math id="mm107"><mml:mrow><mml:mrow><mml:mn>72</mml:mn><mml:mo>%</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>) because this algorithm only uses the support vectors to make predictions.</p><p><xref rid="sensors-20-03919-t003" ref-type="table">Table 3</xref> presents the results of the method applied to the BCI dataset when Algorithm 3 and the <inline-formula><mml:math id="mm108"><mml:mrow><mml:msub><mml:mi>&#x02113;</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>-norm are used. The electrodes selected as relevant are the same as in <xref rid="sensors-20-03919-t001" ref-type="table">Table 1</xref> and <xref rid="sensors-20-03919-t002" ref-type="table">Table 2</xref>, thus confirming, once again, the stability of the method in terms of the selection of relevant information sources even when the type of algorithm is different. <xref rid="sensors-20-03919-t003" ref-type="table">Table 3</xref> also shows that Algorithm 3 reduces the number of samples required for the prediction by nearly <inline-formula><mml:math id="mm109"><mml:mrow><mml:mrow><mml:mn>74</mml:mn><mml:mo>%</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. We should remember that this algorithm takes the information of the samples that the SVM does not select as support vectors for computing mean sigma values and takes advantage of all the available data.</p><p>Taking into account that the stability and reliability of the relevant information sources selected by the method are the most critical factors to analyze, we created <xref rid="sensors-20-03919-t004" ref-type="table">Table 4</xref> with the average relevance assigned to each electrode among all the subjects. The accuracy obtained in the classification of each subject was used to weight this relevance, considering that the electrodes selected as relevant by the method are more reliable when the obtained accuracy is higher. In <xref rid="sensors-20-03919-t004" ref-type="table">Table 4</xref>, it can be seen that the method selected electrodes 8, 13, 14, 18, and 22 as relevant in all the configurations among all the algorithm and penalization types. This table was organized based on the information in <xref rid="sensors-20-03919-t001" ref-type="table">Table 1</xref>, <xref rid="sensors-20-03919-t002" ref-type="table">Table 2</xref> and <xref rid="sensors-20-03919-t003" ref-type="table">Table 3</xref>, by taking the first eight selected electrodes as relevant. Furthermore, if the penalization type is used to analyze the results presented in <xref rid="sensors-20-03919-t004" ref-type="table">Table 4</xref> separately, it can also be seen that electrode 7 was classified as relevant with the <inline-formula><mml:math id="mm110"><mml:mrow><mml:msub><mml:mi>&#x02113;</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>-norm; and electrode 1, with the <inline-formula><mml:math id="mm254"><mml:mrow><mml:msub><mml:mi>&#x02113;</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>-norm.</p></sec><sec sec-type="results" id="sec4dot2-sensors-20-03919"><title>4.2. Results Obtained with the MRI&#x000a0;Dataset</title><p>A total of 18 tests were conducted with the MRI dataset. As in the tests applied to the BCI dataset, a prediction process was performed on the test data while making a sequential reduction in the number of information sources after completing the training stage and obtaining the optimal values for the free parameters. <xref ref-type="fig" rid="sensors-20-03919-f005">Figure 5</xref> shows the curves obtained with the process of reduction of information sources on the MRI dataset. Three different figures that represent the use of the perceptual features, radiomic features and a combination of both summarize the results. The figures show the average value and standard deviation of the accuracy obtained with the three algorithms, separated by the application of the <inline-formula><mml:math id="mm255"><mml:mrow><mml:msub><mml:mi>&#x02113;</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>-norm and <inline-formula><mml:math id="mm256"><mml:mrow><mml:msub><mml:mi>&#x02113;</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>-norm.</p><p><xref ref-type="fig" rid="sensors-20-03919-f005">Figure 5</xref>a shows the performance curves obtained using only the perceptual features. In this figure, the <inline-formula><mml:math id="mm257"><mml:mrow><mml:msub><mml:mi>&#x02113;</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>-norm clearly outperforms the <inline-formula><mml:math id="mm258"><mml:mrow><mml:msub><mml:mi>&#x02113;</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>-norm, reaching the highest mean accuracy with only 5 information sources, which slowly decreases with fewer sources. <xref ref-type="fig" rid="sensors-20-03919-f005">Figure 5</xref>b shows the performance curves obtained using only the radiomic features. In this case, both the <inline-formula><mml:math id="mm259"><mml:mrow><mml:msub><mml:mi>&#x02113;</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>-norm and the <inline-formula><mml:math id="mm260"><mml:mrow><mml:msub><mml:mi>&#x02113;</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>-norm present a similar behavior, although the <inline-formula><mml:math id="mm261"><mml:mrow><mml:msub><mml:mi>&#x02113;</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>-norm slightly outperforms the <inline-formula><mml:math id="mm262"><mml:mrow><mml:msub><mml:mi>&#x02113;</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>-norm when 5 information sources are used. Finally, <xref ref-type="fig" rid="sensors-20-03919-f005">Figure 5</xref>c shows the performance curves using perceptual and radiomic features simultaneously. Again, both the <inline-formula><mml:math id="mm263"><mml:mrow><mml:msub><mml:mi>&#x02113;</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>-norm and the <inline-formula><mml:math id="mm264"><mml:mrow><mml:msub><mml:mi>&#x02113;</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>-norm exhibit a similar performance, and the <inline-formula><mml:math id="mm265"><mml:mrow><mml:msub><mml:mi>&#x02113;</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>-norm slightly outperforms its counterpart when only 6 information sources are used. Based on these results, we decided to include only the detailed performance results of the method using the <inline-formula><mml:math id="mm266"><mml:mrow><mml:msub><mml:mi>&#x02113;</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>-norm, although the results were remarkably similar to the two penalization types.</p><p><xref rid="sensors-20-03919-t005" ref-type="table">Table 5</xref> details the results of the method using only the perceptual features and applying the <inline-formula><mml:math id="mm267"><mml:mrow><mml:msub><mml:mi>&#x02113;</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>-norm. This table presents different performance measures obtained when all the information sources and only the most relevant information sources for each algorithm are implemented. In this case, the table specifies the sources selected as relevant to represent the MRI sequences and also indicates the corresponding reduction rate. Additionally, <xref rid="sensors-20-03919-t005" ref-type="table">Table 5</xref> shows the time needed by the algorithm to complete the training stage of the global model and the prediction stage with the training and test data. The last column shows the number of training samples that were needed to build the global model (support vectors).</p><p>It is evident in <xref rid="sensors-20-03919-t005" ref-type="table">Table 5</xref> that identifying which information sources are relevant for the classification task can significantly improve its performance. Algorithm 2 also presents better performance than the other two algorithms, obtaining the best results in all the performance measures when source reduction was applied. Note the coincidence in the information sources selected as relevant by Algorithms 2 and 3, which show a very similar performance that is also better than that of Algorithm 1.</p><p><xref rid="sensors-20-03919-t006" ref-type="table">Table 6</xref> details the results obtained using the method with the <inline-formula><mml:math id="mm268"><mml:mrow><mml:msub><mml:mi>&#x02113;</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>-norm and only the information sources obtained from the generation of radiomic features on the MRI sequences. In this case, the reduction rate was considerably lower with all the algorithms compared to the previous table, but again the algorithms showed appropriate stability regarding the sources selected as relevant. In addition, Algorithms 2 and 3 present an advantage, especially because they considerably reduce the amount of data that they require for the construction of the final model.</p><p>Finally, the results in <xref rid="sensors-20-03919-t007" ref-type="table">Table 7</xref> take into account a higher number of information sources because they combine the sources obtained from the generation of perceptual and radiomic features. In this case, <xref rid="sensors-20-03919-t007" ref-type="table">Table 7</xref> shows very similar results with the three algorithms, a reduction rate of more than half of the information sources with all the algorithms, and an almost perfect match of the information sources selected as relevant. It is possible to identify highly relevant measures in the MRI sequences represented by subtractions in most tests, with both the perceptual and radiomic features.</p></sec><sec id="sec4dot3-sensors-20-03919"><title>4.3. Comparison against Feature Selection&#x000a0;Methods</title><p>The closest approaches to the automatic selection of sources using machine learning are the feature selection techniques developed in said research area [<xref rid="B64-sensors-20-03919" ref-type="bibr">64</xref>]. It is possible to associate the selection of information sources with the selection of features, considering that it is reasonable to select individual features hoping to eliminate all the features of one specific information source. Hence, the feature selection technique could eliminate the whole information source.</p><p>A new group of tests was performed based on the above and aims to evaluate the contribution of the proposed method to the objective selection of information sources provided for a binary classification task (compared to classical feature selection techniques). These tests consisted of two different experiments: (1) a feature selection process applied to all the information sources in order to automatically eliminate some of these sources if the feature selection process eliminated all the features that composed them; and (2) the application of the proposed method to reduce the number of information sources and the subsequent implementation of the feature selection technique for reducing the number of features that composed the relevant information sources.</p><p>The technique used to perform the feature selection process was the Fisher Score [<xref rid="B65-sensors-20-03919" ref-type="bibr">65</xref>]. This method is a supervised feature selection technique that seeks to preserve features that have a more uniform distribution in one class and a more dispersed one in the others. The Fisher Score method is represented by Equation (<xref ref-type="disp-formula" rid="FD13-sensors-20-03919">13</xref>).
<disp-formula id="FD13-sensors-20-03919"><label>(13)</label><mml:math id="mm269"><mml:mrow><mml:mrow><mml:mi>F</mml:mi><mml:mi>S</mml:mi><mml:mfenced separators="" open="(" close=")"><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>l</mml:mi></mml:msubsup><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:msup><mml:mfenced separators="" open="(" close=")"><mml:msub><mml:mi>&#x003bc;</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>&#x003bc;</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mfenced><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mrow><mml:mrow><mml:msubsup><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>l</mml:mi></mml:msubsup><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:mrow></mml:math></disp-formula>
where <italic>l</italic> is the number of classes; <inline-formula><mml:math id="mm270"><mml:mrow><mml:msub><mml:mi>&#x003bc;</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, the mean of the feature <inline-formula><mml:math id="mm271"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>; <inline-formula><mml:math id="mm272"><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, the number of samples in the <italic>j</italic>-th class; and <inline-formula><mml:math id="mm273"><mml:mrow><mml:msub><mml:mi>&#x003bc;</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm274"><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, the mean and the variance of <inline-formula><mml:math id="mm275"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> in the <italic>j</italic>-th class, respectively [<xref rid="B66-sensors-20-03919" ref-type="bibr">66</xref>].</p><p>Equation (<xref ref-type="disp-formula" rid="FD13-sensors-20-03919">13</xref>) is used to obtain a rank vector ordering the features from the most relevant to the least relevant. Once the features are ordered, they are eliminated one by one starting by the least relevant till identifying the number of features that generate the highest classification performance.</p><p>In the first experiment, the whole features extracted from all information sources are concatenated in a unique feature vector before applying the feature selection and source elimination process. Thus, the relevant information sources for the classification task will be those that retain at least one of its features in the set of features that reported the best performance. In the second experiment, the proposed source selection method is applied to find the most relevant information sources. Then, features extracted from these sources are concatenated in a unique feature vector, which is used as input to the feature selection process, in order to select the most discriminative features that improve the classification task. In this case, the relevant sources could also be reduced, by applying the same process described to the first experiment; however, all sources selected initially by the proposed approach were kept in the experiments performed in this work.</p><p><xref rid="sensors-20-03919-t008" ref-type="table">Table 8</xref> shows the results obtained with the BCI dataset. The left side of the table groups the results of the first experiment; the right side, those of the second experiment. It can be seen that the feature selection technique improves the performance of the classifier and manages to eliminate some information sources for some subjects by itself in some cases. However, in most cases, it cannot reduce the number of information sources, even with a considerable reduction in the number of features. On the other hand, the right side of the table shows that the proposed method manages to reduce the number of information sources for all the subjects with the three proposed algorithms and, at the same time, maintains high performance in the classification task. These results also indicate that the proposed method can be used to reduce the number of information sources and, after that, a feature selection technique can be applied to reduce the number of features; the objective is to achieve the best results in terms of the highest performance with minimum data quantity.</p><p><xref rid="sensors-20-03919-t009" ref-type="table">Table 9</xref> shows the results obtained with the MRI dataset. The results of the first experiment of tests are on the left side; and those of the second experiment, on the right side. It is essential to highlight that the tests achieved the highest performance regarding the classification task when only the feature selection technique was applied, but in this case the task required the use of all the information sources, missing the main objective of the tests. Conversely, the results on the right side of the table show that the proposed algorithm maintained a high performance during all the tests while it eliminated some information sources (more than half in most tests), successfully achieving the proposed objective.</p><p>The sources selected as relevant during this group of tests were the same as those presented in the results in <xref ref-type="sec" rid="sec4dot1-sensors-20-03919">Section 4.1</xref> and <xref ref-type="sec" rid="sec4dot2-sensors-20-03919">Section 4.2</xref>, which again highlights the stability of the proposed method regarding the objective selection of relevant information sources. Moreover, additional tests were conducted to consider the application of the feature selection technique before reducing the information sources following the structure of tests carried out in some studies in the literature. However, the results of those tests are not reported in this paper because they exhibited the same behavior regarding the information sources selected as relevant and the performance measures they achieved, confirming the stability of the proposed algorithm remains in all the evaluation environments considered here.</p></sec></sec><sec sec-type="conclusions" id="sec5-sensors-20-03919"><title>5. Conclusions</title><p>This work proposes an automatic method that implements different types of machine learning algorithms to objectively select the most relevant information sources in a classification task. The proposed method computes a Gaussian kernel for each information source, performing the tuning of the kernel parameters by using the local scaling technique. This technique was adapted through three different algorithms to be used during the prediction stage in the supervised classification task implemented over an SVM. Algorithm 1 uses all the training samples to compute the kernel bandwidth parameter (<inline-formula><mml:math id="mm276"><mml:mrow><mml:mi>&#x003c3;</mml:mi></mml:mrow></mml:math></inline-formula>) corresponding to each prediction sample. Algorithm 2 uses only the SVM support vectors to determine the <inline-formula><mml:math id="mm277"><mml:mrow><mml:mi>&#x003c3;</mml:mi></mml:mrow></mml:math></inline-formula>, thus reducing the amount of information required by the trained model. In contrast, Algorithm 3 collects the neighborhood information of the support vectors to estimate the <inline-formula><mml:math id="mm278"><mml:mrow><mml:mi>&#x003c3;</mml:mi></mml:mrow></mml:math></inline-formula> value of each prediction sample, attempting to keep the information of training samples that are not selected as support vectors while reducing the information required by the trained model.</p><p>Two real application tasks were used to evaluate the proposed method: the selection of electrodes for a classification task in Brain&#x02013;Computer Interface (BCI) systems and the selection of relevant Magnetic Resonance Imaging (MRI) sequences for detection of breast cancer. The obtained results show that the proposed method is stable regarding the sources which are selected as relevant, even when the results are analyzed among the three proposed algorithms. Although the three algorithms presented similar performances and fulfilled the expected function of source selection, it is possible to find a relatively superior performance of Algorithm 2 when using the <inline-formula><mml:math id="mm279"><mml:mrow><mml:msub><mml:mi>&#x02113;</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>-norm and likewise, a leading behavior of Algorithm 3 when using the <inline-formula><mml:math id="mm280"><mml:mrow><mml:msub><mml:mi>&#x02113;</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>-norm. These two algorithms have the particular advantage of reducing the number of samples required to build the trained model since they only require the information of the samples selected by the SVM as support vectors.</p></sec></body><back><ack><title>Acknowledgments</title><p>We would like to acknowledge to the staff of the MIRP laboratory and the IATM Research Group for its technical support in the MRI image database generation.</p></ack><notes><title>Author Contributions</title><p>The work was performed with the substantial contribution of all the authors. H.J.A.-L. carried out the research study, implemented the algorithms, performed the experimentation and wrote the first draft-manuscript; G.M.D., M.L.H., and A.E.C.-O. conceived the project; H.J.A.-L., A.E.C.-O., and G.M.D. conceived and designed the experiments; M.L.H. has contributed to image analysis and interpretation. All authors have contributed to the preparation of the paper, the discussing of the results and the reviewing of the content of this article. All authors have read and agreed to the published version of the manuscript</p></notes><notes><title>Funding</title><p>This research was funded by MinCiencias (Colombia), Instituto Tecnol&#x000f3;gico Metropolitano, and Ayudas Diagn&#x000f3;sticas Sura. Project RC740-2017.</p></notes><notes notes-type="COI-statement"><title>Conflicts of Interest</title><p>The authors declare no conflict of interest.</p></notes><ref-list><title>References</title><ref id="B1-sensors-20-03919"><label>1.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Culache</surname><given-names>O.</given-names></name><name><surname>Obad&#x00103;</surname><given-names>D.R.</given-names></name></person-group><article-title>Multimodality as a Premise for Inducing Online Flow on a Brand Website: A Social Semiotic Approach</article-title><source>Procedia-Soc. Behav. Sci.</source><year>2014</year><volume>149</volume><fpage>261</fpage><lpage>268</lpage><pub-id pub-id-type="doi">10.1016/j.sbspro.2014.08.227</pub-id></element-citation></ref><ref id="B2-sensors-20-03919"><label>2.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Markonis</surname><given-names>D.</given-names></name><name><surname>Schaer</surname><given-names>R.</given-names></name><name><surname>M&#x000fc;ller</surname><given-names>H.</given-names></name></person-group><article-title>Evaluating multimodal relevance feedback techniques for medical image retrieval</article-title><source>Inf. Retr. J.</source><year>2016</year><volume>19</volume><fpage>100</fpage><lpage>112</lpage><pub-id pub-id-type="doi">10.1007/s10791-015-9260-4</pub-id></element-citation></ref><ref id="B3-sensors-20-03919"><label>3.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Adali</surname><given-names>T.</given-names></name><name><surname>Levin-Schwartz</surname><given-names>Y.</given-names></name><name><surname>Calhoun</surname><given-names>V.D.</given-names></name></person-group><article-title>Multimodal data fusion using source separation: Application to medical imaging</article-title><source>Proc. IEEE</source><year>2015</year><volume>103</volume><fpage>1494</fpage><lpage>1506</lpage><pub-id pub-id-type="doi">10.1109/JPROC.2015.2461601</pub-id></element-citation></ref><ref id="B4-sensors-20-03919"><label>4.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Correa</surname><given-names>A.G.</given-names></name><name><surname>Orosco</surname><given-names>L.</given-names></name><name><surname>Laciar</surname><given-names>E.</given-names></name></person-group><article-title>Automatic detection of drowsiness in EEG records based on multimodal analysis</article-title><source>Med. Eng. Phys.</source><year>2014</year><volume>36</volume><fpage>244</fpage><lpage>249</lpage><pub-id pub-id-type="doi">10.1016/j.medengphy.2013.07.011</pub-id><pub-id pub-id-type="pmid">23972332</pub-id></element-citation></ref><ref id="B5-sensors-20-03919"><label>5.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>Z.</given-names></name><name><surname>Yin</surname><given-names>H.</given-names></name><name><surname>Chai</surname><given-names>Y.</given-names></name><name><surname>Yang</surname><given-names>S.X.</given-names></name></person-group><article-title>A novel approach for multimodal medical image fusion</article-title><source>Expert Syst. Appl.</source><year>2014</year><volume>41</volume><fpage>7425</fpage><lpage>7435</lpage><pub-id pub-id-type="doi">10.1016/j.eswa.2014.05.043</pub-id></element-citation></ref><ref id="B6-sensors-20-03919"><label>6.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Barachant</surname><given-names>A.</given-names></name><name><surname>Bonnet</surname><given-names>S.</given-names></name></person-group><article-title>Channel selection procedure using Riemannian distance for BCI applications</article-title><source>Proceedings of the 2011 5th International IEEE/EMBS Conference on Neural Engineering</source><conf-loc>Cancun, Mexico</conf-loc><conf-date>27 April&#x02013;1 May 2011</conf-date><fpage>348</fpage><lpage>351</lpage></element-citation></ref><ref id="B7-sensors-20-03919"><label>7.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eliseyev</surname><given-names>A.</given-names></name><name><surname>Moro</surname><given-names>C.</given-names></name><name><surname>Faber</surname><given-names>J.</given-names></name><name><surname>Wyss</surname><given-names>A.</given-names></name><name><surname>Torres</surname><given-names>N.</given-names></name><name><surname>Mestais</surname><given-names>C.</given-names></name><name><surname>Benabid</surname><given-names>A.L.</given-names></name><name><surname>Aksenova</surname><given-names>T.</given-names></name></person-group><article-title>L1-penalized N-way PLS for subset of electrodes selection in BCI experiments</article-title><source>J. Neural Eng.</source><year>2012</year><volume>9</volume><fpage>045010</fpage><pub-id pub-id-type="doi">10.1088/1741-2560/9/4/045010</pub-id><pub-id pub-id-type="pmid">22832155</pub-id></element-citation></ref><ref id="B8-sensors-20-03919"><label>8.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meyer</surname><given-names>J.S.</given-names></name><name><surname>Siegel</surname><given-names>M.J.</given-names></name><name><surname>Farooqui</surname><given-names>S.O.</given-names></name><name><surname>Jaramillo</surname><given-names>D.</given-names></name><name><surname>Fletcher</surname><given-names>B.D.</given-names></name><name><surname>Hoffer</surname><given-names>F.A.</given-names></name></person-group><article-title>Which MRI sequence of the spine best reveals bone-marrow metastases of neuroblastoma?</article-title><source>Pediatr. Radiol.</source><year>2005</year><volume>35</volume><fpage>778</fpage><lpage>785</lpage><pub-id pub-id-type="doi">10.1007/s00247-005-1470-2</pub-id><pub-id pub-id-type="pmid">15883828</pub-id></element-citation></ref><ref id="B9-sensors-20-03919"><label>9.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>J.</given-names></name><name><surname>Cheng</surname><given-names>K.</given-names></name><name><surname>Wang</surname><given-names>S.</given-names></name><name><surname>Morstatter</surname><given-names>F.</given-names></name><name><surname>Trevino</surname><given-names>R.P.</given-names></name><name><surname>Tang</surname><given-names>J.</given-names></name><name><surname>Liu</surname><given-names>H.</given-names></name></person-group><article-title>Feature selection: A data perspective</article-title><source>ACM Comput. Surv. (CSUR)</source><year>2017</year><volume>50</volume><fpage>94</fpage><pub-id pub-id-type="doi">10.1145/3136625</pub-id></element-citation></ref><ref id="B10-sensors-20-03919"><label>10.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gan</surname><given-names>G.</given-names></name><name><surname>Ng</surname><given-names>M.K.P.</given-names></name></person-group><article-title>Subspace clustering with automatic feature grouping</article-title><source>Pattern Recognit.</source><year>2015</year><volume>48</volume><fpage>3703</fpage><lpage>3713</lpage><pub-id pub-id-type="doi">10.1016/j.patcog.2015.05.016</pub-id></element-citation></ref><ref id="B11-sensors-20-03919"><label>11.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Pir</surname><given-names>D.</given-names></name><name><surname>Brown</surname><given-names>T.</given-names></name></person-group><article-title>Acoustic Group Feature Selection Using Wrapper Method for Automatic Eating Condition Recognition</article-title><source>Proceedings of the Sixteenth Annual Conference of the International Speech Communication Association</source><conf-loc>Dresden, Germany</conf-loc><conf-date>6&#x02013;10 September 2015</conf-date></element-citation></ref><ref id="B12-sensors-20-03919"><label>12.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lal</surname><given-names>T.N.</given-names></name><name><surname>Schroder</surname><given-names>M.</given-names></name><name><surname>Hinterberger</surname><given-names>T.</given-names></name><name><surname>Weston</surname><given-names>J.</given-names></name><name><surname>Bogdan</surname><given-names>M.</given-names></name><name><surname>Birbaumer</surname><given-names>N.</given-names></name><name><surname>Scholkopf</surname><given-names>B.</given-names></name></person-group><article-title>Support vector channel selection in BCI</article-title><source>IEEE Trans. Biomed. Eng.</source><year>2004</year><volume>51</volume><fpage>1003</fpage><lpage>1010</lpage><pub-id pub-id-type="doi">10.1109/TBME.2004.827827</pub-id><pub-id pub-id-type="pmid">15188871</pub-id></element-citation></ref><ref id="B13-sensors-20-03919"><label>13.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sotoca</surname><given-names>J.M.</given-names></name><name><surname>Pla</surname><given-names>F.</given-names></name><name><surname>Sanchez</surname><given-names>J.S.</given-names></name></person-group><article-title>Band selection in multispectral images by minimization of dependent information</article-title><source>IEEE Trans. Syst. Man Cybern. Part C</source><year>2007</year><volume>37</volume><fpage>258</fpage><lpage>267</lpage><pub-id pub-id-type="doi">10.1109/TSMCC.2006.876055</pub-id></element-citation></ref><ref id="B14-sensors-20-03919"><label>14.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Xiang</surname><given-names>S.</given-names></name><name><surname>Yang</surname><given-names>T.</given-names></name><name><surname>Ye</surname><given-names>J.</given-names></name></person-group><article-title>Simultaneous feature and feature group selection through hard thresholding</article-title><source>Proceedings of the 20th ACM SIGKDD International Conference On Knowledge Discovery and Data Mining</source><conf-loc>New York, NY, USA</conf-loc><conf-date>24&#x02013;27 August 2014</conf-date><fpage>532</fpage><lpage>541</lpage></element-citation></ref><ref id="B15-sensors-20-03919"><label>15.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schmidt</surname><given-names>M.</given-names></name></person-group><article-title>Least squares optimization with L1-norm regularization</article-title><source>CS542B Proj. Rep.</source><year>2005</year><volume>504</volume><fpage>195</fpage><lpage>221</lpage></element-citation></ref><ref id="B16-sensors-20-03919"><label>16.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Subrahmanya</surname><given-names>N.</given-names></name><name><surname>Shin</surname><given-names>Y.C.</given-names></name></person-group><article-title>Automated sensor selection and fusion for monitoring and diagnostics of plunge grinding</article-title><source>J. Manuf. Sci. Eng.</source><year>2008</year><volume>130</volume><fpage>031014</fpage><pub-id pub-id-type="doi">10.1115/1.2927439</pub-id></element-citation></ref><ref id="B17-sensors-20-03919"><label>17.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Raza</surname><given-names>H.</given-names></name><name><surname>Cecotti</surname><given-names>H.</given-names></name><name><surname>Prasad</surname><given-names>G.</given-names></name></person-group><article-title>Optimising frequency band selection with forward-addition and backward-elimination algorithms in EEG-based brain-computer interfaces</article-title><source>Proceedings of the 2015 International Joint Conference on Neural Networks (IJCNN)</source><conf-loc>Killarney, Ireland</conf-loc><conf-date>12&#x02013;17 July 2015</conf-date><fpage>1</fpage><lpage>7</lpage></element-citation></ref><ref id="B18-sensors-20-03919"><label>18.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>Y.</given-names></name><name><surname>Wu</surname><given-names>F.X.</given-names></name><name><surname>Ngom</surname><given-names>A.</given-names></name></person-group><article-title>A review on machine learning principles for multi-view biological data integration</article-title><source>Briefings Bioinform.</source><year>2016</year><volume>19</volume><fpage>325</fpage><lpage>340</lpage><pub-id pub-id-type="doi">10.1093/bib/bbw113</pub-id><pub-id pub-id-type="pmid">28011753</pub-id></element-citation></ref><ref id="B19-sensors-20-03919"><label>19.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ren</surname><given-names>Y.</given-names></name><name><surname>Zhang</surname><given-names>L.</given-names></name><name><surname>Suganthan</surname><given-names>P.N.</given-names></name></person-group><article-title>Ensemble classification and regression-recent developments, applications and future directions</article-title><source>IEEE Comput. Intell. Mag.</source><year>2016</year><volume>11</volume><fpage>41</fpage><lpage>53</lpage><pub-id pub-id-type="doi">10.1109/MCI.2015.2471235</pub-id></element-citation></ref><ref id="B20-sensors-20-03919"><label>20.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gu</surname><given-names>Y.</given-names></name><name><surname>Liu</surname><given-names>T.</given-names></name><name><surname>Jia</surname><given-names>X.</given-names></name><name><surname>Benediktsson</surname><given-names>J.A.</given-names></name><name><surname>Chanussot</surname><given-names>J.</given-names></name></person-group><article-title>Nonlinear multiple kernel learning with multiple-structure-element extended morphological profiles for hyperspectral image classification</article-title><source>IEEE Trans. Geosci. Remote Sens.</source><year>2016</year><volume>54</volume><fpage>3235</fpage><lpage>3247</lpage><pub-id pub-id-type="doi">10.1109/TGRS.2015.2514161</pub-id></element-citation></ref><ref id="B21-sensors-20-03919"><label>21.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Althloothi</surname><given-names>S.</given-names></name><name><surname>Mahoor</surname><given-names>M.H.</given-names></name><name><surname>Zhang</surname><given-names>X.</given-names></name><name><surname>Voyles</surname><given-names>R.M.</given-names></name></person-group><article-title>Human activity recognition using multi-features and multiple kernel learning</article-title><source>Pattern Recognit.</source><year>2014</year><volume>47</volume><fpage>1800</fpage><lpage>1812</lpage><pub-id pub-id-type="doi">10.1016/j.patcog.2013.11.032</pub-id></element-citation></ref><ref id="B22-sensors-20-03919"><label>22.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xu</surname><given-names>C.</given-names></name><name><surname>Tao</surname><given-names>D.</given-names></name><name><surname>Xu</surname><given-names>C.</given-names></name></person-group><article-title>A survey on multi-view learning</article-title><source>arXiv</source><year>2013</year><pub-id pub-id-type="arxiv">1304.5634</pub-id></element-citation></ref><ref id="B23-sensors-20-03919"><label>23.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Qiu</surname><given-names>S.</given-names></name><name><surname>Lane</surname><given-names>T.</given-names></name></person-group><article-title>A framework for multiple kernel support vector regression and its applications to siRNA efficacy prediction</article-title><source>IEEE/ACM Trans. Comput. Biol. Bioinform. (TCBB)</source><year>2009</year><volume>6</volume><fpage>190</fpage><lpage>199</lpage></element-citation></ref><ref id="B24-sensors-20-03919"><label>24.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>G&#x000f6;nen</surname><given-names>M.</given-names></name><name><surname>Margolin</surname><given-names>A.A.</given-names></name></person-group><article-title>Localized data fusion for kernel k-means clustering with application to cancer biology</article-title><source>Proceedings of the Advances in Neural Information Processing Systems</source><conf-loc>Montreal, QC, Canada</conf-loc><conf-date>8&#x02013;13 December 2014</conf-date><fpage>1305</fpage><lpage>1313</lpage></element-citation></ref><ref id="B25-sensors-20-03919"><label>25.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>G&#x000f6;nen</surname><given-names>M.</given-names></name><name><surname>Alpayd&#x00131;n</surname><given-names>E.</given-names></name></person-group><article-title>Multiple kernel learning algorithms</article-title><source>J. Mach. Learn. Res.</source><year>2011</year><volume>12</volume><fpage>2211</fpage><lpage>2268</lpage></element-citation></ref><ref id="B26-sensors-20-03919"><label>26.</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Lanckriet</surname><given-names>G.R.</given-names></name><name><surname>Deng</surname><given-names>M.</given-names></name><name><surname>Cristianini</surname><given-names>N.</given-names></name><name><surname>Jordan</surname><given-names>M.I.</given-names></name><name><surname>Noble</surname><given-names>W.S.</given-names></name></person-group><article-title>Kernel-based data fusion and its application to protein function prediction in yeast</article-title><source>Biocomputing 2004</source><publisher-name>World Scientific</publisher-name><publisher-loc>Singapore</publisher-loc><year>2003</year><fpage>300</fpage><lpage>311</lpage></element-citation></ref><ref id="B27-sensors-20-03919"><label>27.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lewis</surname><given-names>D.P.</given-names></name><name><surname>Jebara</surname><given-names>T.</given-names></name><name><surname>Noble</surname><given-names>W.S.</given-names></name></person-group><article-title>Support vector machine learning from heterogeneous data: An empirical analysis using protein sequence and structure</article-title><source>Bioinformatics</source><year>2006</year><volume>22</volume><fpage>2753</fpage><lpage>2760</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btl475</pub-id><pub-id pub-id-type="pmid">16966363</pub-id></element-citation></ref><ref id="B28-sensors-20-03919"><label>28.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Foresti</surname><given-names>L.</given-names></name><name><surname>Tuia</surname><given-names>D.</given-names></name><name><surname>Timonin</surname><given-names>V.</given-names></name><name><surname>Kanevski</surname><given-names>M.F.</given-names></name></person-group><article-title>Time series input selection using multiple kernel learning</article-title><source>Proceedings of the 18th European Symposium on Artificial Neural Networks, ESANN</source><conf-loc>Bruges, Belgium</conf-loc><conf-date>28&#x02013;30 April 2010</conf-date></element-citation></ref><ref id="B29-sensors-20-03919"><label>29.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tuia</surname><given-names>D.</given-names></name><name><surname>Camps-Valls</surname><given-names>G.</given-names></name><name><surname>Matasci</surname><given-names>G.</given-names></name><name><surname>Kanevski</surname><given-names>M.</given-names></name></person-group><article-title>Learning relevant image features with multiple-kernel classification</article-title><source>IEEE Trans. Geosci. Remote Sens.</source><year>2010</year><volume>48</volume><fpage>3780</fpage><lpage>3791</lpage><pub-id pub-id-type="doi">10.1109/TGRS.2010.2049496</pub-id></element-citation></ref><ref id="B30-sensors-20-03919"><label>30.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Subrahmanya</surname><given-names>N.</given-names></name><name><surname>Shin</surname><given-names>Y.C.</given-names></name></person-group><article-title>Sparse multiple kernel learning for signal processing applications</article-title><source>IEEE Trans. Pattern Anal. Mach. Intell.</source><year>2010</year><volume>32</volume><fpage>788</fpage><pub-id pub-id-type="doi">10.1109/TPAMI.2009.98</pub-id><pub-id pub-id-type="pmid">20299705</pub-id></element-citation></ref><ref id="B31-sensors-20-03919"><label>31.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>G&#x000f6;nen</surname><given-names>M.</given-names></name></person-group><article-title>Bayesian efficient multiple kernel learning</article-title><source>arXiv</source><year>2012</year><pub-id pub-id-type="arxiv">1206.6465</pub-id></element-citation></ref><ref id="B32-sensors-20-03919"><label>32.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Zelnik-Manor</surname><given-names>L.</given-names></name><name><surname>Perona</surname><given-names>P.</given-names></name></person-group><article-title>Self-tuning spectral clustering</article-title><source>Proceedings of the Advances in Neural Information Processing Systems</source><conf-loc>Vancouver, BC, Canada</conf-loc><conf-date>5&#x02013;8 December 2005</conf-date><fpage>1601</fpage><lpage>1608</lpage></element-citation></ref><ref id="B33-sensors-20-03919"><label>33.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>L.</given-names></name><name><surname>Hu</surname><given-names>X.</given-names></name></person-group><article-title>Locally adaptive multiple kernel clustering</article-title><source>Neurocomputing</source><year>2014</year><volume>137</volume><fpage>192</fpage><lpage>197</lpage><pub-id pub-id-type="doi">10.1016/j.neucom.2013.05.064</pub-id></element-citation></ref><ref id="B34-sensors-20-03919"><label>34.</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Vapnik</surname><given-names>V.</given-names></name></person-group><source>The Nature of Statistical Learning Theory</source><publisher-name>Springer</publisher-name><publisher-loc>New York, NY, USA</publisher-loc><year>1999</year></element-citation></ref><ref id="B35-sensors-20-03919"><label>35.</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Cristianini</surname><given-names>N.</given-names></name><name><surname>Shawe-Taylor</surname><given-names>J.</given-names></name></person-group><source>An Introduction to Support Vector Machines and Other Kernel-Based Learning Methods</source><publisher-name>Cambridge University Press</publisher-name><publisher-loc>Cambridge, UK</publisher-loc><year>2000</year></element-citation></ref><ref id="B36-sensors-20-03919"><label>36.</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Sch&#x000f6;lkopf</surname><given-names>B.</given-names></name><name><surname>Smola</surname><given-names>A.J.</given-names></name></person-group><source>Learning with Kernels: Support Vector Machines, Regularization, Optimization, and Beyond</source><publisher-name>MIT Press</publisher-name><publisher-loc>Cambridge, MA, USA</publisher-loc><year>2002</year></element-citation></ref><ref id="B37-sensors-20-03919"><label>37.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fan</surname><given-names>R.E.</given-names></name><name><surname>Chen</surname><given-names>P.H.</given-names></name><name><surname>Lin</surname><given-names>C.J.</given-names></name></person-group><article-title>Working set selection using second order information for training support vector machines</article-title><source>J. Mach. Learn. Res.</source><year>2005</year><volume>6</volume><fpage>1889</fpage><lpage>1918</lpage></element-citation></ref><ref id="B38-sensors-20-03919"><label>38.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chang</surname><given-names>C.C.</given-names></name><name><surname>Lin</surname><given-names>C.J.</given-names></name></person-group><article-title>LIBSVM: A library for support vector machines</article-title><source>ACM Trans. Intell. Syst. Technol.</source><year>2011</year><volume>2</volume><fpage>27:1</fpage><lpage>27:27</lpage><pub-id pub-id-type="doi">10.1145/1961189.1961199</pub-id></element-citation></ref><ref id="B39-sensors-20-03919"><label>39.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Lessmann</surname><given-names>S.</given-names></name><name><surname>Stahlbock</surname><given-names>R.</given-names></name><name><surname>Crone</surname><given-names>S.F.</given-names></name></person-group><article-title>Genetic algorithms for support vector machine model selection</article-title><source>Proceedings of the 2006 IEEE International Joint Conference on Neural Network Proceedings</source><conf-loc>Vancouver, BC, Canada</conf-loc><conf-date>16&#x02013;21 July 2006</conf-date><fpage>3063</fpage><lpage>3069</lpage></element-citation></ref><ref id="B40-sensors-20-03919"><label>40.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gomes</surname><given-names>T.A.</given-names></name><name><surname>Prud&#x000ea;ncio</surname><given-names>R.B.</given-names></name><name><surname>Soares</surname><given-names>C.</given-names></name><name><surname>Rossi</surname><given-names>A.L.</given-names></name><name><surname>Carvalho</surname><given-names>A.</given-names></name></person-group><article-title>Combining meta-learning and search techniques to select parameters for support vector machines</article-title><source>Neurocomputing</source><year>2012</year><volume>75</volume><fpage>3</fpage><lpage>13</lpage><pub-id pub-id-type="doi">10.1016/j.neucom.2011.07.005</pub-id></element-citation></ref><ref id="B41-sensors-20-03919"><label>41.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>J.</given-names></name><name><surname>Zio</surname><given-names>E.</given-names></name></person-group><article-title>SVM hyperparameters tuning for recursive multi-step-ahead prediction</article-title><source>Neural Comput. Appl.</source><year>2017</year><volume>28</volume><fpage>3749</fpage><lpage>3763</lpage><pub-id pub-id-type="doi">10.1007/s00521-016-2272-1</pub-id></element-citation></ref><ref id="B42-sensors-20-03919"><label>42.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Xu</surname><given-names>Z.</given-names></name><name><surname>Jin</surname><given-names>R.</given-names></name><name><surname>Yang</surname><given-names>H.</given-names></name><name><surname>King</surname><given-names>I.</given-names></name><name><surname>Lyu</surname><given-names>M.R.</given-names></name></person-group><article-title>Simple and efficient multiple kernel learning by group lasso</article-title><source>Proceedings of the 27th international conference on machine learning (ICML-10)</source><conf-loc>Haifa, Israel</conf-loc><conf-date>21&#x02013;24 June 2010</conf-date><fpage>1175</fpage><lpage>1182</lpage></element-citation></ref><ref id="B43-sensors-20-03919"><label>43.</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Areiza-Laverde</surname><given-names>H.J.</given-names></name><name><surname>D&#x000ed;az</surname><given-names>G.M.</given-names></name><name><surname>Castro-Ospina</surname><given-names>A.E.</given-names></name></person-group><article-title>Feature Group Selection Using MKL Penalized with <italic>&#x02113;</italic><sub>1</sub>-norm and SVM as Base Learner</article-title><source>International Workshop on Experimental and Efficient Algorithms</source><publisher-name>Springer International Publishing</publisher-name><publisher-loc>Cham, Switzerland</publisher-loc><year>2018</year><fpage>136</fpage><lpage>147</lpage></element-citation></ref><ref id="B44-sensors-20-03919"><label>44.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>G&#x000f6;nen</surname><given-names>G.B.</given-names></name><name><surname>G&#x000f6;nen</surname><given-names>M.</given-names></name><name><surname>G&#x000fc;rgen</surname><given-names>F.</given-names></name></person-group><article-title>Probabilistic and discriminative group-wise feature selection methods for credit risk analysis</article-title><source>Expert Syst. Appl.</source><year>2012</year><volume>39</volume><fpage>11709</fpage><lpage>11717</lpage><pub-id pub-id-type="doi">10.1016/j.eswa.2012.04.050</pub-id></element-citation></ref><ref id="B45-sensors-20-03919"><label>45.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kloft</surname><given-names>M.</given-names></name><name><surname>Brefeld</surname><given-names>U.</given-names></name><name><surname>Sonnenburg</surname><given-names>S.</given-names></name><name><surname>Zien</surname><given-names>A.</given-names></name></person-group><article-title>Non-sparse regularization and efficient training with multiple kernels</article-title><source>arXiv</source><year>2010</year><pub-id pub-id-type="arxiv">1003.0079</pub-id></element-citation></ref><ref id="B46-sensors-20-03919"><label>46.</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Brunner</surname><given-names>C.</given-names></name><name><surname>Leeb</surname><given-names>R.</given-names></name><name><surname>M&#x000fc;ller-Putz</surname><given-names>G.</given-names></name><name><surname>Schl&#x000f6;gl</surname><given-names>A.</given-names></name><name><surname>Pfurtscheller</surname><given-names>G.</given-names></name></person-group><source>BCI Competition 2008&#x02013;Graz Data Set A</source><publisher-name>Institute for Knowledge Discovery (Laboratory of Brain-Computer Interfaces), Graz University of Technology</publisher-name><publisher-loc>Graz, Austria</publisher-loc><year>2008</year><volume>Volume 16</volume></element-citation></ref><ref id="B47-sensors-20-03919"><label>47.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Subasi</surname><given-names>A.</given-names></name></person-group><article-title>Automatic recognition of alertness level from EEG by using neural network and wavelet coefficients</article-title><source>Expert Syst. Appl.</source><year>2005</year><volume>28</volume><fpage>701</fpage><lpage>711</lpage><pub-id pub-id-type="doi">10.1016/j.eswa.2004.12.027</pub-id></element-citation></ref><ref id="B48-sensors-20-03919"><label>48.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>Y.</given-names></name><name><surname>Long</surname><given-names>J.</given-names></name><name><surname>Yu</surname><given-names>T.</given-names></name><name><surname>Yu</surname><given-names>Z.</given-names></name><name><surname>Wang</surname><given-names>C.</given-names></name><name><surname>Zhang</surname><given-names>H.</given-names></name><name><surname>Guan</surname><given-names>C.</given-names></name></person-group><article-title>An EEG-based BCI system for 2-D cursor control by combining Mu/Beta rhythm and P300 potential</article-title><source>IEEE Trans. Biomed. Eng.</source><year>2010</year><volume>57</volume><fpage>2495</fpage><lpage>2505</lpage><pub-id pub-id-type="doi">10.1109/TBME.2010.2055564</pub-id><pub-id pub-id-type="pmid">20615806</pub-id></element-citation></ref><ref id="B49-sensors-20-03919"><label>49.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Mar&#x00131;n-Castrill&#x000f3;n</surname><given-names>D.</given-names></name><name><surname>Restrepo-Agudelo</surname><given-names>S.</given-names></name><name><surname>Areiza-Laverde</surname><given-names>H.</given-names></name><name><surname>Castro-Ospina</surname><given-names>A.</given-names></name><name><surname>Duque-Munoz</surname><given-names>L.</given-names></name></person-group><article-title>Exploratory Analysis of Motor Imagery local database for BCI systems</article-title><source>Proceedings of the I Congreso Internacional de Ciencias B&#x000e1;sicas e Ingenier&#x000ed;a&#x02014;CICI 2016</source><conf-loc>Meta, Colombia</conf-loc><conf-date>19&#x02013;21 October 2016</conf-date></element-citation></ref><ref id="B50-sensors-20-03919"><label>50.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Amin</surname><given-names>H.U.</given-names></name><name><surname>Malik</surname><given-names>A.S.</given-names></name><name><surname>Ahmad</surname><given-names>R.F.</given-names></name><name><surname>Badruddin</surname><given-names>N.</given-names></name><name><surname>Kamel</surname><given-names>N.</given-names></name><name><surname>Hussain</surname><given-names>M.</given-names></name><name><surname>Chooi</surname><given-names>W.T.</given-names></name></person-group><article-title>Feature extraction and classification for EEG signals using wavelet transform and machine learning techniques</article-title><source>Australas. Phys. Eng. Sci. Med.</source><year>2015</year><volume>38</volume><fpage>139</fpage><lpage>149</lpage><pub-id pub-id-type="doi">10.1007/s13246-015-0333-x</pub-id><pub-id pub-id-type="pmid">25649845</pub-id></element-citation></ref><ref id="B51-sensors-20-03919"><label>51.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ghaemi</surname><given-names>A.</given-names></name><name><surname>Rashedi</surname><given-names>E.</given-names></name><name><surname>Pourrahimi</surname><given-names>A.M.</given-names></name><name><surname>Kamandar</surname><given-names>M.</given-names></name><name><surname>Rahdari</surname><given-names>F.</given-names></name></person-group><article-title>Automatic channel selection in EEG signals for classification of left or right hand movement in Brain Computer Interfaces using improved binary gravitation search algorithm</article-title><source>Biomed. Signal Process. Control.</source><year>2017</year><volume>33</volume><fpage>109</fpage><lpage>118</lpage><pub-id pub-id-type="doi">10.1016/j.bspc.2016.11.018</pub-id></element-citation></ref><ref id="B52-sensors-20-03919"><label>52.</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Haacke</surname><given-names>E.M.</given-names></name><name><surname>Brown</surname><given-names>R.W.</given-names></name><name><surname>Thompson</surname><given-names>M.R.</given-names></name><name><surname>Venkatesan</surname><given-names>R.</given-names></name></person-group><source>Magnetic Resonance Imaging: Physical Principles and Sequence Design</source><publisher-name>Wiley-Liss New York</publisher-name><publisher-loc>New York, NY, USA</publisher-loc><year>1999</year><volume>Volume 82</volume></element-citation></ref><ref id="B53-sensors-20-03919"><label>53.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liberman</surname><given-names>L.</given-names></name><name><surname>Menell</surname><given-names>J.H.</given-names></name></person-group><article-title>Breast imaging reporting and data system (BI-RADS)</article-title><source>Radiol. Clin.</source><year>2002</year><volume>40</volume><fpage>409</fpage><lpage>430</lpage><pub-id pub-id-type="doi">10.1016/S0033-8389(01)00017-3</pub-id></element-citation></ref><ref id="B54-sensors-20-03919"><label>54.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Borji</surname><given-names>A.</given-names></name><name><surname>Sihite</surname><given-names>D.N.</given-names></name><name><surname>Itti</surname><given-names>L.</given-names></name></person-group><article-title>Quantitative analysis of human-model agreement in visual saliency modeling: A comparative study</article-title><source>IEEE Trans. Image Process.</source><year>2013</year><volume>22</volume><fpage>55</fpage><lpage>69</lpage><pub-id pub-id-type="doi">10.1109/TIP.2012.2210727</pub-id><pub-id pub-id-type="pmid">22868572</pub-id></element-citation></ref><ref id="B55-sensors-20-03919"><label>55.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shaikh</surname><given-names>F.A.</given-names></name><name><surname>Kolowitz</surname><given-names>B.J.</given-names></name><name><surname>Awan</surname><given-names>O.</given-names></name><name><surname>Aerts</surname><given-names>H.J.</given-names></name><name><surname>von Reden</surname><given-names>A.</given-names></name><name><surname>Halabi</surname><given-names>S.</given-names></name><name><surname>Mohiuddin</surname><given-names>S.A.</given-names></name><name><surname>Malik</surname><given-names>S.</given-names></name><name><surname>Shrestha</surname><given-names>R.B.</given-names></name><name><surname>Deible</surname><given-names>C.</given-names></name></person-group><article-title>Technical challenges in the clinical application of radiomics</article-title><source>JCO Clin. Cancer Inform.</source><year>2017</year><volume>1</volume><fpage>1</fpage><lpage>8</lpage><pub-id pub-id-type="doi">10.1200/CCI.17.00004</pub-id></element-citation></ref><ref id="B56-sensors-20-03919"><label>56.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Harel</surname><given-names>J.</given-names></name><name><surname>Koch</surname><given-names>C.</given-names></name><name><surname>Perona</surname><given-names>P.</given-names></name></person-group><article-title>Graph-based visual saliency</article-title><source>Proceedings of the Advances in Neural Information Processing Systems</source><conf-loc>Vancouver, BC, Canada</conf-loc><conf-date>3&#x02013;6 December 2007</conf-date><fpage>545</fpage><lpage>552</lpage></element-citation></ref><ref id="B57-sensors-20-03919"><label>57.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Areiza-Laverde</surname><given-names>H.J.</given-names></name><name><surname>Duarte-Salazar</surname><given-names>C.A.</given-names></name><name><surname>Hern&#x000e1;ndez</surname><given-names>L.</given-names></name><name><surname>Castro-Ospina</surname><given-names>A.E.</given-names></name><name><surname>D&#x000ed;az</surname><given-names>G.M.</given-names></name></person-group><article-title>Breast Lesion Discrimination Using Saliency Features from MRI Sequences and MKL-Based Classification</article-title><source>Proceedings of the Iberoamerican Congress on Pattern Recognition</source><conf-loc>Havana, Cuba</conf-loc><conf-date>28&#x02013;31 October 2019</conf-date><fpage>294</fpage><lpage>305</lpage></element-citation></ref><ref id="B58-sensors-20-03919"><label>58.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Van Griethuysen</surname><given-names>J.J.</given-names></name><name><surname>Fedorov</surname><given-names>A.</given-names></name><name><surname>Parmar</surname><given-names>C.</given-names></name><name><surname>Hosny</surname><given-names>A.</given-names></name><name><surname>Aucoin</surname><given-names>N.</given-names></name><name><surname>Narayan</surname><given-names>V.</given-names></name><name><surname>Beets-Tan</surname><given-names>R.G.</given-names></name><name><surname>Fillion-Robin</surname><given-names>J.C.</given-names></name><name><surname>Pieper</surname><given-names>S.</given-names></name><name><surname>Aerts</surname><given-names>H.J.</given-names></name></person-group><article-title>Computational radiomics system to decode the radiographic phenotype</article-title><source>Cancer Res.</source><year>2017</year><volume>77</volume><fpage>e104</fpage><lpage>e107</lpage><pub-id pub-id-type="doi">10.1158/0008-5472.CAN-17-0339</pub-id><pub-id pub-id-type="pmid">29092951</pub-id></element-citation></ref><ref id="B59-sensors-20-03919"><label>59.</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Fern&#x000e1;ndez</surname><given-names>A.</given-names></name><name><surname>Garc&#x000ed;a</surname><given-names>S.</given-names></name><name><surname>Galar</surname><given-names>M.</given-names></name><name><surname>Prati</surname><given-names>R.C.</given-names></name><name><surname>Krawczyk</surname><given-names>B.</given-names></name><name><surname>Herrera</surname><given-names>F.</given-names></name></person-group><article-title>Performance measures</article-title><source>Learning from Imbalanced Data Sets</source><publisher-name>Springer</publisher-name><publisher-loc>Cham, Switzerland</publisher-loc><year>2018</year><fpage>47</fpage><lpage>61</lpage></element-citation></ref><ref id="B60-sensors-20-03919"><label>60.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Areiza-Laverde</surname><given-names>H.J.</given-names></name><name><surname>Castro-Ospina</surname><given-names>A.E.</given-names></name><name><surname>Peluffo-Ord&#x000f3;&#x000f1;ez</surname><given-names>D.H.</given-names></name></person-group><article-title>Voice Pathology Detection Using Artificial Neural Networks and Support Vector Machines Powered by a Multicriteria Optimization Algorithm</article-title><source>Proceedings of the Workshop on Engineering Applications</source><conf-loc>Medell&#x000ed;n, Colombia</conf-loc><conf-date>17&#x02013;19 October 2018</conf-date><fpage>148</fpage><lpage>159</lpage></element-citation></ref><ref id="B61-sensors-20-03919"><label>61.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>D&#x000e1;vila-Guzm&#x000e1;n</surname><given-names>M.A.</given-names></name><name><surname>Alfonso-Morales</surname><given-names>W.</given-names></name><name><surname>Caicedo-Bravo</surname><given-names>E.F.</given-names></name></person-group><article-title>Heterogeneous architecture to process swarm optimization algorithms</article-title><source>TecnoL&#x000f3;gicas</source><year>2014</year><volume>17</volume><fpage>11</fpage><lpage>20</lpage><pub-id pub-id-type="doi">10.22430/22565337.197</pub-id></element-citation></ref><ref id="B62-sensors-20-03919"><label>62.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gonz&#x000e1;lez-P&#x000e9;rez</surname><given-names>J.E.</given-names></name><name><surname>Garc&#x000ed;a-G&#x000f3;mez</surname><given-names>D.F.</given-names></name></person-group><article-title>Electric field relaxing electrodes design using particle swarm optimization and finite elements method</article-title><source>TecnoL&#x000f3;gicas</source><year>2017</year><volume>20</volume><fpage>27</fpage><lpage>39</lpage><pub-id pub-id-type="doi">10.22430/22565337.577</pub-id></element-citation></ref><ref id="B63-sensors-20-03919"><label>63.</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Clerc</surname><given-names>M.</given-names></name></person-group><article-title>Beyond standard particle swarm optimisation</article-title><source>Innovations and Developments of Swarm Intelligence Applications</source><publisher-name>IGI Global</publisher-name><publisher-loc>Hershey, PA, USA</publisher-loc><year>2012</year><fpage>1</fpage><lpage>19</lpage></element-citation></ref><ref id="B64-sensors-20-03919"><label>64.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Rinc&#x000f3;n</surname><given-names>J.S.</given-names></name><name><surname>Castro-Ospina</surname><given-names>A.E.</given-names></name><name><surname>Narv&#x000e1;ez</surname><given-names>F.R.</given-names></name><name><surname>D&#x000ed;az</surname><given-names>G.M.</given-names></name></person-group><article-title>Machine Learning Methods for Classifying Mammographic Regions Using the Wavelet Transform and Radiomic Texture Features</article-title><source>Proceedings of the International Conference on Technology Trends</source><conf-loc>Babahoyo, Ecuador</conf-loc><conf-date>29&#x02013;31 August 2018</conf-date><fpage>617</fpage><lpage>629</lpage></element-citation></ref><ref id="B65-sensors-20-03919"><label>65.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gu</surname><given-names>Q.</given-names></name><name><surname>Li</surname><given-names>Z.</given-names></name><name><surname>Han</surname><given-names>J.</given-names></name></person-group><article-title>Generalized fisher score for feature selection</article-title><source>arXiv</source><year>2012</year><pub-id pub-id-type="arxiv">1202.3725</pub-id></element-citation></ref><ref id="B66-sensors-20-03919"><label>66.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Vora</surname><given-names>S.</given-names></name><name><surname>Yang</surname><given-names>H.</given-names></name></person-group><article-title>A comprehensive study of eleven feature selection algorithms and their impact on text classification</article-title><source>Proceedings of the 2017 Computing Conference</source><conf-loc>London, UK</conf-loc><conf-date>18&#x02013;20 July 2017</conf-date><fpage>440</fpage><lpage>449</lpage></element-citation></ref></ref-list></back><floats-group><fig id="sensors-20-03919-f001" orientation="portrait" position="float"><label>Figure 1</label><caption><p>Flowchart of the proposed method.</p></caption><graphic xlink:href="sensors-20-03919-g001"/></fig><fig id="sensors-20-03919-f002" orientation="portrait" position="float"><label>Figure 2</label><caption><p>Distribution of electrodes for EEG signals acquisition.</p></caption><graphic xlink:href="sensors-20-03919-g002"/></fig><fig id="sensors-20-03919-f003" orientation="portrait" position="float"><label>Figure 3</label><caption><p>Visualization of the MRI sequences in the breast cancer dataset.</p></caption><graphic xlink:href="sensors-20-03919-g003"/></fig><fig id="sensors-20-03919-f004" orientation="portrait" position="float"><label>Figure 4</label><caption><p>Performance curves obtained with the BCI test dataset when the number of electrodes was reduced. (<bold>a</bold>) Performance curves of Algorithm 1; (<bold>b</bold>) Performance curves of Algorithm 2; (<bold>c</bold>) Performance curves of Algorithm 3.</p></caption><graphic xlink:href="sensors-20-03919-g004"/></fig><fig id="sensors-20-03919-f005" orientation="portrait" position="float"><label>Figure 5</label><caption><p>Performance curves obtained with the test dataset when the number of MRI sequences was reduced. (<bold>a</bold>) Performance curves using only the perceptual features; (<bold>b</bold>) Performance curves using only the radiomic features; (<bold>c</bold>) Performance curves using both perceptual and radiomic features.</p></caption><graphic xlink:href="sensors-20-03919-g005"/></fig><table-wrap id="sensors-20-03919-t001" orientation="portrait" position="float"><object-id pub-id-type="pii">sensors-20-03919-t001_Table 1</object-id><label>Table 1</label><caption><p>Results of selection of BCI channels applying the Algorithm 1 and <inline-formula><mml:math id="mm281"><mml:mrow><mml:msub><mml:mi>&#x02113;</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>-norm.</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" colspan="1">Subject</th><th rowspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" colspan="1">Number<break/>of Sources</th><th colspan="4" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">Performance Measures (%)</th><th rowspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" colspan="1">Reduction<break/>Rate</th><th rowspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" colspan="1">Relevant<break/>Electrodes</th><th rowspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" colspan="1">Required<break/>Time (s)</th><th rowspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" colspan="1">Support<break/>Vectors</th></tr><tr><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Acc</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Geo-M</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Sens</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Spec</th></tr></thead><tbody><tr><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">
<bold>1</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">22</td><td align="center" valign="middle" rowspan="1" colspan="1">64.29</td><td align="center" valign="middle" rowspan="1" colspan="1">63.89</td><td align="center" valign="middle" rowspan="1" colspan="1">71.43</td><td align="center" valign="middle" rowspan="1" colspan="1">57.14</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0.14</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">14, 13, 18, 1,<break/>22, 8, 7, 19, 9,<break/>6, 4, 21, 5, 10,<break/>17, 12, 2, 16, 15</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0.139</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">116<break/>(100.0 %)</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">19</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">75.00</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">74.91</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">78.57</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">71.43</td></tr><tr><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">
<bold>2</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">22</td><td align="center" valign="middle" rowspan="1" colspan="1">53.33</td><td align="center" valign="middle" rowspan="1" colspan="1">51.64</td><td align="center" valign="middle" rowspan="1" colspan="1">40.00</td><td align="center" valign="middle" rowspan="1" colspan="1">66.67</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0.59</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">13, 1, 12, 6,<break/>20, 7, 3, 8, 17</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0.090</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">116<break/>(100.0 %)</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">9</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">76.67</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">76.01</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">66.67</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">86.67</td></tr><tr><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">
<bold>3</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">22</td><td align="center" valign="middle" rowspan="1" colspan="1">60.71</td><td align="center" valign="middle" rowspan="1" colspan="1">59.76</td><td align="center" valign="middle" rowspan="1" colspan="1">71.43</td><td align="center" valign="middle" rowspan="1" colspan="1">50.00</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0.91</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">8, 13</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0.016</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">116<break/>(100.0 %)</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">2</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">89.29</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">88.64</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">78.57</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">100.00</td></tr><tr><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">
<bold>4</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">22</td><td align="center" valign="middle" rowspan="1" colspan="1">57.14</td><td align="center" valign="middle" rowspan="1" colspan="1">56.69</td><td align="center" valign="middle" rowspan="1" colspan="1">64.29</td><td align="center" valign="middle" rowspan="1" colspan="1">50.00</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0.91</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">21, 22</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0.015</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">116<break/>(100.0 %)</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">2</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">75.00</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">72.84</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">92.86</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">57.14</td></tr><tr><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">
<bold>5</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">22</td><td align="center" valign="middle" rowspan="1" colspan="1">60.00</td><td align="center" valign="middle" rowspan="1" colspan="1">58.50</td><td align="center" valign="middle" rowspan="1" colspan="1">73.33</td><td align="center" valign="middle" rowspan="1" colspan="1">46.67</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0.82</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">3, 22, 1, 13</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0.030</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">116<break/>(100.0 %)</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">4</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">63.33</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">62.54</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">73.33</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">53.33</td></tr><tr><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">
<bold>6</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">22</td><td align="center" valign="middle" rowspan="1" colspan="1">63.33</td><td align="center" valign="middle" rowspan="1" colspan="1">63.25</td><td align="center" valign="middle" rowspan="1" colspan="1">66.67</td><td align="center" valign="middle" rowspan="1" colspan="1">60.00</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0.41</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">18, 7, 1, 8, 12,<break/>10, 17, 3, 11,<break/>9, 6, 14, 13</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0.089</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">116<break/>(100.0 %)</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">13</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">70.00</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">69.92</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">66.67</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">73.33</td></tr><tr><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">
<bold>7</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">22</td><td align="center" valign="middle" rowspan="1" colspan="1">46.43</td><td align="center" valign="middle" rowspan="1" colspan="1">46.29</td><td align="center" valign="middle" rowspan="1" colspan="1">50.00</td><td align="center" valign="middle" rowspan="1" colspan="1">42.86</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0.91</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">22, 3</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0.016</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">116<break/>(100.0 %)</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">2</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">67.86</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">67.76</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">64.29</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">71.43</td></tr><tr><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">
<bold>8</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">22</td><td align="center" valign="middle" rowspan="1" colspan="1">75.00</td><td align="center" valign="middle" rowspan="1" colspan="1">74.91</td><td align="center" valign="middle" rowspan="1" colspan="1">78.57</td><td align="center" valign="middle" rowspan="1" colspan="1">71.43</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0.82</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">18, 14, 6, 13</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0.029</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">116<break/>(100.0 %)</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">4</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">85.71</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">85.42</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">92.86</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">78.57</td></tr><tr><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">
<bold>9</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">22</td><td align="center" valign="middle" rowspan="1" colspan="1">71.43</td><td align="center" valign="middle" rowspan="1" colspan="1">71.43</td><td align="center" valign="middle" rowspan="1" colspan="1">71.43</td><td align="center" valign="middle" rowspan="1" colspan="1">71.43</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0.27</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">18, 13, 12, 7,<break/>2, 1, 6, 3, 22,<break/>21, 20, 19, 4,<break/>8, 15, 14</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0.115</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">116<break/>(100.0 %)</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">16</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">78.57</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">78.25</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">85.71</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">71.43</td></tr><tr><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">
<bold>Average</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">22</td><td align="center" valign="middle" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm282"><mml:mrow><mml:mrow><mml:mn>61</mml:mn><mml:mo>.</mml:mo><mml:mn>30</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
<break/>
<inline-formula><mml:math id="mm283"><mml:mrow><mml:mrow><mml:mo>&#x000b1;</mml:mo><mml:mn>8</mml:mn><mml:mo>.</mml:mo><mml:mn>71</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm284"><mml:mrow><mml:mrow><mml:mn>60</mml:mn><mml:mo>.</mml:mo><mml:mn>71</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
<break/>
<inline-formula><mml:math id="mm285"><mml:mrow><mml:mrow><mml:mo>&#x000b1;</mml:mo><mml:mn>8</mml:mn><mml:mo>.</mml:mo><mml:mn>98</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm286"><mml:mrow><mml:mrow><mml:mn>65</mml:mn><mml:mo>.</mml:mo><mml:mn>24</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
<break/>
<inline-formula><mml:math id="mm287"><mml:mrow><mml:mrow><mml:mo>&#x000b1;</mml:mo><mml:mn>12</mml:mn><mml:mo>.</mml:mo><mml:mn>40</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm288"><mml:mrow><mml:mrow><mml:mn>57</mml:mn><mml:mo>.</mml:mo><mml:mn>36</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
<break/>
<inline-formula><mml:math id="mm289"><mml:mrow><mml:mrow><mml:mo>&#x000b1;</mml:mo><mml:mn>10</mml:mn><mml:mo>.</mml:mo><mml:mn>74</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">
<inline-formula><mml:math id="mm290"><mml:mrow><mml:mrow><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:mn>64</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
<break/>
<inline-formula><mml:math id="mm291"><mml:mrow><mml:mrow><mml:mo>&#x000b1;</mml:mo><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:mn>30</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">13, 8, 6, 1,<break/>22, 3, 14, 18</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">
<inline-formula><mml:math id="mm292"><mml:mrow><mml:mrow><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:mn>060</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
<break/>
<inline-formula><mml:math id="mm293"><mml:mrow><mml:mrow><mml:mo>&#x000b1;</mml:mo><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:mn>048</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">116<break/>(100.0 %)</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">8<break/>
<inline-formula><mml:math id="mm294"><mml:mrow><mml:mrow><mml:mo>&#x000b1;</mml:mo><mml:mn>7</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula></td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm295"><mml:mrow><mml:mrow><mml:mn>75</mml:mn><mml:mo>.</mml:mo><mml:mn>71</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
<break/>
<inline-formula><mml:math id="mm296"><mml:mrow><mml:mrow><mml:mo>&#x000b1;</mml:mo><mml:mn>8</mml:mn><mml:mo>.</mml:mo><mml:mn>23</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm297"><mml:mrow><mml:mrow><mml:mn>75</mml:mn><mml:mo>.</mml:mo><mml:mn>14</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
<break/>
<inline-formula><mml:math id="mm298"><mml:mrow><mml:mrow><mml:mo>&#x000b1;</mml:mo><mml:mn>8</mml:mn><mml:mo>.</mml:mo><mml:mn>25</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm299"><mml:mrow><mml:mrow><mml:mn>77</mml:mn><mml:mo>.</mml:mo><mml:mn>73</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
<break/>
<inline-formula><mml:math id="mm300"><mml:mrow><mml:mrow><mml:mo>&#x000b1;</mml:mo><mml:mn>11</mml:mn><mml:mo>.</mml:mo><mml:mn>00</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm301"><mml:mrow><mml:mrow><mml:mn>73</mml:mn><mml:mo>.</mml:mo><mml:mn>70</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
<break/>
<inline-formula><mml:math id="mm302"><mml:mrow><mml:mrow><mml:mo>&#x000b1;</mml:mo><mml:mn>14</mml:mn><mml:mo>.</mml:mo><mml:mn>09</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
</td></tr></tbody></table></table-wrap><table-wrap id="sensors-20-03919-t002" orientation="portrait" position="float"><object-id pub-id-type="pii">sensors-20-03919-t002_Table 2</object-id><label>Table 2</label><caption><p>Results of selection of BCI channels applying the Algorithm 2 and <inline-formula><mml:math id="mm303"><mml:mrow><mml:msub><mml:mi>&#x02113;</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>-norm.</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" colspan="1">Subject</th><th rowspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" colspan="1">Number<break/>of Sources</th><th colspan="4" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">Performance Measures (%)</th><th rowspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" colspan="1">Reduction<break/>Rate</th><th rowspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" colspan="1">Relevant<break/>Electrodes</th><th rowspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" colspan="1">Required<break/>Time (s)</th><th rowspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" colspan="1">Support<break/>Vectors</th></tr><tr><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Acc</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Geo-M</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Sens</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Spec</th></tr></thead><tbody><tr><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">
<bold>1</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">22</td><td align="center" valign="middle" rowspan="1" colspan="1">67.86</td><td align="center" valign="middle" rowspan="1" colspan="1">67.76</td><td align="center" valign="middle" rowspan="1" colspan="1">71.43</td><td align="center" valign="middle" rowspan="1" colspan="1">64.29</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0.50</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">14, 13, 18,<break/>1, 8, 22, 19,<break/>21, 9, 10, 4</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0.065</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">83<break/>(71.6 %)</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">11</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">75.00</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">74.91</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">78.57</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">71.43</td></tr><tr><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">
<bold>2</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">22</td><td align="center" valign="middle" rowspan="1" colspan="1">66.67</td><td align="center" valign="middle" rowspan="1" colspan="1">65.32</td><td align="center" valign="middle" rowspan="1" colspan="1">53.33</td><td align="center" valign="middle" rowspan="1" colspan="1">80.00</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0.36</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">12, 8, 13, 1,<break/>17, 7, 16, 20,<break/>21, 2, 6, 14,<break/>9, 10</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0.096</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">110<break/>(94.8 %)</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">14</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">66.67</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">65.32</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">53.33</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">80.00</td></tr><tr><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">
<bold>3</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">22</td><td align="center" valign="middle" rowspan="1" colspan="1">71.43</td><td align="center" valign="middle" rowspan="1" colspan="1">71.07</td><td align="center" valign="middle" rowspan="1" colspan="1">64.29</td><td align="center" valign="middle" rowspan="1" colspan="1">78.57</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0.82</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">8, 5, 13, 14</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0.024</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">75<break/>(64.7 %)</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">4</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">75.00</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">74.91</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">71.43</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">78.57</td></tr><tr><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">
<bold>4</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">22</td><td align="center" valign="middle" rowspan="1" colspan="1">46.43</td><td align="center" valign="middle" rowspan="1" colspan="1">46.29</td><td align="center" valign="middle" rowspan="1" colspan="1">50.00</td><td align="center" valign="middle" rowspan="1" colspan="1">42.86</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0.91</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">22, 21</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0.017</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">72<break/>(62.1 %)</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">2</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">78.57</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">78.57</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">78.57</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">78.57</td></tr><tr><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">
<bold>5</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">22</td><td align="center" valign="middle" rowspan="1" colspan="1">56.67</td><td align="center" valign="middle" rowspan="1" colspan="1">54.16</td><td align="center" valign="middle" rowspan="1" colspan="1">73.33</td><td align="center" valign="middle" rowspan="1" colspan="1">40.00</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0.77</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">7, 1, 13,<break/>3, 22</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0.030</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">78<break/>(67.2 %)</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">5</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">66.67</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">65.32</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">80.00</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">53.33</td></tr><tr><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">
<bold>6</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">22</td><td align="center" valign="middle" rowspan="1" colspan="1">70.00</td><td align="center" valign="middle" rowspan="1" colspan="1">69.92</td><td align="center" valign="middle" rowspan="1" colspan="1">66.67</td><td align="center" valign="middle" rowspan="1" colspan="1">73.33</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0.55</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">18, 8, 1, 7,<break/>12, 17, 3,<break/>9, 10, 14</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0.066</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">99<break/>(85.3 %)</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">10</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">76.67</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">76.59</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">80.00</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">73.33</td></tr><tr><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">
<bold>7</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">22</td><td align="center" valign="middle" rowspan="1" colspan="1">46.43</td><td align="center" valign="middle" rowspan="1" colspan="1">46.29</td><td align="center" valign="middle" rowspan="1" colspan="1">50.00</td><td align="center" valign="middle" rowspan="1" colspan="1">42.86</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0.91</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">22, 3</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0.013</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">83<break/>(71.6 %)</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">2</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">67.86</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">67.76</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">64.29</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">71.43</td></tr><tr><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">
<bold>8</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">22</td><td align="center" valign="middle" rowspan="1" colspan="1">67.86</td><td align="center" valign="middle" rowspan="1" colspan="1">67.76</td><td align="center" valign="middle" rowspan="1" colspan="1">71.43</td><td align="center" valign="middle" rowspan="1" colspan="1">64.29</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0.82</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">18, 14, 1, 13</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0.028</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">86<break/>(74.1 %)</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">4</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">82.14</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">82.07</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">78.57</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">85.71</td></tr><tr><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">
<bold>9</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">22</td><td align="center" valign="middle" rowspan="1" colspan="1">71.43</td><td align="center" valign="middle" rowspan="1" colspan="1">71.43</td><td align="center" valign="middle" rowspan="1" colspan="1">71.43</td><td align="center" valign="middle" rowspan="1" colspan="1">71.43</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0.73</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">13, 2, 12,<break/>22, 1, 18</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0.035</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">64<break/>(55.2 %)</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">6</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">78.57</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">78.25</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">85.71</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">71.43</td></tr><tr><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">
<bold>Average</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">22</td><td align="center" valign="middle" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm304"><mml:mrow><mml:mrow><mml:mn>62</mml:mn><mml:mo>.</mml:mo><mml:mn>75</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
<break/>
<inline-formula><mml:math id="mm305"><mml:mrow><mml:mrow><mml:mo>&#x000b1;</mml:mo><mml:mn>10</mml:mn><mml:mo>.</mml:mo><mml:mn>25</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm306"><mml:mrow><mml:mrow><mml:mn>62</mml:mn><mml:mo>.</mml:mo><mml:mn>22</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
<break/>
<inline-formula><mml:math id="mm307"><mml:mrow><mml:mrow><mml:mo>&#x000b1;</mml:mo><mml:mn>10</mml:mn><mml:mo>.</mml:mo><mml:mn>40</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm308"><mml:mrow><mml:mrow><mml:mn>63</mml:mn><mml:mo>.</mml:mo><mml:mn>55</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
<break/>
<inline-formula><mml:math id="mm309"><mml:mrow><mml:mrow><mml:mo>&#x000b1;</mml:mo><mml:mn>9</mml:mn><mml:mo>.</mml:mo><mml:mn>77</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm310"><mml:mrow><mml:mrow><mml:mn>61</mml:mn><mml:mo>.</mml:mo><mml:mn>96</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
<break/>
<inline-formula><mml:math id="mm311"><mml:mrow><mml:mrow><mml:mo>&#x000b1;</mml:mo><mml:mn>15</mml:mn><mml:mo>.</mml:mo><mml:mn>98</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">
<inline-formula><mml:math id="mm312"><mml:mrow><mml:mrow><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:mn>71</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
<break/>
<inline-formula><mml:math id="mm313"><mml:mrow><mml:mrow><mml:mo>&#x000b1;</mml:mo><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:mn>19</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">1, 13, 14,<break/>22, 18, 8</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">
<inline-formula><mml:math id="mm314"><mml:mrow><mml:mrow><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:mn>042</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
<break/>
<inline-formula><mml:math id="mm315"><mml:mrow><mml:mrow><mml:mo>&#x000b1;</mml:mo><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:mn>028</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">83<break/>
<inline-formula><mml:math id="mm316"><mml:mrow><mml:mrow><mml:mo>&#x000b1;</mml:mo><mml:mn>14</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula><break/>
(<inline-formula><mml:math id="mm317"><mml:mrow><mml:mrow><mml:mn>71</mml:mn><mml:mo>.</mml:mo><mml:mn>8</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> %<break/>
<inline-formula><mml:math id="mm318"><mml:mrow><mml:mrow><mml:mo>&#x000b1;</mml:mo><mml:mn>12</mml:mn><mml:mo>.</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> %)</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">6<break/>
<inline-formula><mml:math id="mm319"><mml:mrow><mml:mrow><mml:mo>&#x000b1;</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula></td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm320"><mml:mrow><mml:mrow><mml:mn>74</mml:mn><mml:mo>.</mml:mo><mml:mn>13</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
<break/>
<inline-formula><mml:math id="mm321"><mml:mrow><mml:mrow><mml:mo>&#x000b1;</mml:mo><mml:mn>5</mml:mn><mml:mo>.</mml:mo><mml:mn>73</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm322"><mml:mrow><mml:mrow><mml:mn>73</mml:mn><mml:mo>.</mml:mo><mml:mn>74</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
<break/>
<inline-formula><mml:math id="mm323"><mml:mrow><mml:mrow><mml:mo>&#x000b1;</mml:mo><mml:mn>6</mml:mn><mml:mo>.</mml:mo><mml:mn>14</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm324"><mml:mrow><mml:mrow><mml:mn>74</mml:mn><mml:mo>.</mml:mo><mml:mn>50</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
<break/>
<inline-formula><mml:math id="mm325"><mml:mrow><mml:mrow><mml:mo>&#x000b1;</mml:mo><mml:mn>9</mml:mn><mml:mo>.</mml:mo><mml:mn>99</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm326"><mml:mrow><mml:mrow><mml:mn>73</mml:mn><mml:mo>.</mml:mo><mml:mn>76</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
<break/>
<inline-formula><mml:math id="mm327"><mml:mrow><mml:mrow><mml:mo>&#x000b1;</mml:mo><mml:mn>9</mml:mn><mml:mo>.</mml:mo><mml:mn>10</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
</td></tr></tbody></table></table-wrap><table-wrap id="sensors-20-03919-t003" orientation="portrait" position="float"><object-id pub-id-type="pii">sensors-20-03919-t003_Table 3</object-id><label>Table 3</label><caption><p>Results of selection of BCI channels applying the Algorithm 3 and <inline-formula><mml:math id="mm328"><mml:mrow><mml:msub><mml:mi>&#x02113;</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>-norm.</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" colspan="1">Subject</th><th rowspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" colspan="1">Number<break/>of Sources</th><th colspan="4" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">Performance Measures (%)</th><th rowspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" colspan="1">Reduction<break/>Rate</th><th rowspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" colspan="1">Relevant<break/>Electrodes</th><th rowspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" colspan="1">Required<break/>Time (s)</th><th rowspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" colspan="1">Support<break/>Vectors</th></tr><tr><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Acc</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Geo-M</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Sens</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Spec</th></tr></thead><tbody><tr><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">
<bold>1</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">22</td><td align="center" valign="middle" rowspan="1" colspan="1">67.86</td><td align="center" valign="middle" rowspan="1" colspan="1">67.76</td><td align="center" valign="middle" rowspan="1" colspan="1">71.43</td><td align="center" valign="middle" rowspan="1" colspan="1">64.29</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0.77</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">14, 13, 18,<break/>9, 1</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0.041</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">78<break/>(67.2 %)</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">5</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">78.57</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">78.25</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">85.71</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">71.43</td></tr><tr><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">
<bold>2</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">22</td><td align="center" valign="middle" rowspan="1" colspan="1">63.33</td><td align="center" valign="middle" rowspan="1" colspan="1">62.54</td><td align="center" valign="middle" rowspan="1" colspan="1">53.33</td><td align="center" valign="middle" rowspan="1" colspan="1">73.33</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0.05</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">7, 1, 13, 6, 8, 9,<break/>12, 2, 3, 14, 18,<break/>17, 20, 10, 5, 21,<break/>19, 15, 16, 11, 22</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0.171</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">105<break/>(90.5 %)</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">21</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">63.33</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">62.54</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">53.33</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">73.33</td></tr><tr><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">
<bold>3</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">22</td><td align="center" valign="middle" rowspan="1" colspan="1">64.29</td><td align="center" valign="middle" rowspan="1" colspan="1">64.29</td><td align="center" valign="middle" rowspan="1" colspan="1">64.29</td><td align="center" valign="middle" rowspan="1" colspan="1">64.29</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0.91</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">8, 13</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0.017</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">78<break/>(67.2 %)</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">2</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">82.14</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">82.07</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">85.71</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">78.57</td></tr><tr><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">
<bold>4</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">22</td><td align="center" valign="middle" rowspan="1" colspan="1">50.00</td><td align="center" valign="middle" rowspan="1" colspan="1">50.00</td><td align="center" valign="middle" rowspan="1" colspan="1">50.00</td><td align="center" valign="middle" rowspan="1" colspan="1">50.00</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0.91</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">22, 21</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0.018</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">99<break/>(85.3 %)</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">2</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">71.43</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">71.43</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">71.43</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">71.43</td></tr><tr><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">
<bold>5</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">22</td><td align="center" valign="middle" rowspan="1" colspan="1">56.67</td><td align="center" valign="middle" rowspan="1" colspan="1">54.16</td><td align="center" valign="middle" rowspan="1" colspan="1">73.33</td><td align="center" valign="middle" rowspan="1" colspan="1">40.00</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0.77</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">7, 1, 13,<break/>3, 22</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0.039</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">78<break/>(67.2 %)</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">5</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">66.67</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">65.32</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">80.00</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">53.33</td></tr><tr><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">
<bold>6</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">22</td><td align="center" valign="middle" rowspan="1" colspan="1">66.67</td><td align="center" valign="middle" rowspan="1" colspan="1">66.33</td><td align="center" valign="middle" rowspan="1" colspan="1">73.33</td><td align="center" valign="middle" rowspan="1" colspan="1">60.00</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0.50</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">18, 7, 8, 12,<break/>1, 9, 17, 10,<break/>3, 11, 14</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0.090</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">100<break/>(86.2 %)</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">11</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">73.33</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">73.33</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">73.33</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">73.33</td></tr><tr><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">
<bold>7</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">22</td><td align="center" valign="middle" rowspan="1" colspan="1">60.71</td><td align="center" valign="middle" rowspan="1" colspan="1">60.61</td><td align="center" valign="middle" rowspan="1" colspan="1">64.29</td><td align="center" valign="middle" rowspan="1" colspan="1">57.14</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0.91</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">22, 3</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0.017</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">83<break/>(71.6 %)</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">2</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">64.29</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">64.29</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">64.29</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">64.29</td></tr><tr><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">
<bold>8</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">22</td><td align="center" valign="middle" rowspan="1" colspan="1">67.86</td><td align="center" valign="middle" rowspan="1" colspan="1">67.76</td><td align="center" valign="middle" rowspan="1" colspan="1">64.29</td><td align="center" valign="middle" rowspan="1" colspan="1">71.43</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0.77</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">18, 13, 14,<break/>9, 1</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0.044</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">83<break/>(71.6 %)</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">5</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">82.14</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">82.07</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">85.71</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">78.57</td></tr><tr><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">
<bold>9</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">22</td><td align="center" valign="middle" rowspan="1" colspan="1">71.43</td><td align="center" valign="middle" rowspan="1" colspan="1">71.43</td><td align="center" valign="middle" rowspan="1" colspan="1">71.43</td><td align="center" valign="middle" rowspan="1" colspan="1">71.43</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0.73</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">13, 2, 12,<break/>22, 1, 18</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0.045</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">64<break/>(55.2 %)</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">6</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">71.43</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">71.43</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">71.43</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">71.43</td></tr><tr><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">
<bold>Average</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">22</td><td align="center" valign="middle" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm329"><mml:mrow><mml:mrow><mml:mn>63</mml:mn><mml:mo>.</mml:mo><mml:mn>20</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
<break/>
<inline-formula><mml:math id="mm330"><mml:mrow><mml:mrow><mml:mo>&#x000b1;</mml:mo><mml:mn>6</mml:mn><mml:mo>.</mml:mo><mml:mn>59</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm331"><mml:mrow><mml:mrow><mml:mn>62</mml:mn><mml:mo>.</mml:mo><mml:mn>76</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
<break/>
<inline-formula><mml:math id="mm332"><mml:mrow><mml:mrow><mml:mo>&#x000b1;</mml:mo><mml:mn>6</mml:mn><mml:mo>.</mml:mo><mml:mn>91</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm333"><mml:mrow><mml:mrow><mml:mn>65</mml:mn><mml:mo>.</mml:mo><mml:mn>08</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
<break/>
<inline-formula><mml:math id="mm334"><mml:mrow><mml:mrow><mml:mo>&#x000b1;</mml:mo><mml:mn>8</mml:mn><mml:mo>.</mml:mo><mml:mn>55</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm335"><mml:mrow><mml:mrow><mml:mn>61</mml:mn><mml:mo>.</mml:mo><mml:mn>32</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
<break/>
<inline-formula><mml:math id="mm336"><mml:mrow><mml:mrow><mml:mo>&#x000b1;</mml:mo><mml:mn>11</mml:mn><mml:mo>.</mml:mo><mml:mn>00</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">
<inline-formula><mml:math id="mm337"><mml:mrow><mml:mrow><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:mn>70</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
<break/>
<inline-formula><mml:math id="mm338"><mml:mrow><mml:mrow><mml:mo>&#x000b1;</mml:mo><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:mn>28</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">13, 1, 18,<break/>22, 9, 14, 3</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">
<inline-formula><mml:math id="mm339"><mml:mrow><mml:mrow><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:mn>054</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
<break/>
<inline-formula><mml:math id="mm340"><mml:mrow><mml:mrow><mml:mo>&#x000b1;</mml:mo><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:mn>049</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
</td><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">85<break/>
<inline-formula><mml:math id="mm341"><mml:mrow><mml:mrow><mml:mo>&#x000b1;</mml:mo><mml:mn>13</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula><break/>
(<inline-formula><mml:math id="mm342"><mml:mrow><mml:mrow><mml:mn>73</mml:mn><mml:mo>.</mml:mo><mml:mn>6</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> %<break/>
<inline-formula><mml:math id="mm343"><mml:mrow><mml:mrow><mml:mo>&#x000b1;</mml:mo><mml:mn>11</mml:mn><mml:mo>.</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> %)</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">7<break/>
<inline-formula><mml:math id="mm344"><mml:mrow><mml:mrow><mml:mo>&#x000b1;</mml:mo><mml:mn>6</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula></td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm345"><mml:mrow><mml:mrow><mml:mn>72</mml:mn><mml:mo>.</mml:mo><mml:mn>59</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
<break/>
<inline-formula><mml:math id="mm346"><mml:mrow><mml:mrow><mml:mo>&#x000b1;</mml:mo><mml:mn>7</mml:mn><mml:mo>.</mml:mo><mml:mn>17</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm347"><mml:mrow><mml:mrow><mml:mn>72</mml:mn><mml:mo>.</mml:mo><mml:mn>30</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
<break/>
<inline-formula><mml:math id="mm348"><mml:mrow><mml:mrow><mml:mo>&#x000b1;</mml:mo><mml:mn>7</mml:mn><mml:mo>.</mml:mo><mml:mn>39</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm349"><mml:mrow><mml:mrow><mml:mn>74</mml:mn><mml:mo>.</mml:mo><mml:mn>55</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
<break/>
<inline-formula><mml:math id="mm350"><mml:mrow><mml:mrow><mml:mo>&#x000b1;</mml:mo><mml:mn>11</mml:mn><mml:mo>.</mml:mo><mml:mn>07</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm351"><mml:mrow><mml:mrow><mml:mn>70</mml:mn><mml:mo>.</mml:mo><mml:mn>63</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
<break/>
<inline-formula><mml:math id="mm352"><mml:mrow><mml:mrow><mml:mo>&#x000b1;</mml:mo><mml:mn>7</mml:mn><mml:mo>.</mml:mo><mml:mn>76</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
</td></tr></tbody></table></table-wrap><table-wrap id="sensors-20-03919-t004" orientation="portrait" position="float"><object-id pub-id-type="pii">sensors-20-03919-t004_Table 4</object-id><label>Table 4</label><caption><p>Results of selection of BCI channels applying the Algorithms 1 to 3 with <inline-formula><mml:math id="mm353"><mml:mrow><mml:msub><mml:mi>&#x02113;</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>-norm and <inline-formula><mml:math id="mm354"><mml:mrow><mml:msub><mml:mi>&#x02113;</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>-norm.</p></caption><table frame="hsides" rules="groups"><thead><tr><th colspan="6" align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1">Using the <inline-formula><mml:math id="mm355"><mml:mrow><mml:mstyle mathvariant="bold"><mml:msub><mml:mi mathvariant="bold-italic">&#x02113;</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mstyle></mml:mrow></mml:math></inline-formula>-Norm</th><th colspan="6" align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1">Using the <inline-formula><mml:math id="mm356"><mml:mrow><mml:mstyle mathvariant="bold"><mml:msub><mml:mi mathvariant="bold-italic">&#x02113;</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mstyle></mml:mrow></mml:math></inline-formula>-Norm</th></tr><tr><th colspan="2" align="center" valign="middle" style="border-bottom:solid thin" rowspan="1">Algorithm 1</th><th colspan="2" align="center" valign="middle" style="border-bottom:solid thin" rowspan="1">Algorithm 2</th><th colspan="2" align="center" valign="middle" style="border-bottom:solid thin" rowspan="1">Algorithm 3</th><th colspan="2" align="center" valign="middle" style="border-bottom:solid thin" rowspan="1">Algorithm 1</th><th colspan="2" align="center" valign="middle" style="border-bottom:solid thin" rowspan="1">Algorithm 2</th><th colspan="2" align="center" valign="middle" style="border-bottom:solid thin" rowspan="1">Algorithm 3</th></tr><tr><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Electrode</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Relev</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Electrode</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Relev</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Electrode</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Relev</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Electrode</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Relev</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Electrode</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Relev</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Electrode</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Relev</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>18</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">8.95</td><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>14</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">10.22</td><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>13</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">8.00</td><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>13</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">10.08</td><td align="center" valign="middle" rowspan="1" colspan="1">1</td><td align="center" valign="middle" rowspan="1" colspan="1">10.48</td><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>13</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">10.74</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>14</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">7.46</td><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>18</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">9.23</td><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>14</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">7.87</td><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>8</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">7.29</td><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>13</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">10.45</td><td align="center" valign="middle" rowspan="1" colspan="1">1</td><td align="center" valign="middle" rowspan="1" colspan="1">10.52</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>13</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">7.31</td><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>13</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">7.17</td><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>18</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">6.97</td><td align="center" valign="middle" rowspan="1" colspan="1">6</td><td align="center" valign="middle" rowspan="1" colspan="1">7.22</td><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>14</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">8.83</td><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>18</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">8.91</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>8</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">6.09</td><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>22</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">7.08</td><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>8</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">6.88</td><td align="center" valign="middle" rowspan="1" colspan="1">1</td><td align="center" valign="middle" rowspan="1" colspan="1">6.81</td><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>22</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">8.63</td><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>22</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">8.15</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">12</td><td align="center" valign="middle" rowspan="1" colspan="1">6.09</td><td align="center" valign="middle" rowspan="1" colspan="1">1</td><td align="center" valign="middle" rowspan="1" colspan="1">6.47</td><td align="center" valign="middle" rowspan="1" colspan="1">7</td><td align="center" valign="middle" rowspan="1" colspan="1">6.61</td><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>22</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">6.73</td><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>18</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">7.35</td><td align="center" valign="middle" rowspan="1" colspan="1">9</td><td align="center" valign="middle" rowspan="1" colspan="1">7.19</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">7</td><td align="center" valign="middle" rowspan="1" colspan="1">5.98</td><td align="center" valign="middle" rowspan="1" colspan="1">21</td><td align="center" valign="middle" rowspan="1" colspan="1">6.36</td><td align="center" valign="middle" rowspan="1" colspan="1">12</td><td align="center" valign="middle" rowspan="1" colspan="1">6.61</td><td align="center" valign="middle" rowspan="1" colspan="1">3</td><td align="center" valign="middle" rowspan="1" colspan="1">6.67</td><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>8</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">6.90</td><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>14</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">7.19</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>22</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">5.92</td><td align="center" valign="middle" rowspan="1" colspan="1">7</td><td align="center" valign="middle" rowspan="1" colspan="1">6.27</td><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>22</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">5.38</td><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>14</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">5.79</td><td align="center" valign="middle" rowspan="1" colspan="1">12</td><td align="center" valign="middle" rowspan="1" colspan="1">5.22</td><td align="center" valign="middle" rowspan="1" colspan="1">3</td><td align="center" valign="middle" rowspan="1" colspan="1">6.47</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">10</td><td align="center" valign="middle" rowspan="1" colspan="1">5.87</td><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>8</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">5.77</td><td align="center" valign="middle" rowspan="1" colspan="1">6</td><td align="center" valign="middle" rowspan="1" colspan="1">5.32</td><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>18</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">5.79</td><td align="center" valign="middle" rowspan="1" colspan="1">21</td><td align="center" valign="middle" rowspan="1" colspan="1">5.18</td><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>8</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">5.29</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">21</td><td align="center" valign="middle" rowspan="1" colspan="1">5.81</td><td align="center" valign="middle" rowspan="1" colspan="1">6</td><td align="center" valign="middle" rowspan="1" colspan="1">5.59</td><td align="center" valign="middle" rowspan="1" colspan="1">1</td><td align="center" valign="middle" rowspan="1" colspan="1">5.25</td><td align="center" valign="middle" rowspan="1" colspan="1">7</td><td align="center" valign="middle" rowspan="1" colspan="1">5.62</td><td align="center" valign="middle" rowspan="1" colspan="1">9</td><td align="center" valign="middle" rowspan="1" colspan="1">5.14</td><td align="center" valign="middle" rowspan="1" colspan="1">12</td><td align="center" valign="middle" rowspan="1" colspan="1">5.03</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">11</td><td align="center" valign="middle" rowspan="1" colspan="1">4.40</td><td align="center" valign="middle" rowspan="1" colspan="1">12</td><td align="center" valign="middle" rowspan="1" colspan="1">5.28</td><td align="center" valign="middle" rowspan="1" colspan="1">19</td><td align="center" valign="middle" rowspan="1" colspan="1">5.23</td><td align="center" valign="middle" rowspan="1" colspan="1">12</td><td align="center" valign="middle" rowspan="1" colspan="1">5.62</td><td align="center" valign="middle" rowspan="1" colspan="1">10</td><td align="center" valign="middle" rowspan="1" colspan="1">5.14</td><td align="center" valign="middle" rowspan="1" colspan="1">7</td><td align="center" valign="middle" rowspan="1" colspan="1">4.91</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">17</td><td align="center" valign="middle" rowspan="1" colspan="1">4.40</td><td align="center" valign="middle" rowspan="1" colspan="1">9</td><td align="center" valign="middle" rowspan="1" colspan="1">4.87</td><td align="center" valign="middle" rowspan="1" colspan="1">10</td><td align="center" valign="middle" rowspan="1" colspan="1">4.13</td><td align="center" valign="middle" rowspan="1" colspan="1">21</td><td align="center" valign="middle" rowspan="1" colspan="1">4.28</td><td align="center" valign="middle" rowspan="1" colspan="1">3</td><td align="center" valign="middle" rowspan="1" colspan="1">4.97</td><td align="center" valign="middle" rowspan="1" colspan="1">10</td><td align="center" valign="middle" rowspan="1" colspan="1">3.30</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">6</td><td align="center" valign="middle" rowspan="1" colspan="1">4.31</td><td align="center" valign="middle" rowspan="1" colspan="1">2</td><td align="center" valign="middle" rowspan="1" colspan="1">3.40</td><td align="center" valign="middle" rowspan="1" colspan="1">17</td><td align="center" valign="middle" rowspan="1" colspan="1">3.99</td><td align="center" valign="middle" rowspan="1" colspan="1">17</td><td align="center" valign="middle" rowspan="1" colspan="1">4.15</td><td align="center" valign="middle" rowspan="1" colspan="1">7</td><td align="center" valign="middle" rowspan="1" colspan="1">4.94</td><td align="center" valign="middle" rowspan="1" colspan="1">11</td><td align="center" valign="middle" rowspan="1" colspan="1">3.30</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">3</td><td align="center" valign="middle" rowspan="1" colspan="1">4.27</td><td align="center" valign="middle" rowspan="1" colspan="1">15</td><td align="center" valign="middle" rowspan="1" colspan="1">3.40</td><td align="center" valign="middle" rowspan="1" colspan="1">11</td><td align="center" valign="middle" rowspan="1" colspan="1">3.97</td><td align="center" valign="middle" rowspan="1" colspan="1">20</td><td align="center" valign="middle" rowspan="1" colspan="1">2.91</td><td align="center" valign="middle" rowspan="1" colspan="1">2</td><td align="center" valign="middle" rowspan="1" colspan="1">3.42</td><td align="center" valign="middle" rowspan="1" colspan="1">17</td><td align="center" valign="middle" rowspan="1" colspan="1">3.30</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">2</td><td align="center" valign="middle" rowspan="1" colspan="1">4.16</td><td align="center" valign="middle" rowspan="1" colspan="1">19</td><td align="center" valign="middle" rowspan="1" colspan="1">3.40</td><td align="center" valign="middle" rowspan="1" colspan="1">15</td><td align="center" valign="middle" rowspan="1" colspan="1">3.88</td><td align="center" valign="middle" rowspan="1" colspan="1">2</td><td align="center" valign="middle" rowspan="1" colspan="1">2.87</td><td align="center" valign="middle" rowspan="1" colspan="1">17</td><td align="center" valign="middle" rowspan="1" colspan="1">3.37</td><td align="center" valign="middle" rowspan="1" colspan="1">2</td><td align="center" valign="middle" rowspan="1" colspan="1">3.26</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">1</td><td align="center" valign="middle" rowspan="1" colspan="1">4.16</td><td align="center" valign="middle" rowspan="1" colspan="1">11</td><td align="center" valign="middle" rowspan="1" colspan="1">3.11</td><td align="center" valign="middle" rowspan="1" colspan="1">3</td><td align="center" valign="middle" rowspan="1" colspan="1">3.68</td><td align="center" valign="middle" rowspan="1" colspan="1">4</td><td align="center" valign="middle" rowspan="1" colspan="1">2.87</td><td align="center" valign="middle" rowspan="1" colspan="1">4</td><td align="center" valign="middle" rowspan="1" colspan="1">1.76</td><td align="center" valign="middle" rowspan="1" colspan="1">21</td><td align="center" valign="middle" rowspan="1" colspan="1">3.26</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">5</td><td align="center" valign="middle" rowspan="1" colspan="1">2.69</td><td align="center" valign="middle" rowspan="1" colspan="1">20</td><td align="center" valign="middle" rowspan="1" colspan="1">3.11</td><td align="center" valign="middle" rowspan="1" colspan="1">2</td><td align="center" valign="middle" rowspan="1" colspan="1">2.68</td><td align="center" valign="middle" rowspan="1" colspan="1">15</td><td align="center" valign="middle" rowspan="1" colspan="1">2.87</td><td align="center" valign="middle" rowspan="1" colspan="1">5</td><td align="center" valign="middle" rowspan="1" colspan="1">1.76</td><td align="center" valign="middle" rowspan="1" colspan="1">5</td><td align="center" valign="middle" rowspan="1" colspan="1">1.53</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">9</td><td align="center" valign="middle" rowspan="1" colspan="1">2.69</td><td align="center" valign="middle" rowspan="1" colspan="1">4</td><td align="center" valign="middle" rowspan="1" colspan="1">1.75</td><td align="center" valign="middle" rowspan="1" colspan="1">5</td><td align="center" valign="middle" rowspan="1" colspan="1">2.48</td><td align="center" valign="middle" rowspan="1" colspan="1">19</td><td align="center" valign="middle" rowspan="1" colspan="1">2.87</td><td align="center" valign="middle" rowspan="1" colspan="1">19</td><td align="center" valign="middle" rowspan="1" colspan="1">1.76</td><td align="center" valign="middle" rowspan="1" colspan="1">6</td><td align="center" valign="middle" rowspan="1" colspan="1">1.53</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">19</td><td align="center" valign="middle" rowspan="1" colspan="1">2.69</td><td align="center" valign="middle" rowspan="1" colspan="1">3</td><td align="center" valign="middle" rowspan="1" colspan="1">1.56</td><td align="center" valign="middle" rowspan="1" colspan="1">21</td><td align="center" valign="middle" rowspan="1" colspan="1">2.48</td><td align="center" valign="middle" rowspan="1" colspan="1">9</td><td align="center" valign="middle" rowspan="1" colspan="1">2.71</td><td align="center" valign="middle" rowspan="1" colspan="1">6</td><td align="center" valign="middle" rowspan="1" colspan="1">1.57</td><td align="center" valign="middle" rowspan="1" colspan="1">15</td><td align="center" valign="middle" rowspan="1" colspan="1">1.53</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">20</td><td align="center" valign="middle" rowspan="1" colspan="1">2.69</td><td align="center" valign="middle" rowspan="1" colspan="1">10</td><td align="center" valign="middle" rowspan="1" colspan="1">1.56</td><td align="center" valign="middle" rowspan="1" colspan="1">9</td><td align="center" valign="middle" rowspan="1" colspan="1">2.46</td><td align="center" valign="middle" rowspan="1" colspan="1">10</td><td align="center" valign="middle" rowspan="1" colspan="1">2.71</td><td align="center" valign="middle" rowspan="1" colspan="1">16</td><td align="center" valign="middle" rowspan="1" colspan="1">1.57</td><td align="center" valign="middle" rowspan="1" colspan="1">16</td><td align="center" valign="middle" rowspan="1" colspan="1">1.53</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">15</td><td align="center" valign="middle" rowspan="1" colspan="1">1.37</td><td align="center" valign="middle" rowspan="1" colspan="1">16</td><td align="center" valign="middle" rowspan="1" colspan="1">1.56</td><td align="center" valign="middle" rowspan="1" colspan="1">16</td><td align="center" valign="middle" rowspan="1" colspan="1">2.46</td><td align="center" valign="middle" rowspan="1" colspan="1">5</td><td align="center" valign="middle" rowspan="1" colspan="1">1.40</td><td align="center" valign="middle" rowspan="1" colspan="1">20</td><td align="center" valign="middle" rowspan="1" colspan="1">1.57</td><td align="center" valign="middle" rowspan="1" colspan="1">19</td><td align="center" valign="middle" rowspan="1" colspan="1">1.53</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">16</td><td align="center" valign="middle" rowspan="1" colspan="1">1.37</td><td align="center" valign="middle" rowspan="1" colspan="1">17</td><td align="center" valign="middle" rowspan="1" colspan="1">1.56</td><td align="center" valign="middle" rowspan="1" colspan="1">20</td><td align="center" valign="middle" rowspan="1" colspan="1">2.46</td><td align="center" valign="middle" rowspan="1" colspan="1">16</td><td align="center" valign="middle" rowspan="1" colspan="1">1.40</td><td align="center" valign="middle" rowspan="1" colspan="1">11</td><td align="center" valign="middle" rowspan="1" colspan="1">0.00</td><td align="center" valign="middle" rowspan="1" colspan="1">20</td><td align="center" valign="middle" rowspan="1" colspan="1">1.53</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">4</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1.32</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">5</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1.32</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">4</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1.22</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">11</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1.31</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">15</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.00</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">4</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.00</td></tr></tbody></table></table-wrap><table-wrap id="sensors-20-03919-t005" orientation="portrait" position="float"><object-id pub-id-type="pii">sensors-20-03919-t005_Table 5</object-id><label>Table 5</label><caption><p>Results of selection of MRI sequences with perceptual features and <inline-formula><mml:math id="mm357"><mml:mrow><mml:msub><mml:mi>&#x02113;</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>-norm.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">
</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Performance<break/>Measures</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Using All<break/>Sources<break/>(%)</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Applying<break/>Sources<break/>Reduction (%)</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Reduction<break/>Rate</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Relevant<break/>Sequences</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Required<break/>Time<break/>(s)</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Support<break/>Vectors</th></tr></thead><tbody><tr><td rowspan="4" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">
<bold>Algorithm 1</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">Accuracy</td><td align="center" valign="middle" rowspan="1" colspan="1">73.33</td><td align="center" valign="middle" rowspan="1" colspan="1">80.00</td><td rowspan="4" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0.78</td><td rowspan="4" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">P_ADC, P_SUB4</td><td rowspan="4" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0.013</td><td rowspan="4" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">117<break/>(100.0 %)</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Geo-Mean</td><td align="center" valign="middle" rowspan="1" colspan="1">65.91</td><td align="center" valign="middle" rowspan="1" colspan="1">79.59</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Sensitivity</td><td align="center" valign="middle" rowspan="1" colspan="1">94.12</td><td align="center" valign="middle" rowspan="1" colspan="1">82.35</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Specificity</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">46.15</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">76.92</td></tr><tr><td rowspan="4" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">
<bold>Algorithm 2</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">Accuracy</td><td align="center" valign="middle" rowspan="1" colspan="1">80.00</td><td align="center" valign="middle" rowspan="1" colspan="1">93.33</td><td rowspan="4" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0.56</td><td rowspan="4" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">P_SUB2, P_SUB4,<break/>P_SUB3, P_SUB5</td><td rowspan="4" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0.021</td><td rowspan="4" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">97<break/>(82.9 %)</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Geo-Mean</td><td align="center" valign="middle" rowspan="1" colspan="1">76.10</td><td align="center" valign="middle" rowspan="1" colspan="1">93.21</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Sensitivity</td><td align="center" valign="middle" rowspan="1" colspan="1">94.12</td><td align="center" valign="middle" rowspan="1" colspan="1">94.12</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Specificity</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">61.54</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">92.31</td></tr><tr><td rowspan="4" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">
<bold>Algorithm 3</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">Accuracy</td><td align="center" valign="middle" rowspan="1" colspan="1">80.00</td><td align="center" valign="middle" rowspan="1" colspan="1">86.67</td><td rowspan="4" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0.67</td><td rowspan="4" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">P_SUB2, P_SUB5<break/>P_SUB3</td><td rowspan="4" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0.020</td><td rowspan="4" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">97<break/>(82.9 %)</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Geo-Mean</td><td align="center" valign="middle" rowspan="1" colspan="1">76.10</td><td align="center" valign="middle" rowspan="1" colspan="1">85.09</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Sensitivity</td><td align="center" valign="middle" rowspan="1" colspan="1">94.12</td><td align="center" valign="middle" rowspan="1" colspan="1">94.12</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Specificity</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">61.54</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">76.92</td></tr></tbody></table></table-wrap><table-wrap id="sensors-20-03919-t006" orientation="portrait" position="float"><object-id pub-id-type="pii">sensors-20-03919-t006_Table 6</object-id><label>Table 6</label><caption><p>Results of selection of MRI sequences with radiomic features and <inline-formula><mml:math id="mm358"><mml:mrow><mml:msub><mml:mi>&#x02113;</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>-norm.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">
</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Performance<break/>Measures</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Using All<break/>Sources<break/>(%)</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Applying<break/>Sources<break/>Reduction (%)</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Reduction<break/>Rate</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Relevant<break/>Sequences</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Required<break/>Time<break/>(s)</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Support<break/>Vectors</th></tr></thead><tbody><tr><td rowspan="4" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">
<bold>Algorithm 1</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">Accuracy</td><td align="center" valign="middle" rowspan="1" colspan="1">82.76</td><td align="center" valign="middle" rowspan="1" colspan="1">86.21</td><td rowspan="4" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0.33</td><td rowspan="4" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">R_T2, R_T1<break/>R_DWI, R_SUB3<break/>R_SUB5, R_SUB4</td><td rowspan="4" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0.073</td><td rowspan="4" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">117<break/>(100.0 %)</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Geo-Mean</td><td align="center" valign="middle" rowspan="1" colspan="1">84.02</td><td align="center" valign="middle" rowspan="1" colspan="1">87.45</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Sensitivity</td><td align="center" valign="middle" rowspan="1" colspan="1">70.59</td><td align="center" valign="middle" rowspan="1" colspan="1">76.47</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Specificity</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">100.00</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">100.00</td></tr><tr><td rowspan="4" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">
<bold>Algorithm 2</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">Accuracy</td><td align="center" valign="middle" rowspan="1" colspan="1">79.31</td><td align="center" valign="middle" rowspan="1" colspan="1">89.66</td><td rowspan="4" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0.33</td><td rowspan="4" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">R_T1, R_DWI<break/>R_SUB3, R_T2<break/>R_SUB4, R_SUB5</td><td rowspan="4" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0.063</td><td rowspan="4" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">81<break/>(69.2 %)</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Geo-Mean</td><td align="center" valign="middle" rowspan="1" colspan="1">80.44</td><td align="center" valign="middle" rowspan="1" colspan="1">90.75</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Sensitivity</td><td align="center" valign="middle" rowspan="1" colspan="1">64.71</td><td align="center" valign="middle" rowspan="1" colspan="1">82.35</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Specificity</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">100.00</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">100.00</td></tr><tr><td rowspan="4" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">
<bold>Algorithm 3</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">Accuracy</td><td align="center" valign="middle" rowspan="1" colspan="1">86.21</td><td align="center" valign="middle" rowspan="1" colspan="1">89.66</td><td rowspan="4" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0.22</td><td rowspan="4" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">R_T1, R_DWI<break/>R_SUB3, R_T2<break/>R_SUB5, R_SUB4<break/>R_SUB2</td><td rowspan="4" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0.113</td><td rowspan="4" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">92<break/>(78.6 %)</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Geo-Mean</td><td align="center" valign="middle" rowspan="1" colspan="1">87.45</td><td align="center" valign="middle" rowspan="1" colspan="1">90.75</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Sensitivity</td><td align="center" valign="middle" rowspan="1" colspan="1">76.47</td><td align="center" valign="middle" rowspan="1" colspan="1">82.35</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Specificity</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">100.00</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">100.00</td></tr></tbody></table></table-wrap><table-wrap id="sensors-20-03919-t007" orientation="portrait" position="float"><object-id pub-id-type="pii">sensors-20-03919-t007_Table 7</object-id><label>Table 7</label><caption><p>Results of selection of MRI sequences with perceptual and radiomic features with <inline-formula><mml:math id="mm359"><mml:mrow><mml:msub><mml:mi>&#x02113;</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>-norm.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">
</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Performance<break/>Measures</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Using All<break/> Sources<break/>(%)</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Applying<break/>Sources<break/>Reduction (%)</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Reduction<break/>Rate</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Relevant<break/>Sequences</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Required<break/>Time<break/>(s)</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Support<break/>Vectors</th></tr></thead><tbody><tr><td rowspan="4" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">
<bold>Algorithm 1</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">Accuracy</td><td align="center" valign="middle" rowspan="1" colspan="1">76.67</td><td align="center" valign="middle" rowspan="1" colspan="1">86.67</td><td rowspan="4" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0.72</td><td rowspan="4" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">P_SUB2, P_SUB5<break/>P_SUB4, P_SUB3<break/>R_SUB3</td><td rowspan="4" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0.033</td><td rowspan="4" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">117<break/>(100.0 %)</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Geo-Mean</td><td align="center" valign="middle" rowspan="1" colspan="1">75.51</td><td align="center" valign="middle" rowspan="1" colspan="1">85.09</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Sensitivity</td><td align="center" valign="middle" rowspan="1" colspan="1">82.35</td><td align="center" valign="middle" rowspan="1" colspan="1">94.12</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Specificity</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">69.23</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">76.92</td></tr><tr><td rowspan="4" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">
<bold>Algorithm 2</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">Accuracy</td><td align="center" valign="middle" rowspan="1" colspan="1">76.67</td><td align="center" valign="middle" rowspan="1" colspan="1">90.00</td><td rowspan="4" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0.67</td><td rowspan="4" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">P_SUB2, P_SUB5<break/>P_SUB4, P_SUB3<break/>R_SUB3, R_SUB5</td><td rowspan="4" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0.039</td><td rowspan="4" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">97<break/>(82.9 %)</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Geo-Mean</td><td align="center" valign="middle" rowspan="1" colspan="1">75.51</td><td align="center" valign="middle" rowspan="1" colspan="1">89.24</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Sensitivity</td><td align="center" valign="middle" rowspan="1" colspan="1">82.35</td><td align="center" valign="middle" rowspan="1" colspan="1">94.12</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Specificity</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">69.23</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">84.62</td></tr><tr><td rowspan="4" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">
<bold>Algorithm 3</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">Accuracy</td><td align="center" valign="middle" rowspan="1" colspan="1">76.67</td><td align="center" valign="middle" rowspan="1" colspan="1">90.00</td><td rowspan="4" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0.67</td><td rowspan="4" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">P_SUB2, P_SUB5<break/>P_SUB4, P_SUB3<break/>R_SUB3, R_SUB5</td><td rowspan="4" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0.051</td><td rowspan="4" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">97<break/>(82.9 %)</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Geo-Mean</td><td align="center" valign="middle" rowspan="1" colspan="1">75.51</td><td align="center" valign="middle" rowspan="1" colspan="1">89.24</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Sensitivity</td><td align="center" valign="middle" rowspan="1" colspan="1">82.35</td><td align="center" valign="middle" rowspan="1" colspan="1">94.12</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Specificity</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">69.23</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">84.62</td></tr></tbody></table></table-wrap><table-wrap id="sensors-20-03919-t008" orientation="portrait" position="float"><object-id pub-id-type="pii">sensors-20-03919-t008_Table 8</object-id><label>Table 8</label><caption><p>Comparison of results applying feature selection by Fisher Score technique over the BCI data before and after the source reduction process.</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="3" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" colspan="1">Subject</th><th colspan="4" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">Feature Selection over All Information Sources</th><th colspan="4" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">Feature Selection After Reduce Information Sources</th></tr><tr><th colspan="2" align="center" valign="middle" style="border-bottom:solid thin" rowspan="1">Accuracy</th><th rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">Minimal<break/>Required<break/>Features</th><th rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">Reduction<break/>Rate<break/>(by Sources)</th><th colspan="2" align="center" valign="middle" style="border-bottom:solid thin" rowspan="1">Accuracy</th><th rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">Minimal<break/>Required<break/>Features</th><th rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">Reduction<break/>Rate<break/>(by Sources)</th></tr><tr><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">With<break/>All Features</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Reducing<break/>Features</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">With<break/>All Features</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Reducing<break/>Features</th></tr></thead><tbody><tr><td colspan="9" align="center" valign="middle" style="border-bottom:solid thin" rowspan="1">
<bold>Algorithm 1</bold>
</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>1</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">64.29</td><td align="center" valign="middle" rowspan="1" colspan="1">85.71</td><td align="center" valign="middle" rowspan="1" colspan="1">280</td><td align="center" valign="middle" rowspan="1" colspan="1">0.00</td><td align="center" valign="middle" rowspan="1" colspan="1">75.00</td><td align="center" valign="middle" rowspan="1" colspan="1">85.71</td><td align="center" valign="middle" rowspan="1" colspan="1">362</td><td align="center" valign="middle" rowspan="1" colspan="1">0.14</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>2</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">53.33</td><td align="center" valign="middle" rowspan="1" colspan="1">76.67</td><td align="center" valign="middle" rowspan="1" colspan="1">667</td><td align="center" valign="middle" rowspan="1" colspan="1">0.00</td><td align="center" valign="middle" rowspan="1" colspan="1">76.67</td><td align="center" valign="middle" rowspan="1" colspan="1">73.33</td><td align="center" valign="middle" rowspan="1" colspan="1">44</td><td align="center" valign="middle" rowspan="1" colspan="1">0.59</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>3</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">60.71</td><td align="center" valign="middle" rowspan="1" colspan="1">92.86</td><td align="center" valign="middle" rowspan="1" colspan="1">20</td><td align="center" valign="middle" rowspan="1" colspan="1">0.68</td><td align="center" valign="middle" rowspan="1" colspan="1">89.29</td><td align="center" valign="middle" rowspan="1" colspan="1">92.86</td><td align="center" valign="middle" rowspan="1" colspan="1">22</td><td align="center" valign="middle" rowspan="1" colspan="1">0.91</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>4</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">57.14</td><td align="center" valign="middle" rowspan="1" colspan="1">75.00</td><td align="center" valign="middle" rowspan="1" colspan="1">207</td><td align="center" valign="middle" rowspan="1" colspan="1">0.00</td><td align="center" valign="middle" rowspan="1" colspan="1">75.00</td><td align="center" valign="middle" rowspan="1" colspan="1">89.29</td><td align="center" valign="middle" rowspan="1" colspan="1">23</td><td align="center" valign="middle" rowspan="1" colspan="1">0.91</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>5</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">60.00</td><td align="center" valign="middle" rowspan="1" colspan="1">70.00</td><td align="center" valign="middle" rowspan="1" colspan="1">130</td><td align="center" valign="middle" rowspan="1" colspan="1">0.00</td><td align="center" valign="middle" rowspan="1" colspan="1">63.33</td><td align="center" valign="middle" rowspan="1" colspan="1">76.67</td><td align="center" valign="middle" rowspan="1" colspan="1">69</td><td align="center" valign="middle" rowspan="1" colspan="1">0.82</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>6</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">63.33</td><td align="center" valign="middle" rowspan="1" colspan="1">80.00</td><td align="center" valign="middle" rowspan="1" colspan="1">3</td><td align="center" valign="middle" rowspan="1" colspan="1">0.95</td><td align="center" valign="middle" rowspan="1" colspan="1">70.00</td><td align="center" valign="middle" rowspan="1" colspan="1">80.00</td><td align="center" valign="middle" rowspan="1" colspan="1">3</td><td align="center" valign="middle" rowspan="1" colspan="1">0.95</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>7</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">46.43</td><td align="center" valign="middle" rowspan="1" colspan="1">67.86</td><td align="center" valign="middle" rowspan="1" colspan="1">25</td><td align="center" valign="middle" rowspan="1" colspan="1">0.50</td><td align="center" valign="middle" rowspan="1" colspan="1">67.86</td><td align="center" valign="middle" rowspan="1" colspan="1">64.29</td><td align="center" valign="middle" rowspan="1" colspan="1">1</td><td align="center" valign="middle" rowspan="1" colspan="1">0.95</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>8</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">75.00</td><td align="center" valign="middle" rowspan="1" colspan="1">82.14</td><td align="center" valign="middle" rowspan="1" colspan="1">52</td><td align="center" valign="middle" rowspan="1" colspan="1">0.50</td><td align="center" valign="middle" rowspan="1" colspan="1">85.71</td><td align="center" valign="middle" rowspan="1" colspan="1">85.71</td><td align="center" valign="middle" rowspan="1" colspan="1">119</td><td align="center" valign="middle" rowspan="1" colspan="1">0.82</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>9</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">71.43</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">78.57</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">767</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.00</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">78.57</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">75.00</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">83</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.27</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>Average</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm360"><mml:mrow><mml:mrow><mml:mn>61</mml:mn><mml:mo>.</mml:mo><mml:mn>30</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
<break/>
<inline-formula><mml:math id="mm361"><mml:mrow><mml:mrow><mml:mo>&#x000b1;</mml:mo><mml:mn>8</mml:mn><mml:mo>.</mml:mo><mml:mn>71</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm362"><mml:mrow><mml:mrow><mml:mn>78</mml:mn><mml:mo>.</mml:mo><mml:mn>76</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
<break/>
<inline-formula><mml:math id="mm363"><mml:mrow><mml:mrow><mml:mo>&#x000b1;</mml:mo><mml:mn>7</mml:mn><mml:mo>.</mml:mo><mml:mn>70</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm364"><mml:mrow><mml:mrow><mml:mn>239</mml:mn><mml:mo>.</mml:mo><mml:mn>00</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
<break/>
<inline-formula><mml:math id="mm365"><mml:mrow><mml:mrow><mml:mo>&#x000b1;</mml:mo><mml:mn>287</mml:mn><mml:mo>.</mml:mo><mml:mn>44</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm366"><mml:mrow><mml:mrow><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:mn>29</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
<break/>
<inline-formula><mml:math id="mm367"><mml:mrow><mml:mrow><mml:mo>&#x000b1;</mml:mo><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:mn>37</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm368"><mml:mrow><mml:mrow><mml:mn>75</mml:mn><mml:mo>.</mml:mo><mml:mn>71</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
<break/>
<inline-formula><mml:math id="mm369"><mml:mrow><mml:mrow><mml:mo>&#x000b1;</mml:mo><mml:mn>8</mml:mn><mml:mo>.</mml:mo><mml:mn>23</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm370"><mml:mrow><mml:mrow><mml:mn>80</mml:mn><mml:mo>.</mml:mo><mml:mn>32</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
<break/>
<inline-formula><mml:math id="mm371"><mml:mrow><mml:mrow><mml:mo>&#x000b1;</mml:mo><mml:mn>8</mml:mn><mml:mo>.</mml:mo><mml:mn>97</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm372"><mml:mrow><mml:mrow><mml:mn>80</mml:mn><mml:mo>.</mml:mo><mml:mn>67</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
<break/>
<inline-formula><mml:math id="mm373"><mml:mrow><mml:mrow><mml:mo>&#x000b1;</mml:mo><mml:mn>112</mml:mn><mml:mo>.</mml:mo><mml:mn>50</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm374"><mml:mrow><mml:mrow><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:mn>71</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
<break/>
<inline-formula><mml:math id="mm375"><mml:mrow><mml:mrow><mml:mo>&#x000b1;</mml:mo><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:mn>31</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
</td></tr><tr><td colspan="9" align="center" valign="middle" style="border-bottom:solid thin" rowspan="1">
<bold>Algorithm 2</bold>
</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>1</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">67.86</td><td align="center" valign="middle" rowspan="1" colspan="1">85.71</td><td align="center" valign="middle" rowspan="1" colspan="1">243</td><td align="center" valign="middle" rowspan="1" colspan="1">0.00</td><td align="center" valign="middle" rowspan="1" colspan="1">75.00</td><td align="center" valign="middle" rowspan="1" colspan="1">85.71</td><td align="center" valign="middle" rowspan="1" colspan="1">300</td><td align="center" valign="middle" rowspan="1" colspan="1">0.50</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>2</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">66.67</td><td align="center" valign="middle" rowspan="1" colspan="1">73.33</td><td align="center" valign="middle" rowspan="1" colspan="1">166</td><td align="center" valign="middle" rowspan="1" colspan="1">0.00</td><td align="center" valign="middle" rowspan="1" colspan="1">66.67</td><td align="center" valign="middle" rowspan="1" colspan="1">70.00</td><td align="center" valign="middle" rowspan="1" colspan="1">389</td><td align="center" valign="middle" rowspan="1" colspan="1">0.36</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>3</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">71.43</td><td align="center" valign="middle" rowspan="1" colspan="1">96.43</td><td align="center" valign="middle" rowspan="1" colspan="1">2</td><td align="center" valign="middle" rowspan="1" colspan="1">0.91</td><td align="center" valign="middle" rowspan="1" colspan="1">75.00</td><td align="center" valign="middle" rowspan="1" colspan="1">96.43</td><td align="center" valign="middle" rowspan="1" colspan="1">2</td><td align="center" valign="middle" rowspan="1" colspan="1">0.91</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>4</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">46.43</td><td align="center" valign="middle" rowspan="1" colspan="1">75.00</td><td align="center" valign="middle" rowspan="1" colspan="1">201</td><td align="center" valign="middle" rowspan="1" colspan="1">0.00</td><td align="center" valign="middle" rowspan="1" colspan="1">78.57</td><td align="center" valign="middle" rowspan="1" colspan="1">85.71</td><td align="center" valign="middle" rowspan="1" colspan="1">20</td><td align="center" valign="middle" rowspan="1" colspan="1">0.91</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>5</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">56.67</td><td align="center" valign="middle" rowspan="1" colspan="1">70.00</td><td align="center" valign="middle" rowspan="1" colspan="1">281</td><td align="center" valign="middle" rowspan="1" colspan="1">0.00</td><td align="center" valign="middle" rowspan="1" colspan="1">66.67</td><td align="center" valign="middle" rowspan="1" colspan="1">73.33</td><td align="center" valign="middle" rowspan="1" colspan="1">163</td><td align="center" valign="middle" rowspan="1" colspan="1">0.77</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>6</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">70.00</td><td align="center" valign="middle" rowspan="1" colspan="1">83.33</td><td align="center" valign="middle" rowspan="1" colspan="1">420</td><td align="center" valign="middle" rowspan="1" colspan="1">0.00</td><td align="center" valign="middle" rowspan="1" colspan="1">76.67</td><td align="center" valign="middle" rowspan="1" colspan="1">80.00</td><td align="center" valign="middle" rowspan="1" colspan="1">88</td><td align="center" valign="middle" rowspan="1" colspan="1">0.55</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>7</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">46.43</td><td align="center" valign="middle" rowspan="1" colspan="1">67.86</td><td align="center" valign="middle" rowspan="1" colspan="1">35</td><td align="center" valign="middle" rowspan="1" colspan="1">0.41</td><td align="center" valign="middle" rowspan="1" colspan="1">67.86</td><td align="center" valign="middle" rowspan="1" colspan="1">64.29</td><td align="center" valign="middle" rowspan="1" colspan="1">32</td><td align="center" valign="middle" rowspan="1" colspan="1">0.91</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>8</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">67.86</td><td align="center" valign="middle" rowspan="1" colspan="1">82.14</td><td align="center" valign="middle" rowspan="1" colspan="1">62</td><td align="center" valign="middle" rowspan="1" colspan="1">0.36</td><td align="center" valign="middle" rowspan="1" colspan="1">82.14</td><td align="center" valign="middle" rowspan="1" colspan="1">85.71</td><td align="center" valign="middle" rowspan="1" colspan="1">25</td><td align="center" valign="middle" rowspan="1" colspan="1">0.86</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>9</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">71.43</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">78.57</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">445</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.00</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">78.57</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">75.00</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">26</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.73</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>Average</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm376"><mml:mrow><mml:mrow><mml:mn>62</mml:mn><mml:mo>.</mml:mo><mml:mn>75</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
<break/>
<inline-formula><mml:math id="mm377"><mml:mrow><mml:mrow><mml:mo>&#x000b1;</mml:mo><mml:mn>10</mml:mn><mml:mo>.</mml:mo><mml:mn>25</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm378"><mml:mrow><mml:mrow><mml:mn>79</mml:mn><mml:mo>.</mml:mo><mml:mn>15</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
<break/>
<inline-formula><mml:math id="mm379"><mml:mrow><mml:mrow><mml:mo>&#x000b1;</mml:mo><mml:mn>8</mml:mn><mml:mo>.</mml:mo><mml:mn>88</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm380"><mml:mrow><mml:mrow><mml:mn>206</mml:mn><mml:mo>.</mml:mo><mml:mn>11</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
<break/>
<inline-formula><mml:math id="mm381"><mml:mrow><mml:mrow><mml:mo>&#x000b1;</mml:mo><mml:mn>159</mml:mn><mml:mo>.</mml:mo><mml:mn>35</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm382"><mml:mrow><mml:mrow><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:mn>19</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
<break/>
<inline-formula><mml:math id="mm383"><mml:mrow><mml:mrow><mml:mo>&#x000b1;</mml:mo><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:mn>32</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm384"><mml:mrow><mml:mrow><mml:mn>74</mml:mn><mml:mo>.</mml:mo><mml:mn>13</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
<break/>
<inline-formula><mml:math id="mm385"><mml:mrow><mml:mrow><mml:mo>&#x000b1;</mml:mo><mml:mn>5</mml:mn><mml:mo>.</mml:mo><mml:mn>73</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm386"><mml:mrow><mml:mrow><mml:mn>79</mml:mn><mml:mo>.</mml:mo><mml:mn>58</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
<break/>
<inline-formula><mml:math id="mm387"><mml:mrow><mml:mrow><mml:mo>&#x000b1;</mml:mo><mml:mn>9</mml:mn><mml:mo>.</mml:mo><mml:mn>89</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm388"><mml:mrow><mml:mrow><mml:mn>116</mml:mn><mml:mo>.</mml:mo><mml:mn>11</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
<break/>
<inline-formula><mml:math id="mm389"><mml:mrow><mml:mrow><mml:mo>&#x000b1;</mml:mo><mml:mn>140</mml:mn><mml:mo>.</mml:mo><mml:mn>10</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm390"><mml:mrow><mml:mrow><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:mn>72</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
<break/>
<inline-formula><mml:math id="mm391"><mml:mrow><mml:mrow><mml:mo>&#x000b1;</mml:mo><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:mn>21</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
</td></tr><tr><td colspan="9" align="center" valign="middle" style="border-bottom:solid thin" rowspan="1">
<bold>Algorithm 3</bold>
</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>1</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">67.86</td><td align="center" valign="middle" rowspan="1" colspan="1">85.71</td><td align="center" valign="middle" rowspan="1" colspan="1">244</td><td align="center" valign="middle" rowspan="1" colspan="1">0.00</td><td align="center" valign="middle" rowspan="1" colspan="1">78.57</td><td align="center" valign="middle" rowspan="1" colspan="1">78.57</td><td align="center" valign="middle" rowspan="1" colspan="1">97</td><td align="center" valign="middle" rowspan="1" colspan="1">0.77</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>2</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">63.33</td><td align="center" valign="middle" rowspan="1" colspan="1">70.00</td><td align="center" valign="middle" rowspan="1" colspan="1">167</td><td align="center" valign="middle" rowspan="1" colspan="1">0.00</td><td align="center" valign="middle" rowspan="1" colspan="1">63.33</td><td align="center" valign="middle" rowspan="1" colspan="1">70.00</td><td align="center" valign="middle" rowspan="1" colspan="1">155</td><td align="center" valign="middle" rowspan="1" colspan="1">0.05</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>3</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">64.29</td><td align="center" valign="middle" rowspan="1" colspan="1">89.29</td><td align="center" valign="middle" rowspan="1" colspan="1">2</td><td align="center" valign="middle" rowspan="1" colspan="1">0.91</td><td align="center" valign="middle" rowspan="1" colspan="1">82.14</td><td align="center" valign="middle" rowspan="1" colspan="1">96.43</td><td align="center" valign="middle" rowspan="1" colspan="1">58</td><td align="center" valign="middle" rowspan="1" colspan="1">0.91</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>4</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">50.00</td><td align="center" valign="middle" rowspan="1" colspan="1">67.86</td><td align="center" valign="middle" rowspan="1" colspan="1">2</td><td align="center" valign="middle" rowspan="1" colspan="1">0.91</td><td align="center" valign="middle" rowspan="1" colspan="1">71.43</td><td align="center" valign="middle" rowspan="1" colspan="1">82.14</td><td align="center" valign="middle" rowspan="1" colspan="1">7</td><td align="center" valign="middle" rowspan="1" colspan="1">0.91</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>5</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">56.67</td><td align="center" valign="middle" rowspan="1" colspan="1">73.33</td><td align="center" valign="middle" rowspan="1" colspan="1">281</td><td align="center" valign="middle" rowspan="1" colspan="1">0.00</td><td align="center" valign="middle" rowspan="1" colspan="1">66.67</td><td align="center" valign="middle" rowspan="1" colspan="1">73.33</td><td align="center" valign="middle" rowspan="1" colspan="1">163</td><td align="center" valign="middle" rowspan="1" colspan="1">0.77</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>6</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">66.67</td><td align="center" valign="middle" rowspan="1" colspan="1">83.33</td><td align="center" valign="middle" rowspan="1" colspan="1">420</td><td align="center" valign="middle" rowspan="1" colspan="1">0.00</td><td align="center" valign="middle" rowspan="1" colspan="1">73.33</td><td align="center" valign="middle" rowspan="1" colspan="1">80.00</td><td align="center" valign="middle" rowspan="1" colspan="1">10</td><td align="center" valign="middle" rowspan="1" colspan="1">0.82</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>7</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">60.71</td><td align="center" valign="middle" rowspan="1" colspan="1">71.43</td><td align="center" valign="middle" rowspan="1" colspan="1">655</td><td align="center" valign="middle" rowspan="1" colspan="1">0.00</td><td align="center" valign="middle" rowspan="1" colspan="1">64.29</td><td align="center" valign="middle" rowspan="1" colspan="1">64.29</td><td align="center" valign="middle" rowspan="1" colspan="1">32</td><td align="center" valign="middle" rowspan="1" colspan="1">0.91</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>8</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">67.86</td><td align="center" valign="middle" rowspan="1" colspan="1">82.14</td><td align="center" valign="middle" rowspan="1" colspan="1">5</td><td align="center" valign="middle" rowspan="1" colspan="1">0.95</td><td align="center" valign="middle" rowspan="1" colspan="1">82.14</td><td align="center" valign="middle" rowspan="1" colspan="1">82.14</td><td align="center" valign="middle" rowspan="1" colspan="1">5</td><td align="center" valign="middle" rowspan="1" colspan="1">0.95</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>9</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">71.43</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">78.57</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">445</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.00</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">71.43</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">78.57</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">184</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.73</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>Average</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm392"><mml:mrow><mml:mrow><mml:mn>63</mml:mn><mml:mo>.</mml:mo><mml:mn>20</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
<break/>
<inline-formula><mml:math id="mm393"><mml:mrow><mml:mrow><mml:mo>&#x000b1;</mml:mo><mml:mn>6</mml:mn><mml:mo>.</mml:mo><mml:mn>59</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm394"><mml:mrow><mml:mrow><mml:mn>77</mml:mn><mml:mo>.</mml:mo><mml:mn>96</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
<break/>
<inline-formula><mml:math id="mm395"><mml:mrow><mml:mrow><mml:mo>&#x000b1;</mml:mo><mml:mn>7</mml:mn><mml:mo>.</mml:mo><mml:mn>62</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm396"><mml:mrow><mml:mrow><mml:mn>246</mml:mn><mml:mo>.</mml:mo><mml:mn>78</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
<break/>
<inline-formula><mml:math id="mm397"><mml:mrow><mml:mrow><mml:mo>&#x000b1;</mml:mo><mml:mn>229</mml:mn><mml:mo>.</mml:mo><mml:mn>61</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm398"><mml:mrow><mml:mrow><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:mn>31</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
<break/>
<inline-formula><mml:math id="mm399"><mml:mrow><mml:mrow><mml:mo>&#x000b1;</mml:mo><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:mn>46</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm400"><mml:mrow><mml:mrow><mml:mn>72</mml:mn><mml:mo>.</mml:mo><mml:mn>59</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
<break/>
<inline-formula><mml:math id="mm401"><mml:mrow><mml:mrow><mml:mo>&#x000b1;</mml:mo><mml:mn>7</mml:mn><mml:mo>.</mml:mo><mml:mn>17</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm402"><mml:mrow><mml:mrow><mml:mn>78</mml:mn><mml:mo>.</mml:mo><mml:mn>39</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
<break/>
<inline-formula><mml:math id="mm403"><mml:mrow><mml:mrow><mml:mo>&#x000b1;</mml:mo><mml:mn>9</mml:mn><mml:mo>.</mml:mo><mml:mn>02</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm404"><mml:mrow><mml:mrow><mml:mn>79</mml:mn><mml:mo>.</mml:mo><mml:mn>00</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
<break/>
<inline-formula><mml:math id="mm405"><mml:mrow><mml:mrow><mml:mo>&#x000b1;</mml:mo><mml:mn>72</mml:mn><mml:mo>.</mml:mo><mml:mn>67</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm406"><mml:mrow><mml:mrow><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:mn>76</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
<break/>
<inline-formula><mml:math id="mm407"><mml:mrow><mml:mrow><mml:mo>&#x000b1;</mml:mo><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:mn>28</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
</td></tr></tbody></table></table-wrap><table-wrap id="sensors-20-03919-t009" orientation="portrait" position="float"><object-id pub-id-type="pii">sensors-20-03919-t009_Table 9</object-id><label>Table 9</label><caption><p>Comparison of results applying feature selection by Fisher Score technique over the MRI data before and after the source reduction process.</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="3" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" colspan="1">Algorithm</th><th colspan="4" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">Feature Selection Over All Information Sources</th><th colspan="4" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">Feature Selection after Reduce Information Sources</th></tr><tr><th colspan="2" align="center" valign="middle" style="border-bottom:solid thin" rowspan="1">Accuracy</th><th rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">Minimal<break/>Required<break/>Features</th><th rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">Reduction<break/>Rate<break/>(by Sources)</th><th colspan="2" align="center" valign="middle" style="border-bottom:solid thin" rowspan="1">Accuracy</th><th rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">Minimal<break/>Required<break/>Features</th><th rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">Reduction<break/>Rate<break/>(by Sources)</th></tr><tr><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">With<break/>All Features</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Reducing<break/>Features</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">With<break/>All Features</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Reducing<break/>Features</th></tr></thead><tbody><tr><td colspan="9" align="center" valign="middle" style="border-bottom:solid thin" rowspan="1">
<bold>Perceptual Features</bold>
</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>1</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">73.33</td><td align="center" valign="middle" rowspan="1" colspan="1">83.33</td><td align="center" valign="middle" rowspan="1" colspan="1">26</td><td align="center" valign="middle" rowspan="1" colspan="1">0.11</td><td align="center" valign="middle" rowspan="1" colspan="1">80.00</td><td align="center" valign="middle" rowspan="1" colspan="1">80.00</td><td align="center" valign="middle" rowspan="1" colspan="1">7</td><td align="center" valign="middle" rowspan="1" colspan="1">0.78</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>2</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">80.00</td><td align="center" valign="middle" rowspan="1" colspan="1">90.00</td><td align="center" valign="middle" rowspan="1" colspan="1">48</td><td align="center" valign="middle" rowspan="1" colspan="1">0.00</td><td align="center" valign="middle" rowspan="1" colspan="1">93.33</td><td align="center" valign="middle" rowspan="1" colspan="1">93.33</td><td align="center" valign="middle" rowspan="1" colspan="1">26</td><td align="center" valign="middle" rowspan="1" colspan="1">0.56</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>3</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">80.00</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">86.67</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">23</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.22</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">86.67</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">90.00</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">15</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.67</td></tr><tr><td colspan="9" align="center" valign="middle" style="border-bottom:solid thin" rowspan="1">
<bold>Radiomic Features</bold>
</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>1</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">82.76</td><td align="center" valign="middle" rowspan="1" colspan="1">96.55</td><td align="center" valign="middle" rowspan="1" colspan="1">179</td><td align="center" valign="middle" rowspan="1" colspan="1">0.00</td><td align="center" valign="middle" rowspan="1" colspan="1">86.21</td><td align="center" valign="middle" rowspan="1" colspan="1">93.10</td><td align="center" valign="middle" rowspan="1" colspan="1">171</td><td align="center" valign="middle" rowspan="1" colspan="1">0.33</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>2</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">79.31</td><td align="center" valign="middle" rowspan="1" colspan="1">96.55</td><td align="center" valign="middle" rowspan="1" colspan="1">173</td><td align="center" valign="middle" rowspan="1" colspan="1">0.00</td><td align="center" valign="middle" rowspan="1" colspan="1">89.66</td><td align="center" valign="middle" rowspan="1" colspan="1">93.10</td><td align="center" valign="middle" rowspan="1" colspan="1">174</td><td align="center" valign="middle" rowspan="1" colspan="1">0.33</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>3</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">86.21</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">96.55</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">179</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.00</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">89.66</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">93.10</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">269</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.22</td></tr><tr><td colspan="9" align="center" valign="middle" style="border-bottom:solid thin" rowspan="1">
<bold>Perceptual and Radiomic Features</bold>
</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>1</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">76.67</td><td align="center" valign="middle" rowspan="1" colspan="1">90.00</td><td align="center" valign="middle" rowspan="1" colspan="1">302</td><td align="center" valign="middle" rowspan="1" colspan="1">0.00</td><td align="center" valign="middle" rowspan="1" colspan="1">86.67</td><td align="center" valign="middle" rowspan="1" colspan="1">90.00</td><td align="center" valign="middle" rowspan="1" colspan="1">43</td><td align="center" valign="middle" rowspan="1" colspan="1">0.72</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>2</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">76.67</td><td align="center" valign="middle" rowspan="1" colspan="1">90.00</td><td align="center" valign="middle" rowspan="1" colspan="1">526</td><td align="center" valign="middle" rowspan="1" colspan="1">0.00</td><td align="center" valign="middle" rowspan="1" colspan="1">90.00</td><td align="center" valign="middle" rowspan="1" colspan="1">90.00</td><td align="center" valign="middle" rowspan="1" colspan="1">124</td><td align="center" valign="middle" rowspan="1" colspan="1">0.67</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>3</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">76.67</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">90.00</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">526</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.00</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">90.00</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">90.00</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">125</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.67</td></tr></tbody></table></table-wrap></floats-group></article>