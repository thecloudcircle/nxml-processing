
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">Curr Med Imaging Rev</journal-id><journal-id journal-id-type="iso-abbrev">Curr Med Imaging Rev</journal-id><journal-id journal-id-type="publisher-id">CMIR</journal-id><journal-title-group><journal-title>Current Medical Imaging Reviews</journal-title></journal-title-group><issn pub-type="ppub">1573-4056</issn><issn pub-type="epub">1875-6603</issn><publisher><publisher-name>Bentham Science Publishers</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">24772060</article-id><article-id pub-id-type="pmc">3996917</article-id><article-id pub-id-type="publisher-id">CMIR-9-318</article-id><article-id pub-id-type="doi">10.2174/15734056113096660006</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Acoustic Inversion in Optoacoustic Tomography: A Review</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Rosenthal</surname><given-names>Amir</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="corresp" rid="cor1">*</xref></contrib><contrib contrib-type="author"><name><surname>Ntziachristos</surname><given-names>Vasilis</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref></contrib><contrib contrib-type="author"><name><surname>Razansky</surname><given-names>Daniel</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref></contrib></contrib-group><aff id="aff1"><label>1</label>Institute for Biological and Medical Imaging, Helmholtz Zentrum M&#x000fc;nchen, Ingoldst&#x000e4;dter Landstra&#x000df;e 1, Neuherberg 85764, Germay;</aff><aff id="aff2"><label>2</label>Chair for Biological Imaging, Technische Universit&#x000e4;t M&#x000fc;nchen, Ismaninger Str. 22, M&#x000fc;nchen 81675, Germany</aff><author-notes><corresp id="cor1"><label>*</label>Address correspondence to this author at the Institute for Biological and
Medical Imaging, Helmholtz Zentrum M&#x000fc;nchen, Ingoldst&#x000e4;dter Landstra&#x000df;e
1, Neuherberg 85764, Germay and Chair for Biological Imaging, Technische
Universit&#x000e4;t M&#x000fc;nchen, Ismaninger Str. 22, M&#x000fc;nchen 81675, Germany;
Tel: +49 (0) 89 3187 3850; Fax: +49 (0) 89 3187 3017;
E-mail: <email xlink:href="eeamir@tum.de">eeamir@tum.de</email></corresp></author-notes><pub-date pub-type="epub"><month>11</month><year>2013</year></pub-date><pub-date pub-type="ppub"><month>11</month><year>2013</year></pub-date><volume>9</volume><issue>4</issue><fpage>318</fpage><lpage>336</lpage><history><date date-type="received"><day>24</day><month>5</month><year>2013</year></date><date date-type="rev-recd"><day>19</day><month>6</month><year>2013</year></date><date date-type="accepted"><day>24</day><month>6</month><year>2013</year></date></history><permissions><copyright-statement>&#x000a9;2013 Bentham Science Publishers</copyright-statement><copyright-year>2013</copyright-year><copyright-holder>Bentham Science Publishers</copyright-holder><license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/2.5/"><license-p>This is an open access article distributed under the terms of the Creative Commons Attribution License (<uri xlink:type="simple" xlink:href="http://creativecommons.org/licenses/by/2.5/">http://creativecommons.org/licenses/by/2.5/</uri>), which permits unrestrictive use, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p></license></permissions><abstract><p>Optoacoustic tomography enables volumetric imaging with optical contrast in biological tissue at depths beyond
the optical mean free path by the use of optical excitation and acoustic detection. The hybrid nature of optoacoustic
tomography gives rise to two distinct inverse problems: The optical inverse problem, related to the propagation of the excitation
light in tissue, and the acoustic inverse problem, which deals with the propagation and detection of the generated
acoustic waves. Since the two inverse problems have different physical underpinnings and are governed by different types
of equations, they are often treated independently as unrelated problems. From an imaging standpoint, the acoustic inverse
problem relates to forming an image from the measured acoustic data, whereas the optical inverse problem relates to
quantifying the formed image. This review focuses on the acoustic aspects of optoacoustic tomography, specifically
acoustic reconstruction algorithms and imaging-system practicalities. As these two aspects are intimately linked, and no
silver bullet exists in the path towards high-performance imaging, we adopt a holistic approach in our review and discuss
the many links between the two aspects. Four classes of reconstruction algorithms are reviewed: time-domain (so called
back-projection) formulae, frequency-domain formulae, time-reversal algorithms, and model-based algorithms. These algorithms
are discussed in the context of the various acoustic detectors and detection surfaces which are commonly used in
experimental studies. We further discuss the effects of non-ideal imaging scenarios on the quality of reconstruction and
review methods that can mitigate these effects. Namely, we consider the cases of finite detector aperture, limited-view
tomography, spatial under-sampling of the acoustic signals, and acoustic heterogeneities and losses.</p></abstract><kwd-group><title>Keywords</title><kwd>Optoacoustic imaging</kwd><kwd>photoacoustic imaging</kwd><kwd>tomography</kwd><kwd>inverse problems</kwd><kwd>ultrasound detectors</kwd><kwd>algorithms</kwd><kwd>acoustic waves.</kwd></kwd-group></article-meta></front><body><sec sec-type="intro"><label>1.</label><title>INTRODUCTION</title><p>Over the past two decades, optoacoustic imaging has seen steady growth and has demonstrated notable capabilities to visualize living biological tissues with multiple applications emerging in both small-animal and clinical imaging [<xref rid="R1" ref-type="bibr">1</xref>-<xref rid="R10" ref-type="bibr">10</xref>]. Nowadays, the terms optoacoustic and photoacoustic are equally used to describe the effect of acoustic wave generation by transient light absorption. Optoacoustic imaging is based on the principles of the photophonic effect, which was first described in the late 19th century by Alexander Graham Bell and Charles Sumner Tainter [<xref rid="R11" ref-type="bibr">11</xref>], who recognized that sound waves can be generated through the absorption of modulated light and its conversion into heat. Optoacoustics has been used since the late 1930s for sensitive spectroscopy of gases [<xref rid="R12" ref-type="bibr">12</xref>]. However, lack of suitable pulse-laser technology, wideband sensitive ultrasonic detectors, and data processing capacities, have made progress and application challenging. In the 1970s, the effect was first suggested for sensing biological tissue [<xref rid="R13" ref-type="bibr">13</xref>]. While the physical underpinnings of optoacoustic wave generation in solids and liquids had been long established [<xref rid="R14" ref-type="bibr">14</xref>], first imaging studies concentrated on depth profiling of one-dimensional layered tissues [<xref rid="R15" ref-type="bibr">15</xref>]. With the adoption of analytical inversion formulae from the field of computerized tomography, two- and three-dimensional optoacoustic tomographies have later become possible [<xref rid="R16" ref-type="bibr">16</xref>]. </p><p>In modern biomedical optoacoustics, the tissue is irradiated with nanosecond-duration pulses of light, resulting in the generation of ultrasound waves due to optical absorption and rapid thermoelastic expansion [<xref rid="R17" ref-type="bibr">17</xref>]. Even though additional methods of optoacoustic signal generation exist, <italic>e.g.</italic> using modulated continuous wave sources [<xref rid="R18" ref-type="bibr">18</xref>], methods relying on pulsed excitation exhibit significantly better imaging performance in terms of sensitivity [<xref rid="R19" ref-type="bibr">19</xref>]. For deep tissue imaging applications, optical parametric oscillators are often used to provide wavelength tunability with pulse repetition rates in the order of a few tens of Hertz and per-pulse energies in the millijoule range [<xref rid="R8" ref-type="bibr">8</xref>]. In optoacoustic microscopy and other superficial applications, where such high per-pulse energies are not required, other types of sources in the microjoule and nanojoule ranges are considered as well, including high repetition rate lasers [<xref rid="R20" ref-type="bibr">20</xref>], laser diodes [<xref rid="R21" ref-type="bibr">21</xref>] and fiber lasers [<xref rid="R22" ref-type="bibr">22</xref>]. </p><p>Although a great variety of optoacoustic-based techniques exist for imaging and sensing of biological tissue, <italic>e.g.</italic> optical resolution microscopy [<xref rid="R6" ref-type="bibr">6</xref>] and flow cytometry [<xref rid="R23" ref-type="bibr">23</xref>], the focus of this review is solely on tomographic imaging scenarios, such as those found in Refs. [<xref rid="R2" ref-type="bibr">2</xref>,<xref rid="R8" ref-type="bibr"> 8</xref>,<xref rid="R10" ref-type="bibr"> 10</xref>,<xref rid="R24" ref-type="bibr"> 24</xref>-<xref rid="R46" ref-type="bibr">46</xref>]. In optoacoustic tomography, the optically generated pressure profiles are subsequently captured by ultrasound detectors surrounding the imaged object. Acoustic coupling between the imaged object and the detector is usually ensured by water or coupling gel. The tomographic detection of ultrasound is performed by either scanning a single detector, or detector array, around the imaged object or alternatively using multiple detectors to simultaneously capture the generated acoustic signals. The latter configuration allows for ultrafast data acquisition, <italic>e.g.</italic> reconstruction of three-dimensional images from a single laser shot [<xref rid="R24" ref-type="bibr">24</xref>]. In comparison to the purely acoustic ultrasonography, the acoustic signals in optoacoustic tomography are generally weaker and more broadband, making their detection more challenging. Nonetheless, piezoelectric detectors, originally designed for ultrasonography, have been shown to be appropriate for optoacoustic tomography as well, and have enabled much of the progress in the field. In recent years, optical interferometric detection of ultrasound has emerged as a possible alternative to conventional piezoelectric technology, which shows promise for future miniaturization of optoacoustic imaging systems [<xref rid="R34" ref-type="bibr">34</xref>,<xref rid="R39" ref-type="bibr"> 39</xref>,<xref rid="R47" ref-type="bibr"> 47</xref>-<xref rid="R50" ref-type="bibr">50</xref>].</p><p>Due to its hybrid nature, optoacoustic tomography combines highly attractive features attributed to both light and sound, including rich contrast and high versatility in sensing diverse biological targets, excellent spatial resolution not compromised by light scattering, and relatively low cost of implementation. From a technical point of view, the ultimate goal of optoacoustic tomography is creating a quantified three-dimensional map of the optical absorption in tissue. In many cases, multispectral measurements may be used to extract quantified information on the distribution of tissue chromophores based on their optical absorption spectrum [<xref rid="R51" ref-type="bibr">51</xref>-<xref rid="R54" ref-type="bibr">54</xref>]. In order to achieve quantified imaging, two inverse problems must be solved: one acoustical and one optical. The acoustic inverse problem involves mapping the energy deposited in the tissue from the tomographic measurement of the acoustic signals, whereas the optical inverse problem involves turning the acoustic reconstruction into a quantified image of the optical absorption coefficient. The application of optoacoustic tomography to imaging living objects presents major challenges to solving both the optical and acoustical inverse problems. Optically, the large variations in the optical scattering and absorption coefficient of biological tissue lead to a highly complex non-linear inverse problem, whereas the processing of multi-spectral data often requires some <italic>a priori</italic> knowledge of the background spectrum [<xref rid="R51" ref-type="bibr">51</xref>] and accounting for depth-dependant variations in the light spectrum [<xref rid="R53" ref-type="bibr">53</xref>]. Acoustically, practical considerations in system design as well as acoustic heterogeneity and loss often lead to distorted, incomplete measurement data, which in turn may result in distorted reconstructions and imaging artifacts. </p><p>The focus of this review paper is on the technical aspects of the <italic>acoustic</italic> inverse problem in optoacoustic tomography. Mathematically, the acoustic inverse problem is agnostic to the type of electromagnetic energy deposited in the tissue, and therefore in some of the work cited in this review it is studied in the context of <italic>thermoacoustic</italic> tomography, where the excitation is performed using microwave radiation [<xref rid="R25" ref-type="bibr">25</xref>,<xref rid="R27" ref-type="bibr"> 27</xref>,<xref rid="R29" ref-type="bibr"> 29</xref>,<xref rid="R32" ref-type="bibr"> 32</xref>]. For a detailed review of the <italic>optical</italic> inverse problem and of applications of optoacoustic imaging, we refer the interested reader to Refs. [<xref rid="R55" ref-type="bibr">55</xref>-<xref rid="R60" ref-type="bibr">60</xref>] and the references contained therein. As optoacoustic tomography has grown into a highly versatile imaging technology, the acoustic inverse problem in fact represents a series of problems whose formulations depend on the specific implementation used. Practical considerations such as high sensitivity, short imaging sessions, and geometrical compatibility to the imaged object often play a decisive role in the design of optoacoustic systems. The result is often a sub-optimal acoustic measurement due to factors such as the frequency response of the acoustic detector, the finite aperture of the detector, limited-view tomography, etc. It is therefore important to realize what the effect such practical considerations have on the resulting acoustic inversion and to determine which reconstruction algorithms are most appropriate for a given scenario. Accordingly, much of the review is devoted to the relations between the theoretical and experimental facets of optoacoustic tomography. </p><p>The paper is organized as follows: In Section 2 we discuss the forward acoustic problem in terms of both its basic mathematical description and the experimental techniques used for acoustic detection. In Section 3 we review the state of the art of acoustic inversion algorithms, which we divide to 4 categories: time-domain (so called back-projection) formulae, frequency-domain formulae, time-reversal algorithms, and model-based algorithms. In Section 4 we discuss the effect of non-ideal imaging scenarios on the characteristics of the acoustic inversion, and the conclusion is given in Section 5. </p></sec><sec><label>2.</label><title>THE FORWARD PROBLEM</title><p>In optoacoustic tomography, the acoustic forward problem relates to the calculation of the acoustic fields in time and space from a <italic>known</italic> heat source, or optoacoustic source., <mml:math id="beq1"><mml:mrow><mml:mi>H</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math> ., which represents the electromagnetic energy deposited in the medium per unit volume and per unit time. As discussed in the Introduction, the physical processes leading to the generation of <mml:math id="beq2"><mml:mrow><mml:mi>H</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math> may be considered as a separate physical problem, solely related to the electromagnetic (optical) properties of the medium and of the excitation sources, and are outside the scope of this review. </p><p>In the case of acoustically homogeneous liquid medium, under the condition of thermal confinement, the optoacoustically induced pressure wave <mml:math id="beq3"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math> obeys the following differential equation [<xref rid="R61" ref-type="bibr">61</xref>]:</p><p>
<disp-formula id="formula-qf-1"><label>(1)</label><mml:math id="eq1"><mml:mrow><mml:mfrac><mml:mrow><mml:msup><mml:mo>&#x02202;</mml:mo><mml:mn>2</mml:mn></mml:msup><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>&#x02202;</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac><mml:mo>&#x02212;</mml:mo><mml:msup><mml:mi>v</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:msup><mml:mo>&#x02207;</mml:mo><mml:mn>2</mml:mn></mml:msup><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>&#x00393;</mml:mi><mml:mfrac><mml:mo>&#x02202;</mml:mo><mml:mrow><mml:mo>&#x02202;</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mi>H</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>
</p><p>where v is the speed of sound in the medium, and &#x00413; is a dimensionless parameter called the Gr&#x000fc;neisen coefficient, which describes the conversion efficiency of heat to pressure. Equation (1) is given in 3D, where <mml:math id="beq4"><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mi>z</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math>. The conventional solution to Eq. 1 is based on the free-space Green&#x02019;s function [<xref rid="R62" ref-type="bibr">62</xref>]. Briefly, replacing the right-hand side of Eq. 1 by <mml:math id="beq5"><mml:mrow><mml:mi>&#x003b4;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo><mml:mi>&#x003b4;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math>, where &#x003b4; is the Dirac delta function, leads to the following solution:</p><p>
<disp-formula id="formula-qf-2"><label>(2)</label><mml:math id="eq2"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>&#x003b4;</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>&#x003b4;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mo>|</mml:mo></mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mi>&#x003bd;</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn>4</mml:mn><mml:mi>&#x003c0;</mml:mi><mml:mrow><mml:mo>|</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula>
</p><p>Since Eq. (1) is linear, any solution can be represented as a superposition of the fundamental solution given in Eq. 2, <italic>i.e.</italic></p><p>
<disp-formula id="formula-qf-3"><label>(3)</label><mml:math id="eq3"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mi>&#x00393;</mml:mi><mml:mrow><mml:mn>4</mml:mn><mml:mi>&#x003c0;</mml:mi></mml:mrow></mml:mfrac><mml:mstyle displaystyle="true"><mml:mrow><mml:mo>&#x0222b;</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mi>&#x003b4;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi><mml:mo>-</mml:mo><mml:mi>r</mml:mi><mml:mo>'</mml:mo></mml:mstyle></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mi>&#x003bd;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mi>t</mml:mi><mml:mo>'</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi><mml:mo>-</mml:mo><mml:mi>r</mml:mi><mml:mo>'</mml:mo></mml:mstyle></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:mrow></mml:mstyle><mml:mi>H</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mo>'</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mo>,</mml:mo></mml:mstyle><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>d</mml:mi><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mo>'</mml:mo><mml:mi>d</mml:mi><mml:mi>t</mml:mi><mml:mo>'</mml:mo></mml:mrow></mml:math></disp-formula>
</p><p>In most optoacoustic imaging applications, Eq. (3) may be simplified by recognizing that the temporal duration of the electromagnetic excitation is shorter than the temporal resolution of the acoustic detectors. In this case, the heat source may be approximated by <mml:math id="beq6"><mml:mrow><mml:mi>H</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>&#x003b4;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math>., where <mml:math id="beq7"><mml:mrow><mml:mi>H</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>&#x003b4;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math> is the deposited energy per volume, and Eq. 3 takes the form of</p><p>
<disp-formula id="formula-qf-4"><label>(4)</label><mml:math id="eq4"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mi>&#x00393;</mml:mi><mml:mrow><mml:mn>4</mml:mn><mml:mi>&#x003c0;</mml:mi><mml:mi>&#x003bd;</mml:mi></mml:mrow></mml:mfrac><mml:mfrac><mml:mo>&#x02202;</mml:mo><mml:mrow><mml:mo>&#x02202;</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mstyle displaystyle="true"><mml:mrow><mml:munder><mml:mo>&#x0222b;</mml:mo><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi><mml:mo>-</mml:mo><mml:mi>r</mml:mi><mml:mo>'</mml:mo></mml:mstyle></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>v</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mfrac><mml:mrow><mml:mi>H</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mo>'</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi><mml:mo>-</mml:mo><mml:mi>r</mml:mi><mml:mo>'</mml:mo></mml:mstyle></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mi>d</mml:mi><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mo>'</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula>
</p><p>where integration is performed over a sphere, as depicted in (Fig. <bold><xref ref-type="fig" rid="F1">1A</xref></bold>). </p><p>Equation 4 offers a simple way to calculate the pressure field at a specific position and time instant and is the basis for several inversion approaches, as discussed in the following sections. Nonetheless, when one wishes to calculate the pressure fields at numerous positions, so called <italic>k-wave techniques </italic>are preferable [<xref rid="R63" ref-type="bibr">63</xref>], in which the 3D spatial Fourier transform is used. In k-space, for a heat source <mml:math id="beq8"><mml:mrow><mml:mi>H</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>&#x003b4;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math>, Eq. 1 takes the form of </p><p>
<disp-formula id="formula-qf-5"><label>(5)</label><mml:math id="eq5"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msup><mml:mi>d</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msup><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac><mml:mo>&#x02212;</mml:mo><mml:msup><mml:mi>v</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:msup><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>k</mml:mi></mml:mstyle><mml:mo>|</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mover accent="true"><mml:mi>p</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>k</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>&#x00393;</mml:mi><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>k</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo><mml:mfrac><mml:mi>d</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mi>&#x003b4;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>
</p><p>where <mml:math id="beq888"><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="true">&#x002c6;</mml:mo></mml:mover><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>.</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math> and <mml:math id="beq9"><mml:mrow><mml:mover><mml:mi>H</mml:mi><mml:mo stretchy="true">&#x002c6;</mml:mo></mml:mover><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math> are the spatial Fourier transforms of <mml:math id="beq10"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo>.</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mtext>&#x000a0;</mml:mtext><mml:mi mathvariant="italic">and</mml:mi><mml:mtext>&#x000a0;</mml:mtext><mml:mi>H</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mtext>&#x000a0;</mml:mtext><mml:mo lspace="0px" form="infix">'</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math>, respectively, and <mml:math id="beq11"><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>k</mml:mi></mml:mstyle><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mi>z</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math> is the spatial frequency. The solution of Eq. 5 is found using the Green&#x02019;s function and is given by [<xref rid="R63" ref-type="bibr">63</xref>]</p><p>
<disp-formula id="formula-qf-6"><label>(6)</label><mml:math id="eq6"><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="true">&#x002c6;</mml:mo></mml:mover><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>.</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>= &#x00413;</mml:mo><mml:mover><mml:mi> H</mml:mi><mml:mo stretchy="true">&#x002c6;</mml:mo></mml:mover><mml:mfenced open="(" close=")"><mml:mi>k</mml:mi></mml:mfenced><mml:mi mathvariant="italic">cos</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:mi>v</mml:mi><mml:mfenced open="|" close="|"><mml:mi>k</mml:mi></mml:mfenced><mml:mi>t</mml:mi></mml:mrow></mml:mfenced><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>
</p><p>for <mml:math id="beq12"><mml:mrow><mml:mi>t</mml:mi><mml:mo>&#x02265;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math>, and <mml:math id="beq13"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math> is given by</p><p>
<disp-formula id="formula-qf-7"><label>(7)</label><mml:math id="eq7"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mi>&#x00413; F</mml:mi><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mfenced open="{" close="}"><mml:mrow><mml:mover><mml:mi>H</mml:mi><mml:mo stretchy="true">&#x002c6;</mml:mo></mml:mover><mml:mfenced open="(" close=")"><mml:mi>k</mml:mi></mml:mfenced><mml:mi mathvariant="italic">cos</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:mi>v</mml:mi><mml:mfenced open="|" close="|"><mml:mi>k</mml:mi></mml:mfenced><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>
</p><p>where <mml:math id="beq14"><mml:mrow><mml:msup><mml:mi>F</mml:mi><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math> denotes the inverse Fourier transform . In contrast to Eq. 4, Eq. 7 offers a direct way to calculate pressure field for all positions in space for a given time instant <italic>t</italic> in a single step. Equation 7 also shows that the initial pressure field <mml:math id="beq15"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math> is proportional to the optoacoustic source:</p><p>
<disp-formula id="formula-qf-8"><label>(8)</label><mml:math id="eq8"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mfenced open="(" close=")"><mml:mi>r</mml:mi></mml:mfenced><mml:mo>=</mml:mo><mml:mi>&#x00413; H</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula>
</p><sec><label>2.1.</label><title>2D Representations</title><p>Although wave propagation in optoacoustic tomography is inherently a 3D phenomenon, in some imaging geometries, 2D representations are valid. We first consider the case in which the optoacoustic source lies on the plane z=0, <italic>i.e.</italic>
</p><p>
<disp-formula id="formula-qf-9"><label>(9)</label><mml:math id="eq9"><mml:mrow><mml:mi>H</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>H</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>&#x003b4;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
</p><p>In this case, the solution to the forward problem may be found by substituting Eq. 9 in Eq. 4. The result is the same equation only with <bold>r</bold> replaced by &#x003c1;=(x,y), <italic>i.e.</italic> the integration is performed over circles rather than spheres. This 2D representation is often used when light-sheet illumination and/or focused acoustic detectors are used [<xref rid="R2" ref-type="bibr">2</xref>,<xref rid="R7" ref-type="bibr"> 7</xref>,<xref rid="R8" ref-type="bibr"> 8</xref>,<xref rid="R37" ref-type="bibr"> 37</xref>]. The validity of this model for specific imaging scenarios is discussed in Section 4.5. </p><p>An additional 2D version of the optoacoustic equation is obtained when homogeneity in <italic>z</italic> is assumed, leading to <mml:math id="beq181"><mml:mrow><mml:mi>&#x02202;p</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfenced><mml:mo>/</mml:mo><mml:mi>&#x02202;z</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math>. Equation 1 thus takes the form</p><p><disp-formula id="formula-qf-10"><label>(10)</label><mml:math id="eq10"><mml:mrow><mml:mfrac><mml:mrow><mml:msup><mml:mn>&#x02202;</mml:mn><mml:mn>2</mml:mn></mml:msup><mml:mi>p</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:mi mathvariant="normal">&#x003c1;</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:msup><mml:mrow><mml:mi>&#x02202;t</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mfrac><mml:mo>&#x02212;</mml:mo><mml:msup><mml:mi>v</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mfenced open="(" close=")"><mml:mrow><mml:mfrac><mml:msup><mml:mn>&#x02202;</mml:mn><mml:mn>2</mml:mn></mml:msup><mml:msup><mml:mrow><mml:mi>&#x02202;x</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:msup><mml:mn>&#x02202;</mml:mn><mml:mn>2</mml:mn></mml:msup><mml:msup><mml:mrow><mml:mi>&#x02202;y</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mfrac></mml:mrow></mml:mfenced><mml:mi>p</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:mi mathvariant="normal">&#x003c1;</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mi>&#x02202;</mml:mi><mml:mrow><mml:mi>&#x02202;t</mml:mi></mml:mrow></mml:mfrac><mml:mi>H</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:mi mathvariant="normal">&#x003c1;</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:math></disp-formula></p><p>The solution to Eq. 10 may be readily found by repeating the procedure in Eqs. 5-7. The result is Eq. 7 with
<mml:math id="beq16"><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi mathvariant="normal">&#x003c1;</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfenced open="(" close=")"><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mi>y</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:math> substituted in place of <bold>k</bold>, where the Fourier transform is performed in 2D over <italic>x</italic> and <italic>y</italic>. Although it is unrealistic to assume that the optoacoustic source is homogeneous in <italic>z</italic>, this 2D model also applies in imaging scenarios in which the detector is homogenous in <italic>z</italic>. In such cases <mml:math id="beq177"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">&#x003c1;</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mtext>&#x000a0;</mml:mtext><mml:mi mathvariant="italic">and</mml:mi><mml:mtext>&#x000a0;</mml:mtext><mml:mi>H</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:mi mathvariant="normal">&#x003c1;</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:math> do not represent the pressure field and optoacoustic source, but rather their respective integrals over <italic>z</italic> [<xref rid="R34" ref-type="bibr">34</xref>,<xref rid="R64" ref-type="bibr"> 64</xref>]. </p></sec><sec><label>2.2.</label><title>Detector Properties</title><p>The acoustic inverse problem relates to the reconstruction of the heat source <mml:math id="beq17"><mml:mrow><mml:mi>H</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math>, or alternatively the initial pressure distribution <mml:math id="beq18"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math>, from a set of pressure waves measured at multiple positions. The pressure measurements, which are performed by ultrasound detectors, do not however exactly correspond to the mathematical description given in the previous section. Specifically, realistic ultrasound detectors are characterized by a finite aperture and finite bandwidth, or temporal resolution. The detected acoustic signals can often be modeled by the following equation [<xref rid="R31" ref-type="bibr">31</xref>,<xref rid="R65" ref-type="bibr"> 65</xref>]:</p><p>
<disp-formula id="formula-qf-11"><label>(11)</label><mml:math id="eq11"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>det</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>h</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x02217;</mml:mo><mml:mstyle displaystyle="true"><mml:mrow><mml:munder><mml:mo>&#x0222b;</mml:mo><mml:mi>S</mml:mi></mml:munder><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mstyle><mml:mi>D</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mo>)</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:mi>S</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>
</p><p>where <italic>S</italic> is the detector&#x02019;s surface, <mml:math id="beq19"><mml:mrow><mml:mi>D</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math> is the detector&#x02019;s sensitivity distribution, and <mml:math id="beq20"><mml:mrow><mml:mi>h</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math> is the temporal impulse response of the detector. It is often assumed that <mml:math id="beq21"><mml:mrow><mml:mi>D</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math> is uniform within the detector&#x02019;s surface, though some detectors are inherently characterized by non-uniform sensitivity distributions [<xref rid="R48" ref-type="bibr">48</xref>,<xref rid="R66" ref-type="bibr"> 66</xref>]. </p><p>Two types of ultrasound detectors are commonly used in optoacoustic tomography: piezoelectric detectors [<xref rid="R67" ref-type="bibr">67</xref>,<xref rid="R68" ref-type="bibr"> 68</xref>], in which pressure is directly transformed into voltage, and optical detectors [<xref rid="R34" ref-type="bibr">34</xref>,<xref rid="R39" ref-type="bibr"> 39</xref>,<xref rid="R47" ref-type="bibr"> 47</xref>-<xref rid="R50" ref-type="bibr">50</xref>], in which pressure is interferometrically detected <italic>via</italic> its effect on the optical path of the interrogation beam. In the former case, the temporal response of the detector is largely determined by the acoustic and electrical impedances of the piezocomposite material, and is thus often referred to as the electrical impulse response. Many piezoelectric detectors are designed to resonate at a specific acoustic frequency to increase their sensitivity, leading to a complex electrical response. The calculation of the electrical response requires exact knowledge of its design [<xref rid="R68" ref-type="bibr">68</xref>], which may not always be provided by the manufacturer, and it is therefore often required that the response be directly measured, <italic>e.g.</italic> using the techniques in Refs. [<xref rid="R66" ref-type="bibr">66</xref>,<xref rid="R69" ref-type="bibr"> 69</xref>,<xref rid="R70" ref-type="bibr"> 70</xref>]. In Ref. [<xref rid="R70" ref-type="bibr">70</xref>], the difference between optoacoustic techniques and pure ultrasound techniques for characterization of ultrasound detectors is discussed. In the case of optical detectors, the temporal impulse response is determined by the thickness of the detection region [<xref rid="R39" ref-type="bibr">39</xref>,<xref rid="R65" ref-type="bibr"> 65</xref>] and the acoustic impedance mismatch between the optical medium in which the interrogation beam propagates and the acoustic medium (usually water) [<xref rid="R71" ref-type="bibr">71</xref>]. For most optical detectors, the optical medium, leading to a relatively simple temporal impulse response, which is nothing more than a low-pass operation which corresponds to the width of the detection region [<xref rid="R65" ref-type="bibr">65</xref>]. The major exception to this rule is optical detectors which are based on silica fibers, which are highly acoustically mismatched to water. In that case, the temporal response needs to be either measured [<xref rid="R66" ref-type="bibr">66</xref>], or numerically simulated [<xref rid="R71" ref-type="bibr">71</xref>]. We note that when complex acoustic propagation patterns exist due to acoustic impedance mismatches, <italic>e.g.</italic> acoustic waves guided in silica fibers [<xref rid="R66" ref-type="bibr">66</xref>], or angle-dependent reflection and refraction pattern which appear in piezoelectric transducers, the model used in Eq. 11 loses its validity. Such cases would require either a more elaborate model or, alternatively, measuring the spatially dependent impulse response of the detector, as discussed in Section 3.4.
</p><p>Numerous aperture types have been demonstrated for optoacoustic tomography, some chosen owing to technological constraints and some due to limitations imposed by the geometry of the imaging application. Nonetheless, with but a few exceptions [<xref rid="R72" ref-type="bibr">72</xref>,<xref rid="R73" ref-type="bibr"> 73</xref>], detector surfaces used in the field may be described by a combination of two out of three simple detector types in 2D space: point, line (or line segment), and focused. In other words, the 2D surface of the detector often has a separable geometry, where the geometry on each of the surface&#x02019;s dimensions corresponds to one of the three simple 1D curves listed above. (Fig. <bold><xref ref-type="fig" rid="F1">1</xref></bold>) shows schematically the three basic detector geometries. The figure further illustrates the different detection patterns characterizing these geometries. In the case of a point detector, the sensitivity is isotropic while the signals detected at a given time instant are assumed to originate from sources located on spheres (3D) or arcs (2D), as shown by Eq. 4. A detector may be considered as a point detector if its size is significantly smaller than the size of the features in the optoacoustic source <mml:math id="beq222"><mml:mrow><mml:mi>H</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math>. In the case of a line detector, sources whose detection delay is the same (<italic>i.e.</italic> the time it takes for the acoustic signals they generate to be detected) generally lie on a line in 2D space parallel to the detector. If the detector is a finite line-segment, the sensitivity is anisotropic and generally higher for regions directly facing the detector [<xref rid="R74" ref-type="bibr">74</xref>]. For infinite-line detectors, the sensitivity depends only on the distance from the detector [<xref rid="R34" ref-type="bibr">34</xref>]. Focused detectors are used in order to limit the sensitivity to a small region. The full-width-half-maximum (FWHM) of the focal zone depends on the focal length <italic>f</italic>, the transducer aperture size 2&#x003b1;, and acoustic wavelength [<xref rid="R67" ref-type="bibr">67</xref>]:</p><p>
<disp-formula id="formula-qf-12"><label>(12)</label><mml:math id="eq12"><mml:mrow><mml:mtext>FWHM</mml:mtext><mml:mo>=</mml:mo><mml:mn>1.41</mml:mn><mml:mi>&#x003bb;</mml:mi><mml:mi>f</mml:mi><mml:mo>/</mml:mo><mml:mn>2</mml:mn><mml:mi>a</mml:mi></mml:mrow></mml:math></disp-formula>
</p><p>The depth of field (DOF), <italic>i.e.</italic> the distance over which the sensitivity field remains within the 50% of its maximum value, is given by</p><p><disp-formula id="formula-qf-13"><label>(13)</label><mml:math id="eq13"><mml:mrow><mml:mi mathvariant="italic">DOF</mml:mi><mml:mo>=</mml:mo><mml:mn>9.7</mml:mn><mml:mi mathvariant="normal">&#x003bb;</mml:mi><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo>/</mml:mo><mml:mn>2</mml:mn><mml:mi>a</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math></disp-formula></p><p>when using Eqs. (12) and (13), two points must be considered. First, these equations have been developed for focused transducers in 3D space with circular apertures (focused disks) [<xref rid="R67" ref-type="bibr">67</xref>]. 2<italic>a</italic> in this case represents the disk diameter. In the case of non-circular apertures, or detectors that are focused only along one axis, a deviation from the constant numerical factors in Eqs. (12) and (13) is expected, but not in the dependence on the physical parameters. The second point is that in optoacoustic tomography, the source does not emit acoustic waves with a single frequency and wavelength, but is rather characterized by a broad spectrum. We elaborate further on this point in Section 4.5, where the reconstruction using focused transducers is discussed.</p><p>For detectors in 3D space, the three 2D options depicted in (Fig. <bold><xref ref-type="fig" rid="F1">1</xref></bold>) lead to 6 different combinations of detector types. For detectors which are point-like in both their dimensions, the most successful implementation so far has been optical [<xref rid="R10" ref-type="bibr">10</xref>,<xref rid="R39" ref-type="bibr"> 39</xref>] since in optical detection the detector&#x02019;s sensitivity is often independent of its surface area. In contrast, the sensitivity of piezoelectric detectors scales with their size. Accordingly, miniaturized piezoelectric detectors used for optoacoustic tomography are often significantly larger than their optical counterparts and thus may only be considered point-like for larger features in the optoacoustic source. The combination point-line relates to detectors which are very small in one dimension and are large and straight in the other. This combination enables increasing sensitivity while still maintaining a relatively compact detector design. However, the increase in sensitivity depends on the acoustic wavelength, whereas higher wavelengths are less emphasized in the detection owing to the effect of spatial averaging on the long dimension of the sensor [<xref rid="R74" ref-type="bibr">74</xref>]. Piezoelectric implementations of this geometry are often based on commercially available ultrasound linear arrays [<xref rid="R75" ref-type="bibr">75</xref>], whereas optical implementations are based on long Mach-Zehnder or Fabry-Perot interferometers [<xref rid="R34" ref-type="bibr">34</xref>]. In the latter case, the length of the detector may be made sufficiently large, such that it can be approximated by an infinite line. Further increase in sensitivity could potentially be achieved by using the line-line combination, <italic>i.e.</italic> detectors which are flat and significantly larger in both their dimensions than the typical size of the features in the optoacoustic source [<xref rid="R29" ref-type="bibr">29</xref>-<xref rid="R31" ref-type="bibr">31</xref>].</p><p>Similarly to line detectors, focused detectors may achieve higher sensitivity than point-like detectors due to their larger size. However, unlike line detectors, the sensitivity enhancement attained in the focal zone is independent of acoustic wavelength. Thus, the sensitivity achieved by a focused detector may be significantly higher than the one achieved by a flat detector of the same size when imaging objects which are considerably smaller than the detector&#x02019;s size. Additionally, since the sensitivity of focused detectors is confined to a small region, it is only necessary to create the optoacoustic source within that region. Detectors which are focused in one dimension are often referred to as <italic>cylindrically focused</italic> detectors. In such detectors, the focal zone has a planar geometry [<xref rid="R2" ref-type="bibr">2</xref>,<xref rid="R7" ref-type="bibr"> 7</xref>]. For such detectors, the second dimension may be considered as either a point [<xref rid="R37" ref-type="bibr">37</xref>] or a line [<xref rid="R76" ref-type="bibr">76</xref>]. Detectors which are focused in two dimensions are said to be <italic>spherically focused</italic>, and their focal zone lies on a line [<xref rid="R3" ref-type="bibr">3</xref>], [<xref rid="R67" ref-type="bibr">67</xref>]. Although focused detectors are most commonly implemented using piezoelectric technology, it has been recently shown that an optical implementation may be enabled by using a focusing mirror [<xref rid="R38" ref-type="bibr">38</xref>]. </p><p>We note that the choice of a specific detector type is not trivial and is affected by both technological considerations and the particular application. Large-area detectors have the advantage of higher sensitivity, but their size also inhibits their use in array configurations, which can simultaneously measure ultrasound at multiple positions and potentially reduce the imaging time. In some cases, focused detectors can mitigate the requirement for high-power lasers for creating the optoacoustic source by partially focusing the laser beam to a small region on the surface of the imaged object to better match the focal zone [<xref rid="R3" ref-type="bibr">3</xref>,<xref rid="R7" ref-type="bibr"> 7</xref>]. However, the benefit from this approach diminishes as the size of the imaged object increases owing to scattering of the laser light within the object. Some geometries might be preferable in terms of sensitivity, but require more complex inversion algorithms to form an image. In some cases, <italic>e.g.</italic> in small animal imaging applications, imaging speed might be favored over spatial resolution in order to enable high throughput and reduce motion artifacts [<xref rid="R24" ref-type="bibr">24</xref>,<xref rid="R77" ref-type="bibr"> 77</xref>], whereas in some stationary clinical applications, it may be preferable to have longer imaging sessions in order to obtain the highest resolution possible [<xref rid="R26" ref-type="bibr">26</xref>]. In addition to the aforementioned technical tradeoffs, it is also clear that an imaging system needs to be reliable, robust, and relatively easy to use. In light of these considerations, it is not surprising that so many detector geometries have been tested for optoacoustic tomography.</p><p>Finally, we note that the distinction we made between point and line detectors is not always absolute and may depend not only on the characteristic size of features in the imaged object, but also on the detection surface (see Sections 2.3 and 4.2). For imaging purposes, a more general definition of a point detector may be adopted based on the discussion in Sections 4.2: A detector may be considered to be a point detector if reconstruction algorithms for point detectors may be applied without distorting the features of interest in the imaged object. As discussed in Section 4.2, in some cases, <italic>e.g.</italic> spherical detection surface, such reconstruction properties may be achieved even when the detector is larger than the features of interest in the imaged object. </p></sec><sec><label>2.3.</label><title>Detection Surface</title><p>The detection surface on which the acoustic measurements are performed has a direct effect on both the quality of the reconstruction achieved as well as on the choice of reconstruction algorithms. Mathematically, if the pressure wave <mml:math id="beq22"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math> is known over a closed surface <italic>S</italic> that encloses the optoacoustic source, a unique solution to the inverse problem exists as well as <italic>stable</italic> inversion procedures [<xref rid="R78" ref-type="bibr">78</xref>-<xref rid="R81" ref-type="bibr">81</xref>]. The practical implication of this property is the following: If point-like detectors with sufficient bandwidth are placed over such a surface with sufficient density, an exact reconstruction of the optoacoustic source over any given resolution may be achieved. Three detection surfaces are of special importance in optoacoustic tomography due to their mathematical properties as well as due to practical considerations; these are the spherical, cylindrical, and planar detection surfaces, as shown in (Fig. <bold><xref ref-type="fig" rid="F2">2</xref></bold>).</p><p>The three detection geometries depicted in (Fig. <bold><xref ref-type="fig" rid="F2">2</xref></bold>) are often discussed in mathematical texts since they possess analytical solutions to the acoustic inversion problem [<xref rid="R32" ref-type="bibr">32</xref>,<xref rid="R40" ref-type="bibr"> 40</xref>,<xref rid="R82" ref-type="bibr"> 82</xref>]. We note that these solutions are unique even though the cylindrical and planar surfaces, which are infinite, are not closed. Practically, these surfaces, or their truncated versions in the cylindrical and planar cases, are compatible with most of the detection technologies employed in the field. For example, piezoelectric detector arrays are commonly manufactured over flat [<xref rid="R83" ref-type="bibr">83</xref>,<xref rid="R84" ref-type="bibr"> 84</xref>] or curved surfaces [<xref rid="R8" ref-type="bibr">8</xref>,<xref rid="R24" ref-type="bibr"> 24</xref>,<xref rid="R36" ref-type="bibr"> 36</xref>], and mechanical scanning is considerably easier to perform over circular or straight paths than over irregular paths which offer no apparent advantage except for special cases [<xref rid="R85" ref-type="bibr">85</xref>]. Although most mathematical texts focus on point-detectors, these three detection surfaces have been used with a variety of finite-size detectors. (Table <bold><xref ref-type="table" rid="T1">1</xref></bold>) summarizes the different combinations of detection surfaces and detector types which have been discussed in the literature.</p></sec></sec><sec><label>3.</label><title>RECONSTRUCTION ALGORITHMS </title><p>The mathematical foundation for much of the early development of optoacoustic reconstruction algorithms [<xref rid="R16" ref-type="bibr">16</xref>,<xref rid="R86" ref-type="bibr"> 86</xref>], whether involving approximate or exact solutions, has been known for several decades now and has been applied in the fields of ultrasonic reflectivity imaging and X-ray computerized tomography [<xref rid="R87" ref-type="bibr">87</xref>,<xref rid="R88" ref-type="bibr"> 88</xref>]. Nonetheless, the large diversity of imaging scenarios which exists in optoacoustic tomography, as discussed in Sections 2 and 4, as well as its unique physical underpinnings has led to new challenges specific to optoacoustic tomography. The exponential growth in computational power as well as the emergence of new algorithms in fields such as image and signal processing have created new possibilities for more versatile reconstruction algorithms which would have been considered highly impractical less than a decade ago. It is therefore not surprising that many new image-reconstruction algorithms are still being developed. Since novel detector types [<xref rid="R39" ref-type="bibr">39</xref>,<xref rid="R49" ref-type="bibr"> 49</xref>,<xref rid="R48" ref-type="bibr"> 48</xref>,<xref rid="R72" ref-type="bibr"> 72</xref>] and detection geometries [<xref rid="R85" ref-type="bibr">85</xref>] are still emerging, this trend is expected to continue. </p><p>In the following we review the state-of-the-art in algorithms for optoacoustic reconstruction in 3D and 2D. Although numerous algorithms have been proposed to this end, most may be included in one of the following categories: closed-form time-domain (back-projection) solutions, closed-form frequency-domain solutions, numerical time reversal techniques, and numerical model-based algorithms. For the 2D inverse problem, we note that in the case of homogeneity in <italic>z</italic> (Eq. 10), the solution <mml:math id="beq23"><mml:mrow><mml:mi>H</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:mi mathvariant="normal">&#x003c1;</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:math> is equal to <mml:math id="beq24"><mml:mrow><mml:mi>H</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:math> integrated over and therefore does not constitute a full solution to the inverse problem on its own. Nonetheless, a set of recovered functions <mml:math id="beq25"><mml:mrow><mml:mi>H</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:mi mathvariant="normal">&#x003c1;</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:math> obtained at different orientations of the source may be used to recover <mml:math id="beq26"><mml:mrow><mml:mi>H</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:mi mathvariant="normal">r</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:math>
<italic>via</italic> the 2D inverse Radon transform [<xref rid="R34" ref-type="bibr">34</xref>]. In contrast, in case of an optoacoustic source which is assumed to be restricted to a plane (Eq. 9), recovering <mml:math id="beq28"><mml:mrow><mml:mi>H</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:mi mathvariant="normal">&#x003c1;</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:math> is equivalent to recovering
<mml:math id="beq27"><mml:mrow><mml:mi>H</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:mi mathvariant="normal">&#x003c1;</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:math> for the imaged plane. Practically, the reconstruction procedure may be applied for different imaging planes in the imaged object, thus recovering the entire 3D optoacoustic source plane-by-plane without the need for additional inversion steps [<xref rid="R7" ref-type="bibr">7</xref>].</p><sec><label>3.1.</label><title>Time-domain Algorithms </title><p>Time-domain algorithms are commonly based on projecting each of the 1D acoustic signals onto 3D space in a way that is consistent with the time-of-flight principle. The back-projection process generally involves 3 steps:</p><list list-type="order"><list-item><p>Pre-processing: A mathematical operation performed on each of the measured acoustic signals <mml:math id="beq29"><mml:mrow><mml:mi>p</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:math> to form a new function, which we denote here by <mml:math id="beq30"><mml:mrow><mml:mi>b</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:math>, where <mml:math id="beq33"><mml:mrow><mml:msubsup><mml:mrow><mml:mo>{</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mi>n</mml:mi></mml:msub><mml:mo>}</mml:mo></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup></mml:mrow></mml:math> are the locations of the acoustic detectors.</p></list-item><list-item><p>Back-projection: Each of the functions <mml:math id="beq31"><mml:mrow><mml:mi>b</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:math> is projected onto concentric spheres in 3D space based on the following equations:</p><p>
<disp-formula id="formula-qf-14"><label>(14)</label><mml:math id="eq14"><mml:mrow><mml:msub><mml:mi>B</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>b</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mi>n</mml:mi></mml:msub></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mi>&#x003bd;</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
</p><p>The physical interpertation of Eq. 14 is that the signal at each time instant <italic>t</italic> is projected to all the positions in which it could have originated, <italic>i.e.</italic> a sphere centered on <mml:math id="beq344"><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:math> with a radius of <italic>vt</italic>. Additional spatial processing, <italic>e.g.</italic> weighting, may be performed on . </p></list-item><list-item><p>Summation: Image formation by summing up all the functions calculated in Step. 2.</p></list-item></list><p>A geometrical representation of the back-projection procedure is given in (Fig. <bold><xref ref-type="fig" rid="F3">3</xref></bold>). As shown in the figure, the success of the back-projection approach may be understood from a purely geometrical perceptive, independent of the exact functions that are back-projected. It is therefore not surprising that early applications of the back-projection concept in optoacoustic tomography achieved good reconstructions while relying on mostly heuristic reasoning [<xref rid="R1" ref-type="bibr">1</xref>,<xref rid="R89" ref-type="bibr"> 89</xref>,<xref rid="R90" ref-type="bibr"> 90</xref>], rather than rigorous mathematical analysis, which was only later developed. Arguably, the most basic implementation of the back-projection procedure is the so-called <italic>delay-and-sum</italic>
<italic>algorithm</italic> in which no pre-processing is performed and <mml:math id="beq34"><mml:mrow><mml:mi>p</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:math> are projected directly [<xref rid="R1" ref-type="bibr">1</xref>]. Although this approach accurately quantifies the position and size of simple optoacoustic sources, it is inadequate for quantitative imaging, as revealed by more rigorous formulations.</p><p>More advanced back-projection algorithms have been developed for the case of far-field acoustic detection [<xref rid="R25" ref-type="bibr">25</xref>,<xref rid="R33" ref-type="bibr"> 33</xref>,<xref rid="R86" ref-type="bibr"> 86</xref>]. Namely, it is assumed that the distance between the imaged object and the detectors is significantly larger than the size of the object or, alternatively, than the size of features of interest. Mathematically, the condition for the far-field approximation is that for every <bold>r<sub>s</sub></bold> on the detection surface and every <bold>r</bold> within the imaged object, <mml:math id="beq35"><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mi>s</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mo>&#x02245;</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:math>. Consequentially, the integration over the spheres in Eq. 4, may be approximated by integration over plane, leading to the 3D Radon transform. Far-field inversions have been developed in spherical, cylindrical, and planar geometries by Xu <italic>et al.</italic> [<xref rid="R25" ref-type="bibr">25</xref>] and [<xref rid="R33" ref-type="bibr">33</xref>]. More recently, Burgholzer <italic>et al.</italic> generalized the far-field inversion equation to arbitrary closed surfaces and obtained the following equation [<xref rid="R81" ref-type="bibr">81</xref>]:</p><p>
<disp-formula id="formula-qf-15"><label>(15)</label><mml:math id="eq15"><mml:mrow><mml:mi>H</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x02245;</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>2</mml:mn><mml:mi>&#x003c0;</mml:mi><mml:mi>&#x00393;</mml:mi></mml:mrow></mml:mfrac><mml:msub><mml:mrow><mml:mstyle displaystyle="true"><mml:mrow><mml:munder><mml:mo>&#x0222b;</mml:mo><mml:mi>S</mml:mi></mml:munder><mml:mrow><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mfrac><mml:mrow><mml:mo>&#x02202;</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mi>s</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>&#x02202;</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mstyle></mml:mrow><mml:mrow><mml:mi>&#x003bd;</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mi>s</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:mi>d</mml:mi><mml:msub><mml:mi>&#x003a9;</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mi>s</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
</p><p>where <mml:math id="beq36"><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>&#x003a9;</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mi>s</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math> is the solid angle element corresponding to the detector surface element <italic>dS</italic> when viewed from <bold>r</bold>, as depicted in (Fig. <bold><xref ref-type="fig" rid="F4">4</xref></bold>). The analytical representation of <mml:math id="beq37"><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>&#x003a9;</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mi>s</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math> is given by <mml:math id="beq388"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mi>s</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>n</mml:mi></mml:mstyle><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mi>s</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x022c5;</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mi>s</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle></mml:mrow><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mi>s</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math>, where <mml:math id="beq389"><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>n</mml:mi></mml:mstyle><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mi>s</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math> denotes the normal vector at pointing outwards, and denotes the scalar product between two vectors. Recalling the far-field approximation, <mml:math id="beq38"><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>&#x003a9;</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mi>s</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math> may be simplified to <mml:math id="beq39"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mi>s</mml:mi></mml:msub></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>n</mml:mi></mml:mstyle><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mi>s</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x022c5;</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mi>s</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mi>s</mml:mi></mml:msub></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math>.</p><p>Finally, in the case of spherical, cylindrical, and planar detection surfaces, exact back-projection formulae are known. One of the most notable formulations of the back-projection algorithm is the <italic>universal back-projection algorithm, </italic>developed by M. Xu<italic> et al., </italic>which is exact for all three detection surfaces [<xref rid="R82" ref-type="bibr">82</xref>]:</p><p>
<disp-formula id="formula-qf-16"><label>(16)</label><mml:math id="eq16"><mml:mrow><mml:mi>H</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>2</mml:mn><mml:mi>&#x00393;</mml:mi></mml:mfrac><mml:msub><mml:mrow><mml:mstyle displaystyle="true"><mml:mrow><mml:munder><mml:mo>&#x0222b;</mml:mo><mml:mi>S</mml:mi></mml:munder><mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mi>s</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mi>t</mml:mi><mml:mfrac><mml:mrow><mml:mo>&#x02202;</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mi>s</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>&#x02202;</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mstyle></mml:mrow><mml:mrow><mml:mi>&#x003bd;</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mi>s</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>&#x003a9;</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mi>s</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mi>&#x003a9;</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula>
</p><p>where <mml:math id="beq40"><mml:mrow><mml:msub><mml:mi>&#x003a9;</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math> is the solid angle of the whole detection surface, and therefore is equal to 4p for spherical and cylindrical surfaces, and to 2p for planar surfaces. We note that the only difference between Eq. 16 and Eq. 15 is the addition of the term <mml:math id="beq41"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mi>s</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math> in Eq. 16, which is indeed negligible under the far-field approximation.</p><p>Despite the elegant representation of Eq. 16, its exact numerical implementation is computationally demanding, as noted in Ref. [<xref rid="R81" ref-type="bibr">81</xref>]. The main reason for this numerical complexity is that for each voxel in the reconstruction grid, the solid angle element has to be calculated for every discrete value of <bold>r<sub>s</sub></bold>. For an object with <mml:math id="beq42"><mml:mrow><mml:mi>M</mml:mi><mml:mo>&#x000d7;</mml:mo><mml:mi>M</mml:mi><mml:mo>&#x000d7;</mml:mo><mml:mi>M</mml:mi></mml:mrow></mml:math> voxels and corresponding <mml:math id="beq43"><mml:mrow><mml:mi>M</mml:mi><mml:mo>&#x000d7;</mml:mo><mml:mi>M</mml:mi></mml:mrow></mml:math> back-projected signals, the result is a complexity of <mml:math id="beq44"><mml:mrow><mml:mi>O</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>M</mml:mi><mml:mn>5</mml:mn></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math> for the trigonometric calculations involved with the calculation of <mml:math id="beq45"><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>&#x003a9;</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mi>s</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math>. However, under the far-field approximation, <mml:math id="beq46"><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>&#x003a9;</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mi>s</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math> does not depend on <bold>r</bold> and, thus, its calculation involves only <mml:math id="beq48"><mml:mrow><mml:mi>O</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>M</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math> operations. If the detection surface is also spherical, <mml:math id="beq47"><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>&#x003a9;</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mi>s</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math> may be approximated by the constant <mml:math id="beq49"><mml:mrow><mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>S</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mi>s</mml:mi></mml:msub></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mrow></mml:mrow></mml:math>, leading to a significantly lower computational complexity. Despite the high complexity often associated with back-projection formula, recent implementations on graphical-processing-units (GPUs) [<xref rid="R91" ref-type="bibr">91</xref>,<xref rid="R92" ref-type="bibr"> 92</xref>] have been shown to be highly efficient, enabling real-time reconstruction in 3D. </p><p>In the case of 2D imaging, back-projection algorithms have been developed for plane-bound 2D sources (Eq. 9) and infinite sources (Eq. 10). In the case of plane-bound source, Filbir <italic>el al.</italic> demonstrated an approximate back-projection formula that may be applied to arbitrary detection geometries [<xref rid="R93" ref-type="bibr">93</xref>]. Formally, the reconstructed object in this algorithm is not the source, but rather a convolution of the source with a point-spread function (PSF) which approximates the delta function. In the case of infinite sources, Burgholzer <italic>et al. </italic>[<xref rid="R64" ref-type="bibr">64</xref>] demonstrated a procedure that enables applying any 3D back-projection formula to the 2D case.</p><p>One of the advantages of the back-projection approach is that it is based on robust physical principles, and therefore may produce visually pleasing results useful for identifying the underlying anatomy of the imaged specimen even when the description of the imaging scenario does not coincide with the conditions for exact reconstruction. In such non-ideal scenarios, image quality may be often improved by introducing additional weighting to the back-projected signals <mml:math id="beq500"><mml:mrow><mml:mi>b</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math>. In Ref. [<xref rid="R94" ref-type="bibr">94</xref>] this concept was used for the case of limited-view tomography (see Section 4.4) to prevent over-extenuation of features for which a better angular coverage was given. In Refs. [<xref rid="R95" ref-type="bibr">95</xref>,<xref rid="R96" ref-type="bibr"> 96</xref>] a more complex weighting function was used to account for acoustic heterogeneities assuming some <italic>a priori</italic> information on their distribution. Weighting was performed to favor signals originating close to the detectors, as they are less likely to suffer from deformation due to acoustic heterogeneities. </p></sec><sec><label>3.2.</label><title>Frequency-domain Algorithms</title><p>Frequency-domain algorithms are based on solving the inverse problem in the Fourier domain and transforming the solution back to the spatial domain. For <mml:math id="beq50"><mml:mrow><mml:mi>t</mml:mi><mml:mo>&#x0003e;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math> the acoustic forward problem is described by the homogeneous wave equation. As a result, the acoustic fields may be written as an infinite sum of known product functions in four-dimensional space <mml:math id="beq51"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math>:</p><p>
<disp-formula id="formula-qf-17"><label>(17)</label><mml:math id="eq17"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mo>&#x02211;</mml:mo><mml:mi>n</mml:mi></mml:munder><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mn>3</mml:mn><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mn>4</mml:mn><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>
</p><p>where <mml:math id="beq270"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>d </mml:mi><mml:msub><mml:mi> r</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:mrow></mml:math> are the three spatial variables that correspond to the geometry of the problem. We note that Eq. 17 is only an abstract, general representation of <mml:math id="beq52"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math>, in which the sum over <italic>n</italic> may also correspond to integrating over a continuous parameter. The ability to transform <mml:math id="beq53"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math> into a sum of <italic>separable</italic> functions is at the heart of many of the frequency-domain techniques used in optoacoustic tomography. Since the base functions are pre-determined, knowing the coefficients <mml:math id="beq633"><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:math> equates to knowing <mml:math id="beq54"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math> for all values of <bold>r</bold> and <italic>t</italic>. The procedure leading to the forward solution in Eq. 7 may also be understood in the context of Eq. 17: In the forward problem, <mml:math id="beq55"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math> is known for for all values of <mml:math id="beq58"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>d </mml:mi><mml:msub><mml:mi> r</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:mrow></mml:math>. The known function <mml:math id="beq56"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math> can be transformed in the three-dimensional space of <bold>r</bold> using the same base functions as in Eq. 17:</p><p>
<disp-formula id="formula-qf-18"><label>(18)</label><mml:math id="eq18"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mo>&#x02211;</mml:mo><mml:mi>n</mml:mi></mml:munder><mml:mrow><mml:msub><mml:mi>b</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mn>3</mml:mn><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula>
</p><p>In order to compare Eqs. 17 and 18, it is required that a unique dispersion relation be known between the temporal and spatial functions, <italic>i.e.</italic> that each of the combinations of spatial functions in Eq. 18 corresponds to only to a single temporal function. Then, when substituting t=0 in Eq. 17 and equating to Eq. 18, one obtains</p><p>
<disp-formula id="formula-qf-19"><label>(19)</label><mml:math id="eq19"><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>b</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mn>4</mml:mn><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula>
</p><p>The analysis performed in Eqs. 5-7 is equivalent to the one given above with <mml:math id="beq59"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi><mml:msub><mml:mi> r</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:mrow></mml:math> being the Cartesian spatial coordinates and the functions <mml:math id="beq60"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>&#x003b1;</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>&#x003b1;</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>&#x003b1;</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math> being complex exponential functions. The calculation of <mml:math id="beq62"><mml:mrow><mml:msub><mml:mi>b</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:math> from <mml:math id="beq61"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math> is thus performed in this case by the 3D Fourier transform. </p><p>The procedure performed in Eqs. 18 and 19, when put in a broader context, enables calculating <mml:math id="beq63"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math> in 4D space when it is known over three of its four variables. In the forward problem, <mml:math id="beq64"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math> is known over the three spatial variables at a given time instant. In the inverse problem, <mml:math id="beq65"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math> is known over two spatial variables and over the time variable for a single value of the third spatial variable. In other words, <mml:math id="beq66"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math> is known over a surface which corresponds to the geometry used in the decomposition in Eq. 17. In both the forward and inverse problems, the degeneracy in the dispersion relation, corresponding to fields which propagate in opposite directions but have the same spatial profile, needs to be addressed by applying constraints to the problem. In the case of planar geometry [<xref rid="R40" ref-type="bibr">40</xref>,<xref rid="R97" ref-type="bibr"> 97</xref>], the decomposition is to planar waves and the detection surface must also be planar. Accordingly, in the cases of cylindrical and spherical geometries [<xref rid="R25" ref-type="bibr">25</xref>,<xref rid="R32" ref-type="bibr"> 32</xref>,<xref rid="R98" ref-type="bibr"> 98</xref>], the waves are cylindrical and spherical, and the detection surfaces are a cylinder and a sphere, respectively. The planar case is favorable both in its mathematical simplicity and numerical efficiency because the decomposition in Eq. 17 may be implemented by the Fourier transform. In contrast, cylindrical and spherical waves involve complex mathematical functions, and the decomposition cannot be performed with high efficiency. We therefore limit our discussion here to the planar geometry, whereas the solutions to the cylindrical and spherical geometries may be found in Refs. [<xref rid="R25" ref-type="bibr">25</xref>,<xref rid="R32" ref-type="bibr"> 32</xref>,<xref rid="R98" ref-type="bibr"> 98</xref>]. Finally, we note that Wang <italic>et al. </italic>recently developed an exceptionally simple Fourier-domain formula for the spherical case that is not based on the decomposition given in Eq. 17 [<xref rid="R99" ref-type="bibr">99</xref>]. </p><sec><label>3.2.1.</label><title>Planar Geometry</title><p>The following analysis is based on the one given in Ref. [<xref rid="R97" ref-type="bibr">97</xref>], and a detailed numerical implementation of the inversion algorithm may be found in Ref. [<xref rid="R100" ref-type="bibr">100</xref>]. The analysis also applies to the 2D inversion problem described by Eq. 10 with only minor modifications [<xref rid="R34" ref-type="bibr">34</xref>]. We assume that <mml:math id="beq67"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math> is known at <mml:math id="beq68"><mml:mrow><mml:mi>z</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math> and wish to find <mml:math id="beq69"><mml:mrow><mml:mi>H</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math> or, alternatively, the equivalent initial pressure distribution <mml:math id="beq70"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math> (Eq. 8). According to Eqs. 6-8, the decomposition of <mml:math id="beq71"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math> into a sum of separable functions for <mml:math id="beq72"><mml:mrow><mml:mi>t</mml:mi><mml:mo>&#x0003e;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math> is given by Eq. 20.</p><p>For simplicity of the analysis, we assume that Eq. (20) is valid for all values of <italic>t</italic>, enforcing time symmetry on <mml:math id="beq73"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math>, <italic>i.e. </italic>.<mml:math id="beq74"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math>. We denote the measurement on the plane <mml:math id="beq75"><mml:mrow><mml:mi>z</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math> with <mml:math id="beq766"><mml:mrow><mml:mi>u</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math>, and its Fourier transform by <mml:math id="beq76"><mml:mrow><mml:mi>U</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>&#x003c9;</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math>, as shown in Eq. (21). Since <mml:math id="beq77"><mml:mrow><mml:mi>u</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math> is real and symmetric in <italic>t</italic>, its Fourier transform is symmetric in <italic>&#x003c9;</italic>, leading to the equivalent representation given in Eq. (22). Substituting <mml:math id="beq788"><mml:mrow><mml:mi>z</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math> in Eq. (20), one obtains Eq. (23). Comparing Eqs. (22) and (23) one obtains the dispersion relation between <italic>&#x003c9;</italic> and <bold>k</bold> and its differential, given in Eqs. (24a) and (24b). Substituting Eqs. (24a) and (24b) in Eq. (23), and comparing to Eq. (22), one obtains Eq. (25).</p><p>Equation 25 reveals that <mml:math id="beq78"><mml:mrow><mml:mi>H</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mi>z</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math> and <mml:math id="beq79"><mml:mrow><mml:mi>H</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mi>z</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math> create the same pressure on <mml:math id="beq80"><mml:mrow><mml:mi>z</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math>, <italic>i.e.</italic> planar measurements cannot determine from which side the pressure waves arrive at the plane <mml:math id="beq81"><mml:mrow><mml:mi>z</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math> [<xref rid="R97" ref-type="bibr">97</xref>]. By assuming a symmetric source, for which <mml:math id="beq82"><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mi>z</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mi>z</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math>, one obtains</p><p>
<disp-formula id="formula-qf-20"><label>(20)</label><mml:math id="eq20"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>2</mml:mn><mml:mi>&#x003c0;</mml:mi></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>3</mml:mn></mml:msup><mml:mstyle displaystyle="true"><mml:mrow><mml:munderover><mml:mo>&#x0222b;</mml:mo><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mi>&#x0221e;</mml:mi></mml:mrow><mml:mi>&#x0221e;</mml:mi></mml:munderover><mml:mrow><mml:mstyle displaystyle="true"><mml:mrow><mml:munderover><mml:mo>&#x0222b;</mml:mo><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mi>&#x0221e;</mml:mi></mml:mrow><mml:mi>&#x0221e;</mml:mi></mml:munderover><mml:mrow><mml:mstyle displaystyle="true"><mml:mrow><mml:munderover><mml:mo>&#x0222b;</mml:mo><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mi>&#x0221e;</mml:mi></mml:mrow><mml:mi>&#x0221e;</mml:mi></mml:munderover><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mi>z</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>cos</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>&#x003bd;</mml:mi><mml:mrow><mml:mo>|</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>k</mml:mi></mml:mstyle><mml:mo>|</mml:mo></mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:msub><mml:mi>k</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mi>x</mml:mi><mml:mo>+</mml:mo><mml:mi>i</mml:mi><mml:msub><mml:mi>k</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mi>y</mml:mi><mml:mo>+</mml:mo><mml:mi>i</mml:mi><mml:msub><mml:mi>k</mml:mi><mml:mi>z</mml:mi></mml:msub><mml:mi>z</mml:mi></mml:mrow></mml:msup><mml:mi>d</mml:mi><mml:msub><mml:mi>k</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mi>d</mml:mi><mml:msub><mml:mi>k</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mi>d</mml:mi><mml:msub><mml:mi>k</mml:mi><mml:mi>z</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula>
</p><p>
<disp-formula id="formula-qf-21"><label>(21)</label><mml:math id="eq21"><mml:mrow><mml:mi>u</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>2</mml:mn><mml:mi>&#x003c0;</mml:mi></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>3</mml:mn></mml:msup><mml:mstyle displaystyle="true"><mml:mrow><mml:munderover><mml:mo>&#x0222b;</mml:mo><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mi>&#x0221e;</mml:mi></mml:mrow><mml:mi>&#x0221e;</mml:mi></mml:munderover><mml:mrow><mml:mstyle displaystyle="true"><mml:mrow><mml:munderover><mml:mo>&#x0222b;</mml:mo><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mi>&#x0221e;</mml:mi></mml:mrow><mml:mi>&#x0221e;</mml:mi></mml:munderover><mml:mrow><mml:mstyle displaystyle="true"><mml:mrow><mml:munderover><mml:mo>&#x0222b;</mml:mo><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mi>&#x0221e;</mml:mi></mml:mrow><mml:mi>&#x0221e;</mml:mi></mml:munderover><mml:mrow><mml:mi>U</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>&#x003c9;</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:msub><mml:mi>k</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mi>x</mml:mi><mml:mo>+</mml:mo><mml:mi>i</mml:mi><mml:msub><mml:mi>k</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mi>y</mml:mi><mml:mo>+</mml:mo><mml:mi>i</mml:mi><mml:mi>&#x003c9;</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msup><mml:mi>d</mml:mi><mml:msub><mml:mi>k</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mi>d</mml:mi><mml:msub><mml:mi>k</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mi>d</mml:mi><mml:mi>&#x003c9;</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:mrow></mml:mstyle><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula>
</p><p>
<disp-formula id="formula-qf-22"><label>(22)</label><mml:math id="eq22"><mml:mrow><mml:mi>u</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>2</mml:mn><mml:mi>&#x003c0;</mml:mi></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>3</mml:mn></mml:msup><mml:mstyle displaystyle="true"><mml:mrow><mml:munderover><mml:mo>&#x0222b;</mml:mo><mml:mn>0</mml:mn><mml:mi>&#x0221e;</mml:mi></mml:munderover><mml:mrow><mml:mi>d</mml:mi><mml:mi>&#x003c9;</mml:mi><mml:mstyle displaystyle="true"><mml:mrow><mml:munderover><mml:mo>&#x0222b;</mml:mo><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mi>&#x0221e;</mml:mi></mml:mrow><mml:mi>&#x0221e;</mml:mi></mml:munderover><mml:mrow><mml:mstyle displaystyle="true"><mml:mrow><mml:munderover><mml:mo>&#x0222b;</mml:mo><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mi>&#x0221e;</mml:mi></mml:mrow><mml:mi>&#x0221e;</mml:mi></mml:munderover><mml:mrow><mml:mn>2</mml:mn><mml:mi>U</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>&#x003c9;</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>cos</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>&#x003c9;</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:msub><mml:mi>k</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mi>x</mml:mi><mml:mo>+</mml:mo><mml:mi>i</mml:mi><mml:msub><mml:mi>k</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mi>y</mml:mi></mml:mrow></mml:msup><mml:mi>d</mml:mi><mml:msub><mml:mi>k</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mi>d</mml:mi><mml:msub><mml:mi>k</mml:mi><mml:mi>y</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:mrow></mml:mstyle><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>
</p><p>
<disp-formula id="formula-qf-23"><label>(23)</label><mml:math id="eq23"><mml:mrow><mml:mi>u</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>2</mml:mn><mml:mi>&#x003c0;</mml:mi></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>3</mml:mn></mml:msup><mml:mstyle displaystyle="true"><mml:mrow><mml:munderover><mml:mo>&#x0222b;</mml:mo><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mi>&#x0221e;</mml:mi></mml:mrow><mml:mi>&#x0221e;</mml:mi></mml:munderover><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>k</mml:mi><mml:mi>z</mml:mi></mml:msub><mml:mstyle displaystyle="true"><mml:mrow><mml:munderover><mml:mo>&#x0222b;</mml:mo><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mi>&#x0221e;</mml:mi></mml:mrow><mml:mi>&#x0221e;</mml:mi></mml:munderover><mml:mrow><mml:mstyle displaystyle="true"><mml:mrow><mml:munderover><mml:mo>&#x0222b;</mml:mo><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mi>&#x0221e;</mml:mi></mml:mrow><mml:mi>&#x0221e;</mml:mi></mml:munderover><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mi>z</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>cos</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>&#x003bd;</mml:mi><mml:mrow><mml:mo>|</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>k</mml:mi></mml:mstyle><mml:mo>|</mml:mo></mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:msub><mml:mi>k</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mi>x</mml:mi><mml:mo>+</mml:mo><mml:mi>i</mml:mi><mml:msub><mml:mi>k</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mi>y</mml:mi></mml:mrow></mml:msup><mml:mi>d</mml:mi><mml:msub><mml:mi>k</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mi>d</mml:mi><mml:msub><mml:mi>k</mml:mi><mml:mi>y</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula>
</p><p>
<disp-formula id="formula-qf-24a"><label>(24a)</label><mml:math id="eq24a"><mml:mrow><mml:mi>&#x003c9;</mml:mi><mml:mo>=</mml:mo><mml:mi>&#x003bd;</mml:mi><mml:mrow><mml:mo>|</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>k</mml:mi></mml:mstyle><mml:mo>|</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>&#x003bd;</mml:mi><mml:msqrt><mml:mrow><mml:msubsup><mml:mi>k</mml:mi><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>k</mml:mi><mml:mi>y</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>k</mml:mi><mml:mi>z</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:msqrt><mml:mtext>&#x02009;</mml:mtext></mml:mrow></mml:math></disp-formula>
</p><p>
<disp-formula id="formula-qf-24b"><label>(24b)</label><mml:math id="eq24b"><mml:mrow><mml:mi>d</mml:mi><mml:mi>&#x003c9;</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mi>&#x003bd;</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mfrac><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>z</mml:mi></mml:msub></mml:mrow><mml:mi>&#x003c9;</mml:mi></mml:mfrac><mml:mi>d</mml:mi><mml:msub><mml:mi>k</mml:mi><mml:mi>z</mml:mi></mml:msub></mml:mrow></mml:math></disp-formula>
</p><p>
<disp-formula id="formula-qf-25"><label>(25)</label><mml:math id="eq25"><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msqrt><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi>&#x003c9;</mml:mi><mml:mo>/</mml:mo><mml:mi>&#x003bd;</mml:mi></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>&#x02212;</mml:mo><mml:msubsup><mml:mi>k</mml:mi><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>&#x02212;</mml:mo><mml:msubsup><mml:mi>k</mml:mi><mml:mi>y</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:msqrt></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mo>&#x02212;</mml:mo><mml:msqrt><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi>&#x003c9;</mml:mi><mml:mo>/</mml:mo><mml:mi>&#x003bd;</mml:mi></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>&#x02212;</mml:mo><mml:msubsup><mml:mi>k</mml:mi><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>&#x02212;</mml:mo><mml:msubsup><mml:mi>k</mml:mi><mml:mi>y</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:msqrt></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:msup><mml:mi>&#x003bd;</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:msub><mml:mi>k</mml:mi><mml:mi>z</mml:mi></mml:msub></mml:mrow><mml:mi>&#x003c9;</mml:mi></mml:mfrac><mml:mi>U</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>&#x003c9;</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
</p><p>
<disp-formula id="formula-qf-26"><label>(26)</label><mml:math id="eq26"><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mo>&#x000b1;</mml:mo><mml:msqrt><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi>&#x003c9;</mml:mi><mml:mo>/</mml:mo><mml:mi>&#x003bd;</mml:mi></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>&#x02212;</mml:mo><mml:msubsup><mml:mi>k</mml:mi><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>&#x02212;</mml:mo><mml:msubsup><mml:mi>k</mml:mi><mml:mi>y</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:msqrt></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mi>&#x003bd;</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:msub><mml:mi>k</mml:mi><mml:mi>z</mml:mi></mml:msub></mml:mrow><mml:mi>&#x003c9;</mml:mi></mml:mfrac><mml:mi>U</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>&#x003c9;</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
</p><p>The inversion procedure may thus be summarized as follows:</p><list list-type="order"><list-item><p>Given the measurement data <mml:math id="beq83"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mi>z</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math> for <mml:math id="beq84"><mml:mrow><mml:mi>t</mml:mi><mml:mo>&#x0003e;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math>, calculate the time-symmetric function <mml:math id="beq85"><mml:mrow><mml:mi>u</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mi>z</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mi>z</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math> and its corresponding 3D Fourier transform <mml:math id="beq86"><mml:mrow><mml:mi>U</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>&#x003c9;</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math>.</p></list-item><list-item><p>Calculate <mml:math id="beq87"><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mi>z</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math> using Eq. 26. Numerically, this step involves interpolating the data given on discrete values of <italic>&#x003c9;</italic> to discrete values of <mml:math id="beq88"><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>z</mml:mi></mml:msub></mml:mrow></mml:math> based on the dispersion relation [<xref rid="R100" ref-type="bibr">100</xref>].</p></list-item><list-item><p>Calculate <mml:math id="beq89"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math> by performing the 3D inverse Fourier transform on <mml:math id="beq90"><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mi>z</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math>.</p></list-item><list-item><p>The result of Step 3 will be a source which is symmetric with respect to <mml:math id="beq91"><mml:mrow><mml:mi>z</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math>. If it is known that the source is non-zero only for <mml:math id="beq92"><mml:mrow><mml:mi>z</mml:mi><mml:mo>&#x0003e;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math>, multiply the result by <mml:math id="beq93"><mml:mrow><mml:mn>2</mml:mn><mml:mi>&#x003bc;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math>, where <mml:math id="beq94"><mml:mrow><mml:mi>&#x003bc;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mo>&#x000b7;</mml:mo><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math> is the Heaviside step function. </p></list-item></list><p>One of the factors that determine the quality of the reconstruction using Fourier-domain algorithm in the planar geometry is the accuracy of the interpolation performed in Step 2. To minimize image artifacts resulting from interpolation errors, regularization may be used [<xref rid="R101" ref-type="bibr">101</xref>]. Alternatively, Fourier-domain reconstruction may be performed without the need of regularization by using the Fourier domain synthetic aperture focusing technique (F-SAFT) [<xref rid="R102" ref-type="bibr">102</xref>,<xref rid="R103" ref-type="bibr"> 103</xref>]. In F-SAFT a frequency-domain free-space propagator is used to find <mml:math id="beq95"><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>z</mml:mi><mml:mo>=</mml:mo><mml:mi>&#x003b6;</mml:mi><mml:mo>,</mml:mo><mml:mi>&#x003c9;</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math>, <italic>i.e.</italic> the Fourier transform of the acoustic wave on the plane <mml:math id="beq96"><mml:mrow><mml:mi>z</mml:mi><mml:mo>=</mml:mo><mml:mi>&#x003b6;</mml:mi></mml:mrow></mml:math>, from <mml:math id="beq97"><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>z</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>&#x003c9;</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>u</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>&#x003c9;</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math>. The algorithm steps are as follows:</p><list list-type="order"><list-item><p>Calculate <mml:math id="beq98"><mml:mrow><mml:mi>U</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>&#x003c9;</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math>.</p></list-item><list-item><p>Propagate the fields from <mml:math id="beq99"><mml:mrow><mml:mi>z</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math> to all values of <italic>z</italic> in which the optoacoustic source is to be found using the following equation: <mml:math id="beq100"><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>&#x003c9;</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>U</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>&#x003c9;</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x000d7;</mml:mo><mml:mi>exp</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mtext>isign</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi>&#x003c9;</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>z</mml:mi><mml:msqrt><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi>&#x003c9;</mml:mi><mml:mo>/</mml:mo><mml:mi>&#x003bd;</mml:mi></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>&#x02212;</mml:mo><mml:msubsup><mml:mi>k</mml:mi><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>&#x02212;</mml:mo><mml:msubsup><mml:mi>k</mml:mi><mml:mi>y</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:msqrt></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></p></list-item><list-item><p>Integrate over frequency to find the pressure distribution at <mml:math id="beq101"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math>: <mml:math id="beq102"><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>z</mml:mi><mml:mo>=</mml:mo><mml:mi>&#x003b6;</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:mrow><mml:munderover><mml:mo>&#x0222b;</mml:mo><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mi>&#x0221e;</mml:mi></mml:mrow><mml:mi>&#x0221e;</mml:mi></mml:munderover><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>z</mml:mi><mml:mo>=</mml:mo><mml:mi>&#x003b6;</mml:mi><mml:mo>,</mml:mo><mml:mi>&#x003c9;</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:mi>&#x003c9;</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:math>.</p></list-item><list-item><p>Perform the 2D inverse Fourier transform on <mml:math id="beq103"><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math> to find the initial pressure distribution <mml:math id="beq104"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math>.</p></list-item></list></sec></sec><sec><label>3.3.</label><title>Time-reversal Algorithms</title><p>Time reversal generally implies that the pressure distribution <mml:math id="beq105"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math> at some <mml:math id="beq106"><mml:mrow><mml:mi>t</mml:mi><mml:mo>&#x0003e;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math> may be propagated backwards in time, <italic>e.g.</italic> by solving Eq. 1, to achieve the initial pressure distribution and thus the optoacoustic source (Eq. 8). A trivial implementation of this concept would thus require knowing <mml:math id="beq107"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math> at a specific time instant <mml:math id="beq108"><mml:mrow><mml:mi>t</mml:mi><mml:mo>&#x0003e;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math> for all positions in space. However, as the detection of the acoustic signals is performed over a surface, and not over a volume, such a trivial implementation is impractical. The first time-reversal formula compatible with the optoacoustic measurement was developed by Xu <italic>et al.</italic> [<xref rid="R78" ref-type="bibr">78</xref>] and Finch <italic>et al.</italic> [<xref rid="R79" ref-type="bibr">79</xref>] and was based on the Green&#x02019;s function subjected to the Dirichlet boundary condition. Under the far-field approximation, it was shown that this formula leads to the universal back-projection formula (Eq. 16) [<xref rid="R78" ref-type="bibr">78</xref>]. Thus, the early analytical formulation of the time-reversal approach could be included within the back-projection framework (Section 3.1). Much of the later work on time-reversal algorithms has been based on numerical implementations [<xref rid="R81" ref-type="bibr">81</xref>,<xref rid="R104" ref-type="bibr"> 104</xref>,<xref rid="R105" ref-type="bibr"> 105</xref>], which deviated from the back-projection formalism and enabled exact reconstruction for more general imaging scenarios. Specifically, time-reversal algorithms have been demonstrated with arbitrary detection boundaries [<xref rid="R81" ref-type="bibr">81</xref>], acoustic heterogeneities [<xref rid="R105" ref-type="bibr">105</xref>,<xref rid="R106" ref-type="bibr"> 106</xref>] and acoustic absorption and dispersion [<xref rid="R104" ref-type="bibr">104</xref>]. It is therefore that we consider time-reversal algorithms as a separate category of inversion algorithms. </p><p>In the case of lossless, homogeneous acoustic medium, time-reversal is based on two properties of Eq. 1:</p><list list-type="order"><list-item><p>Finite time response: Since the optoaoucstic source is enclosed within the detection surface, for a sufficiently large time <italic>T<sub>0</sub></italic>, the pressure waves generated by the source will all leave the volume trapped within the surface. </p></list-item><list-item><p>Invariance under time reversal: <mml:math id="beq109"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math> fulfills the same wave equation as <mml:math id="beq110"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math>. </p></list-item></list><p>The time reversed pressure field is defined by</p><p>
<disp-formula id="formula-qf-27"><label>(27)</label><mml:math id="eq27"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:msub><mml:mi>T</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mtext>&#x02009; &#x02009; &#x02009; &#x02009; &#x02009; &#x02009; &#x02009; &#x02009; &#x02009; &#x02009; &#x02009; &#x02009; &#x02009; &#x02009; &#x02009; &#x02009; &#x02009; &#x02009; &#x02009; &#x02009; &#x02009; &#x02009;</mml:mtext><mml:msub><mml:mi>T</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>&#x0003c;</mml:mo><mml:mi>t</mml:mi><mml:mo>&#x0003c;</mml:mo><mml:mn>2</mml:mn><mml:msub><mml:mi>T</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></disp-formula>
</p><p>Because of the two properties described above, <mml:math id="beq111"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi mathvariant="italic">tr</mml:mi></mml:msub><mml:mfenced open="(" close=")"><mml:mrow><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:math> fulfills Eq. 1 with the initial condition</p><p>
<disp-formula id="formula-qf-28"><label>(28)</label><mml:math id="eq28"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:mo>&#x02202;</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>/</mml:mo><mml:mo>&#x02202;</mml:mo></mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mtext>&#x02009; &#x02009; &#x02009; &#x02009; &#x02009; &#x02009;</mml:mtext><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mo>&#x02208;</mml:mo><mml:mi>V</mml:mi></mml:mrow></mml:math></disp-formula>
</p><p>And boundary values</p><p>
<disp-formula id="formula-qf-29"><label>(29)</label><mml:math id="eq29"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mi>s</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mi>s</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:msub><mml:mi>T</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mtext>&#x02009; &#x02009; &#x02009; &#x02009; &#x02009; &#x02009; &#x02009; &#x02009; &#x02009; &#x02009; &#x02009; &#x02009; &#x02009; &#x02009; &#x02009; &#x02009; &#x02009; &#x02009; &#x02009; &#x02009; &#x02009;</mml:mtext><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mi>s</mml:mi></mml:msub><mml:mo>&#x02208;</mml:mo><mml:mi>S</mml:mi><mml:mo>,</mml:mo><mml:mtext>&#x02009;</mml:mtext><mml:msub><mml:mi>T</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>&#x0003c;</mml:mo><mml:mi>t</mml:mi><mml:mo>&#x0003c;</mml:mo><mml:mn>2</mml:mn><mml:msub><mml:mi>T</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></disp-formula>
</p><p>where <italic>S</italic> is the surface over which the acoustic measurement is performed and <italic>V</italic> is the volume enclosed by <italic>S</italic>. The conditions in Eqs. 27-29 lead to a unique solution <mml:math id="beq112"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mi>s</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math> which can be calculated numerically [<xref rid="R81" ref-type="bibr">81</xref>]. The time-reversed pressure field <mml:math id="beq113"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mi>s</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math> at <mml:math id="eq114"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:msub><mml:mi>T</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math> gives the initial pressure distribution and thus the optoacoustic source. </p><p>Generalization of the time-reversal approach for more complex acoustic media requires modifying the procedure described above. In the case of acoustic losses, the wave equation is not invariant under time reversal. Specifically, the loss term in the original equation turns into a gain term in the time-reversed equation [<xref rid="R104" ref-type="bibr">104</xref>]. When the medium is acoustically heterogeneous, the assumption of a finite time response may not apply as waves may be trapped in the medium owing to acoustic reverberations [<xref rid="R105" ref-type="bibr">105</xref>,<xref rid="R106" ref-type="bibr"> 106</xref>]. Nonetheless, after sufficiently long time, it is still expected that the magnitude of the remaining fields in the enclosed volume becomes negligible. </p></sec><sec><label>3.4.</label><title>Model-based Algorithms</title><p>The model-based approach is based on a discrete representation of the forward acoustic problem. Namely, because the connection between the measured acoustic field and optoacoustic source is linear, its discretization may be written in a matrix form [<xref rid="R107" ref-type="bibr">107</xref>]:</p><p>
<disp-formula id="formula-qf-30"><label>(30)</label><mml:math id="eq30"><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>p</mml:mi></mml:mstyle><mml:mo>=</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>M</mml:mi><mml:mi>h</mml:mi></mml:mstyle></mml:mrow></mml:math></disp-formula>
</p><p>where <bold>p</bold> is a column vector representing the acoustic fields measured at a set of positions and time instants; <bold>h</bold> is a column vector representing the values of the energy density on the grid; and <bold>M</bold> is the model matrix. Once the discrete formulation has been established, the inverse problem is reduced to the algebraic problem of inverting Eq. 30. One of the main advantages of the model-based approach is the ability to include in the inversion process any linear effect in the imaging system, <italic>e.g.</italic> the detection field of finite-size detectors [<xref rid="R31" ref-type="bibr">31</xref>,<xref rid="R74" ref-type="bibr"> 74</xref>] or acoustic heterogeneities [<xref rid="R108" ref-type="bibr">108</xref>-<xref rid="R110" ref-type="bibr">110</xref>]. </p><p>In the ideal case of point detectors and a homogeneous lossless acoustic medium, the model matrix may be calculated by discretizing the integral relation in Eq. 4. Since the integration is performed on spherical surfaces (or arcs in the 2D case), which do not match the grid points on which the optoacoustic source is discretized, an accurate discretization of Eq. 4 requires approximating <mml:math id="beq115"><mml:mrow><mml:mi>H</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math> by a finite sum of <italic>a priori</italic> defined interpolation functions: </p><p>
<disp-formula id="formula-qf-31"><label>(31)</label><mml:math id="eq31"><mml:mrow><mml:mi>H</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x02248;</mml:mo><mml:mstyle displaystyle="true"><mml:msubsup><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:msub><mml:mi>f</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula>
</p><p>where <italic>h</italic> are the values of <mml:math id="beq116"><mml:mrow><mml:mi>H</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math> on the image grid. Substituting Eq. 31 in Eq. 4, and performing the integration over <mml:math id="beq117"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math>, one obtains the model matrix <bold>M</bold> [<xref rid="R31" ref-type="bibr">31</xref>,<xref rid="R107" ref-type="bibr"> 107</xref>,<xref rid="R111" ref-type="bibr"> 111</xref>-<xref rid="R113" ref-type="bibr">113</xref>]. The accuracy of the model matrix has a direct effect on the quality of the sequential reconstruction. For example, it has been shown that discontinuities in the interpolation, <italic>e.g.</italic> when piece-wise constant interpolation is used, may lead to numerical errors in the reconstruction [<xref rid="R111" ref-type="bibr">111</xref>].</p><p>Once a model matrix for the ideal case is constructed, it may be modified to include the response of the detector. Since the response of ultrasound detectors is generally linear and time-independent, it may be described by a spatially dependent impulse response <mml:math id="beq118"><mml:mrow><mml:mtext>&#x02009;</mml:mtext><mml:mi>R</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mi>s</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math>, where <bold>r</bold> is the position of a delta-function source, and <mml:math id="beq119"><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:math> is the detector&#x02019;s position on the detection surface. <mml:math id="beq120"><mml:mrow><mml:mtext>&#x02009;</mml:mtext><mml:mi>R</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mi>s</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math> may be numerically simulated to include the geometrical effects of the detector&#x02019;s finite aperture [<xref rid="R68" ref-type="bibr">68</xref>,<xref rid="R74" ref-type="bibr"> 74</xref>] and/or experimentally measured to include the effect of acoustic and electric impedance mismatches in the detection process [<xref rid="R69" ref-type="bibr">69</xref>,<xref rid="R70" ref-type="bibr"> 70</xref>]. It has been shown that the effect of <mml:math id="beq121"><mml:mrow><mml:mtext>&#x02009;</mml:mtext><mml:mi>R</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mi>s</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math> may be included by modifying Eq. 4 as follows:</p><p>
<disp-formula id="formula-qf-32"><label>(32)</label><mml:math id="eq32"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mi>s</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mi>&#x00393;</mml:mi><mml:mrow><mml:mn>4</mml:mn><mml:mi>&#x003c0;</mml:mi></mml:mrow></mml:mfrac><mml:mstyle displaystyle="true"><mml:mrow><mml:mo>&#x0222b;</mml:mo><mml:mrow><mml:mo>|</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>s</mml:mi></mml:mstyle></mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mo>-</mml:mo><mml:mi>r</mml:mi><mml:mo>'</mml:mo></mml:mstyle><mml:mo>|</mml:mo><mml:mi>R</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mo>|</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>s</mml:mi></mml:mstyle></mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mo>-</mml:mo><mml:mi>r</mml:mi><mml:mo>'</mml:mo></mml:mstyle><mml:mo>|</mml:mo></mml:mrow><mml:mi>&#x003bd;</mml:mi></mml:mfrac><mml:mo>,</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi><mml:mo>'</mml:mo></mml:mstyle><mml:mo>,</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>s</mml:mi></mml:mstyle></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>*</mml:mo><mml:mfrac><mml:mrow><mml:mi>&#x003b4;</mml:mi><mml:mo>'</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mo>|</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>s</mml:mi></mml:mstyle></mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mo>-</mml:mo><mml:mi>r</mml:mi><mml:mo>'</mml:mo></mml:mstyle><mml:mo>|</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mi>&#x003bd;</mml:mi><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>s</mml:mi></mml:mstyle></mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mo>-</mml:mo><mml:mi>r</mml:mi><mml:mo>'</mml:mo></mml:mstyle><mml:mo>|</mml:mo></mml:mrow></mml:mfrac><mml:msub><mml:mi>H</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi><mml:mo>'</mml:mo></mml:mstyle><mml:mo stretchy="false">)</mml:mo><mml:mi>d</mml:mi><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi><mml:mo>'</mml:mo></mml:mstyle></mml:mrow></mml:mrow></mml:mstyle><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>
</p><p>where <italic>*</italic> denotes temporal convolution [<xref rid="R74" ref-type="bibr">74</xref>]. <mml:math id="beq122"><mml:mrow><mml:mtext>&#x02009;</mml:mtext><mml:mi>R</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mi>s</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math> may be either measured experimentally or calculated numerically, depending on the detector technology. When Eq. 11 is valid, a hybrid method based on both measurement and simulation may be used [<xref rid="R114" ref-type="bibr">114</xref>]. Since the difference between Eqs. (32) and Eq. (4) is the addition of a temporal convolution operation, the model matrix corresponding to Eq. (32) may be obtained by performing discrete convolution on the columns of the model matrix calculated for the case of ideal detectors [<xref rid="R74" ref-type="bibr">74</xref>].</p><p>When the inverse problem is well-posed, <italic>i.e.</italic> the projection data is sufficient for performing an exact reconstruction, the inversion of Eq. (30) may be performed by solving the following least-square problem [<xref rid="R111" ref-type="bibr">111</xref>]:</p><p>
<disp-formula id="formula-qf-33"><label>(33)</label><mml:math id="eq33"><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>h</mml:mi></mml:mstyle><mml:mrow><mml:mtext>sol</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>arg</mml:mi><mml:msub><mml:mrow><mml:mi>min</mml:mi></mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>h</mml:mi></mml:mstyle></mml:msub><mml:msup><mml:mrow><mml:mrow><mml:mo>&#x02016;</mml:mo><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>p</mml:mi></mml:mstyle><mml:mo>&#x02212;</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>M</mml:mi><mml:mi>h</mml:mi></mml:mstyle></mml:mrow><mml:mo>&#x02016;</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>
</p><p>where <mml:math id="beq123"><mml:mrow><mml:mrow><mml:mo>&#x02016;</mml:mo><mml:mo>&#x022c5;</mml:mo><mml:mo>&#x02016;</mml:mo></mml:mrow></mml:mrow></mml:math> is the <mml:math id="beq124"><mml:mrow><mml:msub><mml:mi>&#x02113;</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math> norm. The solution to Eq. (33) is given by the Moore&#x02013;Penrose pseudo-inverse:</p><p>
<disp-formula id="formula-qf-34"><label>(34)</label><mml:math id="eq34"><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>h</mml:mi></mml:mstyle><mml:mrow><mml:mtext>sol</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>M</mml:mi></mml:mstyle><mml:mo>&#x02020;</mml:mo></mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>p</mml:mi></mml:mstyle><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>
</p><p>where <mml:math id="beq125"><mml:mrow><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>M</mml:mi></mml:mstyle><mml:mo>&#x02020;</mml:mo></mml:msup></mml:mrow></mml:math> is the pseudo-inverse and is given by <bold>M</bold><mml:math id="beq126"><mml:mrow><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>M</mml:mi></mml:mstyle><mml:mo>&#x02020;</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>M</mml:mi></mml:mstyle><mml:mi>T</mml:mi></mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>M</mml:mi></mml:mstyle></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>M</mml:mi></mml:mstyle><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:math>, and <italic>T</italic> denotes the conjugate transpose operator. The advantage of using the pseudo-inverse approach is that the pseudo-inverse matrix <bold>M</bold> is determined only by the experimental setup, <italic>e.g.</italic>, positions of the detectors, their electric and geometric responses, etc., and not by the measured data. Thus, <bold>M</bold> may be calculated once for a given measurement configuration with inversion reduced to multiplying it by the measured values of <bold>p</bold> &#x02013; a process that can be realistically performed in real time. The disadvantage of the pseudo-inverse approach is that its calculation might involve multiplication and inversion of very large matrices, which may turn impractical. </p><p>When the model matrix is too large to be inverted directly, iterative algorithms may be used instead to solve Eq. (33) [<xref rid="R107" ref-type="bibr">107</xref>], <italic>e.g.</italic> gradient descent or conjugate gradient [<xref rid="R31" ref-type="bibr">31</xref>]. In the iterative process, matrix-matrix multiplications are avoided, and matrix-vector multiplications are performed instead. Thus, the calculation of each iteration may be performed with high numerical efficiency. Generally, the conjugate-gradient method is a preferred method as it is characterized by a fast convergence rate. Further increase in efficiency may be achieved by using LSQR [<xref rid="R111" ref-type="bibr">111</xref>] &#x02013; an implementation of the conjugate-gradient method which is exceptionally efficient in the case of sparse matrices. Indeed, model matrices in optoacoustic tomography are generally sparse because the acoustic signals measured at a specific projection angle and time instant are not affected by the entire image, but rather by a small portion of it, which in the case of ideal detection withers into a spherical shell. </p><p>In many cases, the inversion problem is either ill-conditioned or ill-posed, <italic>i.e.</italic> the acquired projection data is insufficient to both uniquely and accurately determine the optoacoustic source over the prescribed grid. In other words, a large number of inherently different sources may all produce a dataset of acoustic signals that is very close to the measured data. In contrast to the other classes of inversion techniques discussed in this review, the model-based approach enables imposing constraints on the optoacoustic source to regularize the solution of the inverse problem. Many regularization techniques have been demonstrated for optoacoustic tomography, including Tikhonov regularization [<xref rid="R113" ref-type="bibr">113</xref>,<xref rid="R115" ref-type="bibr"> 115</xref>], singular value decomposition (SVD) [<xref rid="R115" ref-type="bibr">115</xref>], multi-scale techniques [<xref rid="R115" ref-type="bibr">115</xref>,<xref rid="R116" ref-type="bibr"> 116</xref>], limited-iteration LSQR [<xref rid="R117" ref-type="bibr">117</xref>], and total-variation (TV) regularization [<xref rid="R118" ref-type="bibr">118</xref>]. Multi-scale-based and TV regularizations rely on nonlinear optimization techniques from the field of image processing which provide statistical measures to distinguish between &#x0201c;natural&#x0201d; images and &#x0201c;spurious&#x0201d; images such as artifacts and noise [<xref rid="R119" ref-type="bibr">119</xref>]. </p><p>The major downside of the model-based approach is the relatively large computational resources it requires for high-resolution imaging. This deficiency, which has traditionally limited the application of model-based techniques [<xref rid="R61" ref-type="bibr">61</xref>], has been mitigated in recent years with the aid of more sophisticated algorithms and better computational resources. One of the most notable hardware improvements has been the application of GPUs in model-based inversion, which was implemented for the computationally demanding TV regularization [<xref rid="R118" ref-type="bibr">118</xref>]. Memory requirements could be reduced by the matrix compression method [<xref rid="R41" ref-type="bibr">41</xref>] or on-the-fly calculation of matrix elements [<xref rid="R31" ref-type="bibr">31</xref>]. Fast inversion algorithms include the numerically efficient LSQR as well as the pseudo-inverse technique. Finally, it has been recently shown that the model matrix may be approximated by a set of smaller matrices using a wavelet-packet-based formalism, thus enabling the use of computationally intensive matrix-inversion algorithms [<xref rid="R120" ref-type="bibr">120</xref>]. </p></sec></sec><sec><label>4.</label><title>RECONSTRUCTION CHARACTERISTICS</title><p>In this section we discuss the effect of practical limitations on the quality of reconstruction. Mathematically, the acoustic inverse problem is often described as the reconstruction of an optoacoustic source from the pressure field on a closed surface enclosing the source. In practice, the measured data is only a partial representation of the pressure field on the surface. First, as always true for experimental measurements, the projection data is contaminated by noise. Second, the bandwidth and aperture of the detector are finite, and in many cases, the approximation of a point detector is invalid. Third, the acoustic data that can be experimentally collected is always discrete whereas the exact mathematical solutions assume that the pressure field is known over continuous variables. Finally, in many cases, the imaged object is not accessible from all angles, leading to the so-called limited view scenario.</p></sec><sec><label>4.1.</label><title>Detector&#x02019;s Temporal Response</title><p>As discussed in Section 2.2, the measured acoustic signal may often be represented by a temporal convolution between the pressure waves on the detector&#x02019;s surface and the temporal response of the detector. Much of the ultrasound detection technology used today involves resonating detectors whose response may be modeled by a bandpass filter. The loss of lower frequencies in the signal may prevent the reconstruction of the low spatial frequencies of the optoacoustic source, thus leading to an image with negative values. <italic>Ad hoc</italic> solutions such as the application of the Hilbert transform may lead to positive images [<xref rid="R121" ref-type="bibr">121</xref>], but cannot truly restore the lost low-frequency data. Although the low-frequency data in the reconstruction generally does not reveal much interesting structure, it plays a major role in the optical inverse problem of optoacoustics [<xref rid="R122" ref-type="bibr">122</xref>]. The loss of high frequencies in the signal leads to smearing in the detected signals and consequentially in the reconstruction.</p><p>In the case of full-view reconstruction, the effect of the detector&#x02019;s temporal response on the image may be exactly quantified. Xu <italic>et al. </italic>showed that when the inversion operator for ideal acoustic detectors is performed on temporally convolved signals, the resulting reconstructed source would be the originating source spatially convolved with the following point spread function (PSF) [<xref rid="R123" ref-type="bibr">123</xref>]: </p><p>
<disp-formula id="formula-qf-35"><label>(35)</label><mml:math id="eq35"><mml:mrow><mml:mtext>PSF=-</mml:mtext><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>4</mml:mn><mml:mi>&#x003c0;</mml:mi><mml:mrow><mml:mo>|</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>h</mml:mi><mml:mo>'</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mo>|</mml:mo></mml:mrow></mml:mrow><mml:mo>/</mml:mo><mml:mi>&#x003bd;</mml:mi></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>h</mml:mi><mml:mo>'</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mrow><mml:mo>|</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mo>|</mml:mo></mml:mrow></mml:mrow><mml:mo>/</mml:mo><mml:mi>&#x003bd;</mml:mi></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
</p><p>where <mml:math id="beq127"><mml:mrow><mml:mi>h</mml:mi><mml:mo>'</mml:mo></mml:mrow></mml:math> is the derivative of the detector&#x02019;s temporal response, given in Eq. (11), and <mml:math id="beq128"><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi></mml:mstyle><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:math> is the distance from the origin. A similar result has also been recently obtained by Haltmeier <italic>et al.</italic> [<xref rid="R65" ref-type="bibr">65</xref>]. An interesting property of Eq. (35) is that the PSF is isotropic. Thus, if the detected signal is smeared by the detector&#x02019;s temporal response, the image will be equally smeared in all directions. </p><p>When <mml:math id="beq129"><mml:mrow><mml:mi>h</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math> is known, and its corresponding spectrum is non-zero over the measurement frequency band, its effect may be theoretically eliminated by performing deconvolution. Since the PSF of Eq. 35 is spatially independent, <italic>i.e.</italic> every point in the reconstruction is convolved with the same PSF, the image may be deconvolved with the PSF to obtain the original image. Alternatively, the measured acoustic signal may be deconvolved with the temporal response <mml:math id="beq130"><mml:mrow><mml:mi>h</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math> [<xref rid="R36" ref-type="bibr">36</xref>], or it may be included in the model [<xref rid="R111" ref-type="bibr">111</xref>] when model based inversion is used. Practically, however, deconvolution may restore attenuated frequency components only when their value is above the noise level of the measurement [<xref rid="R36" ref-type="bibr">36</xref>]. If deconvolution is performed in order to recover frequency components for which the response is below the measurement noise floor, the result would only be amplification of the noise at these frequencies. </p></sec><sec><label>4.2.</label><title>Detector&#x02019;s Aperture</title><p>Because of the finite size of the detector&#x02019;s surface, the measured acoustic signal is a spatial average of the pressure field, as shown in Eq. 11. It is thus expected that when reconstruction is performed with the assumption of ideal detection, the result would be a spatially averaged (smeared) version of the originating optoacoustic source. The effect of the detector aperture on the reconstruction was studied in Ref. [<xref rid="R123" ref-type="bibr">123</xref>] for the spherical, cylindrical, and planar geometries. It was found that the resulting PSFs depend on the detection geometry and may be spatially dependent, <italic>i.e.</italic> different smearing may occur at different positions in the reconstructed source. Although the exact PSFs are not always known explicitly, their effect may be approximated in the case of small flat detectors. In Ref. [<xref rid="R123" ref-type="bibr">123</xref>], M. Xu <italic>et al. </italic>provide a simple rule to estimate the smearing in the reconstruction due to the detector&#x02019;s aperture: Assuming that the detector&#x02019;s surface is a disk with a diameter <italic>&#x003b4;</italic>, if the scan is performed linearly in a certain direction, the reconstructed source will be smeared in that direction with a spatially invariant PSF with a width of <mml:math id="beq131"><mml:mrow><mml:mo>&#x02248;</mml:mo><mml:mi>&#x003b4;</mml:mi></mml:mrow></mml:math> if the scan is performed over a circle with a radius <mml:math id="beq132"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math>, the reconstructed source will be smeared tangentially with a spatially dependent PSF with a width <mml:math id="beq133"><mml:mrow><mml:mo>&#x02248;</mml:mo><mml:mi>&#x003b4;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mo>/</mml:mo><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math>, where <italic>r</italic> is the distance of the feature of interest from the origin. In the case of a circular scan, the result is based on the assumption of a small detector <mml:math id="beq134"><mml:mrow><mml:mi>&#x003b4;</mml:mi><mml:mo>&#x0226a;</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math>. We note that the PSFs found here are based on the assumption of an infinite detection bandwidth. As shown in Ref. [<xref rid="R65" ref-type="bibr">65</xref>], when accounting for both the detector&#x02019;s aperture and bandwidth, the image is smeared with both the PSFs found here and in Section 4.1.</p><p>The practical implications of the PSFs on the performance of optoacoustic imaging systems are far reaching, yet are rarely discussed in the literature. When a linear scan is performed, either as part of a cylindrical scan or a planar scan, the reconstructed source will be smeared by the size of the detector, which in the case of piezoelectric technology is often in the millimeter range. Thus, sub-millimeter resolution is difficult to achieve for linear scans with standard flat detectors. In contrast, the scale of the smearing effect in circular scans may be reduced significantly below the detector&#x02019;s size by increasing the scanning radius with respect to the size of the optoacoustic source. It is therefore not surprising that flat piezoelectric transducers are used in optoacoustic tomography almost exclusively with circular scans, whereas linear scans are performed with either focused detectors or miniaturized optical detectors that can achieve high sensitivity with small detector sizes (see Table <bold><xref ref-type="table" rid="T1">1</xref></bold>). </p><p>In Ref. [<xref rid="R61" ref-type="bibr">61</xref>] it was noted that over-sampling in the spatial domain, <italic>i.e.</italic> scanning with step sizes smaller than the detector&#x02019;s size, cannot mitigate the effect of the PSF due to the detector&#x02019;s aperture. This assertion, however, is only true when the inversion procedure used is based on the assumption of point detectors. It has been recently shown that if the detector&#x02019;s aperture is accounted for in model-based inversion, the effect of the detector&#x02019;s aperture on the reconstruction may be significantly mitigated, leading to enhanced resolution [<xref rid="R74" ref-type="bibr">74</xref>,<xref rid="R124" ref-type="bibr"> 124</xref>]. Alternatively, post-reconstruction processing techniques such as spin deblurring may be used to undo the effect of the detector&#x02019;s PSF [<xref rid="R125" ref-type="bibr">125</xref>]. Nonetheless, the restoration of high frequencies in the image, which were attenuated in the measurement owing to spatial averaging, may come at a price of enhancing high-frequency noise components in the reconstruction [<xref rid="R31" ref-type="bibr">31</xref>]. Though regularization may reduce the effect of noise, it is clear that similarly to the case discussed in Section 4.1, resolution enhancement beyond the system&#x02019;s &#x0201c;natural&#x0201d; values relies on low noise levels in the measurement. Finally, we note that the resolution enhancement reported in Ref. [<xref rid="R74" ref-type="bibr">74</xref>] relied on spatial over-sampling, i.e using scan steps which are smaller than the detector&#x02019;s size. When over-sampling is not possible, modeling the detector&#x02019;s aperture does not on its own enable resolution enhancement. </p></sec><sec><label>4.3.</label><title>Sampling</title><p>Although most mathematical formulations of the inverse problem assume that the pressure fields are known over the continuous coordinates of space and time, the measured acoustic data is inherently discrete. When designing an optoacoustic imaging system it is thus important to determine how time and space are discretized. In time, discretization is determined by the sampling rate of the acquisition of the acoustic signals, whereas in space discretization relates to the step size used in scanning. From the Nyquist sampling theorem it is known that a band-limited signal may be sampled at a rate that is equal to twice the signal&#x02019;s highest frequency without loss of information. Practically, the sampling rate is often determined by some cut-off frequency above which the signal&#x02019;s spectral content is sufficiently small. If the sampling rate is lower than the one prescribed by the Nyquist criterion, aliasing may occur, which may lead to false interpretation of the signal and artifacts in the reconstruction.</p><p>The case of discretization in time is straightforward: Since the signal is low-passed by the temporal response of the detector, the sampling rate should simply be chosen as twice the detector&#x02019;s cut-off frequency. Determining the adequate spatial sampling rate, however, is often not trivial as it depends on detector&#x02019;s aperture and on its temporal response. Generally, the effect of the detector&#x02019;s finite aperture is a spatial low-pass operation on the measured acoustic signals, where the spatial coordinates are those of the detection surface (<italic>e.g.</italic> Fig. <bold><xref ref-type="fig" rid="F2">2</xref></bold>). Assuming a flat square detector, the corresponding low-pass operation is characterized by a sinc function, which decays slowly at high frequencies. Therefore, in order to minimize aliasing, the scan step should ideally be several times smaller than the detector&#x02019;s length. It has been previously noted that a practical step size is between 2 and 5 times smaller than the detector&#x02019;s length [<xref rid="R61" ref-type="bibr">61</xref>]. In many cases, however, in order to improve acquisition speed, detector arrays are used for which the scan step is equal to the detector&#x02019;s length [<xref rid="R8" ref-type="bibr">8</xref>,<xref rid="R37" ref-type="bibr"> 37</xref>]. </p><p>In Ref. [<xref rid="R120" ref-type="bibr">120</xref>] it was shown that the spatial frequency content of the measured acoustic signals depends on their temporal frequency content. For example, applying a <italic>temporal</italic> low-pass filter on the acoustic signals removes also the high <italic>spatial</italic> frequencies in the signals and might enable scan steps larger than the detector&#x02019;s length without risk of aliasing. This relation between the temporal and spatial low-pass operations of the acoustic signals is not surprizing when considering that the PSF in Eq. 35 is isotropic and smears the reconstruction also in the smearing directions of the spatial low-pass operation. For example, let us consider the case of linear scanning with a flat detector with a width of <italic>&#x003b4;</italic>, as described in Section 4.2. Additionally, let us assume that the acoustic signals are significantly low-passed in time, resulting in an isotropic PSF (Eq. 35) that smears the image over a scale of 10&#x003b4;. Clearly, in such a case, the smearing effect due to the detector&#x02019;s aperture would be negligible and would not change considerably unless the detector&#x02019;s size is increased to an approximate size of 10&#x003b4; or above. In other words, the result of <italic>temporal</italic> filtering in this case would be the loss of all <italic>spatial</italic> frequencies in the acoustic data above the frequency<mml:math id="beq1344"><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>10</mml:mn><mml:mi>&#x003b4;</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math>. The implication of this spatial low-pass filtering is that in this case the scan step may be increased above the detector&#x02019;s size without risk of aliasing. </p><p>When the acoustic signals are spatially under-sampled, streak artifacts often appear in the image [<xref rid="R115" ref-type="bibr">115</xref>,<xref rid="R116" ref-type="bibr"> 116</xref>]. Numerical simulations have shown that these artifacts are most apparent when back-projection algorithms are used, whereas model-based inversion is less affected by streak artifacts [<xref rid="R111" ref-type="bibr">111</xref>,<xref rid="R113" ref-type="bibr"> 113</xref>]. Within the model-based framework, it was found that the best suppression of streak artifacts may be obtained when the regularization algorithm is based on the compressed sensing approach which penalizes features in the reconstruction which are not typical to &#x0201c;natural&#x0201d; images [<xref rid="R115" ref-type="bibr">115</xref>,<xref rid="R116" ref-type="bibr"> 116</xref>].</p></sec><sec><label>4.4.</label><title>Limited-view Tomography</title><p>While it is preferable that the acoustic detection be performed over a closed surface, it is often not feasible because of practical constraints associated with the experimental setup and the particular imaging application. Such constraints often arise in imaging systems designed for specific organs, <italic>e.g.</italic> the breast [<xref rid="R26" ref-type="bibr">26</xref>] or skin [<xref rid="R10" ref-type="bibr">10</xref>], rather than in whole-body imaging scenarios [<xref rid="R30" ref-type="bibr">30</xref>]. When designing such systems it is important to realize how the tomographic coverage affects the reconstruction. From the discussion in Section 2.3 it is clear that the full-tomographic coverage offered by closed surfaces is not essential as infinite planar detection surfaces enable exact and stable reconstructions (see Section 2.3). </p><p>In Ref. [<xref rid="R126" ref-type="bibr">126</xref>], Xu <italic>et al. </italic>formulated rules to determine for arbitrary surfaces the regions in space for which a full-tomographic view is effectively obtained. In these so-called <italic>detection regions</italic>, an accurate reconstruction may be obtained for all features in the optoacoustic source. A point is said to be in the detection region if any line that passes through it intersects with the detection surface. In other words, each point in the detection region must be covered by the detection surface over a solid angle of at least 2&#x003c0; steradian in the 3D case, and over an angle of &#x003c0; radians in the 2D case. Closed surfaces, which offer a full 4&#x003c0; steradian view, are thus, at least theoretically, superfluous.</p><p>Limited-view tomography relates to imaging scenarios in which part of the imaged object lies outside the detection region, as illustrated in (Fig. <bold><xref ref-type="fig" rid="F5">5</xref></bold>). For regions outside the detection region, some features may be lost in the reconstructed source [<xref rid="R94" ref-type="bibr">94</xref>], [<xref rid="R126" ref-type="bibr">126</xref>]. Specifically, it has been noted that boundaries whose normals do not intersect the detection surface will be blurred in the reconstruction process. Thus, for the example shown in (Fig. <bold><xref ref-type="fig" rid="F5">5</xref></bold>), boundary 1 will be blurred, whereas boundary 2 will be reconstructed well. Quantitative formulation of the blurring effect may be obtained by applying the wavelet-packet framework used in Ref. [<xref rid="R120" ref-type="bibr">120</xref>]. Although the wavelet-packet framework normally requires extensive numerical analysis, at least under the far-field approximation a simple description of the blurring effect may be obtained. In this case, the optoacoustic source may be divided into narrow bands in the spatial-frequency domain, where each band is detected only at locations on the detection surface which correspond to the direction of the frequency band. Thus, if some angles are missing in the coverage of the detection surface, approximately the same angles will be missing in the spatial-frequency spectrum of the reconstructed source. This property is more general than the one stated in Ref. [<xref rid="R126" ref-type="bibr">126</xref>] as it affects objects of all scales, and is not limited to only sharp boundaries, as shown in (Fig. <bold><xref ref-type="fig" rid="F6">6</xref></bold>). Finally, we note that the wavelet-packet analysis does not require that the far-field approximation apply for the whole object, but rather to only small regions, as expressed by the so-called <italic>local Radon transform</italic> in Ref. [<xref rid="R120" ref-type="bibr">120</xref>]. Naturally, owing to the uncertainty principle, the size of these regions limits the resolution in which the spatial-frequencies in the object and their corresponding detection angles may be identified. </p><p>Finally, we note that the definition of limited view is rather heuristic and is mostly useful in realistic imaging scenarios in which the detection surfaces are finite. Cylindrical and planar detection surfaces (Fig. <bold><xref ref-type="fig" rid="F2">2B</xref></bold> and <bold><xref ref-type="fig" rid="F2">2c</xref></bold>, respectively) technically correspond to our definition of limited-view tomography although they indeed possess stable inversion formulae. For instance, in the cylindrical detection geometry, all lines parallel to the <italic>z</italic> axis never intersect the detection surface, whereas for planar detection, the same is true for all the lines parallel to the detection plane. However, since all the vectors parallel to these detection surfaces cover a solid angle of 0, their effect may be neglected. Alternatively, one may adopt concepts from projective geometry, in which parallel lines are said to meet at infinity. Practically, however, cylindrical and planar detection surfaces are always finite, and thus do not have a detection region as defined in Ref. [<xref rid="R126" ref-type="bibr">126</xref>].</p></sec><sec><label>4.5.</label><title>Focused Detectors</title><p>As can be appreciated by our review so far, most of the development of reconstruction techniques in optoacoustic tomography has focused on ideal detectors, whether infinitesimal or infinite. Model-based techniques notwithstanding, finite-aperture flat detectors are usually treated as a degenerate form of point detectors for which the point-detector approximation may still be applied in reconstruction, albeit at the price of some loss of image resolution (Section 4.2). Focused detectors represent a different class of detectors whose properties vary significantly from those of ideal detectors. As a result, most of the techniques presented in Section 3 are inapplicable to focused detectors. Focused detectors possess two properties which make them attractive for optoacoustic imaging: the ability to confine the detection field to a small region in space, and the ability to combine wideband operation with the large detection surfaces necessary for achieving high sensitivity. The combination of these two properties has made focused detectors a favorable option over flat detectors when linear scans are performed.</p><p>Optoacoustic systems in which the detection surface is cylindrical (Fig. <bold><xref ref-type="fig" rid="F2">2.2</xref></bold>) are almost exclusively based on cylindrically focused detectors [<xref rid="R2" ref-type="bibr">2</xref>,<xref rid="R7" ref-type="bibr"> 7</xref>,<xref rid="R8" ref-type="bibr"> 8</xref>]. These detectors may be characterized by either a point or a line in the dimension corresponding to the circular scan and are focused in the dimension corresponding to the linear scan (see discussion in Section 2.2). The resulting focal region is thus approximately planar. Reconstruction in this case may be performed separately for each plane, <italic>i.e.</italic> each circular scan may be used to find an approximation for the in-plane optoacoustic source, based on Eq. 9. Since reconstructing a single slice of the optoacoustic source requires fewer projections than the entire 3D volume, cylindrically focused detectors enable fast data acquisition for <italic>selective-plane imaging</italic> [<xref rid="R8" ref-type="bibr">8</xref>]. The main disadvantage of this approach is that the thickness of the imaged plane is not constant, but is rather determined by the acoustic wavelengths or feature sizes exhibited by the optoacoustic source, as described by Eq. (12). Thus, for large objects, little or no focusing is achieved. A practical solution to the problem is high-passing the detected signals, thus limiting the reconstruction to acoustic frequencies for which the detector is focused to a sufficiently thin slice. However, as noted in Section 4.1, loss of low frequency-information in the reconstruction may hinder subsequent attempts for quantification. </p><p>When the detection surface is planar, <italic>i.e.</italic> a linear scan is performed in both dimensions (Fig. <bold><xref ref-type="fig" rid="F2">2.3</xref></bold>), high-resolution imaging with large-area detectors requires that the detectors be spherically focused [<xref rid="R3" ref-type="bibr">3</xref>]. If one ignored diffraction, and assumed ideal focusing characteristic, <italic>i.e.</italic> detection of only those sources lying on a line, the resulting inversion problem would be trivial, namely the integral in Eq. (4) would be replaced by the value of the optoacoustic image at a point on the detection line whose distance is directly related to the detection instant <italic>via</italic> the time-of-flight principle. Reconstruction would thus mean simply projecting the measured signal over the detection line. In this way, by linearly scanning the detector, the entire optoacoustic source may be reconstructed line-by-line. This procedure is extremely simple as each measurement is separately used to reconstruct a separate part of the source. In practice, however, ideal focusing along a line is impossible owing to the laws of diffraction, as described by Eq. (12) and (13). Thus, early implementations of this algorithm were limited to the focal zone of the detector, <italic>i.e.</italic> a cylindrical volume with the diameter and length given by Eq. (12) and (13), respectively. Although exact reconstruction formulae for focused detectors do not exist, heuristic approaches, such as the virtual detector (VD), enable expanding the volume which can be reconstructed beyond the focal-zone limit [<xref rid="R127" ref-type="bibr">127</xref>]. Nonetheless, the VD approach generally requires that low-frequency information be filtered out to achieve high-resolution in the reconstruction. Further improvement in reconstruction quality has been recently achieved by using a model-based approach in which the surface of cylindrically [<xref rid="R128" ref-type="bibr">128</xref>] and spherically [<xref rid="R129" ref-type="bibr">129</xref>] focused detector was included in the model. Since the model equally applies to all temporal frequencies in the detected signals, it generally enables a better reconstruction of large features in the imaged object. </p></sec><sec sec-type="conclusion"><label>5.</label><title>CONCLUSION</title><p>The term optoacoustic imaging represents a diverse biomedical imaging methodology capable of producing multiscale images <italic>via</italic> various contrast mechanisms. Much of the diversity of optoacoustic imaging stems from its hybridity, as different patterns of optical excitation and acoustic detection lead to distinct imaging scenarios. When imaging tissue at depths below the optical mean free path, optical focusing may be used to achieve high resolution, similarly to purely optical microscopy techniques. Therefore, in applications such as optical-resolution microscopy [<xref rid="R6" ref-type="bibr">6</xref>], the optical design has the most decisive effect on the system&#x02019;s performance metrics. When imaging at depths significantly larger than the optical mean free path, the role of acoustic detection increases and becomes essential to attaining high reconstruction quality. It is in this regime, where light is fully, or almost fully, diffusive, that optoacoustic imaging may provide imaging resolutions vastly superior to purely optical techniques. Specifically, the illumination leads to the creation of acoustic sources in a large volume in the tissue, whose amplitudes are proportional to the amount of energy locally absorbed, while the spatial resolution of the reconstruction is solely determined by the acoustic, rather than the optical, characteristics of the imaging experiment. In optoacoustic tomography, a tomographic measurement of the subsequent acoustic waves provides sufficient information to retrieve a map of energy distribution in the tissue by means of acoustic inversion algorithms. As the deposited energy is proportional to the optical absorption coefficient, tomographic inversion thus yields an image with optical contrast and acoustic resolution. </p><p>In this paper we reviewed the plurality of detection schemes (Section 2) and corresponding inversion algorithms used in optoacoustic tomography (Section 3) and discussed their characteristics. Specific attention was given to practical aspects of the techniques used in the field. Theoretically, in the case of a homogeneous acoustic medium, the optoacoustic source may be exactly recovered when the pressure waves it emits are detected over a surface enclosing the source. Numerous inversion methods, both analytical and numerical, have been developed for this ideal picture of optoacoustic tomography. Practically, the measured acoustic data is inherently limited and corresponds to only an approximate representation of the pressure waves. The consequence of this limitation is an inevitable degradation in reconstruction quality. The effects non-ideal detection patterns have on the reconstruction are largely known and are discussed in Section 4. Considerable progress has been made in mitigating these effects by means of improved hardware that better emulates the ideal detection scenario as well as new inversion algorithms that take the non-ideal detection patterns into account. Effects of non-ideal wave propagation due to acoustic heterogeneity, losses, and dispersion, are more challenging to overcome as they cannot be solved by means of better hardware, and their modeling generally requires some additional <italic>a priori</italic> information on the imaged object. </p><p>In order to simplify the discussion on the numerous inversion techniques which have been developed for optoacoustic tomography, we divided them into 4 categories: time-domain (back-projection) algorithms, frequency-domain algorithms, time-reversal algorithms, and model-based algorithms. The first two categories largely involve closed-form solutions to the inversion problem. Arguably, the reconstruction approach most favored in experimental works is the back-projection approach as it is very easy to implement and is generally acceptable for most practical imaging scenarios, even when not exact. Specifically, in optoacoustic systems which rely on piezoelectric detectors, the distance of the detector from the imaged object is often sufficiently large so that the far-field approximation has some validity, and thus also Eq. 15. Fourier-domain techniques are mostly used for planar detection surfaces owing to their high numerical efficiency in that case. For spherical and cylindrical surfaces, this approach is commonly avoided due to its high mathematical and numerical complexity and the availability of the universal back-projection formula (Eq. 16), which applies to these cases. Nonetheless, the simple structure of the Fourier-domain formula recently developed in Ref. [<xref rid="R99" ref-type="bibr">99</xref>] for the spherical case could potentially offer an attractive alternative to the back-projection approach. </p><p>The last two categories of inversion algorithms are largely numerical, and as such offer a more versatile solution to the inverse problem. Time-reversal techniques are based on back-tracking the propagation of the acoustic waves. Mathematically, the time axis is reversed in the differential equation describing the system, and the measured pressure distribution is used as the initial value. The solution is thus found by simply solving the new differential equation to recover the initial pressure distribution. Because the equation may be solved for any closed surface, this approach is applicable to arbitrary closed detection surfaces. Additionally, any effects that can be accurately included in the differential equation, <italic>e.g.</italic> frequency-dependent acoustic losses or dispersion, may be accounted for in the inversion process. This is currently an impossible feat for analytical approaches, which rely on an ideal description of the wave equation. </p><p>Model-based algorithms represent the most general category of algorithms of those reviewed in this paper. Fundamentally, the model-based approach requires only that the tomographic problem be linear, <italic>i.e.</italic> that a linear relation exist between the optoacoustic source and the measured pressure fields. This relation is discretized and represented by a matrix equation, which is subsequently inverted. The advantage of this approach is that any linear effect in the system may be considered, whether it relates to the pressure wave propagation or to the acoustic detection. Thus, finite detection apertures may be taken into account in the inversion process, or more generally, any spatio-temporal detection response as long as it can be modeled or measured. In contrast, time-reversal algorithms can account for physical effects in the wave propagation, but not for effects in the acoustic detection. The major downside of model-based algorithms is the extremely large matrix sizes which are required for high-resolution imaging: ranging from several gigabytes in the 2D case to hundreds of gigabytes or more in the 3D case. Handling and processing such large data is one of the big challenges this category of algorithms is faced with. Nonetheless, the continual growth in computation power and computer memory alongside with the development of numerically efficient algorithms has already made model-based inversion a viable option for the 2D case, and an acceptable option for 3D reconstructions when high throughput is not required. The ability of model-based algorithms to account for all linear effects in the imaging systems as well as the ability to apply sophisticated regularization algorithms has been shown to increase imaging performance beyond the one achieved by classical time- and Fourier-domain techniques. As computational capacities continue to increase, one should expect to see the model-based approach applied more often in quantified experimental imaging studies, especially in non-ideal imaging scenarios where analytical inverse formulations significantly deviate from reality. </p></sec></body><back><ack><title>ACKNOWLEDGEMENTS</title><p>D.R. acknowledges support from the European Union under grant agreement ERC-2010-StG-260991.</p></ack><sec><title>CONFLICT OF INTEREST</title><p>The authors confirm that this article content has no conflict of interest.</p></sec><ref-list><title>REFERENCES</title><ref id="R1"><label>1</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hoelen</surname><given-names>CGA</given-names></name><name><surname>de Mul</surname><given-names>FFM</given-names></name><name><surname>Pongers</surname><given-names>R</given-names></name><name><surname>Dekker</surname><given-names>A</given-names></name></person-group><article-title>Three-dimensional photoacoustic imaging of blood vessels in tissue.</article-title><source>Opt Lett</source><year>1998</year><volume>23</volume><issue>8</issue><fpage>648</fpage><lpage>50</lpage><pub-id pub-id-type="pmid">18084605</pub-id></element-citation></ref><ref id="R2"><label>2</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>X</given-names></name><name><surname>Pang</surname><given-names>Y</given-names></name><name><surname>Ku</surname><given-names>G</given-names></name><name><surname>Xie</surname><given-names>X</given-names></name><name><surname>Stoica</surname><given-names>G</given-names></name><name><surname>Wang</surname><given-names>LV</given-names></name></person-group><article-title>Noninvasive laser-induced photoacoustic tomography for structural and functional in vivo imaging of the brain.</article-title><source>Nature Biotechnol</source><year>2003</year><volume>21</volume><issue>7</issue><fpage>803</fpage><lpage>06</lpage><pub-id pub-id-type="pmid">12808463</pub-id></element-citation></ref><ref id="R3"><label>3</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>HF</given-names></name><name><surname>Maslov</surname><given-names>K</given-names></name><name><surname>Stoica</surname><given-names>G</given-names></name><name><surname>Wang</surname><given-names>LV</given-names></name></person-group><article-title>Functional photoacoustic microscopy for high-resolution and noninvasive in vivo imaging.</article-title><source>Nature Biotechol</source><year>2006</year><volume>24</volume><issue>7</issue><fpage>848</fpage><lpage>51</lpage></element-citation></ref><ref id="R4"><label>4</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sethuraman</surname><given-names>S</given-names></name><name><surname>Aglyamov</surname><given-names>SR</given-names></name><name><surname>Amirian</surname><given-names>JH</given-names></name><name><surname>Smalling</surname><given-names>RW</given-names></name><name><surname>Emelianov</surname><given-names>SY</given-names></name></person-group><article-title>Intravascular photoacoustic imaging using an IVUS imaging catheter.</article-title><source>IEEE Trans Ultrason Ferroelectr Freq Control</source><year>2007</year><volume>54</volume><issue>5</issue><fpage>978</fpage><lpage>986</lpage><pub-id pub-id-type="pmid">17523562</pub-id></element-citation></ref><ref id="R5"><label>5</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>De La Zerda</surname><given-names>A</given-names></name><name><surname>Zavaleta</surname><given-names>C</given-names></name><name><surname>Keren</surname><given-names>S </given-names></name><etal/></person-group><article-title>Carbon nanotubes as photoacoustic molecular imaging agents in living mice.</article-title><source>Nature Nano</source><year>2008</year><volume>3</volume><fpage>557</fpage><lpage>62</lpage></element-citation></ref><ref id="R6"><label>6</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maslov</surname><given-names>K</given-names></name><name><surname>Zhang</surname><given-names>HF</given-names></name><name><surname>Hu</surname><given-names>S</given-names></name><name><surname>Wang</surname><given-names>LV</given-names></name></person-group><article-title>Optical-resolution photoacoustic microscopy for in vivo imaging of single capillaries.</article-title><source>Opt Lett</source><year>2008</year><volume>33</volume><issue>9</issue><fpage>929</fpage><lpage>31</lpage><pub-id pub-id-type="pmid">18451942</pub-id></element-citation></ref><ref id="R7"><label>7</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Razansky</surname><given-names>D</given-names></name><name><surname>Distel</surname><given-names>M</given-names></name><name><surname>Vinegoni</surname><given-names>C </given-names></name><etal/></person-group><article-title>Multispectral opto-acoustic tomography of deep-seated fluorescent proteins in vivo.</article-title><source>Nature Photonics</source><year>2009</year><volume>3</volume><fpage>412</fpage><lpage>17</lpage></element-citation></ref><ref id="R8"><label>8</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Razansky</surname><given-names>D</given-names></name><name><surname>Buehler</surname><given-names>A</given-names></name><name><surname>Ntziachristos</surname><given-names>V</given-names></name></person-group><article-title>Volumetric real-time multispectral optoacoustic tomography of biomarkers .</article-title><source>Nature Protocols</source><year>2011</year><volume>6</volume><fpage>1121</fpage><lpage>29</lpage></element-citation></ref><ref id="R9"><label>9</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yang</surname><given-names>JM</given-names></name><name><surname>Favazza</surname><given-names>C</given-names></name><name><surname>Chen</surname><given-names>R </given-names></name><etal/></person-group><article-title>Simultaneous functional photoacoustic and ultrasonic endoscopy of internal organs in vivo.</article-title><source>Nature Med</source><year>2012</year><volume>18</volume><fpage>1297</fpage><lpage>1302</lpage><pub-id pub-id-type="pmid">22797808</pub-id></element-citation></ref><ref id="R10"><label>10</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Laufer</surname><given-names>J</given-names></name><name><surname>Johnson</surname><given-names>P</given-names></name><name><surname>Zhang</surname><given-names>E</given-names></name><etal/></person-group><article-title>In vivo preclinical photoacoustic imaging of tumor vasculature development and therapy.</article-title><source>J Biomed Opt.</source><year>2012</year><volume>17</volume><issue>5</issue><fpage>056016</fpage><pub-id pub-id-type="pmid">22612139</pub-id></element-citation></ref><ref id="R11"><label>11</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tainter</surname><given-names>CS</given-names></name><name><surname>Bell</surname><given-names>AG</given-names></name></person-group><article-title>Selenium and the photophone.</article-title><source>Nature</source><year>1880</year><volume>22</volume><fpage>500</fpage><lpage>503</lpage></element-citation></ref><ref id="R12"><label>12</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Veingerov</surname><given-names>ML</given-names></name></person-group><article-title>New method of gas analysis based on Tyndall-R&#x000f6;ntgen optic-acoustic effect.</article-title><source>Dokl Akad Nauk (USSR)</source><year>1938</year><volume>19</volume><fpage>687</fpage><lpage>88</lpage></element-citation></ref><ref id="R13"><label>13</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rosencwaig</surname><given-names>A</given-names></name></person-group><article-title>Photoacoustic spectroscopy of biological materials.</article-title><source>Science</source><year>1973</year><volume>181</volume><fpage>657</fpage><lpage>58</lpage><pub-id pub-id-type="pmid">4353357</pub-id></element-citation></ref><ref id="R14"><label>14</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Patel</surname><given-names>CKN</given-names></name><name><surname>Tam</surname><given-names>AC</given-names></name></person-group><article-title>Pulsed photoacoustic spectroscopy of condensed matter.</article-title><source>Rev Mod Phys</source><year>1981</year><volume>53</volume><fpage>517</fpage><lpage>50</lpage></element-citation></ref><ref id="R15"><label>15</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oraevsky</surname><given-names>AA</given-names></name><name><surname>Jacques</surname><given-names>SL</given-names></name><name><surname>Esenaliev</surname><given-names>RO</given-names></name><name><surname>Tittel</surname><given-names>FK</given-names></name></person-group><article-title>Time-resolved optoacoustic imaging in layered biological tissues.</article-title><source>New York: Academic Press</source><year>1994</year></element-citation></ref><ref id="R16"><label>16</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kruger</surname><given-names>RA</given-names></name><name><surname>Liu</surname><given-names>P</given-names></name><name><surname>Fang</surname><given-names>Y</given-names></name><name><surname>Appledorn</surname><given-names>CR</given-names></name></person-group><article-title>Photoacoustic ultrasound (PAUS)&#x02014;Reconstruction tomography.</article-title><source>Med Phys</source><year>1995</year><volume>22</volume><issue>10</issue><fpage>1605</fpage><lpage>09</lpage><pub-id pub-id-type="pmid">8551984</pub-id></element-citation></ref><ref id="R17"><label>17</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gusev</surname><given-names>VZ</given-names></name><name><surname>Karabutov</surname><given-names>AA</given-names></name></person-group><article-title>Laser Optoacoustics.</article-title><source>New York: AIP</source><year>1993</year></element-citation></ref><ref id="R18"><label>18</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Telenkov</surname><given-names>S</given-names></name><name><surname>Mandelis</surname><given-names>A</given-names></name><name><surname>Lashkari</surname><given-names>B</given-names></name><name><surname>Forcht</surname><given-names>M</given-names></name></person-group><article-title>Frequency-domain photothermoacoustics: Alternative imaging modality of biological tissues .</article-title><source>Appl Phys</source><year>2009</year><volume>105</volume><issue>10</issue><fpage>102029</fpage></element-citation></ref><ref id="R19"><label>19</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Petschke</surname><given-names>A</given-names></name><name><surname>La Rivi&#x000e8;re</surname><given-names>PJ</given-names></name></person-group><article-title>Comparison of intensity-modulated continuous-wave lasers with a chirped modulation frequency to pulsed lasers for photoacoustic imaging applications.</article-title><source>Biomed Opt Express</source><year>2010</year><volume>1</volume><issue>4</issue><fpage>1188</fpage><lpage>95</lpage><pub-id pub-id-type="pmid">21258540</pub-id></element-citation></ref><ref id="R20"><label>20</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ma</surname><given-names>R</given-names></name><name><surname>Soentges</surname><given-names>S</given-names></name><name><surname>Shoham</surname><given-names>S</given-names></name><name><surname>Ntziachristos</surname><given-names>V</given-names></name><name><surname>Razansky</surname><given-names>D</given-names></name></person-group><article-title>Fast scanning coaxial optoacoustic microscopy.</article-title><source>Biomed Opt Exp</source><year>2012</year><volume>3</volume><issue>7</issue><fpage>1724</fpage><lpage>31</lpage></element-citation></ref><ref id="R21"><label>21</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Allen</surname><given-names>TJ</given-names></name><name><surname>Beard</surname><given-names>PC</given-names></name></person-group><article-title>Pulsed near-infrared laser diode excitation system for biomedical photoacoustic imaging.</article-title><source>Opt Lett</source><year>2006</year><volume>31</volume><issue>23</issue><fpage>3462</fpage><lpage>64</lpage><pub-id pub-id-type="pmid">17099750</pub-id></element-citation></ref><ref id="R22"><label>22</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>Y</given-names></name><name><surname>Maslov</surname><given-names>K</given-names></name><name><surname>Zhang</surname><given-names>Y </given-names></name><etal/></person-group><article-title>Fiber-laser-based photoacoustic microscopy and melanoma cell detection.</article-title><source>J Biomed Opt</source><year>2011</year><volume>16</volume><issue>1</issue><fpage>011014</fpage><pub-id pub-id-type="pmid">21280901</pub-id></element-citation></ref><ref id="R23"><label>23</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zharov</surname><given-names>VP</given-names></name><name><surname>Galanzha</surname><given-names>EI</given-names></name><name><surname>Shashkov</surname><given-names>EV</given-names></name><name><surname>Khlebtsov</surname><given-names>NG</given-names></name><name><surname>Tuchin</surname><given-names>VV</given-names></name></person-group><article-title>In vivo photoacoustic flow cytometry for monitoring of circulating single cancer cells and contrast agents.</article-title><source>Opt Lett</source><year>2006</year><volume>31</volume><issue>24</issue><fpage>3623</fpage><lpage>25</lpage><pub-id pub-id-type="pmid">17130924</pub-id></element-citation></ref><ref id="R24"><label>24</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buehler</surname><given-names>A</given-names></name><name><surname>De&#x000e1;n-Ben</surname><given-names>XL</given-names></name><name><surname>Claussen</surname><given-names>J</given-names></name><name><surname>Ntziachristos</surname><given-names>V</given-names></name><name><surname>Razansky</surname><given-names>D</given-names></name></person-group><article-title>Three-dimensional optoacoustic tomography at video rate.</article-title><source>Opt Express</source><year>2012</year><volume>20</volume><issue>20</issue><fpage>22712</fpage><lpage>19</lpage><pub-id pub-id-type="pmid">23037421</pub-id></element-citation></ref><ref id="R25"><label>25</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xu</surname><given-names>M</given-names></name><name><surname>Wang</surname><given-names>LV</given-names></name></person-group><article-title>Time-domain reconstruction for thermoacoustic tomography in a spherical geometry.</article-title><source>IEEE Trans Med Imaging</source><year>2002</year><volume>21</volume><issue>7</issue><fpage>814 </fpage><lpage> 822</lpage><pub-id pub-id-type="pmid">12374318</pub-id></element-citation></ref><ref id="R26"><label>26</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kruger</surname><given-names>RA</given-names></name><name><surname>Lam</surname><given-names>RB</given-names></name><name><surname>Reinecke</surname><given-names>DR</given-names></name><name><surname>Del Rio</surname><given-names>SP</given-names></name><name><surname>Doyle</surname><given-names>RP</given-names></name></person-group><article-title>Photoacoustic angiography of the breast.</article-title><source>Med Phys</source><year>2010</year><volume>37</volume><issue>1</issue><fpage>6096</fpage><lpage>7001</lpage><pub-id pub-id-type="pmid">21158321</pub-id></element-citation></ref><ref id="R27"><label>27</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haltmeier</surname><given-names>M</given-names></name><name><surname>Scherzer</surname><given-names>O</given-names></name><name><surname>Burgholzer</surname><given-names>P</given-names></name></person-group><article-title>Thermoacoustic tomography and the circular Radon transform: exact inversion formula.</article-title><source>Math. Models Methods Appl. Sci.</source><year>2007</year><volume>17</volume><issue>4</issue><fpage>635</fpage><lpage>655</lpage></element-citation></ref><ref id="R28"><label>28</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gr&#x000fc;n</surname><given-names>H</given-names></name><name><surname>Berer</surname><given-names>T</given-names></name><name><surname>Burgholzer</surname><given-names>P</given-names></name><name><surname>Nuster</surname><given-names>R</given-names></name><name><surname>Paltauf</surname><given-names>G</given-names></name></person-group><article-title>Three-dimensional photoacoustic imaging using fiber-based line detectors.</article-title><source>J Biomed Opt</source><year>2010</year><volume>15</volume><issue>2</issue><fpage>021306</fpage><pub-id pub-id-type="pmid">20459228</pub-id></element-citation></ref><ref id="R29"><label>29</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haltmeier</surname><given-names>M</given-names></name><name><surname>Scherzer</surname><given-names>O</given-names></name><name><surname>Burgholzer</surname><given-names>P</given-names></name><name><surname>Paltauf</surname><given-names>G</given-names></name></person-group><article-title>Thermoacoustic computed tomography with large planar receivers.</article-title><source>Inverse Problems</source><year>2004</year><volume>20</volume><issue>5</issue><fpage>1663</fpage><lpage>73</lpage></element-citation></ref><ref id="R30"><label>30</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brecht</surname><given-names>HP</given-names></name><name><surname>Su</surname><given-names>R</given-names></name><name><surname>Fronheiser</surname><given-names>M</given-names></name><name><surname>Ermilov</surname><given-names>SA</given-names></name><name><surname>Conjusteau</surname><given-names>A</given-names></name><name><surname>Oraevsky</surname><given-names>AA</given-names></name></person-group><article-title>Whole-body three-dimensional optoacoustic tomography system for small animals.</article-title><source>J Biomed Opt</source><year>2009</year><volume>14</volume><issue>6</issue><fpage>064007</fpage><pub-id pub-id-type="pmid">20059245</pub-id></element-citation></ref><ref id="R31"><label>31</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>K</given-names></name><name><surname>Ermilov</surname><given-names>SA</given-names></name><name><surname>Su</surname><given-names>R</given-names></name><name><surname>Brecht</surname><given-names>HP</given-names></name><name><surname>Oraevsky</surname><given-names>AA</given-names></name><name><surname>Anastasio</surname><given-names>MA</given-names></name></person-group><article-title>An imaging model incorporating ultrasonic transducer properties for three-dimensional optoacoustic tomography.</article-title><source>IEEE Trans Med Imaging</source><year>2011</year><volume>21</volume><issue>7</issue><fpage>823</fpage><lpage>28</lpage><pub-id pub-id-type="pmid">12374319</pub-id></element-citation></ref><ref id="R32"><label>32</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xu</surname><given-names>Y</given-names></name><name><surname>Xu</surname><given-names>M</given-names></name><name><surname>Wang</surname><given-names>LH</given-names></name></person-group><article-title>Exact frequency-domain reconstruction for thermoacoustic tomography: II.Cylindrical geometry.</article-title><source> IEEE Trans Med Imaging</source><year>2002</year><volume>21</volume><issue>7</issue><fpage>829</fpage><lpage>33</lpage><pub-id pub-id-type="pmid">12374320</pub-id></element-citation></ref><ref id="R33"><label>33</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xu</surname><given-names>M</given-names></name><name><surname>Xu</surname><given-names>Y</given-names></name><name><surname>Wang</surname><given-names>LV</given-names></name></person-group><article-title>Time-domain reconstruction algorithms and numerical simulations for thermoacoustic tomography in various geometries.</article-title><source>IEEE Trans Biomed Eng</source><year>2003</year><volume>50</volume><issue>9</issue><fpage>1086</fpage><lpage>99</lpage><pub-id pub-id-type="pmid">12943276</pub-id></element-citation></ref><ref id="R34"><label>34</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Paltauf</surname><given-names>G</given-names></name><name><surname>Nuster</surname><given-names>R</given-names></name><name><surname>Haltmeier</surname><given-names>M</given-names></name><name><surname>Peter</surname><given-names>Burgholzer</given-names></name></person-group><article-title>Photoacoustic tomography using a Mach-Zehnder interferometer as an acoustic line detector.</article-title><source>Appl Opt</source><year>2007</year><volume>46</volume><issue>16</issue><fpage>3352</fpage><lpage>58</lpage><pub-id pub-id-type="pmid">17514293</pub-id></element-citation></ref><ref id="R35"><label>35</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>X</given-names></name><name><surname>Xu</surname><given-names>Y</given-names></name><name><surname>Xu</surname><given-names>M </given-names></name><etal/></person-group><article-title>Photoacoustic tomography of biological tissues with high cross-section resolution: Reconstruction and experiment.</article-title><source>Med Phys</source><year>2002</year><volume>29</volume><issue>12</issue><fpage>2799</fpage><lpage>2805</lpage><pub-id pub-id-type="pmid">12512713</pub-id></element-citation></ref><ref id="R36"><label>36</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gamelin</surname><given-names>J</given-names></name><name><surname>Aguirre</surname><given-names>A</given-names></name><name><surname>Maurudis</surname><given-names>A </given-names></name><etal/></person-group><article-title>Curved array photoacoustic tomo-graphic system for small animal imaging.</article-title><source>J Biomed Opt</source><year>2008</year><volume>13</volume><issue>2</issue><fpage>024007</fpage><pub-id pub-id-type="pmid">18465970</pub-id></element-citation></ref><ref id="R37"><label>37</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gamelin</surname><given-names>J</given-names></name><name><surname>Maurudis</surname><given-names>A</given-names></name><name><surname>Aguirre</surname><given-names>A </given-names></name><etal/></person-group><article-title>A real-time photoacoustic tomography system for small animals.</article-title><source>pt Express</source><year>2009</year><volume>17</volume><issue>13</issue><fpage>10489</fpage><lpage>98</lpage></element-citation></ref><ref id="R38"><label>38</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nuster</surname><given-names>R</given-names></name><name><surname>Gratt</surname><given-names>S</given-names></name><name><surname>Passler</surname><given-names>K</given-names></name><name><surname>Meyer</surname><given-names>D</given-names></name><name><surname>Paltauf</surname><given-names>G</given-names></name></person-group><article-title>Photoacoustic section imaging using an elliptical acoustic mirror and optical detection.</article-title><source>J Biomed Opt</source><year>2012</year><volume>17</volume><issue>3</issue><fpage>030503</fpage><pub-id pub-id-type="pmid">22502554</pub-id></element-citation></ref><ref id="R39"><label>39</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>E</given-names></name><name><surname>Laufer</surname><given-names>J</given-names></name><name><surname>Beard</surname><given-names>P</given-names></name></person-group><article-title>Backward-mode multiwavelength photoacoustic scanner using a planar Fabry-Perot polymer film ultrasound sensor for high-resolution three-dimensional imaging of biological tissues.</article-title><source>Appl Opt</source><year>2008</year><volume>47</volume><issue>4</issue><fpage>561</fpage><lpage>77</lpage><pub-id pub-id-type="pmid">18239717</pub-id></element-citation></ref><ref id="R40"><label>40</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xu</surname><given-names>Y</given-names></name><name><surname>Feng</surname><given-names>D</given-names></name><name><surname>Wang</surname><given-names>LV</given-names></name></person-group><article-title>Exact frequency-domain reconstruction for thermoacoustic tomography.I. Planar geometry.</article-title><source> IEEE Trans Med Imaging</source><year>2002</year><volume>21</volume><issue>7</issue><fpage>823</fpage><lpage>28</lpage><pub-id pub-id-type="pmid">12374319</pub-id></element-citation></ref><ref id="R41"><label>41</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bu</surname><given-names>S</given-names></name><name><surname>Liu</surname><given-names>Z</given-names></name><name><surname>Shiina</surname><given-names>T </given-names></name><etal/></person-group><article-title>Model-based reconstruction integrated with fluence compensation for photoacoustic tomography.</article-title><source>IEEE Trans Biomed Eng</source><year>2012</year><volume>59</volume><issue>5</issue><fpage>1354</fpage><lpage>63</lpage><pub-id pub-id-type="pmid">22345521</pub-id></element-citation></ref><ref id="R42"><label>42</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maslov</surname><given-names>K</given-names></name><name><surname>Stoica</surname><given-names>G</given-names></name><name><surname>Wang</surname><given-names>LV</given-names></name></person-group><article-title>In vivo dark-field reflection-mode photoacoustic microscopy.</article-title><source>Opt Lett</source><year>2005</year><volume>30</volume><issue>6</issue><fpage>625</fpage><lpage>27</lpage><pub-id pub-id-type="pmid">15791997</pub-id></element-citation></ref><ref id="R43"><label>43</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>ML</given-names></name><name><surname>Zhang</surname><given-names>HE</given-names></name><name><surname>Maslov</surname><given-names>K</given-names></name><name><surname>Stoica</surname><given-names>G</given-names></name><name><surname>Wang</surname><given-names>L V</given-names></name></person-group><article-title>Improved in vivo photoacoustic microscopy based on a virtual-detector concept.</article-title><source>Optics Letters</source><year>2006</year><volume>31 pp</volume><fpage>474</fpage><lpage>176</lpage><pub-id pub-id-type="pmid">16496891</pub-id></element-citation></ref><ref id="R44"><label>44</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lao</surname><given-names>Y</given-names></name><name><surname>Xing</surname><given-names>D</given-names></name><name><surname>Yang</surname><given-names>S</given-names></name><name><surname>Xiang</surname><given-names>L</given-names></name></person-group><article-title>Noninvasive photoacoustic imaging of the developing vasculature during early tumor growth.</article-title><source>Phys Med Biol</source><year>2008</year><volume>53</volume><issue>15</issue><fpage>4203</fpage><lpage>12</lpage><pub-id pub-id-type="pmid">18635896</pub-id></element-citation></ref><ref id="R45"><label>45</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kim</surname><given-names>C</given-names></name><name><surname>Erpelding</surname><given-names>TN</given-names></name><name><surname>Jankovic</surname><given-names>L</given-names></name><name><surname>Pashley</surname><given-names>MD</given-names></name><name><surname>Wang</surname><given-names>LV</given-names></name></person-group><article-title>Deeply penetrating in vivo photoacoustic imaging using a clinical ultrasound array system.</article-title><source>Biomed Opt Express</source><year>2010</year><volume>1</volume><issue>1</issue><fpage>278</fpage><lpage>84</lpage><pub-id pub-id-type="pmid">21258465</pub-id></element-citation></ref><ref id="R46"><label>46</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Taruttis</surname><given-names>A</given-names></name><name><surname>Morscher</surname><given-names>S</given-names></name><name><surname>Burton</surname><given-names>NC</given-names></name><name><surname>Razansky</surname><given-names>D</given-names></name><name><surname>Ntziachristos</surname><given-names>V</given-names></name></person-group><article-title>Fast multispectral optoacoustic tomography (MSOT for dynamic imaging of pharmacokinetics and biodistribution in multiple organs.</article-title><source>PLoS ONE</source><year>2012</year><volume>7</volume><fpage>e30491</fpage><pub-id pub-id-type="pmid">22295087</pub-id></element-citation></ref><ref id="R47"><label>47</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Beard</surname><given-names>PC</given-names></name><name><surname>Hurrell</surname><given-names>A</given-names></name><name><surname>Mills</surname><given-names>TN</given-names></name></person-group><article-title>Characterisation of a polymer film optical fibre hydrophone for the measurement of ultrasound fields for use in the range 1-30MHz: a comparison with PVDF needle and membrane hydrophones.</article-title><source>IEEE Trans Ultrason Ferroelectr Freq Control</source><year>2000</year><volume>47 </volume><issue>1</issue><fpage>2482</fpage><lpage>91</lpage></element-citation></ref><ref id="R48"><label>48</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>SL</given-names></name><name><surname>Huang</surname><given-names>SW</given-names></name><name><surname>Ling</surname><given-names>W</given-names></name><name><surname>Ashkenazi</surname><given-names>S</given-names></name><name><surname>Guo</surname><given-names>LJ</given-names></name></person-group><article-title>Polymer microring resonators for high-sensitivity and wideband photoacoustic imaging.</article-title><source>IEEE Trans Ultrason Ferroelectr Freq Control</source><year>2009</year><volume>56</volume><issue>11</issue><fpage>2482</fpage><lpage>2491</lpage><pub-id pub-id-type="pmid">19942534</pub-id></element-citation></ref><ref id="R49"><label>49</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rosenthal</surname><given-names>A</given-names></name><name><surname>Razansky</surname><given-names>D</given-names></name><name><surname>Ntziachristos</surname><given-names>V</given-names></name></person-group><article-title>High-sensitivity compact ultrasonic detector based on a pi-phase-shifted fiber Bragg grating.</article-title><source>Opt Lett</source><year>2011</year><volume>36</volume><issue>10</issue><fpage>1833</fpage><lpage>35</lpage><pub-id pub-id-type="pmid">21593906</pub-id></element-citation></ref><ref id="R50"><label>50</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rosenthal</surname><given-names>A</given-names></name><name><surname>Razansky</surname><given-names>D</given-names></name><name><surname>Ntziachristos</surname><given-names>V</given-names></name></person-group><article-title>Wideband optical sensing using pulse interferometry.</article-title><source>Opt Express</source><year>2012</year><volume>20</volume><issue>17</issue><fpage>19016</fpage><lpage>29</lpage><pub-id pub-id-type="pmid">23038542</pub-id></element-citation></ref><ref id="R51"><label>51</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Razansky</surname><given-names>D</given-names></name><name><surname>Vinegoni</surname><given-names>C</given-names></name><name><surname>Ntziachristos</surname><given-names>V</given-names></name></person-group><article-title>Multispectral photoacoustic imaging of fluorochromes in small animals.</article-title><source>Opt Lett</source><year>2007</year><volume>32</volume><issue>9</issue><fpage>2891</fpage><lpage>93</lpage><pub-id pub-id-type="pmid">17909608</pub-id></element-citation></ref><ref id="R52"><label>52</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Laufer</surname><given-names>J</given-names></name><name><surname>Delpy</surname><given-names>D</given-names></name><name><surname>Elwell</surname><given-names>C</given-names></name><name><surname>Beard</surname><given-names>P</given-names></name></person-group><article-title>Quantitative spatially resolved measurement of tissue chromophore concentrations using photoacoustic spectroscopy: application to the measurement of blood oxygenation and haemoglobin concentration.</article-title><source>Phys Med Biol</source><year>2007</year><volume>52</volume><issue>1</issue><fpage>141</fpage><lpage>68</lpage><pub-id pub-id-type="pmid">17183133</pub-id></element-citation></ref><ref id="R53"><label>53</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cox</surname><given-names>BT</given-names></name><name><surname>Arridge</surname><given-names>SR</given-names></name><name><surname>Beard</surname><given-names>PC</given-names></name></person-group><article-title>Estimating chromophore distributions from multiwavelength photoacoustic images.</article-title><source>J Opt Soc Am</source><year>2009</year><volume>26</volume><issue>2</issue><fpage>443</fpage><lpage>55</lpage></element-citation></ref><ref id="R54"><label>54</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Glatz</surname><given-names>J</given-names></name><name><surname>Deliolanis</surname><given-names>NC</given-names></name><name><surname>Buehler</surname><given-names>A</given-names></name><name><surname>Razansky</surname><given-names>D</given-names></name><name><surname>Ntziachristos</surname><given-names>V</given-names></name></person-group><article-title>Blind source unmixing in multi-spectral optoacoustic tomography.</article-title><source>Opt Express</source><year>2011</year><volume>19</volume><issue>4</issue><fpage>3175</fpage><lpage>84</lpage><pub-id pub-id-type="pmid">21369139</pub-id></element-citation></ref><ref id="R55"><label>55</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cox</surname><given-names>B</given-names></name><name><surname>Laufer</surname><given-names>JP</given-names></name><name><surname>Arridge</surname><given-names>SR</given-names></name><name><surname>Beard</surname><given-names>PC</given-names></name></person-group><article-title>Quantitative spectroscopic photoacoustic imaging: a review.</article-title><source>J Biomed Opt</source><year>2012</year><volume>17</volume><issue>6</issue><fpage>061202</fpage><pub-id pub-id-type="pmid">22734732</pub-id></element-citation></ref><ref id="R56"><label>56</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Razansky</surname><given-names>D</given-names></name></person-group><article-title>Multi-Spectral Optoacoustic Tomography - Volumetric Color Hearing in Real Time.</article-title><source>IEEE J Sel Topics Quantum Electron.</source><year>2012</year><volume>18</volume><issue>3</issue><fpage>1234</fpage><lpage>43</lpage></element-citation></ref><ref id="R57"><label>57</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ntziachristos</surname><given-names>V</given-names></name><name><surname>Razansky</surname><given-names>D</given-names></name></person-group><article-title>Molecular imaging by means of multispectral opto-acoustic tomography (MSOT).</article-title><source>Chem Rev</source><year>2010</year><volume>110</volume><issue>5</issue><fpage>2783</fpage><lpage>2794</lpage><pub-id pub-id-type="pmid">20387910</pub-id></element-citation></ref><ref id="R58"><label>58</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yao</surname><given-names>J</given-names></name><name><surname>Wang</surname><given-names>LV</given-names></name></person-group><article-title>Photoacoustic tomography: fundamentals. advances and prospects.</article-title><source> Contrast Media Mol Imaging</source><year>2011</year><volume>6</volume><issue>5</issue><fpage>332</fpage><lpage>45</lpage><pub-id pub-id-type="pmid">22025335</pub-id></element-citation></ref><ref id="R59"><label>59</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>LV</given-names></name><name><surname>Hu</surname><given-names>S</given-names></name></person-group><article-title>Photoacoustic tomography: In vivo imaging from organelles to organs.</article-title><source>Science</source><year>2012</year><volume>335</volume><fpage>1458</fpage><lpage>62</lpage><pub-id pub-id-type="pmid">22442475</pub-id></element-citation></ref><ref id="R60"><label>60</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ntziachristos</surname><given-names>V</given-names></name></person-group><article-title>Going deeper than microscopy: the optical imaging frontier in biology.</article-title><source>Nature Methods</source><year>2010</year><volume>7</volume><issue>8</issue><fpage>603</fpage><lpage>614</lpage><pub-id pub-id-type="pmid">20676081</pub-id></element-citation></ref><ref id="R61"><label>61</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xu</surname><given-names>M</given-names></name><name><surname>Wang</surname><given-names>LV</given-names></name></person-group><article-title>Photoacoustic imaging in biomedicine.</article-title><source>Rev Sci Instrum</source><year>2006</year><volume>77</volume><issue>4</issue><fpage>04110</fpage></element-citation></ref><ref id="R62"><label>62</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Blackstock</surname><given-names>DT</given-names></name></person-group><article-title>Fundementals of physical acoustics.</article-title><source>New York: D T John Wiley &#x00026; Sons</source><year>2000</year></element-citation></ref><ref id="R63"><label>63</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cox</surname><given-names>BT</given-names></name><name><surname>Beard</surname><given-names>PC</given-names></name></person-group><article-title>Fast calculation of pulsed photoacoustic fields using k-space methods.</article-title><source>J Acoust Soc Am</source><year>2005</year><volume>127</volume><issue>5</issue><fpage>2825</fpage><lpage>35</lpage></element-citation></ref><ref id="R64"><label>64</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burgholzer</surname><given-names>P</given-names></name><name><surname>Bauer-Marschallinger</surname><given-names>J</given-names></name><name><surname>Gr&#x000fc;n</surname><given-names>H</given-names></name><name><surname>Haltmeier</surname><given-names>M</given-names></name><name><surname>Paltauf</surname><given-names>G</given-names></name></person-group><article-title>Temporal back-projection algorithms for photoacoustic tomography with integrating line detectors.</article-title><source>Inverse Problems</source><year>2007</year><volume>23</volume><issue>6</issue><fpage>S65</fpage><lpage>S80</lpage></element-citation></ref><ref id="R65"><label>65</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haltmeier</surname><given-names>M</given-names></name><name><surname>Zangerl</surname><given-names>G</given-names></name></person-group><article-title>Spatial resolution in photoacoustic tomography: effects of detector size and detector bandwidth.</article-title><source>Inverse Problems</source><year>2010</year><volume>26</volume><issue>12</issue><fpage>125002</fpage></element-citation></ref><ref id="R66"><label>66</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rosenthal</surname><given-names>A</given-names></name><name><surname>Caballero</surname><given-names>M A</given-names></name><name><surname>Kellnberger</surname><given-names>S</given-names></name><name><surname>Razansky</surname><given-names>D</given-names></name><name><surname>Ntziachristos</surname><given-names>V</given-names></name></person-group><article-title>Spatial characterization of the response of a silica optical fiber to wideband ultrasound.</article-title><source>Opt Lett</source><year>2012</year><volume>37</volume><issue>15</issue><fpage>3174</fpage><lpage>76</lpage><pub-id pub-id-type="pmid">22859123</pub-id></element-citation></ref><ref id="R67"><label>67</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hunt</surname><given-names>J</given-names></name><name><surname>Arditi</surname><given-names>M</given-names></name><name><surname>Foster</surname><given-names>FS</given-names></name></person-group><article-title>Ultrasound transducers for pulse-echo medical imaging.</article-title><source>IEEE Trans Biomed Eng</source><year>1983</year><volume>30</volume><issue>8</issue><fpage>453</fpage><lpage>81</lpage><pub-id pub-id-type="pmid">6629380</pub-id></element-citation></ref><ref id="R68"><label>68</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baek</surname><given-names>D</given-names></name><name><surname>Jensen</surname><given-names>JA</given-names></name><name><surname>Willatzen</surname><given-names>M</given-names></name></person-group><article-title>Modeling transducer impulse responses for predicting calibrated pressure pulses with the ultrasound simulation program Field II.</article-title><source>J Acoust Soc Am</source><year>2010</year><volume>127</volume><issue>5</issue><fpage>2825</fpage><lpage>35</lpage><pub-id pub-id-type="pmid">21117733</pub-id></element-citation></ref><ref id="R69"><label>69</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Beard</surname><given-names>PC</given-names></name><name><surname>Perennes</surname><given-names>F</given-names></name><name><surname>Mills</surname><given-names>TN</given-names></name></person-group><article-title>Transduction mechanisms of the Fabry-Perot polymer film sensing concept for wideband ultrasound detection.</article-title><source>IEEE Trans Ultrason Ferroelectr Freq Control</source><year>1999</year><volume>46</volume><issue>6</issue><fpage>1575</fpage><lpage>1582</lpage><pub-id pub-id-type="pmid">18244356</pub-id></element-citation></ref><ref id="R70"><label>70</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rosenthal</surname><given-names>A</given-names></name><name><surname>Ntziachristos</surname><given-names>V</given-names></name><name><surname>Razansky</surname><given-names>D</given-names></name></person-group><article-title>Optoacoustic methods for frequency calibration of ultrasonic sensors.</article-title><source>IEEE Trans Ultrason Ferroelectr Freq Control</source><year>2011</year><volume>58</volume><issue>2</issue><fpage>316</fpage><lpage>26</lpage><pub-id pub-id-type="pmid">21342817</pub-id></element-citation></ref><ref id="R71"><label>71</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Berer</surname><given-names>T</given-names></name><name><surname>Veres</surname><given-names>IA</given-names></name><name><surname>Gr&#x000fc;n</surname><given-names>H</given-names></name><name><surname>Bauer-Marschallinger</surname><given-names>J</given-names></name><name><surname>Felbermayer</surname><given-names>K</given-names></name><name><surname>Burgholzer</surname><given-names>P</given-names></name></person-group><article-title>Characterization of broadband fiber optic line detectors for photoacoustic tomography.</article-title><source>J Biophotonics</source><year>2012</year><volume>5</volume><issue>7</issue><fpage>518</fpage><lpage>528</lpage><pub-id pub-id-type="pmid">22371304</pub-id></element-citation></ref><ref id="R72"><label>72</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Passler</surname><given-names>K</given-names></name><name><surname>Nuster</surname><given-names>R</given-names></name><name><surname>Gratt</surname><given-names>S</given-names></name><name><surname>Burgholzer</surname><given-names>P</given-names></name><name><surname>Berer</surname><given-names>T</given-names></name><name><surname>Paltauf</surname><given-names>G</given-names></name></person-group><article-title>Scanning acoustic-photoacoustic microscopy using axicon transducers.</article-title><source>Biomed Opt Express</source><year>2010</year><volume>1</volume><issue>1</issue><fpage>318</fpage><lpage>323</lpage><pub-id pub-id-type="pmid">21258469</pub-id></element-citation></ref><ref id="R73"><label>73</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pramanik</surname><given-names>M</given-names></name><name><surname>Ku</surname><given-names>G</given-names></name><name><surname>Wang</surname><given-names>LV</given-names></name></person-group><article-title>Tangential resolution improvement in thermoacoustic and photoacoustic tomography using a negative acoustic lens.</article-title><source>J Biomed Opt</source><year>2009</year><volume>14</volume><issue>2</issue><fpage>024028</fpage><pub-id pub-id-type="pmid">19405757</pub-id></element-citation></ref><ref id="R74"><label>74</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rosenthal</surname><given-names>A</given-names></name><name><surname>Razansky</surname><given-names>D</given-names></name><name><surname>Ntziachristos</surname><given-names>V</given-names></name></person-group><article-title>Model-based optoacoustic inversion with arbitrary-shape detectors.</article-title><source>Medical Physics</source><year>2011</year><volume>38</volume><issue>7</issue><fpage>4285</fpage><lpage>95</lpage><pub-id pub-id-type="pmid">21859030</pub-id></element-citation></ref><ref id="R75"><label>75</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yuan</surname><given-names>Y</given-names></name><name><surname>Yang</surname><given-names>S</given-names></name><name><surname>Xing</surname><given-names>D</given-names></name></person-group><article-title>Preclinical photoacoustic imaging endoscope based on acousto-optic coaxial system using ring transducer array.</article-title><source>Opt Lett</source><year>2010</year><volume>35</volume><issue>13</issue><fpage>2266</fpage><lpage>68</lpage><pub-id pub-id-type="pmid">20596215</pub-id></element-citation></ref><ref id="R76"><label>76</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burgholzer</surname><given-names>P</given-names></name><name><surname>Hofer</surname><given-names>C</given-names></name><name><surname>Paltauf</surname><given-names>G</given-names></name><name><surname>Haltmeier</surname><given-names>M</given-names></name><name><surname>Scherzer</surname><given-names>O</given-names></name></person-group><article-title>Thermoacoustic tomography with integrating area and line detectors.</article-title><source>IEEE Trans Ultrason Ferroelectr Freq Control</source><year>2005</year><volume>52</volume><issue>9</issue><fpage>1577</fpage><lpage>83</lpage><pub-id pub-id-type="pmid">16285456</pub-id></element-citation></ref><ref id="R77"><label>77</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ephrat</surname><given-names>P</given-names></name><name><surname>Roumeliotis</surname><given-names>M</given-names></name><name><surname>Prato</surname><given-names>FS</given-names></name><name><surname>Carson</surname><given-names>JJ</given-names></name></person-group><article-title>Four-dimensional photoacoustic imaging of moving targets.</article-title><source>Opt Express</source><year>2008</year><volume>16</volume><issue>26</issue><fpage>21570</fpage><lpage>81</lpage><pub-id pub-id-type="pmid">19104588</pub-id></element-citation></ref><ref id="R78"><label>78</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xu</surname><given-names>Y</given-names></name><name><surname>Wang</surname><given-names>LV</given-names></name></person-group><article-title>Time Reversal and Its Application to Tomography with Diffracting Sources.</article-title><source>Phys Rev Lett</source><year>2004</year><volume>92</volume><issue>3</issue><fpage>033902</fpage><pub-id pub-id-type="pmid">14753876</pub-id></element-citation></ref><ref id="R79"><label>79</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Finch</surname><given-names>D</given-names></name><name><surname>Patch</surname><given-names>SK</given-names></name></person-group><article-title>Determining a function from its mean values over a family of spheres related data.</article-title><source>SIAM J Math Anal</source><year>2004</year><volume>35</volume><issue>5</issue><fpage>1213</fpage><lpage>40</lpage></element-citation></ref><ref id="R80"><label>80</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Agranovsky</surname><given-names>M</given-names></name><name><surname>Kuchment</surname><given-names>P</given-names></name></person-group><article-title>Uniqueness of reconstruction and an inversion procedure for thermoacoustic and photoacoustic tomography with variable sound speed.</article-title><source>Inverse Problems</source><year>2007</year><volume>23</volume><issue>5</issue><fpage>2089</fpage><lpage>2102</lpage></element-citation></ref><ref id="R81"><label>81</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burgholzer</surname><given-names>P</given-names></name><name><surname>Matt</surname><given-names>GJ</given-names></name><name><surname>Haltmeier</surname><given-names>M</given-names></name><name><surname>Paltauf</surname><given-names>G</given-names></name></person-group><article-title>Exact and approximative imaging methods for photoacoustic tomography using an arbitrary detection surface.</article-title><source>Phys Rev E</source><year>2007</year><volume>75</volume><issue>4</issue><fpage>046706</fpage></element-citation></ref><ref id="R82"><label>82</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xu</surname><given-names>M</given-names></name><name><surname>Wang</surname><given-names>LV</given-names></name></person-group><article-title>Universal back-projection algorithm for photoacoustic computed tomography.</article-title><source>Phys Rev E</source><year>2007</year><volume>71</volume><issue>1</issue><fpage>016706</fpage></element-citation></ref><ref id="R83"><label>83</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kruger</surname><given-names>RA</given-names></name><name><surname>Kiser</surname><given-names>WL</given-names></name><name><surname>Reinecke</surname><given-names>DR</given-names></name><name><surname>Kruger</surname><given-names>GA</given-names></name></person-group><article-title>Thermoacoustic computed tomography using a conventional linear transducer array.</article-title><source>Med Phys</source><year>2003</year><volume>30</volume><issue>5</issue><fpage>856</fpage><lpage>60</lpage><pub-id pub-id-type="pmid">12772993</pub-id></element-citation></ref><ref id="R84"><label>84</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zemp</surname><given-names>RJ</given-names></name><name><surname>Bitton</surname><given-names>R</given-names></name><name><surname>Li</surname><given-names>ML</given-names></name><name><surname>Shung</surname><given-names>KK</given-names></name><name><surname>Stoica</surname><given-names>G</given-names></name><name><surname>Wang</surname><given-names>LV</given-names></name></person-group><article-title>Photoacoustic imaging of the microvasculature with a high-frequency ultrasound array transducer.</article-title><source>J Biomed Opt</source><year>2007</year><volume>12</volume><issue>1</issue><fpage>010501</fpage><pub-id pub-id-type="pmid">17343475</pub-id></element-citation></ref><ref id="R85"><label>85</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gateau</surname><given-names>J</given-names></name><name><surname>Caballero</surname><given-names>M A</given-names></name><name><surname>Dima</surname><given-names>A</given-names></name><name><surname>Ntziachristos</surname><given-names>V</given-names></name></person-group><article-title>Three-dimensional optoacoustic tomography using a conventional ultrasound linear detector array: Whole-body tomographic system for small animals.</article-title><source>Med Phys</source><year>2013</year><volume>40</volume><issue>1</issue><fpage>013302</fpage><pub-id pub-id-type="pmid">23298121</pub-id></element-citation></ref><ref id="R86"><label>86</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kruger</surname><given-names>RA</given-names></name><name><surname>Reinecke</surname><given-names>DR</given-names></name><name><surname>Kruger</surname><given-names>GA</given-names></name></person-group><article-title>Thermoacoustic computed tomography-technical considerations.</article-title><source>Med Phys</source><year>1999</year><volume>26</volume><issue>9</issue><fpage>1832</fpage><lpage>1837</lpage><pub-id pub-id-type="pmid">10505871</pub-id></element-citation></ref><ref id="R87"><label>87</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Norton</surname><given-names>S</given-names></name></person-group><article-title>Ultrasonic reflectivity imaging in three dimensions: Exact inverse scattering solutions for plane cylindrical and spherical apertures.</article-title><source>IEEE Trans Biomed Eng</source><year>1981</year><volume>28</volume><issue>2</issue><fpage>202</fpage><lpage>220</lpage><pub-id pub-id-type="pmid">7287023</pub-id></element-citation></ref><ref id="R88"><label>88</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barrett</surname><given-names>HH</given-names></name></person-group><article-title>The Radon transform and its applications.</article-title><source>Progress in Optics</source><year>1984</year><volume>21</volume><fpage>17</fpage><lpage>86</lpage></element-citation></ref><ref id="R89"><label>89</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hoelen</surname><given-names>CGA</given-names></name><name><surname>de Mul</surname><given-names>FFM</given-names></name></person-group><article-title>Image reconstruction for photoacoustic scanning of tissue structures.</article-title><source>Appl Opt</source><year>2000</year><volume>39</volume><issue>31</issue><fpage>5872</fpage><lpage>83</lpage><pub-id pub-id-type="pmid">18354591</pub-id></element-citation></ref><ref id="R90"><label>90</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Feng</surname><given-names>D</given-names></name><name><surname>Xu</surname><given-names>Y</given-names></name><name><surname>Ku</surname><given-names>G</given-names></name><name><surname>Wang</surname><given-names>LV</given-names></name></person-group><article-title>Microwave-induced thermoacoustic tomography: Reconstruction by synthetic aperture.</article-title><source>Med Phys</source><year>2001</year><volume>28</volume><issue>12</issue><fpage>2427</fpage><lpage>2431</lpage><pub-id pub-id-type="pmid">11797945</pub-id></element-citation></ref><ref id="R91"><label>91</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ozbek</surname><given-names>A</given-names></name><name><surname>D&#x000e9;an-Ben</surname><given-names>XL</given-names></name><name><surname>Razansky</surname><given-names>D</given-names></name></person-group><article-title>A GPU implementation of parallel back-projection reconstruction for three-dimensional handheld optoacoustic imaging devices In: European Conferences on Biomedical Optics May 12-16.</article-title><source>Messe Munchen Munich Germany</source><year>2013</year></element-citation></ref><ref id="R92"><label>92</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>K</given-names></name><name><surname>Huang</surname><given-names>C</given-names></name><name><surname>Kao</surname><given-names>YJ</given-names></name><name><surname>Chou</surname><given-names>CY</given-names></name><name><surname>Oraevsky</surname><given-names>AA</given-names></name><name><surname>Anastasio</surname><given-names>MA</given-names></name></person-group><article-title>Accelerating image reconstruction in three-dimensional optoacoustic tomography on graphics processing units.</article-title><source>Med Phys</source><year>2013</year><volume>40</volume><issue>3</issue><fpage>023301</fpage><pub-id pub-id-type="pmid">23387778</pub-id></element-citation></ref><ref id="R93"><label>93</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Filbir</surname><given-names>F</given-names></name><name><surname>Hielschera</surname><given-names>R</given-names></name><name><surname>Madych</surname><given-names>WR</given-names></name></person-group><article-title>Reconstruction from circular and spherical mean data.</article-title><source>Appl. Comput. Harmon. Anal</source><year>2010</year><volume>29</volume><issue>1</issue><fpage>111</fpage><lpage>20</lpage></element-citation></ref><ref id="R94"><label>94</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Paltauf</surname><given-names>G</given-names></name><name><surname>Nuster</surname><given-names>R</given-names></name><name><surname>Burgholzer</surname><given-names>P</given-names></name></person-group><article-title>Weight factors for limited angle photoacoustic tomography.</article-title><source>Phys Med Biol</source><year>2009</year><volume>54</volume><issue>11</issue><fpage>3303</fpage><lpage>14</lpage><pub-id pub-id-type="pmid">19430108</pub-id></element-citation></ref><ref id="R95"><label>95</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dean-Ben</surname><given-names>XL</given-names></name><name><surname>Ntziachristos</surname><given-names>V</given-names></name><name><surname>Razansky</surname><given-names>D</given-names></name></person-group><article-title>Statistical optoacoustic image reconstruction using a-priori knowledge on the location of acoustic distortions.</article-title><source>Appl Phys Lett</source><year>2011</year><volume>98</volume><issue>11</issue><fpage>171110</fpage></element-citation></ref><ref id="R96"><label>96</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dean-Ben</surname><given-names>XL</given-names></name><name><surname>Ntziachristos</surname><given-names>V</given-names></name><name><surname>Razansky</surname><given-names>D</given-names></name></person-group><article-title>Artefact reduction in optoacoustic tomographic imaging by estimating the distribution of acoustic scatterers.</article-title><source>J Biomed Opt</source><year>2012</year><volume>17</volume><issue>11</issue><fpage>110504</fpage><pub-id pub-id-type="pmid">23096956</pub-id></element-citation></ref><ref id="R97"><label>97</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kostli</surname><given-names>KP</given-names></name><name><surname>Frenz</surname><given-names>M</given-names></name><name><surname>Bebie</surname><given-names>H</given-names></name><name><surname>Weber</surname><given-names>HP</given-names></name></person-group><article-title>Temporal backward projection of optoacoustic pressure transients using Fourier transform methods.</article-title><source>Phys Med Biol</source><year>2001</year><volume>46</volume><issue>7</issue><fpage>1863</fpage><lpage>72</lpage><pub-id pub-id-type="pmid">11474930</pub-id></element-citation></ref><ref id="R98"><label>98</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kunyansky</surname><given-names>LA</given-names></name></person-group><article-title>Fast reconstruction algorithms for the thermoacoustic tomography in certain domains with cylindrical or spherical symmetries.</article-title><source>Inverse Prob Imag</source><year>2012</year><volume>6</volume><issue>1</issue><fpage>111</fpage><lpage>31</lpage></element-citation></ref><ref id="R99"><label>99</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>K</given-names></name><name><surname>Anastasio</surname><given-names>MA</given-names></name></person-group><article-title>A simple Fourier transform-based reconstruction formula for photoacoustic computed tomography with a circular or spherical measurement geometry.</article-title><source>Phys Med Biol</source><year>2012</year><volume>57</volume><issue>23</issue><fpage>N493</fpage><lpage>N499</lpage><pub-id pub-id-type="pmid">23165199</pub-id></element-citation></ref><ref id="R100"><label>100</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Treeby</surname><given-names>BE</given-names></name><name><surname>Cox</surname><given-names>BT</given-names></name></person-group><article-title>k-Wave: MATLAB toolbox for the simulation and reconstruction of photoacoustic wave fields.</article-title><source>J Biomed Opt</source><year>2010</year><volume>15</volume><issue>2</issue><fpage>021314</fpage><pub-id pub-id-type="pmid">20459236</pub-id></element-citation></ref><ref id="R101"><label>101</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jaeger</surname><given-names>M</given-names></name><name><surname>Sch&#x000fc;pbach</surname><given-names>S</given-names></name><name><surname>Gertsch</surname><given-names>A</given-names></name><name><surname>Kitz</surname><given-names>M</given-names></name><name><surname>Frenz</surname><given-names>M</given-names></name></person-group><article-title>Fourier reconstruction in optoacoustic imaging using truncated regularized inverse k-space interpolation.</article-title><source>Inverse Problems</source><year>2007</year><volume>23</volume><issue>6</issue><fpage>S51</fpage><lpage>S63</lpage></element-citation></ref><ref id="R102"><label>102</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>L&#x000e9;vesque</surname><given-names>D</given-names></name><name><surname>Blouin</surname><given-names>A</given-names></name><name><surname>N&#x000e9;ron</surname><given-names>C</given-names></name><name><surname>Monchalin</surname><given-names>JP</given-names></name></person-group><article-title>Performance of laser-ultrasonic F-SAFT imaging.</article-title><source>Ultrasonics</source><year>2002</year><volume>40</volume><issue>10</issue><fpage>1057</fpage><lpage>1063</lpage><pub-id pub-id-type="pmid">12441182</pub-id></element-citation></ref><ref id="R103"><label>103</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burgholzer</surname><given-names>P</given-names></name><name><surname>Berer</surname><given-names>T</given-names></name><name><surname>Gr&#x000fc;n</surname><given-names>H </given-names></name><etal/></person-group><article-title>Photoacoustic tomography using integrating line detectors.</article-title><source>J. Phys.: Conf. Ser.</source><year>2010</year><volume>214</volume><issue>1</issue><fpage>012009</fpage></element-citation></ref><ref id="R104"><label>104</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Treeby</surname><given-names>BE</given-names></name><name><surname>Zhang</surname><given-names>EZ</given-names></name><name><surname>Cox</surname><given-names>BT</given-names></name></person-group><article-title>Photoacoustic tomography in absorbing acoustic media using time reversal.</article-title><source>Inverse Problems</source><year>2010</year><volume>26</volume><issue>11</issue><fpage>115003</fpage></element-citation></ref><ref id="R105"><label>105</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cox</surname><given-names>BT</given-names></name><name><surname>Treeby</surname><given-names>BE</given-names></name></person-group><article-title>Artifact trapping during time reversal photoacoustic imaging for acoustically heterogeneous media.</article-title><source>IEEE Trans Med Imaging</source><year>2010</year><volume>29</volume><issue>2</issue><fpage>387</fpage><lpage>396</lpage><pub-id pub-id-type="pmid">19887310</pub-id></element-citation></ref><ref id="R106"><label>106</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hristova</surname><given-names>Y</given-names></name><name><surname>Kuchment</surname><given-names>P</given-names></name><name><surname>Nguyen</surname><given-names>L</given-names></name></person-group><article-title>Reconstruction and time reversal in thermoacoustic tomography in acoustically homogeneous and inhomogeneous media.</article-title><source>Inverse Problems</source><year>2008</year><volume>24</volume><issue>5</issue><fpage>055006</fpage></element-citation></ref><ref id="R107"><label>107</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Paltauf</surname><given-names>G</given-names></name><name><surname>Viator</surname><given-names>J A</given-names></name><name><surname>Prahl</surname><given-names>SA</given-names></name><name><surname>Jacques</surname><given-names>SL</given-names></name></person-group><article-title>Iterative reconstruction algorithm for optoacoustic imaging.</article-title><source>J Acoust Soc Am.</source><year>2002</year><volume>112</volume><issue>4</issue><fpage>1536</fpage><lpage>44</lpage><pub-id pub-id-type="pmid">12398460</pub-id></element-citation></ref><ref id="R108"><label>108</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Anastasio</surname><given-names>MA</given-names></name><name><surname>Zhang</surname><given-names>J</given-names></name><name><surname>Pan</surname><given-names>X</given-names></name><name><surname>Zou</surname><given-names>Y</given-names></name><name><surname>Ku</surname><given-names>G</given-names></name><name><surname>Wang</surname><given-names>LV</given-names></name></person-group><article-title>Half-Time Image Reconstruction in Thermoacoustic Tomography.</article-title><source>IEEE Trans Med Imaging</source><year>2005</year><volume>24</volume><issue>2</issue><fpage>199</fpage><lpage>210</lpage><pub-id pub-id-type="pmid">15707246</pub-id></element-citation></ref><ref id="R109"><label>109</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jose</surname><given-names>J</given-names></name><name><surname>Willemink</surname><given-names>RGH</given-names></name><name><surname>Steenbergen</surname><given-names>W</given-names></name><name><surname>Slump</surname><given-names>CH</given-names></name><name><surname>van Leeuwen</surname><given-names>TG</given-names></name><name><surname>Manohar</surname><given-names>S</given-names></name></person-group><article-title>Speed-of-sound compensated photoacoustic tomography for accurate imaging.</article-title><source>Med Phys</source><year>2012</year><volume>39</volume><issue>12</issue><fpage>7262</fpage><lpage>71</lpage><pub-id pub-id-type="pmid">23231277</pub-id></element-citation></ref><ref id="R110"><label>110</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huang</surname><given-names>C</given-names></name><name><surname>Wang</surname><given-names>K</given-names></name><name><surname>Nie</surname><given-names>L</given-names></name><name><surname>Wang</surname><given-names>LV</given-names></name><name><surname>Anastasio</surname><given-names>MA</given-names></name></person-group><article-title>Full-wave iterative image reconstruction in photoacoustic tomography with acoustically inhomogeneous media.</article-title><source>to be published in IEEE Trans Med Imaging</source></element-citation></ref><ref id="R111"><label>111</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rosenthal</surname><given-names>A</given-names></name><name><surname>Razansky</surname><given-names>D</given-names></name><name><surname>Ntziachristos</surname><given-names>V</given-names></name></person-group><article-title>Fast semi-analytical model-based acoustic inversion for quantitative optoacoustic tomography.</article-title><source>IEEE Trans Med Imaging</source><year>2010</year><volume>29</volume><issue>6</issue><fpage>1275</fpage><lpage>85</lpage><pub-id pub-id-type="pmid">20304725</pub-id></element-citation></ref><ref id="R112"><label>112</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dean-Ben</surname><given-names>XL</given-names></name><name><surname>Ntziachristos</surname><given-names>V</given-names></name><name><surname>Razansky</surname><given-names>D</given-names></name></person-group><article-title>Acceleration of optoacoustic model-based reconstruction using angular image discretization.</article-title><source>IEEE Trans Med Imaging</source><year>2012</year><volume>31</volume><issue>5</issue><fpage>1154</fpage><lpage>62</lpage><pub-id pub-id-type="pmid">22333989</pub-id></element-citation></ref><ref id="R113"><label>113</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dean-Ben</surname><given-names>XL</given-names></name><name><surname>Buehler</surname><given-names>A</given-names></name><name><surname>Ntziachristos</surname><given-names>V</given-names></name><name><surname>Razansky</surname><given-names>D</given-names></name></person-group><article-title>Accurate model-based reconstruction algorithm for three-dimensional optoacoustic tomography.</article-title><source>IEEE Trans Med Imaging</source><year>2012</year><volume>31</volume><issue>10</issue><fpage>1922</fpage><lpage>1928</lpage><pub-id pub-id-type="pmid">23033065</pub-id></element-citation></ref><ref id="R114"><label>114</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Caballero</surname><given-names>MAA</given-names></name><name><surname>Rosenthal</surname><given-names>AAA</given-names></name><name><surname>Buehler</surname><given-names>A</given-names></name><name><surname>Razansky</surname><given-names>D</given-names></name><name><surname>Ntziachristos</surname><given-names>D</given-names></name></person-group><article-title>Optoacoustic determination of spatio-temporal responses of ultrasound sensors.</article-title><source>Trans Ultrason Ferroelectr Freq Control</source><year>2013</year><volume>60</volume><issue>6</issue><fpage>1234</fpage><lpage>1244</lpage></element-citation></ref><ref id="R115"><label>115</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Provost</surname><given-names>J</given-names></name><name><surname>Lesage</surname><given-names>F</given-names></name></person-group><article-title>The application of compressed sensing for photo-acoustic tomography.</article-title><source>IEEE Trans Med Imaging</source><year>2009</year><volume>28</volume><issue>4</issue><fpage>585</fpage><lpage>94</lpage><pub-id pub-id-type="pmid">19272991</pub-id></element-citation></ref><ref id="R116"><label>116</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guo</surname><given-names>Z</given-names></name><name><surname>Li</surname><given-names>C</given-names></name><name><surname>Song</surname><given-names>L</given-names></name><name><surname>Wang</surname><given-names>LV</given-names></name></person-group><article-title>Compressed sensing in photoacoustic tomography in vivo.</article-title><source>J Biomed Opt</source><year>2010</year><volume>15</volume><issue>2</issue><fpage>021311</fpage><pub-id pub-id-type="pmid">20459233</pub-id></element-citation></ref><ref id="R117"><label>117</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buehler</surname><given-names>A</given-names></name><name><surname>Rosenthal</surname><given-names>A</given-names></name><name><surname>Jetzfellner</surname><given-names>T</given-names></name><name><surname>Dima</surname><given-names>A</given-names></name><name><surname>Razansky</surname><given-names>D</given-names></name><name><surname>Ntziachristos</surname><given-names>V</given-names></name></person-group><article-title>Model-based optoacoustic inversions with incomplete projection data.</article-title><source>Med Phys</source><year>2011</year><volume>38</volume><issue>3</issue><fpage>1694</fpage><lpage>1704</lpage><pub-id pub-id-type="pmid">21520882</pub-id></element-citation></ref><ref id="R118"><label>118</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>K</given-names></name><name><surname>Su</surname><given-names>R</given-names></name><name><surname>Oraevsky</surname><given-names>A</given-names></name><name><surname>Anastasio</surname><given-names>MA</given-names></name></person-group><article-title>Investigation of iterative image reconstruction in three-dimensional optoacoustic tomography.</article-title><source>Physics in Medicine and Biology</source><year>2012</year><volume>57</volume><issue>17</issue><fpage>5399</fpage><lpage>423</lpage><pub-id pub-id-type="pmid">22864062</pub-id></element-citation></ref><ref id="R119"><label>119</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mallat</surname><given-names>S</given-names></name></person-group><article-title>A Wavelet Tour of Signal Processing Third Edition: The Sparse Way.</article-title><source>Burlington: Academic press</source><year>2008</year></element-citation></ref><ref id="R120"><label>120</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rosenthal</surname><given-names>A</given-names></name><name><surname>Jetzfellner</surname><given-names>T</given-names></name><name><surname>Razansky</surname><given-names>D</given-names></name><name><surname>Ntziachristos</surname><given-names>V</given-names></name></person-group><article-title>Efficient framework for model-based tomographic image reconstruction using wavelet packets.</article-title><source>IEEE Trans Med Imaging</source><year>2012</year><volume>31</volume><issue>7</issue><fpage>1346</fpage><lpage>1357</lpage><pub-id pub-id-type="pmid">22345528</pub-id></element-citation></ref><ref id="R121"><label>121</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hsieh</surname><given-names>BY</given-names></name><name><surname>Chen</surname><given-names>SL</given-names></name><name><surname>Ling</surname><given-names>T</given-names></name><name><surname>Guo</surname><given-names>LJ</given-names></name><name><surname>Li</surname><given-names>PC</given-names></name></person-group><article-title>Integrated intravascular ultrasound and photoacoustic imaging scan head.</article-title><source>Opt Lett</source><year>2010</year><volume>35</volume><issue>17</issue><fpage>2892</fpage><lpage>94</lpage><pub-id pub-id-type="pmid">20808360</pub-id></element-citation></ref><ref id="R122"><label>122</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rosenthal</surname><given-names>A</given-names></name><name><surname>Razansky</surname><given-names>D</given-names></name><name><surname>Ntziachristos</surname><given-names>V</given-names></name></person-group><article-title>Quantitative optoacoustic signal extraction using sparse signal representation.</article-title><source>IEEE Trans Med Imaging</source><year>2009</year><volume>28</volume><issue>12</issue><fpage>1997</fpage><lpage>2006</lpage><pub-id pub-id-type="pmid">19628454</pub-id></element-citation></ref><ref id="R123"><label>123</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xu</surname><given-names>M</given-names></name><name><surname>Wang</surname><given-names>LV</given-names></name></person-group><article-title>Analytic explanation of spatial resolution related to bandwidth and detector aperture size in thermoacoustic or photoacoustic reconstruction.</article-title><source>Phys Rev E</source><year>2003</year><volume>67</volume><issue>5</issue><fpage>056605</fpage></element-citation></ref><ref id="R124"><label>124</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>ML</given-names></name><name><surname>Tseng</surname><given-names>YC</given-names></name><name><surname>Cheng</surname><given-names>CC</given-names></name></person-group><article-title>Model-based correction of finite aperture effect in photoacoustic tomography.</article-title><source>Opt Express</source><year>2010</year><volume>18</volume><issue>25</issue><fpage>26285</fpage><lpage>92</lpage><pub-id pub-id-type="pmid">21164977</pub-id></element-citation></ref><ref id="R125"><label>125</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burgholzer</surname><given-names>P</given-names></name><name><surname>Roitner</surname><given-names>H</given-names></name><name><surname>Berer</surname><given-names>T </given-names></name><etal/></person-group><article-title>Deconvolution algorithms for photoacoustic tomography to reduce blurring caused by finite sized detectors.</article-title><source>Proceedings of SPIE</source><year>2013</year><volume>8581</volume><fpage>858137</fpage></element-citation></ref><ref id="R126"><label>126</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xu</surname><given-names>Y</given-names></name><name><surname>Wang</surname><given-names>LV</given-names></name><name><surname>Ambartsoumian</surname><given-names>G</given-names></name><name><surname>Kuchment</surname><given-names>P</given-names></name></person-group><article-title>Reconstructions in limited-view thermoacoustic tomography.</article-title><source>Medical Physics</source><year>2004</year><volume>31</volume><issue>4</issue><fpage>724</fpage><lpage>34</lpage><pub-id pub-id-type="pmid">15124989</pub-id></element-citation></ref><ref id="R127"><label>127</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>ML</given-names></name><name><surname>Zhang</surname><given-names>HE</given-names></name><name><surname>Maslov</surname><given-names>K</given-names></name><name><surname>Stoica</surname><given-names>G</given-names></name><name><surname>Wang</surname><given-names>LV</given-names></name></person-group><article-title>Improved in vivo photoacoustic microscopy based on a virtual-detector concept.</article-title><source>Opt Lett</source><year>2006</year><volume>31</volume><issue>4</issue><fpage>474</fpage><lpage>76</lpage><pub-id pub-id-type="pmid">16496891</pub-id></element-citation></ref><ref id="R128"><label>128</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Paltauf</surname><given-names>G</given-names></name><name><surname>Nuster</surname><given-names>R</given-names></name></person-group><article-title>Iterative reconstruction method for photoacoustic section imaging with integrating cylindrical detectors.</article-title><source>Proceedings of SPIE</source><year>2013</year><volume>8581</volume><fpage>85814N</fpage></element-citation></ref><ref id="R129"><label>129</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Caballero</surname><given-names>MAA</given-names></name><name><surname>Rosenthal</surname><given-names>AAA</given-names></name><name><surname>Gateau</surname><given-names>J</given-names></name><name><surname>Razansky</surname><given-names>D</given-names></name><name><surname>Ntziachristos</surname><given-names>D</given-names></name></person-group><article-title>Model-based optoacoustic imaging using focused detector scanning.</article-title><source>Opt Lett</source><year>2012</year><volume>37</volume><issue>19</issue><fpage>4080</fpage><lpage>82</lpage><pub-id pub-id-type="pmid">23027285</pub-id></element-citation></ref></ref-list></back><floats-group><fig id="F1" position="float"><label>Fig. (1)</label><caption><p>A schematic 2D description of the 3 common detector types used in optoacoustic tomography: (a) point-like detector, whose aperture
is significantly smaller than any feature in the optoacoustic source; (b) line detector (either finite or infinite); and (c) focused detector. In
3D, most ultrasound detectors used in the field may be represented as a combination of these three options. The figure further illustrates the
different detection patterns characterizing these three geometries, where the solid curves represent positions for which the detector is sensitive
and the detection delay is constant. The case of point-like detectors is described by Eq. 4. For line detectors, if the detector is significantly
longer than the imaged object, it may be approximated by an infinite line, and the detection pattern is then described by Eq. 10. In the
case of focused detectors, the full-width-at-half-maximum (FWHM) and the depth of field are given by Eq. 12 and 13, respectively.
</p></caption><graphic xlink:href="CMIR-9-318_F1"/></fig><fig id="F2" position="float"><label>Fig. (2)</label><caption><p>The three most common detection surfaces used in optoacoustic tomography: (a) spherical, (b) cylindrical, and (c) planar. These
detection surfaces may be achieved experimentally by scanning either a single detector or a detector array over the surface. The arrows show
the directions in which a single detectors needs to be scanned. The detector types appropriate for each of these detection surfaces are listed in
(Table 1).
</p></caption><graphic xlink:href="CMIR-9-318_F2"/></fig><fig id="F3" position="float"><label>Fig. (3)</label><caption><p>A graphical 2D illustration of the process of backprojection,
discussed in Section 3.1. (a). A point source detected at
4 positions on a circular detection surface <mml:math id="beq141"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1...4</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math>
with the corresponding
distance from the source <mml:math id="beq142"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mi>&#x02113;</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1...4</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math>
. (b) The acoustic
signals measured by the 4 detectors with delays proportional to the
distances <mml:math id="beq143"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mi>&#x02113;</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1...4</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math>
. (c) Each of the signals is projected to an arc
(or spherical shell in 3D) with a radius equal to its original distance
<mml:math id="beq144"><mml:mrow><mml:msub><mml:mi>&#x02113;</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math>
. The only location where all the arcs intersect is the original
position of the source. Thus, the contributions of all the backprojected
signals can add up coherently only at the original position
of the point source. If the reconstruction formula is exact and the
number of back-projected signals is sufficiently large, the originating
point source will be recovered. In the case of approximate formulae,
the reconstructed source may be distorted, but will still be
well-localized owing to the geometrical properties of the backprojection
procedure.
</p></caption><graphic xlink:href="CMIR-9-318_F3"/></fig><fig id="F4" position="float"><label>Fig. (4)</label><caption><p>An illustration of the variables used in the back-projection
formulae of Eqs. 15 and 16. An arbitrary detection surface <italic>S</italic> encompasses
the optoacoustic source H (r). The vectors r and r<sub>s</sub>
represent positions in the optoacoustic source and detection surface,
respectively. n<sub>s</sub> (r<sub>s</sub>) is a unit vector orthogonal to the surface at the
position r<sub>s</sub>, respectively. <italic>dS</italic> is the infinitesimal surface element and
d&#x003a9;(r<sub>s</sub>) is the corresponding infinitesimal solid-angle element.
</p></caption><graphic xlink:href="CMIR-9-318_F4"/></fig><fig id="F5" position="float"><label>Fig. (5)</label><caption><p>The case of limited-view detection depicted in 2D. The socalled
detection region, described in Section 4.4, is marked in gray.
In this region, the optoacoustic source may be exactly reconstructed.
Outside the detection region, the only features which can
be exactly reconstructed are those whose spatial frequencies are in
the direction of the detection surface. In the case of sharp boundaries,
this requirement is equivalent to having the normal to the
boundary intersecting with the detection surface. Therefore, in this
example, the part of the source&#x02019;s boundary denoted by &#x0201c;1&#x0201d; may not
be accurately reconstructed, whereas the part denoted by &#x0201c;2&#x0201d; may.
</p></caption><graphic xlink:href="CMIR-9-318_F5"/></fig><fig id="F6" position="float"><label>Fig. (6)</label><caption><p>A 2D illustration of the effect of the limited-view scenario
on the characteristics of the reconstruction under the far-field approximation.
(a) The originating optoacoustic source and the corresponding
limited angular coverage of the detection curve (or surface
in 3D). (b) The image obtained by filtering out all spatial frequencies
that correspond to angles outside the detection coverage.
As noted in Ref. [126], limited-view detection leads to smearing of
boundaries whose normal vectors are in directions not covered by
the detection surface. Clearly objects which have no defined
boundaries are also distorted and smeared in the direction not covered
by the detection surface. As the figure shows, the smearing
effect is very similar for objects of different sizes. (c) The filtered
image after setting the negative values in the image to zero. The
~50% reduction in the amplitude of the objects with respect to the
originating image is due to the filtering out of half the spatial frequencies.
</p></caption><graphic xlink:href="CMIR-9-318_F6"/></fig><table-wrap id="T1" position="float"><label>Table 1.</label><caption><p>A Review of the Combinations of Detection Surfaces and Detector Shapes Used in Optoacoustic Tomography. We Note
that the Distinction Between Point and Line Detectors is not Absolute and Depends on the Feature Sizes in the Imaged
Object and Possibly on the Detection Surface, as Discussed in Section 4.2.</p></caption><table frame="border" rules="all" width="100%"><thead><tr><th valign="middle" align="center" rowspan="1" colspan="1">&#x000a0;</th><th valign="middle" align="center" rowspan="1" colspan="1">Spherical</th><th valign="middle" align="center" rowspan="1" colspan="1">Cylindrical</th><th valign="middle" align="center" rowspan="1" colspan="1">Planar</th></tr></thead><tbody><tr><td valign="middle" align="center" rowspan="1" colspan="1">Point</td><td valign="middle" align="center" rowspan="1" colspan="1">[25], [26]</td><td valign="middle" align="center" rowspan="1" colspan="1">[32], [33]</td><td valign="middle" align="center" rowspan="1" colspan="1">[10], [39], [40] </td></tr><tr><td valign="middle" align="center" rowspan="1" colspan="1">Point-line</td><td valign="middle" align="center" rowspan="1" colspan="1">[27],[28] </td><td valign="middle" align="center" rowspan="1" colspan="1">[34]</td><td valign="middle" align="center" rowspan="1" colspan="1">&#x000a0;</td></tr><tr><td valign="middle" align="center" rowspan="1" colspan="1">Line-line (flat)</td><td valign="middle" align="center" rowspan="1" colspan="1">[29]-[31] </td><td valign="middle" align="center" rowspan="1" colspan="1">[35] </td><td valign="middle" align="center" rowspan="1" colspan="1">[41]</td></tr><tr><td valign="middle" align="center" rowspan="1" colspan="1">Cylindrically focused</td><td valign="middle" align="center" rowspan="1" colspan="1">&#x000a0;</td><td valign="middle" align="center" rowspan="1" colspan="1">[2], [7],[8], [36]-[38]</td><td valign="middle" align="center" rowspan="1" colspan="1">&#x000a0;</td></tr><tr><td valign="middle" align="center" rowspan="1" colspan="1">Spherically focused</td><td valign="middle" align="center" rowspan="1" colspan="1">&#x000a0;</td><td valign="middle" align="center" rowspan="1" colspan="1">&#x000a0;</td><td valign="middle" align="center" rowspan="1" colspan="1">[42], [43] </td></tr></tbody></table></table-wrap></floats-group></article>